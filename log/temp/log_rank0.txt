[2024-01-20 13:03:57 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:04:01 root] (main.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:04:42 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:04:46 root] (main.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:05:04 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:05:08 root] (main.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:05:34 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:05:38 root] (main.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:05:43 root] (main.py 373): INFO number of params: 304326632
[2024-01-20 13:05:44 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:12:05  flops: 42.2904 (42.2904)  loss: 1.2375 (1.2375)  acc1: 74.7475 (74.7475)  acc5: 90.9091 (90.9091)  time: 1.4507  data: 0.0009  max mem: 2168
[2024-01-20 13:05:47 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:56  flops: 42.2904 (42.2904)  loss: 1.1535 (1.1635)  acc1: 75.2577 (76.0971)  acc5: 91.6667 (91.1298)  time: 0.3595  data: 0.0002  max mem: 2170
[2024-01-20 13:05:49 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:24  flops: 42.2904 (42.2904)  loss: 1.0802 (1.0893)  acc1: 77.3196 (76.9193)  acc5: 91.7526 (91.6910)  time: 0.2425  data: 0.0001  max mem: 2179
[2024-01-20 13:05:51 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:10  flops: 42.2904 (42.2904)  loss: 1.0235 (1.0776)  acc1: 77.7778 (77.3907)  acc5: 92.9293 (91.8501)  time: 0.2314  data: 0.0001  max mem: 2179
[2024-01-20 13:05:54 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:01  flops: 42.2904 (42.2904)  loss: 1.0750 (1.0805)  acc1: 77.3196 (77.5043)  acc5: 91.9192 (91.8469)  time: 0.2278  data: 0.0001  max mem: 2179
[2024-01-20 13:05:56 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:01:55  flops: 42.2904 (42.2904)  loss: 1.1207 (1.0912)  acc1: 75.7576 (77.1000)  acc5: 92.0000 (91.9600)  time: 0.2272  data: 0.0001  max mem: 2179
[2024-01-20 13:05:58 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:01:51  flops: 42.2904 (42.2904)  loss: 1.1192 (1.0828)  acc1: 77.3196 (77.4307)  acc5: 92.9293 (92.0815)  time: 0.2280  data: 0.0001  max mem: 2179
[2024-01-20 13:06:01 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:01:47  flops: 42.2904 (42.2904)  loss: 1.0332 (1.0840)  acc1: 78.3505 (77.2740)  acc5: 92.0000 (92.0947)  time: 0.2290  data: 0.0001  max mem: 2179
[2024-01-20 13:06:03 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:01:43  flops: 42.2904 (42.2904)  loss: 1.0518 (1.0783)  acc1: 77.5510 (77.4088)  acc5: 92.0000 (92.2264)  time: 0.2286  data: 0.0001  max mem: 2179
[2024-01-20 13:06:05 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:01:40  flops: 42.2904 (42.2904)  loss: 1.0772 (1.0801)  acc1: 77.5510 (77.4779)  acc5: 92.8571 (92.2052)  time: 0.2284  data: 0.0001  max mem: 2179
[2024-01-20 13:06:07 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:01:37  flops: 42.2904 (42.2904)  loss: 1.0548 (1.0739)  acc1: 77.5510 (77.5222)  acc5: 92.9293 (92.2922)  time: 0.2291  data: 0.0001  max mem: 2179
[2024-01-20 13:06:10 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:01:34  flops: 42.2904 (42.2904)  loss: 1.0175 (1.0708)  acc1: 78.3505 (77.6493)  acc5: 92.0000 (92.3112)  time: 0.2303  data: 0.0001  max mem: 2179
[2024-01-20 13:06:12 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:01:31  flops: 42.2904 (42.2904)  loss: 1.0530 (1.0791)  acc1: 79.0000 (77.5263)  acc5: 92.0000 (92.2423)  time: 0.2308  data: 0.0001  max mem: 2179
[2024-01-20 13:06:14 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:01:28  flops: 42.2904 (42.2904)  loss: 1.0611 (1.0734)  acc1: 77.5510 (77.5161)  acc5: 92.9293 (92.2904)  time: 0.2305  data: 0.0001  max mem: 2179
[2024-01-20 13:06:17 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:01:26  flops: 42.2904 (42.2904)  loss: 1.0432 (1.0753)  acc1: 77.5510 (77.4995)  acc5: 92.9293 (92.2977)  time: 0.2306  data: 0.0001  max mem: 2179
[2024-01-20 13:06:19 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:01:23  flops: 42.2904 (42.2904)  loss: 1.0143 (1.0720)  acc1: 78.4946 (77.5823)  acc5: 92.8571 (92.3611)  time: 0.2332  data: 0.0001  max mem: 2179
[2024-01-20 13:06:21 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:01:21  flops: 42.2904 (42.2904)  loss: 1.0143 (1.0747)  acc1: 78.4946 (77.5367)  acc5: 92.8571 (92.2887)  time: 0.2314  data: 0.0001  max mem: 2179
[2024-01-20 13:06:24 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:01:18  flops: 42.2904 (42.2904)  loss: 1.0737 (1.0739)  acc1: 77.5510 (77.5885)  acc5: 91.6667 (92.2554)  time: 0.2314  data: 0.0001  max mem: 2179
[2024-01-20 13:06:26 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:01:16  flops: 42.2904 (42.2904)  loss: 1.0750 (1.0790)  acc1: 76.7677 (77.4600)  acc5: 90.9091 (92.1752)  time: 0.2317  data: 0.0001  max mem: 2179
[2024-01-20 13:06:28 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:01:13  flops: 42.2904 (42.2904)  loss: 1.0401 (1.0802)  acc1: 75.7576 (77.4489)  acc5: 91.8367 (92.1559)  time: 0.2294  data: 0.0001  max mem: 2179
[2024-01-20 13:06:30 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:01:11  flops: 42.2904 (42.2904)  loss: 1.0309 (1.0805)  acc1: 78.7879 (77.5396)  acc5: 91.9192 (92.0859)  time: 0.2302  data: 0.0001  max mem: 2179
[2024-01-20 13:06:33 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:01:08  flops: 42.2904 (42.2904)  loss: 1.1017 (1.0829)  acc1: 78.3505 (77.4844)  acc5: 90.9091 (92.0749)  time: 0.2294  data: 0.0001  max mem: 2179
[2024-01-20 13:06:35 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:01:06  flops: 42.2904 (42.2904)  loss: 1.0877 (1.0814)  acc1: 77.7778 (77.5126)  acc5: 91.9192 (92.0787)  time: 0.2294  data: 0.0001  max mem: 2179
[2024-01-20 13:06:37 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:01:03  flops: 42.2904 (42.2904)  loss: 1.0877 (1.0871)  acc1: 77.0000 (77.3977)  acc5: 91.8367 (92.0575)  time: 0.2301  data: 0.0001  max mem: 2179
[2024-01-20 13:06:40 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:01:01  flops: 42.2904 (42.2904)  loss: 1.2134 (1.0874)  acc1: 75.5319 (77.3736)  acc5: 91.0000 (92.0564)  time: 0.2298  data: 0.0001  max mem: 2179
[2024-01-20 13:06:42 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:58  flops: 42.2904 (42.2904)  loss: 1.0241 (1.0890)  acc1: 76.5306 (77.3004)  acc5: 91.0000 (92.0277)  time: 0.2293  data: 0.0001  max mem: 2179
[2024-01-20 13:06:44 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:56  flops: 42.2904 (42.2904)  loss: 1.0537 (1.0904)  acc1: 75.5102 (77.2809)  acc5: 90.8163 (91.9964)  time: 0.2291  data: 0.0001  max mem: 2179
[2024-01-20 13:06:47 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:54  flops: 42.2904 (42.2904)  loss: 1.2376 (1.0954)  acc1: 75.0000 (77.1749)  acc5: 90.8163 (91.9808)  time: 0.2296  data: 0.0001  max mem: 2179
[2024-01-20 13:06:49 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:51  flops: 42.2904 (42.2904)  loss: 1.2167 (1.0960)  acc1: 75.0000 (77.1795)  acc5: 92.7083 (91.9849)  time: 0.2307  data: 0.0001  max mem: 2179
[2024-01-20 13:06:51 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:49  flops: 42.2904 (42.2904)  loss: 1.0714 (1.0960)  acc1: 76.5306 (77.1822)  acc5: 92.7083 (91.9533)  time: 0.2311  data: 0.0001  max mem: 2179
[2024-01-20 13:06:54 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:46  flops: 42.2904 (42.2904)  loss: 1.0520 (1.0936)  acc1: 77.7778 (77.2592)  acc5: 90.9091 (91.9643)  time: 0.2310  data: 0.0001  max mem: 2179
[2024-01-20 13:06:56 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:44  flops: 42.2904 (42.2904)  loss: 1.0776 (1.0964)  acc1: 77.7778 (77.2265)  acc5: 90.9091 (91.9288)  time: 0.2310  data: 0.0001  max mem: 2179
[2024-01-20 13:06:58 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:42  flops: 42.2904 (42.2904)  loss: 1.1137 (1.0947)  acc1: 76.5306 (77.2453)  acc5: 91.8367 (91.9605)  time: 0.2304  data: 0.0001  max mem: 2179
[2024-01-20 13:07:00 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:39  flops: 42.2904 (42.2904)  loss: 1.0502 (1.0932)  acc1: 77.7778 (77.2783)  acc5: 91.8367 (91.9790)  time: 0.2289  data: 0.0001  max mem: 2179
[2024-01-20 13:07:03 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:37  flops: 42.2904 (42.2904)  loss: 1.0469 (1.0924)  acc1: 77.7778 (77.3010)  acc5: 91.7526 (91.9728)  time: 0.2295  data: 0.0001  max mem: 2179
[2024-01-20 13:07:05 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:35  flops: 42.2904 (42.2904)  loss: 1.0500 (1.0907)  acc1: 78.7879 (77.3335)  acc5: 92.8571 (92.0006)  time: 0.2305  data: 0.0001  max mem: 2179
[2024-01-20 13:07:07 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:32  flops: 42.2904 (42.2904)  loss: 1.0670 (1.0909)  acc1: 78.0000 (77.3474)  acc5: 92.9293 (91.9874)  time: 0.2300  data: 0.0001  max mem: 2179
[2024-01-20 13:07:10 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:30  flops: 42.2904 (42.2904)  loss: 1.0753 (1.0892)  acc1: 77.8947 (77.3669)  acc5: 90.9091 (91.9954)  time: 0.2307  data: 0.0001  max mem: 2179
[2024-01-20 13:07:12 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:28  flops: 42.2904 (42.2904)  loss: 1.0403 (1.0880)  acc1: 78.5714 (77.3908)  acc5: 91.9192 (92.0003)  time: 0.2314  data: 0.0001  max mem: 2179
[2024-01-20 13:07:14 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:25  flops: 42.2904 (42.2904)  loss: 1.0124 (1.0869)  acc1: 78.5714 (77.3923)  acc5: 92.8571 (92.0118)  time: 0.2308  data: 0.0001  max mem: 2179
[2024-01-20 13:07:17 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:23  flops: 42.2904 (42.2904)  loss: 1.0319 (1.0866)  acc1: 76.2887 (77.3526)  acc5: 93.0000 (92.0370)  time: 0.2311  data: 0.0001  max mem: 2179
[2024-01-20 13:07:19 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:21  flops: 42.2904 (42.2904)  loss: 1.0782 (1.0853)  acc1: 77.3196 (77.3687)  acc5: 93.0000 (92.0565)  time: 0.2310  data: 0.0001  max mem: 2179
[2024-01-20 13:07:21 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:18  flops: 42.2904 (42.2904)  loss: 1.0798 (1.0874)  acc1: 77.5510 (77.3416)  acc5: 91.9192 (92.0247)  time: 0.2300  data: 0.0001  max mem: 2179
[2024-01-20 13:07:23 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:16  flops: 42.2904 (42.2904)  loss: 1.1225 (1.0870)  acc1: 77.5510 (77.3511)  acc5: 90.8163 (92.0274)  time: 0.2303  data: 0.0001  max mem: 2179
[2024-01-20 13:07:26 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:14  flops: 42.2904 (42.2904)  loss: 1.0776 (1.0881)  acc1: 78.3505 (77.3472)  acc5: 92.8571 (92.0410)  time: 0.2300  data: 0.0001  max mem: 2179
[2024-01-20 13:07:28 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:11  flops: 42.2904 (42.2904)  loss: 1.0707 (1.0889)  acc1: 76.2887 (77.3135)  acc5: 92.9293 (92.0403)  time: 0.2295  data: 0.0001  max mem: 2179
[2024-01-20 13:07:30 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:09  flops: 42.2904 (42.2904)  loss: 1.0707 (1.0872)  acc1: 76.2887 (77.3337)  acc5: 92.9293 (92.0638)  time: 0.2308  data: 0.0001  max mem: 2179
[2024-01-20 13:07:33 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:06  flops: 42.2904 (42.2904)  loss: 1.0926 (1.0877)  acc1: 78.0000 (77.3381)  acc5: 92.8571 (92.0532)  time: 0.2317  data: 0.0001  max mem: 2179
[2024-01-20 13:07:35 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:04  flops: 42.2904 (42.2904)  loss: 1.1099 (1.0883)  acc1: 78.0000 (77.3153)  acc5: 91.9192 (92.0601)  time: 0.2314  data: 0.0001  max mem: 2179
[2024-01-20 13:07:37 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:02  flops: 42.2904 (42.2904)  loss: 1.1099 (1.0892)  acc1: 74.7475 (77.2742)  acc5: 91.9192 (92.0542)  time: 0.2314  data: 0.0001  max mem: 2179
[2024-01-20 13:07:39 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 42.2904 (42.2904)  loss: 1.0405 (1.0874)  acc1: 76.7677 (77.3324)  acc5: 91.9192 (92.0633)  time: 0.2316  data: 0.0001  max mem: 2179
[2024-01-20 13:07:39 root] (utils.py 307): INFO Test: Total time: 0:01:56 (0.2332 s / it)
[2024-01-20 13:07:39 root] (engine.py 119): INFO prune kept number:[197, 197, 197, 195, 194, 193, 191, 187, 182, 180, 173, 149, 142, 134, 125, 121, 111, 106, 91, 87, 77, 39, 38, 32]
[2024-01-20 13:07:39 root] (engine.py 120): INFO merge kept number:[197, 197, 196, 194, 193, 192, 187, 183, 181, 173, 154, 146, 137, 127, 123, 114, 105, 98, 87, 75, 43, 45, 32, 32]
[2024-01-20 13:07:39 root] (engine.py 124): INFO * Acc@1 77.332 Acc@5 92.063 loss 1.087 flops 42.290
[2024-01-20 13:07:39 root] (main.py 381): INFO Accuracy of the network on the 50000 test images: 77.3%
[2024-01-20 13:08:02 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:08:06 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:08:11 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 13:08:12 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:11:37  flops: 39.7595 (39.7595)  loss: 1.2401 (1.2401)  acc1: 73.7374 (73.7374)  acc5: 90.9091 (90.9091)  time: 1.3957  data: 0.0007  max mem: 2124
[2024-01-20 13:08:15 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:56  flops: 39.7595 (39.7595)  loss: 1.1900 (1.1973)  acc1: 74.7368 (75.4435)  acc5: 90.9091 (91.3165)  time: 0.3596  data: 0.0002  max mem: 2124
[2024-01-20 13:08:17 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:25  flops: 39.7595 (39.7595)  loss: 1.1152 (1.1225)  acc1: 76.0417 (76.3848)  acc5: 91.0000 (91.7396)  time: 0.2482  data: 0.0001  max mem: 2127
[2024-01-20 13:08:20 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:11  flops: 39.7595 (39.7595)  loss: 1.0408 (1.1084)  acc1: 76.7677 (76.7992)  acc5: 92.9293 (91.8830)  time: 0.2370  data: 0.0001  max mem: 2127
[2024-01-20 13:08:22 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:03  flops: 39.7595 (39.7595)  loss: 1.0881 (1.1083)  acc1: 77.0833 (77.0321)  acc5: 92.7083 (91.7226)  time: 0.2328  data: 0.0001  max mem: 2127
[2024-01-20 13:08:24 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:01:57  flops: 39.7595 (39.7595)  loss: 1.1456 (1.1160)  acc1: 76.7677 (76.7200)  acc5: 91.6667 (91.8800)  time: 0.2314  data: 0.0001  max mem: 2127
[2024-01-20 13:08:27 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:01:52  flops: 39.7595 (39.7595)  loss: 1.1226 (1.1098)  acc1: 77.7778 (76.9629)  acc5: 92.8571 (91.9980)  time: 0.2317  data: 0.0001  max mem: 2127
[2024-01-20 13:08:29 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:01:48  flops: 39.7595 (39.7595)  loss: 1.0845 (1.1093)  acc1: 78.0000 (76.9440)  acc5: 92.0000 (92.0086)  time: 0.2330  data: 0.0001  max mem: 2127
[2024-01-20 13:08:31 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:01:45  flops: 39.7595 (39.7595)  loss: 1.0957 (1.1055)  acc1: 75.5102 (76.9434)  acc5: 91.8367 (92.1258)  time: 0.2329  data: 0.0001  max mem: 2127
[2024-01-20 13:08:34 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:01:41  flops: 39.7595 (39.7595)  loss: 1.1005 (1.1074)  acc1: 75.7576 (76.9739)  acc5: 91.8367 (92.0596)  time: 0.2323  data: 0.0001  max mem: 2127
[2024-01-20 13:08:36 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:01:38  flops: 39.7595 (39.7595)  loss: 1.0949 (1.1034)  acc1: 76.5306 (77.0178)  acc5: 91.9192 (92.1005)  time: 0.2325  data: 0.0001  max mem: 2127
[2024-01-20 13:08:38 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:01:35  flops: 39.7595 (39.7595)  loss: 1.0710 (1.0990)  acc1: 77.0000 (77.0988)  acc5: 91.6667 (92.1369)  time: 0.2331  data: 0.0001  max mem: 2127
[2024-01-20 13:08:41 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:01:33  flops: 39.7595 (39.7595)  loss: 1.0710 (1.1068)  acc1: 77.0000 (76.9962)  acc5: 91.6667 (92.0656)  time: 0.2337  data: 0.0001  max mem: 2127
[2024-01-20 13:08:43 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:01:30  flops: 39.7595 (39.7595)  loss: 1.0537 (1.1012)  acc1: 77.5510 (76.9876)  acc5: 92.0000 (92.1427)  time: 0.2332  data: 0.0001  max mem: 2127
[2024-01-20 13:08:45 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:01:27  flops: 39.7595 (39.7595)  loss: 1.0789 (1.1033)  acc1: 77.0833 (76.9581)  acc5: 92.9293 (92.1100)  time: 0.2335  data: 0.0001  max mem: 2127
[2024-01-20 13:08:48 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:01:25  flops: 39.7595 (39.7595)  loss: 1.0348 (1.0999)  acc1: 77.0833 (77.0698)  acc5: 92.8571 (92.1723)  time: 0.2365  data: 0.0001  max mem: 2127
[2024-01-20 13:08:50 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:01:22  flops: 39.7595 (39.7595)  loss: 1.0569 (1.1029)  acc1: 77.5510 (77.0306)  acc5: 92.7835 (92.1116)  time: 0.2356  data: 0.0001  max mem: 2127
[2024-01-20 13:08:52 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:01:19  flops: 39.7595 (39.7595)  loss: 1.1117 (1.1028)  acc1: 77.3196 (77.0940)  acc5: 91.7526 (92.1006)  time: 0.2358  data: 0.0001  max mem: 2127
[2024-01-20 13:08:55 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:01:17  flops: 39.7595 (39.7595)  loss: 1.1262 (1.1087)  acc1: 76.0417 (76.9140)  acc5: 91.0000 (92.0232)  time: 0.2358  data: 0.0001  max mem: 2127
[2024-01-20 13:08:57 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:01:14  flops: 39.7595 (39.7595)  loss: 1.1066 (1.1094)  acc1: 74.7475 (76.9264)  acc5: 91.6667 (92.0066)  time: 0.2336  data: 0.0001  max mem: 2128
[2024-01-20 13:08:59 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:01:12  flops: 39.7595 (39.7595)  loss: 1.0588 (1.1100)  acc1: 78.7879 (76.9823)  acc5: 91.9192 (91.9795)  time: 0.2344  data: 0.0001  max mem: 2128
[2024-01-20 13:09:02 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:01:09  flops: 39.7595 (39.7595)  loss: 1.1130 (1.1121)  acc1: 77.5510 (76.9390)  acc5: 91.9192 (91.9832)  time: 0.2339  data: 0.0001  max mem: 2128
[2024-01-20 13:09:04 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:01:07  flops: 39.7595 (39.7595)  loss: 1.1193 (1.1102)  acc1: 77.5510 (76.9872)  acc5: 91.7526 (91.9635)  time: 0.2335  data: 0.0001  max mem: 2128
[2024-01-20 13:09:06 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:01:04  flops: 39.7595 (39.7595)  loss: 1.1210 (1.1157)  acc1: 76.5306 (76.8248)  acc5: 90.9091 (91.9385)  time: 0.2339  data: 0.0001  max mem: 2128
[2024-01-20 13:09:09 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:01:02  flops: 39.7595 (39.7595)  loss: 1.2567 (1.1166)  acc1: 75.0000 (76.8074)  acc5: 91.0000 (91.9424)  time: 0.2337  data: 0.0001  max mem: 2128
[2024-01-20 13:09:11 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:59  flops: 39.7595 (39.7595)  loss: 1.0731 (1.1186)  acc1: 76.0000 (76.7730)  acc5: 91.0000 (91.9101)  time: 0.2332  data: 0.0001  max mem: 2128
[2024-01-20 13:09:13 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:57  flops: 39.7595 (39.7595)  loss: 1.0968 (1.1202)  acc1: 76.5306 (76.7697)  acc5: 89.8990 (91.8676)  time: 0.2332  data: 0.0001  max mem: 2128
[2024-01-20 13:09:16 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:54  flops: 39.7595 (39.7595)  loss: 1.2739 (1.1252)  acc1: 75.7576 (76.6713)  acc5: 90.8163 (91.8455)  time: 0.2337  data: 0.0001  max mem: 2128
[2024-01-20 13:09:18 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:52  flops: 39.7595 (39.7595)  loss: 1.2197 (1.1256)  acc1: 75.0000 (76.6940)  acc5: 92.7083 (91.8509)  time: 0.2348  data: 0.0001  max mem: 2128
[2024-01-20 13:09:20 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:50  flops: 39.7595 (39.7595)  loss: 1.1124 (1.1260)  acc1: 76.5306 (76.6994)  acc5: 91.8367 (91.8273)  time: 0.2352  data: 0.0001  max mem: 2128
[2024-01-20 13:09:23 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:47  flops: 39.7595 (39.7595)  loss: 1.0721 (1.1232)  acc1: 77.5510 (76.7925)  acc5: 91.8367 (91.8459)  time: 0.2348  data: 0.0001  max mem: 2128
[2024-01-20 13:09:25 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:45  flops: 39.7595 (39.7595)  loss: 1.0882 (1.1261)  acc1: 76.5306 (76.7584)  acc5: 91.8367 (91.8044)  time: 0.2345  data: 0.0001  max mem: 2128
[2024-01-20 13:09:27 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:42  flops: 39.7595 (39.7595)  loss: 1.1090 (1.1239)  acc1: 77.0833 (76.7887)  acc5: 91.7526 (91.8337)  time: 0.2338  data: 0.0001  max mem: 2128
[2024-01-20 13:09:30 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:40  flops: 39.7595 (39.7595)  loss: 1.0703 (1.1221)  acc1: 79.3814 (76.8507)  acc5: 92.7083 (91.8682)  time: 0.2324  data: 0.0001  max mem: 2128
[2024-01-20 13:09:32 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:38  flops: 39.7595 (39.7595)  loss: 1.0831 (1.1214)  acc1: 77.7778 (76.8620)  acc5: 91.9192 (91.8623)  time: 0.2329  data: 0.0001  max mem: 2128
[2024-01-20 13:09:34 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:35  flops: 39.7595 (39.7595)  loss: 1.0686 (1.1200)  acc1: 76.8421 (76.8722)  acc5: 92.8571 (91.8903)  time: 0.2339  data: 0.0001  max mem: 2128
[2024-01-20 13:09:37 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:33  flops: 39.7595 (39.7595)  loss: 1.0677 (1.1202)  acc1: 77.5510 (76.8931)  acc5: 92.9293 (91.8745)  time: 0.2334  data: 0.0001  max mem: 2128
[2024-01-20 13:09:39 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:30  flops: 39.7595 (39.7595)  loss: 1.0880 (1.1189)  acc1: 77.7778 (76.9113)  acc5: 90.8163 (91.8664)  time: 0.2340  data: 0.0001  max mem: 2128
[2024-01-20 13:09:41 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:28  flops: 39.7595 (39.7595)  loss: 1.0560 (1.1176)  acc1: 77.7778 (76.9231)  acc5: 90.8163 (91.8827)  time: 0.2349  data: 0.0001  max mem: 2128
[2024-01-20 13:09:44 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:26  flops: 39.7595 (39.7595)  loss: 1.0406 (1.1163)  acc1: 77.5510 (76.9391)  acc5: 91.9192 (91.8972)  time: 0.2343  data: 0.0001  max mem: 2128
[2024-01-20 13:09:46 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:23  flops: 39.7595 (39.7595)  loss: 1.0611 (1.1161)  acc1: 76.0000 (76.9057)  acc5: 93.0000 (91.9252)  time: 0.2343  data: 0.0001  max mem: 2128
[2024-01-20 13:09:54 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:09:58 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:10:03 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 13:10:04 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:11:25  flops: 45.6860 (45.6860)  loss: 1.2392 (1.2392)  acc1: 74.7475 (74.7475)  acc5: 87.8788 (87.8788)  time: 1.3712  data: 0.0008  max mem: 2148
[2024-01-20 13:10:07 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:52  flops: 45.6860 (45.6860)  loss: 1.1670 (1.1714)  acc1: 75.2577 (75.2568)  acc5: 91.5789 (90.6629)  time: 0.3526  data: 0.0002  max mem: 2151
[2024-01-20 13:10:09 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:23  flops: 45.6860 (45.6860)  loss: 1.0750 (1.0891)  acc1: 75.7895 (76.7736)  acc5: 91.8367 (91.7881)  time: 0.2444  data: 0.0001  max mem: 2154
[2024-01-20 13:10:11 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:10  flops: 45.6860 (45.6860)  loss: 1.0240 (1.0780)  acc1: 76.7677 (76.9964)  acc5: 92.9293 (91.8501)  time: 0.2349  data: 0.0001  max mem: 2154
[2024-01-20 13:10:14 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:02  flops: 45.6860 (45.6860)  loss: 1.0504 (1.0796)  acc1: 77.3196 (77.0569)  acc5: 91.8367 (91.7475)  time: 0.2311  data: 0.0001  max mem: 2154
[2024-01-20 13:10:16 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:01:56  flops: 45.6860 (45.6860)  loss: 1.1179 (1.0884)  acc1: 75.7576 (76.8000)  acc5: 91.8367 (91.9000)  time: 0.2304  data: 0.0001  max mem: 2154
[2024-01-20 13:10:18 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:01:51  flops: 45.6860 (45.6860)  loss: 1.1148 (1.0803)  acc1: 77.7778 (77.1467)  acc5: 92.8571 (91.9479)  time: 0.2311  data: 0.0001  max mem: 2154
[2024-01-20 13:10:21 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:01:47  flops: 45.6860 (45.6860)  loss: 1.0567 (1.0811)  acc1: 78.3505 (77.0588)  acc5: 91.9192 (91.9369)  time: 0.2320  data: 0.0001  max mem: 2154
[2024-01-20 13:10:23 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:01:44  flops: 45.6860 (45.6860)  loss: 1.0739 (1.0763)  acc1: 77.7778 (77.2830)  acc5: 92.0000 (92.1258)  time: 0.2315  data: 0.0001  max mem: 2154
[2024-01-20 13:10:25 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:01:41  flops: 45.6860 (45.6860)  loss: 1.0739 (1.0772)  acc1: 77.5510 (77.3099)  acc5: 92.8571 (92.1268)  time: 0.2313  data: 0.0001  max mem: 2154
[2024-01-20 13:10:28 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:01:38  flops: 45.6860 (45.6860)  loss: 1.0696 (1.0728)  acc1: 76.7677 (77.3507)  acc5: 91.9192 (92.1812)  time: 0.2319  data: 0.0001  max mem: 2154
[2024-01-20 13:10:30 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:01:35  flops: 45.6860 (45.6860)  loss: 1.0184 (1.0700)  acc1: 78.5714 (77.4566)  acc5: 91.8367 (92.2103)  time: 0.2328  data: 0.0001  max mem: 2154
[2024-01-20 13:10:32 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:01:32  flops: 45.6860 (45.6860)  loss: 1.0545 (1.0778)  acc1: 79.0000 (77.3748)  acc5: 91.6667 (92.1245)  time: 0.2330  data: 0.0001  max mem: 2154
[2024-01-20 13:10:35 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:01:29  flops: 45.6860 (45.6860)  loss: 1.0545 (1.0734)  acc1: 77.0000 (77.2907)  acc5: 93.0000 (92.1893)  time: 0.2326  data: 0.0001  max mem: 2154
[2024-01-20 13:10:37 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:01:27  flops: 45.6860 (45.6860)  loss: 1.0338 (1.0748)  acc1: 76.2887 (77.2540)  acc5: 92.9293 (92.1750)  time: 0.2327  data: 0.0001  max mem: 2154
[2024-01-20 13:10:39 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:01:24  flops: 45.6860 (45.6860)  loss: 1.0187 (1.0714)  acc1: 76.7677 (77.3530)  acc5: 92.8571 (92.2263)  time: 0.2351  data: 0.0001  max mem: 2154
[2024-01-20 13:10:42 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:01:21  flops: 45.6860 (45.6860)  loss: 1.0188 (1.0748)  acc1: 78.1250 (77.2773)  acc5: 92.8571 (92.1875)  time: 0.2340  data: 0.0001  max mem: 2154
[2024-01-20 13:10:44 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:01:19  flops: 45.6860 (45.6860)  loss: 1.0921 (1.0738)  acc1: 76.2887 (77.2966)  acc5: 91.9192 (92.1959)  time: 0.2344  data: 0.0001  max mem: 2154
[2024-01-20 13:10:46 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:01:16  flops: 45.6860 (45.6860)  loss: 1.0876 (1.0791)  acc1: 76.0417 (77.1786)  acc5: 91.8367 (92.1189)  time: 0.2347  data: 0.0001  max mem: 2154
[2024-01-20 13:10:49 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:01:14  flops: 45.6860 (45.6860)  loss: 1.0610 (1.0794)  acc1: 76.0417 (77.1983)  acc5: 91.7526 (92.1079)  time: 0.2327  data: 0.0001  max mem: 2154
[2024-01-20 13:10:51 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:01:11  flops: 45.6860 (45.6860)  loss: 1.0272 (1.0803)  acc1: 79.0000 (77.2660)  acc5: 91.9192 (92.0758)  time: 0.2334  data: 0.0001  max mem: 2154
[2024-01-20 13:10:53 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:01:09  flops: 45.6860 (45.6860)  loss: 1.0952 (1.0827)  acc1: 77.7778 (77.2286)  acc5: 91.9192 (92.0604)  time: 0.2327  data: 0.0001  max mem: 2154
[2024-01-20 13:10:56 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:01:06  flops: 45.6860 (45.6860)  loss: 1.0952 (1.0809)  acc1: 76.5306 (77.2775)  acc5: 92.7835 (92.0695)  time: 0.2326  data: 0.0001  max mem: 2154
[2024-01-20 13:10:58 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:01:04  flops: 45.6860 (45.6860)  loss: 1.0984 (1.0864)  acc1: 76.5306 (77.1509)  acc5: 91.8367 (92.0398)  time: 0.2330  data: 0.0001  max mem: 2154
[2024-01-20 13:11:00 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:01:01  flops: 45.6860 (45.6860)  loss: 1.2233 (1.0874)  acc1: 75.7576 (77.1327)  acc5: 91.8367 (92.0522)  time: 0.2325  data: 0.0001  max mem: 2154
[2024-01-20 13:11:03 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:59  flops: 45.6860 (45.6860)  loss: 1.0325 (1.0889)  acc1: 76.2887 (77.0935)  acc5: 91.0000 (92.0359)  time: 0.2320  data: 0.0001  max mem: 2154
[2024-01-20 13:11:05 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:57  flops: 45.6860 (45.6860)  loss: 1.0440 (1.0903)  acc1: 75.7576 (77.0936)  acc5: 90.9091 (92.0159)  time: 0.2320  data: 0.0001  max mem: 2154
[2024-01-20 13:11:07 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:54  flops: 45.6860 (45.6860)  loss: 1.2004 (1.0949)  acc1: 75.7576 (77.0020)  acc5: 91.0000 (92.0033)  time: 0.2324  data: 0.0001  max mem: 2154
[2024-01-20 13:11:10 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:52  flops: 45.6860 (45.6860)  loss: 1.2105 (1.0956)  acc1: 77.0000 (77.0092)  acc5: 91.9192 (91.9994)  time: 0.2334  data: 0.0001  max mem: 2154
[2024-01-20 13:11:12 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:49  flops: 45.6860 (45.6860)  loss: 1.0626 (1.0955)  acc1: 76.0000 (76.9968)  acc5: 92.0000 (91.9882)  time: 0.2333  data: 0.0001  max mem: 2154
[2024-01-20 13:11:14 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:47  flops: 45.6860 (45.6860)  loss: 1.0374 (1.0930)  acc1: 76.7677 (77.0800)  acc5: 92.8571 (92.0116)  time: 0.2332  data: 0.0001  max mem: 2154
[2024-01-20 13:11:17 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:45  flops: 45.6860 (45.6860)  loss: 1.0882 (1.0958)  acc1: 76.7677 (77.0530)  acc5: 92.7835 (91.9713)  time: 0.2333  data: 0.0001  max mem: 2154
[2024-01-20 13:11:19 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:42  flops: 45.6860 (45.6860)  loss: 1.0942 (1.0938)  acc1: 77.0833 (77.0741)  acc5: 91.9192 (92.0081)  time: 0.2326  data: 0.0001  max mem: 2154
[2024-01-20 13:11:21 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:40  flops: 45.6860 (45.6860)  loss: 1.0301 (1.0922)  acc1: 78.5714 (77.1214)  acc5: 92.8571 (92.0343)  time: 0.2311  data: 0.0001  max mem: 2154
[2024-01-20 13:11:23 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:37  flops: 45.6860 (45.6860)  loss: 1.0531 (1.0914)  acc1: 77.7778 (77.1427)  acc5: 91.7526 (92.0265)  time: 0.2317  data: 0.0001  max mem: 2154
[2024-01-20 13:11:26 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:35  flops: 45.6860 (45.6860)  loss: 1.0531 (1.0902)  acc1: 78.5714 (77.1710)  acc5: 92.8571 (92.0441)  time: 0.2326  data: 0.0001  max mem: 2154
[2024-01-20 13:11:28 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:33  flops: 45.6860 (45.6860)  loss: 1.0399 (1.0900)  acc1: 78.1250 (77.1922)  acc5: 92.7835 (92.0353)  time: 0.2321  data: 0.0001  max mem: 2154
[2024-01-20 13:11:30 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:30  flops: 45.6860 (45.6860)  loss: 1.0553 (1.0886)  acc1: 76.7677 (77.1995)  acc5: 91.9192 (92.0530)  time: 0.2328  data: 0.0001  max mem: 2154
[2024-01-20 13:11:33 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:28  flops: 45.6860 (45.6860)  loss: 1.0376 (1.0875)  acc1: 76.7677 (77.2224)  acc5: 92.0000 (92.0618)  time: 0.2334  data: 0.0001  max mem: 2154
[2024-01-20 13:11:35 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:25  flops: 45.6860 (45.6860)  loss: 1.0159 (1.0861)  acc1: 78.5714 (77.2282)  acc5: 92.8571 (92.0717)  time: 0.2329  data: 0.0001  max mem: 2154
[2024-01-20 13:11:37 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:23  flops: 45.6860 (45.6860)  loss: 1.0447 (1.0857)  acc1: 75.5102 (77.1926)  acc5: 93.0000 (92.0903)  time: 0.2332  data: 0.0001  max mem: 2154
[2024-01-20 13:11:40 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:21  flops: 45.6860 (45.6860)  loss: 1.0867 (1.0845)  acc1: 77.0833 (77.1928)  acc5: 93.8144 (92.1184)  time: 0.2330  data: 0.0001  max mem: 2154
[2024-01-20 13:11:42 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:18  flops: 45.6860 (45.6860)  loss: 1.0867 (1.0866)  acc1: 77.0833 (77.1553)  acc5: 92.8571 (92.0948)  time: 0.2321  data: 0.0001  max mem: 2154
[2024-01-20 13:11:44 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:16  flops: 45.6860 (45.6860)  loss: 1.1458 (1.0864)  acc1: 76.5306 (77.1763)  acc5: 89.8990 (92.0723)  time: 0.2323  data: 0.0001  max mem: 2154
[2024-01-20 13:11:47 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:14  flops: 45.6860 (45.6860)  loss: 1.0790 (1.0875)  acc1: 78.5714 (77.1809)  acc5: 92.6316 (92.0734)  time: 0.2320  data: 0.0001  max mem: 2154
[2024-01-20 13:11:49 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:11  flops: 45.6860 (45.6860)  loss: 1.0848 (1.0885)  acc1: 76.0417 (77.1328)  acc5: 92.6316 (92.0629)  time: 0.2315  data: 0.0001  max mem: 2154
[2024-01-20 13:11:51 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:09  flops: 45.6860 (45.6860)  loss: 1.0931 (1.0867)  acc1: 76.0000 (77.1569)  acc5: 91.9192 (92.0793)  time: 0.2327  data: 0.0001  max mem: 2154
[2024-01-20 13:11:54 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:07  flops: 45.6860 (45.6860)  loss: 1.1036 (1.0872)  acc1: 77.7778 (77.1543)  acc5: 91.9192 (92.0705)  time: 0.2336  data: 0.0001  max mem: 2154
[2024-01-20 13:11:56 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:04  flops: 45.6860 (45.6860)  loss: 1.1303 (1.0881)  acc1: 76.5306 (77.1141)  acc5: 91.6667 (92.0644)  time: 0.2333  data: 0.0001  max mem: 2154
[2024-01-20 13:11:58 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:02  flops: 45.6860 (45.6860)  loss: 1.1609 (1.0890)  acc1: 75.0000 (77.0606)  acc5: 91.8367 (92.0583)  time: 0.2334  data: 0.0001  max mem: 2154
[2024-01-20 13:12:00 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 45.6860 (45.6860)  loss: 1.0435 (1.0870)  acc1: 75.7576 (77.1166)  acc5: 91.9192 (92.0714)  time: 0.2336  data: 0.0001  max mem: 2154
[2024-01-20 13:12:00 root] (utils.py 307): INFO Test: Total time: 0:01:57 (0.2355 s / it)
[2024-01-20 13:12:03 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:12:07 root] (main.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:12:12 root] (main.py 373): INFO number of params: 304326632
[2024-01-20 13:12:14 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:12:24  flops: 42.2904 (42.2904)  loss: 1.2383 (1.2383)  acc1: 74.7475 (74.7475)  acc5: 90.9091 (90.9091)  time: 1.4882  data: 0.0007  max mem: 2168
[2024-01-20 13:12:16 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:58  flops: 42.2904 (42.2904)  loss: 1.1522 (1.1628)  acc1: 76.2887 (76.0971)  acc5: 91.6667 (91.1298)  time: 0.3649  data: 0.0002  max mem: 2170
[2024-01-20 13:12:19 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:26  flops: 42.2904 (42.2904)  loss: 1.0794 (1.0885)  acc1: 77.3196 (76.8222)  acc5: 91.7526 (91.7396)  time: 0.2451  data: 0.0001  max mem: 2179
[2024-01-20 13:12:21 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:11  flops: 42.2904 (42.2904)  loss: 1.0274 (1.0770)  acc1: 77.7778 (77.3579)  acc5: 92.9293 (91.8830)  time: 0.2342  data: 0.0001  max mem: 2179
[2024-01-20 13:12:23 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:03  flops: 42.2904 (42.2904)  loss: 1.0724 (1.0799)  acc1: 77.3196 (77.4795)  acc5: 91.9192 (91.8717)  time: 0.2304  data: 0.0001  max mem: 2179
[2024-01-20 13:12:26 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:01:57  flops: 42.2904 (42.2904)  loss: 1.1196 (1.0907)  acc1: 75.7576 (77.0800)  acc5: 92.0000 (91.9800)  time: 0.2296  data: 0.0001  max mem: 2179
[2024-01-20 13:12:28 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:01:52  flops: 42.2904 (42.2904)  loss: 1.1186 (1.0826)  acc1: 77.3196 (77.4140)  acc5: 92.9293 (92.0815)  time: 0.2301  data: 0.0001  max mem: 2179
[2024-01-20 13:12:30 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:01:48  flops: 42.2904 (42.2904)  loss: 1.0333 (1.0838)  acc1: 78.3505 (77.2597)  acc5: 92.0000 (92.1090)  time: 0.2308  data: 0.0001  max mem: 2179
[2024-01-20 13:12:33 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:01:44  flops: 42.2904 (42.2904)  loss: 1.0538 (1.0781)  acc1: 77.5510 (77.3711)  acc5: 92.0000 (92.2390)  time: 0.2305  data: 0.0001  max mem: 2179
[2024-01-20 13:12:35 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:01:41  flops: 42.2904 (42.2904)  loss: 1.0764 (1.0798)  acc1: 77.5510 (77.4443)  acc5: 92.8571 (92.2052)  time: 0.2303  data: 0.0001  max mem: 2179
[2024-01-20 13:12:37 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:01:38  flops: 42.2904 (42.2904)  loss: 1.0525 (1.0736)  acc1: 77.5510 (77.4718)  acc5: 92.9293 (92.2922)  time: 0.2306  data: 0.0001  max mem: 2179
[2024-01-20 13:12:40 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:01:35  flops: 42.2904 (42.2904)  loss: 1.0200 (1.0707)  acc1: 77.7778 (77.6126)  acc5: 92.0000 (92.3112)  time: 0.2315  data: 0.0001  max mem: 2179
[2024-01-20 13:12:42 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:01:32  flops: 42.2904 (42.2904)  loss: 1.0527 (1.0790)  acc1: 79.0000 (77.4842)  acc5: 92.0000 (92.2423)  time: 0.2321  data: 0.0001  max mem: 2179
[2024-01-20 13:12:44 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:01:29  flops: 42.2904 (42.2904)  loss: 1.0605 (1.0733)  acc1: 77.5510 (77.4695)  acc5: 92.9293 (92.2826)  time: 0.2316  data: 0.0001  max mem: 2179
[2024-01-20 13:12:46 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:01:27  flops: 42.2904 (42.2904)  loss: 1.0469 (1.0753)  acc1: 77.5510 (77.4634)  acc5: 92.9293 (92.2833)  time: 0.2316  data: 0.0001  max mem: 2179
[2024-01-20 13:12:49 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:01:24  flops: 42.2904 (42.2904)  loss: 1.0171 (1.0719)  acc1: 78.7879 (77.5620)  acc5: 92.8571 (92.3476)  time: 0.2341  data: 0.0001  max mem: 2179
[2024-01-20 13:12:51 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:01:21  flops: 42.2904 (42.2904)  loss: 1.0171 (1.0746)  acc1: 78.5714 (77.5114)  acc5: 92.8571 (92.2824)  time: 0.2330  data: 0.0001  max mem: 2179
[2024-01-20 13:12:54 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:01:19  flops: 42.2904 (42.2904)  loss: 1.0748 (1.0739)  acc1: 77.5510 (77.5766)  acc5: 91.6667 (92.2554)  time: 0.2335  data: 0.0001  max mem: 2179
[2024-01-20 13:12:56 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:01:16  flops: 42.2904 (42.2904)  loss: 1.0760 (1.0790)  acc1: 76.7677 (77.4375)  acc5: 90.9091 (92.1752)  time: 0.2336  data: 0.0001  max mem: 2179
[2024-01-20 13:12:58 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:01:14  flops: 42.2904 (42.2904)  loss: 1.0411 (1.0802)  acc1: 75.7576 (77.4276)  acc5: 91.8367 (92.1559)  time: 0.2315  data: 0.0001  max mem: 2179
[2024-01-20 13:13:00 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:01:11  flops: 42.2904 (42.2904)  loss: 1.0337 (1.0806)  acc1: 78.7879 (77.5042)  acc5: 91.9192 (92.0859)  time: 0.2322  data: 0.0001  max mem: 2179
[2024-01-20 13:13:03 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:01:09  flops: 42.2904 (42.2904)  loss: 1.1042 (1.0830)  acc1: 78.3505 (77.4603)  acc5: 90.9091 (92.0749)  time: 0.2315  data: 0.0001  max mem: 2179
[2024-01-20 13:13:13 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:13:16 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:13:21 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 13:13:23 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:12:31  flops: 45.6860 (45.6860)  loss: 1.1923 (1.1923)  acc1: 74.7475 (74.7475)  acc5: 91.9192 (91.9192)  time: 1.5025  data: 0.0008  max mem: 2227
[2024-01-20 13:13:26 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:03:14  flops: 45.6860 (45.6860)  loss: 1.1575 (1.1539)  acc1: 75.2577 (75.4435)  acc5: 91.5789 (90.9430)  time: 0.3961  data: 0.0002  max mem: 2232
[2024-01-20 13:13:29 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:41  flops: 45.6860 (45.6860)  loss: 1.0923 (1.0847)  acc1: 75.7895 (77.0165)  acc5: 91.7526 (91.8853)  time: 0.2780  data: 0.0001  max mem: 2237
[2024-01-20 13:13:31 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:27  flops: 45.6860 (45.6860)  loss: 1.0135 (1.0721)  acc1: 76.7677 (77.4893)  acc5: 92.9293 (92.0473)  time: 0.2673  data: 0.0001  max mem: 2237
[2024-01-20 13:13:34 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:18  flops: 45.6860 (45.6860)  loss: 1.0451 (1.0743)  acc1: 77.0833 (77.5292)  acc5: 92.7083 (91.9463)  time: 0.2635  data: 0.0001  max mem: 2237
[2024-01-20 13:13:36 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:02:11  flops: 45.6860 (45.6860)  loss: 1.1257 (1.0849)  acc1: 75.5102 (77.0600)  acc5: 91.8367 (92.0600)  time: 0.2625  data: 0.0001  max mem: 2237
[2024-01-20 13:13:39 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:02:06  flops: 45.6860 (45.6860)  loss: 1.1138 (1.0783)  acc1: 76.7677 (77.2469)  acc5: 92.7835 (92.1651)  time: 0.2634  data: 0.0001  max mem: 2237
[2024-01-20 13:13:42 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:02:02  flops: 45.6860 (45.6860)  loss: 1.0697 (1.0789)  acc1: 78.0000 (77.2453)  acc5: 92.0000 (92.1664)  time: 0.2642  data: 0.0001  max mem: 2237
[2024-01-20 13:13:44 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:01:58  flops: 45.6860 (45.6860)  loss: 1.0785 (1.0752)  acc1: 77.5510 (77.3459)  acc5: 92.0000 (92.2516)  time: 0.2634  data: 0.0001  max mem: 2237
[2024-01-20 13:13:47 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:01:54  flops: 45.6860 (45.6860)  loss: 1.0785 (1.0761)  acc1: 77.5510 (77.4107)  acc5: 92.8571 (92.2724)  time: 0.2632  data: 0.0001  max mem: 2237
[2024-01-20 13:13:50 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:01:51  flops: 45.6860 (45.6860)  loss: 1.0524 (1.0721)  acc1: 76.5306 (77.4415)  acc5: 91.9192 (92.3123)  time: 0.2640  data: 0.0001  max mem: 2237
[2024-01-20 13:13:52 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:01:48  flops: 45.6860 (45.6860)  loss: 1.0328 (1.0682)  acc1: 77.0000 (77.5025)  acc5: 91.9192 (92.3387)  time: 0.2653  data: 0.0001  max mem: 2237
[2024-01-20 13:13:55 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:01:45  flops: 45.6860 (45.6860)  loss: 1.0333 (1.0766)  acc1: 78.1250 (77.3917)  acc5: 92.0000 (92.2760)  time: 0.2656  data: 0.0001  max mem: 2237
[2024-01-20 13:13:58 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:01:41  flops: 45.6860 (45.6860)  loss: 1.0333 (1.0713)  acc1: 77.5510 (77.3918)  acc5: 92.9293 (92.3214)  time: 0.2651  data: 0.0001  max mem: 2237
[2024-01-20 13:14:00 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:01:38  flops: 45.6860 (45.6860)  loss: 1.0480 (1.0727)  acc1: 77.5510 (77.3695)  acc5: 92.8571 (92.2977)  time: 0.2651  data: 0.0001  max mem: 2237
[2024-01-20 13:14:03 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:01:36  flops: 45.6860 (45.6860)  loss: 1.0193 (1.0697)  acc1: 77.7778 (77.4879)  acc5: 93.5484 (92.3476)  time: 0.2680  data: 0.0001  max mem: 2237
[2024-01-20 13:14:06 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:01:33  flops: 45.6860 (45.6860)  loss: 1.0276 (1.0730)  acc1: 78.5714 (77.4291)  acc5: 92.8571 (92.2950)  time: 0.2669  data: 0.0001  max mem: 2237
[2024-01-20 13:14:08 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:01:30  flops: 45.6860 (45.6860)  loss: 1.0824 (1.0720)  acc1: 76.7677 (77.4753)  acc5: 92.0000 (92.2733)  time: 0.2675  data: 0.0001  max mem: 2237
[2024-01-20 13:14:11 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:01:27  flops: 45.6860 (45.6860)  loss: 1.0860 (1.0774)  acc1: 76.0417 (77.3531)  acc5: 91.8367 (92.1921)  time: 0.2677  data: 0.0001  max mem: 2237
[2024-01-20 13:14:14 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:01:24  flops: 45.6860 (45.6860)  loss: 1.0860 (1.0781)  acc1: 75.7576 (77.3583)  acc5: 91.8367 (92.1826)  time: 0.2655  data: 0.0001  max mem: 2237
[2024-01-20 13:14:16 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:01:21  flops: 45.6860 (45.6860)  loss: 1.0252 (1.0788)  acc1: 79.0000 (77.3978)  acc5: 91.9192 (92.1366)  time: 0.2664  data: 0.0001  max mem: 2237
[2024-01-20 13:14:19 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:01:18  flops: 45.6860 (45.6860)  loss: 1.0976 (1.0814)  acc1: 77.3196 (77.3445)  acc5: 91.9192 (92.1232)  time: 0.2655  data: 0.0001  max mem: 2237
[2024-01-20 13:14:22 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:01:16  flops: 45.6860 (45.6860)  loss: 1.0838 (1.0797)  acc1: 77.3196 (77.3881)  acc5: 91.7526 (92.1110)  time: 0.2652  data: 0.0001  max mem: 2237
[2024-01-20 13:14:24 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:01:13  flops: 45.6860 (45.6860)  loss: 1.0866 (1.0854)  acc1: 76.5306 (77.2303)  acc5: 91.7526 (92.0971)  time: 0.2658  data: 0.0001  max mem: 2237
[2024-01-20 13:14:27 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:01:10  flops: 45.6860 (45.6860)  loss: 1.2331 (1.0861)  acc1: 74.4898 (77.2257)  acc5: 91.6667 (92.1029)  time: 0.2653  data: 0.0001  max mem: 2237
[2024-01-20 13:14:30 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:01:07  flops: 45.6860 (45.6860)  loss: 1.0292 (1.0884)  acc1: 76.0417 (77.1746)  acc5: 91.6667 (92.0764)  time: 0.2647  data: 0.0001  max mem: 2237
[2024-01-20 13:14:32 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:01:04  flops: 45.6860 (45.6860)  loss: 1.0711 (1.0900)  acc1: 76.5306 (77.1716)  acc5: 90.9091 (92.0549)  time: 0.2646  data: 0.0001  max mem: 2237
[2024-01-20 13:14:35 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:01:02  flops: 45.6860 (45.6860)  loss: 1.2356 (1.0947)  acc1: 76.0000 (77.0696)  acc5: 90.8163 (92.0484)  time: 0.2649  data: 0.0001  max mem: 2237
[2024-01-20 13:14:37 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:59  flops: 45.6860 (45.6860)  loss: 1.1956 (1.0950)  acc1: 76.0000 (77.0962)  acc5: 91.6667 (92.0357)  time: 0.2660  data: 0.0001  max mem: 2237
[2024-01-20 13:14:40 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:56  flops: 45.6860 (45.6860)  loss: 1.0654 (1.0953)  acc1: 75.7576 (77.0808)  acc5: 91.8367 (92.0162)  time: 0.2660  data: 0.0001  max mem: 2237
[2024-01-20 13:14:43 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:54  flops: 45.6860 (45.6860)  loss: 1.0617 (1.0928)  acc1: 77.5510 (77.1544)  acc5: 91.8367 (92.0252)  time: 0.2659  data: 0.0001  max mem: 2237
[2024-01-20 13:14:45 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:51  flops: 45.6860 (45.6860)  loss: 1.0776 (1.0958)  acc1: 77.5510 (77.1184)  acc5: 91.7526 (91.9877)  time: 0.2661  data: 0.0001  max mem: 2237
[2024-01-20 13:14:48 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:48  flops: 45.6860 (45.6860)  loss: 1.1179 (1.0945)  acc1: 77.0833 (77.1470)  acc5: 91.7526 (92.0145)  time: 0.2652  data: 0.0001  max mem: 2237
[2024-01-20 13:14:51 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:45  flops: 45.6860 (45.6860)  loss: 1.0490 (1.0929)  acc1: 78.3505 (77.2014)  acc5: 91.8367 (92.0436)  time: 0.2636  data: 0.0001  max mem: 2237
[2024-01-20 13:14:53 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:43  flops: 45.6860 (45.6860)  loss: 1.0554 (1.0923)  acc1: 78.3505 (77.2173)  acc5: 91.7526 (92.0385)  time: 0.2646  data: 0.0001  max mem: 2237
[2024-01-20 13:14:56 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:40  flops: 45.6860 (45.6860)  loss: 1.0554 (1.0907)  acc1: 78.7879 (77.2436)  acc5: 92.7835 (92.0702)  time: 0.2656  data: 0.0001  max mem: 2237
[2024-01-20 13:14:59 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:37  flops: 45.6860 (45.6860)  loss: 1.0566 (1.0906)  acc1: 77.8947 (77.2599)  acc5: 92.7835 (92.0579)  time: 0.2650  data: 0.0001  max mem: 2237
[2024-01-20 13:15:01 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:35  flops: 45.6860 (45.6860)  loss: 1.0663 (1.0891)  acc1: 77.5510 (77.2818)  acc5: 91.5789 (92.0640)  time: 0.2658  data: 0.0001  max mem: 2237
[2024-01-20 13:15:04 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:32  flops: 45.6860 (45.6860)  loss: 1.0315 (1.0880)  acc1: 78.0000 (77.2999)  acc5: 91.9192 (92.0752)  time: 0.2665  data: 0.0001  max mem: 2237
[2024-01-20 13:15:07 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:29  flops: 45.6860 (45.6860)  loss: 1.0238 (1.0868)  acc1: 79.5918 (77.3168)  acc5: 93.7500 (92.0951)  time: 0.2659  data: 0.0001  max mem: 2237
[2024-01-20 13:15:09 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:26  flops: 45.6860 (45.6860)  loss: 1.0368 (1.0865)  acc1: 77.3196 (77.2815)  acc5: 93.7500 (92.1157)  time: 0.2662  data: 0.0001  max mem: 2237
[2024-01-20 13:15:12 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:24  flops: 45.6860 (45.6860)  loss: 1.0739 (1.0853)  acc1: 76.5306 (77.2919)  acc5: 92.9293 (92.1358)  time: 0.2659  data: 0.0001  max mem: 2237
[2024-01-20 13:15:15 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:21  flops: 45.6860 (45.6860)  loss: 1.0744 (1.0872)  acc1: 77.3196 (77.2762)  acc5: 91.8367 (92.1069)  time: 0.2650  data: 0.0001  max mem: 2237
[2024-01-20 13:15:17 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:18  flops: 45.6860 (45.6860)  loss: 1.1106 (1.0869)  acc1: 77.3196 (77.3086)  acc5: 90.8163 (92.0983)  time: 0.2653  data: 0.0001  max mem: 2237
[2024-01-20 13:15:20 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:16  flops: 45.6860 (45.6860)  loss: 1.0717 (1.0877)  acc1: 77.3196 (77.2963)  acc5: 92.6316 (92.1080)  time: 0.2650  data: 0.0001  max mem: 2237
[2024-01-20 13:15:23 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:13  flops: 45.6860 (45.6860)  loss: 1.0770 (1.0885)  acc1: 76.8421 (77.2615)  acc5: 92.6316 (92.1035)  time: 0.2645  data: 0.0001  max mem: 2237
[2024-01-20 13:15:25 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:10  flops: 45.6860 (45.6860)  loss: 1.0822 (1.0869)  acc1: 76.5306 (77.2718)  acc5: 91.9192 (92.1301)  time: 0.2658  data: 0.0001  max mem: 2237
[2024-01-20 13:15:28 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:08  flops: 45.6860 (45.6860)  loss: 1.0822 (1.0875)  acc1: 76.7677 (77.2602)  acc5: 91.9192 (92.1159)  time: 0.2668  data: 0.0001  max mem: 2237
[2024-01-20 13:15:31 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:05  flops: 45.6860 (45.6860)  loss: 1.1194 (1.0880)  acc1: 76.7677 (77.2369)  acc5: 90.9091 (92.1109)  time: 0.2664  data: 0.0001  max mem: 2237
[2024-01-20 13:15:33 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:02  flops: 45.6860 (45.6860)  loss: 1.1194 (1.0886)  acc1: 74.7475 (77.2037)  acc5: 91.8367 (92.1040)  time: 0.2663  data: 0.0001  max mem: 2237
[2024-01-20 13:15:36 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 45.6860 (45.6860)  loss: 1.0330 (1.0868)  acc1: 75.7895 (77.2612)  acc5: 91.8367 (92.1203)  time: 0.2666  data: 0.0001  max mem: 2237
[2024-01-20 13:15:36 root] (utils.py 307): INFO Test: Total time: 0:02:14 (0.2684 s / it)
[2024-01-20 13:17:49 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:17:53 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:17:58 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 13:17:59 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:12:27  flops: 45.6860 (45.6860)  loss: 1.2030 (1.2030)  acc1: 74.7475 (74.7475)  acc5: 90.9091 (90.9091)  time: 1.4957  data: 0.0008  max mem: 2227
[2024-01-20 13:18:02 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:18:02 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:03:13  flops: 45.6860 (45.6860)  loss: 1.1599 (1.1549)  acc1: 75.0000 (75.4435)  acc5: 90.9091 (91.0364)  time: 0.3944  data: 0.0002  max mem: 2232
[2024-01-20 13:18:05 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:40  flops: 45.6860 (45.6860)  loss: 1.0772 (1.0850)  acc1: 75.7576 (77.0165)  acc5: 91.5789 (91.8853)  time: 0.2769  data: 0.0001  max mem: 2237
[2024-01-20 13:18:05 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:18:08 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:29  flops: 45.6860 (45.6860)  loss: 1.0135 (1.0723)  acc1: 76.7677 (77.4565)  acc5: 93.8144 (92.0473)  time: 0.2773  data: 0.0001  max mem: 2237
[2024-01-20 13:18:10 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:20  flops: 45.6860 (45.6860)  loss: 1.0382 (1.0737)  acc1: 77.0833 (77.5043)  acc5: 92.0000 (91.9215)  time: 0.2742  data: 0.0001  max mem: 2237
[2024-01-20 13:18:11 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 13:18:13 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:02:16  flops: 45.6860 (45.6860)  loss: 1.1342 (1.0850)  acc1: 75.2577 (77.0400)  acc5: 91.8367 (92.0200)  time: 0.2791  data: 0.0001  max mem: 2237
[2024-01-20 13:18:15 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:35:24  flops: 45.6860 (45.6860)  loss: 1.2429 (1.2429)  acc1: 74.7475 (74.7475)  acc5: 87.8788 (87.8788)  time: 4.2485  data: 0.0007  max mem: 2148
[2024-01-20 13:18:18 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:02:28  flops: 45.6860 (45.6860)  loss: 1.1206 (1.0789)  acc1: 76.2887 (77.1968)  acc5: 92.0000 (92.1149)  time: 0.4063  data: 0.0001  max mem: 2237
[2024-01-20 13:18:19 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:06:35  flops: 45.6860 (45.6860)  loss: 1.1666 (1.1721)  acc1: 74.7475 (75.2568)  acc5: 91.5789 (90.6629)  time: 0.8077  data: 0.0002  max mem: 2151
[2024-01-20 13:18:24 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:05:03  flops: 45.6860 (45.6860)  loss: 1.0732 (1.0892)  acc1: 75.7576 (76.7250)  acc5: 91.8367 (91.7881)  time: 0.4522  data: 0.0001  max mem: 2154
[2024-01-20 13:18:25 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:02:46  flops: 45.6860 (45.6860)  loss: 1.0623 (1.0790)  acc1: 78.0000 (77.1879)  acc5: 91.7526 (92.1377)  time: 0.5977  data: 0.0001  max mem: 2237
[2024-01-20 13:18:28 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:04:26  flops: 45.6860 (45.6860)  loss: 1.0243 (1.0774)  acc1: 76.7677 (76.9964)  acc5: 92.9293 (91.8501)  time: 0.4350  data: 0.0001  max mem: 2154
[2024-01-20 13:18:32 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:02:57  flops: 45.6860 (45.6860)  loss: 1.0744 (1.0750)  acc1: 78.0000 (77.3333)  acc5: 92.0000 (92.2264)  time: 0.6769  data: 0.0001  max mem: 2237
[2024-01-20 13:18:32 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:04:05  flops: 45.6860 (45.6860)  loss: 1.0475 (1.0792)  acc1: 77.3196 (77.1315)  acc5: 91.8367 (91.7475)  time: 0.4273  data: 0.0001  max mem: 2154
[2024-01-20 13:18:37 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:03:50  flops: 45.6860 (45.6860)  loss: 1.1150 (1.0880)  acc1: 75.7576 (76.9000)  acc5: 91.8367 (91.8800)  time: 0.4252  data: 0.0001  max mem: 2154
[2024-01-20 13:18:39 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:03:04  flops: 45.6860 (45.6860)  loss: 1.0744 (1.0759)  acc1: 77.5510 (77.4107)  acc5: 92.8571 (92.2388)  time: 0.6757  data: 0.0001  max mem: 2237
[2024-01-20 13:18:41 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:03:39  flops: 45.6860 (45.6860)  loss: 1.1150 (1.0801)  acc1: 77.5510 (77.2135)  acc5: 92.8571 (91.9479)  time: 0.4270  data: 0.0001  max mem: 2154
[2024-01-20 13:18:45 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:03:29  flops: 45.6860 (45.6860)  loss: 1.0547 (1.0805)  acc1: 78.0000 (77.1449)  acc5: 91.9192 (91.9082)  time: 0.4293  data: 0.0001  max mem: 2154
[2024-01-20 13:18:45 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:03:08  flops: 45.6860 (45.6860)  loss: 1.0534 (1.0718)  acc1: 77.0000 (77.4314)  acc5: 91.9192 (92.2821)  time: 0.6762  data: 0.0001  max mem: 2237
[2024-01-20 13:18:50 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:03:21  flops: 45.6860 (45.6860)  loss: 1.0699 (1.0756)  acc1: 78.0000 (77.3459)  acc5: 92.0000 (92.1006)  time: 0.4282  data: 0.0001  max mem: 2154
[2024-01-20 13:18:52 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:03:11  flops: 45.6860 (45.6860)  loss: 1.0389 (1.0683)  acc1: 77.0000 (77.4933)  acc5: 91.9192 (92.3020)  time: 0.6791  data: 0.0001  max mem: 2237
[2024-01-20 13:18:54 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:03:14  flops: 45.6860 (45.6860)  loss: 1.0743 (1.0767)  acc1: 78.0000 (77.4107)  acc5: 92.8571 (92.0932)  time: 0.4276  data: 0.0001  max mem: 2154
[2024-01-20 13:18:58 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:03:08  flops: 45.6860 (45.6860)  loss: 1.0743 (1.0724)  acc1: 76.7677 (77.4516)  acc5: 91.9192 (92.1610)  time: 0.4295  data: 0.0001  max mem: 2154
[2024-01-20 13:18:59 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:03:12  flops: 45.6860 (45.6860)  loss: 1.0514 (1.0764)  acc1: 78.1250 (77.3917)  acc5: 92.0000 (92.2507)  time: 0.6816  data: 0.0001  max mem: 2237
[2024-01-20 13:19:02 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:03:02  flops: 45.6860 (45.6860)  loss: 1.0148 (1.0695)  acc1: 78.5714 (77.5576)  acc5: 91.8367 (92.1736)  time: 0.4309  data: 0.0001  max mem: 2154
[2024-01-20 13:19:06 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:03:12  flops: 45.6860 (45.6860)  loss: 1.0334 (1.0710)  acc1: 77.5510 (77.3840)  acc5: 92.9293 (92.2981)  time: 0.6812  data: 0.0001  max mem: 2237
[2024-01-20 13:19:07 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:02:56  flops: 45.6860 (45.6860)  loss: 1.0567 (1.0776)  acc1: 79.0000 (77.4590)  acc5: 91.6667 (92.0825)  time: 0.4318  data: 0.0001  max mem: 2154
[2024-01-20 13:19:11 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:02:50  flops: 45.6860 (45.6860)  loss: 1.0567 (1.0732)  acc1: 76.0000 (77.3374)  acc5: 92.9293 (92.1427)  time: 0.4318  data: 0.0001  max mem: 2154
[2024-01-20 13:19:13 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:03:11  flops: 45.6860 (45.6860)  loss: 1.0459 (1.0725)  acc1: 77.7778 (77.3695)  acc5: 92.8571 (92.2760)  time: 0.6820  data: 0.0001  max mem: 2237
[2024-01-20 13:19:15 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:02:45  flops: 45.6860 (45.6860)  loss: 1.0318 (1.0746)  acc1: 76.2887 (77.2973)  acc5: 91.9192 (92.1244)  time: 0.4308  data: 0.0001  max mem: 2154
[2024-01-20 13:19:20 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:03:09  flops: 45.6860 (45.6860)  loss: 1.0275 (1.0695)  acc1: 77.7778 (77.4744)  acc5: 93.8144 (92.3341)  time: 0.6862  data: 0.0001  max mem: 2237
[2024-01-20 13:19:20 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:02:40  flops: 45.6860 (45.6860)  loss: 1.0152 (1.0713)  acc1: 76.7677 (77.3800)  acc5: 92.0000 (92.1791)  time: 0.4351  data: 0.0001  max mem: 2154
[2024-01-20 13:19:24 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:02:35  flops: 45.6860 (45.6860)  loss: 1.0204 (1.0747)  acc1: 78.1250 (77.3153)  acc5: 92.8571 (92.1495)  time: 0.4345  data: 0.0001  max mem: 2154
[2024-01-20 13:19:26 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:03:07  flops: 45.6860 (45.6860)  loss: 1.0275 (1.0728)  acc1: 78.5714 (77.4102)  acc5: 92.8571 (92.2761)  time: 0.6833  data: 0.0001  max mem: 2237
[2024-01-20 13:19:28 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:02:30  flops: 45.6860 (45.6860)  loss: 1.0932 (1.0736)  acc1: 76.2887 (77.3323)  acc5: 91.9192 (92.1542)  time: 0.4347  data: 0.0001  max mem: 2154
[2024-01-20 13:19:33 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:02:25  flops: 45.6860 (45.6860)  loss: 1.0879 (1.0789)  acc1: 76.2887 (77.2180)  acc5: 91.8367 (92.0795)  time: 0.4346  data: 0.0001  max mem: 2154
[2024-01-20 13:19:33 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:03:04  flops: 45.6860 (45.6860)  loss: 1.0820 (1.0716)  acc1: 76.2887 (77.4395)  acc5: 91.8367 (92.2495)  time: 0.6827  data: 0.0001  max mem: 2237
[2024-01-20 13:19:37 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:02:20  flops: 45.6860 (45.6860)  loss: 1.0608 (1.0792)  acc1: 76.7677 (77.2410)  acc5: 91.7526 (92.0706)  time: 0.4317  data: 0.0001  max mem: 2154
[2024-01-20 13:19:40 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:03:00  flops: 45.6860 (45.6860)  loss: 1.0820 (1.0770)  acc1: 76.0000 (77.3080)  acc5: 91.8367 (92.1696)  time: 0.6832  data: 0.0001  max mem: 2237
[2024-01-20 13:19:41 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:02:15  flops: 45.6860 (45.6860)  loss: 1.0266 (1.0802)  acc1: 79.0000 (77.2964)  acc5: 91.9192 (92.0454)  time: 0.4338  data: 0.0001  max mem: 2154
[2024-01-20 13:19:46 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:02:10  flops: 45.6860 (45.6860)  loss: 1.1044 (1.0827)  acc1: 77.7778 (77.2528)  acc5: 91.9192 (92.0411)  time: 0.4333  data: 0.0001  max mem: 2154
[2024-01-20 13:19:47 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:02:57  flops: 45.6860 (45.6860)  loss: 1.0723 (1.0777)  acc1: 75.7576 (77.3210)  acc5: 91.8367 (92.1559)  time: 0.6815  data: 0.0001  max mem: 2237
[2024-01-20 13:19:50 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:02:06  flops: 45.6860 (45.6860)  loss: 1.0998 (1.0809)  acc1: 76.5306 (77.3052)  acc5: 91.9192 (92.0464)  time: 0.4327  data: 0.0001  max mem: 2154
[2024-01-20 13:19:54 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:02:53  flops: 45.6860 (45.6860)  loss: 1.0250 (1.0785)  acc1: 78.7879 (77.3522)  acc5: 91.9192 (92.1113)  time: 0.6845  data: 0.0001  max mem: 2237
[2024-01-20 13:19:54 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:02:01  flops: 45.6860 (45.6860)  loss: 1.0998 (1.0863)  acc1: 76.0000 (77.1862)  acc5: 91.8367 (92.0178)  time: 0.4323  data: 0.0001  max mem: 2154
[2024-01-20 13:19:59 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:01:56  flops: 45.6860 (45.6860)  loss: 1.2211 (1.0873)  acc1: 75.7576 (77.1665)  acc5: 91.8367 (92.0311)  time: 0.4322  data: 0.0001  max mem: 2154
[2024-01-20 13:20:00 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:02:48  flops: 45.6860 (45.6860)  loss: 1.0935 (1.0810)  acc1: 76.2887 (77.3010)  acc5: 91.9192 (92.0990)  time: 0.6835  data: 0.0001  max mem: 2237
[2024-01-20 13:20:03 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:01:52  flops: 45.6860 (45.6860)  loss: 1.0403 (1.0889)  acc1: 76.2887 (77.1300)  acc5: 91.0000 (92.0115)  time: 0.4314  data: 0.0001  max mem: 2154
[2024-01-20 13:20:07 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:02:44  flops: 45.6860 (45.6860)  loss: 1.0861 (1.0795)  acc1: 76.7677 (77.3467)  acc5: 91.7526 (92.0787)  time: 0.6824  data: 0.0001  max mem: 2237
[2024-01-20 13:20:07 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:01:47  flops: 45.6860 (45.6860)  loss: 1.0446 (1.0903)  acc1: 75.7576 (77.1326)  acc5: 90.9091 (91.9964)  time: 0.4313  data: 0.0001  max mem: 2154
[2024-01-20 13:20:12 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:01:42  flops: 45.6860 (45.6860)  loss: 1.1954 (1.0949)  acc1: 75.7576 (77.0396)  acc5: 91.0000 (91.9845)  time: 0.4327  data: 0.0001  max mem: 2154
[2024-01-20 13:20:14 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:02:39  flops: 45.6860 (45.6860)  loss: 1.0861 (1.0852)  acc1: 76.5306 (77.1994)  acc5: 91.8367 (92.0751)  time: 0.6836  data: 0.0001  max mem: 2237
[2024-01-20 13:20:16 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:01:38  flops: 45.6860 (45.6860)  loss: 1.2114 (1.0956)  acc1: 76.0417 (77.0563)  acc5: 91.9192 (91.9849)  time: 0.4345  data: 0.0001  max mem: 2154
[2024-01-20 13:20:20 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:01:33  flops: 45.6860 (45.6860)  loss: 1.0632 (1.0955)  acc1: 76.5306 (77.0458)  acc5: 92.0000 (91.9742)  time: 0.4337  data: 0.0001  max mem: 2154
[2024-01-20 13:20:21 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:02:34  flops: 45.6860 (45.6860)  loss: 1.2323 (1.0858)  acc1: 75.0000 (77.2045)  acc5: 91.8367 (92.0860)  time: 0.6819  data: 0.0001  max mem: 2237
[2024-01-20 13:20:25 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:01:29  flops: 45.6860 (45.6860)  loss: 1.0373 (1.0929)  acc1: 77.0000 (77.1172)  acc5: 92.8571 (91.9947)  time: 0.4340  data: 0.0001  max mem: 2154
[2024-01-20 13:20:28 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:02:29  flops: 45.6860 (45.6860)  loss: 1.0327 (1.0880)  acc1: 75.5102 (77.1543)  acc5: 91.6667 (92.0643)  time: 0.6806  data: 0.0001  max mem: 2237
[2024-01-20 13:20:29 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:01:24  flops: 45.6860 (45.6860)  loss: 1.0861 (1.0957)  acc1: 77.5510 (77.0955)  acc5: 91.7526 (91.9550)  time: 0.4342  data: 0.0001  max mem: 2154
[2024-01-20 13:20:33 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:01:20  flops: 45.6860 (45.6860)  loss: 1.0930 (1.0937)  acc1: 77.0833 (77.1090)  acc5: 91.9192 (91.9923)  time: 0.4329  data: 0.0001  max mem: 2154
[2024-01-20 13:20:35 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:02:24  flops: 45.6860 (45.6860)  loss: 1.0757 (1.0896)  acc1: 75.5102 (77.1443)  acc5: 90.9091 (92.0432)  time: 0.6805  data: 0.0001  max mem: 2237
[2024-01-20 13:20:38 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:01:15  flops: 45.6860 (45.6860)  loss: 1.0209 (1.0921)  acc1: 77.7778 (77.1491)  acc5: 92.8571 (92.0220)  time: 0.4293  data: 0.0001  max mem: 2154
[2024-01-20 13:20:41 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:02:18  flops: 45.6860 (45.6860)  loss: 1.2313 (1.0944)  acc1: 75.5102 (77.0546)  acc5: 90.8163 (92.0334)  time: 0.6825  data: 0.0001  max mem: 2237
[2024-01-20 13:20:42 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:01:11  flops: 45.6860 (45.6860)  loss: 1.0538 (1.0914)  acc1: 77.5510 (77.1666)  acc5: 91.7526 (92.0176)  time: 0.4299  data: 0.0001  max mem: 2154
[2024-01-20 13:20:46 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:01:06  flops: 45.6860 (45.6860)  loss: 1.0538 (1.0901)  acc1: 78.5714 (77.1943)  acc5: 92.8571 (92.0354)  time: 0.4338  data: 0.0001  max mem: 2154
[2024-01-20 13:20:48 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:02:13  flops: 45.6860 (45.6860)  loss: 1.1933 (1.0947)  acc1: 76.0000 (77.0817)  acc5: 91.9192 (92.0212)  time: 0.6845  data: 0.0001  max mem: 2237
[2024-01-20 13:20:51 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:01:02  flops: 45.6860 (45.6860)  loss: 1.0402 (1.0900)  acc1: 78.0000 (77.2035)  acc5: 92.7835 (92.0297)  time: 0.4321  data: 0.0001  max mem: 2154
[2024-01-20 13:20:55 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:57  flops: 45.6860 (45.6860)  loss: 1.0535 (1.0885)  acc1: 76.7677 (77.2160)  acc5: 91.9192 (92.0503)  time: 0.4327  data: 0.0001  max mem: 2154
[2024-01-20 13:20:55 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:02:08  flops: 45.6860 (45.6860)  loss: 1.0669 (1.0951)  acc1: 75.7576 (77.0633)  acc5: 92.0000 (91.9952)  time: 0.6840  data: 0.0001  max mem: 2237
[2024-01-20 13:20:59 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:53  flops: 45.6860 (45.6860)  loss: 1.0396 (1.0874)  acc1: 77.5510 (77.2358)  acc5: 91.9192 (92.0564)  time: 0.4338  data: 0.0001  max mem: 2154
[2024-01-20 13:21:02 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:02:02  flops: 45.6860 (45.6860)  loss: 1.0588 (1.0925)  acc1: 77.5510 (77.1408)  acc5: 92.7835 (92.0116)  time: 0.6843  data: 0.0001  max mem: 2237
[2024-01-20 13:21:04 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:48  flops: 45.6860 (45.6860)  loss: 1.0180 (1.0860)  acc1: 78.5714 (77.2464)  acc5: 92.8571 (92.0639)  time: 0.4326  data: 0.0001  max mem: 2154
[2024-01-20 13:21:08 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:44  flops: 45.6860 (45.6860)  loss: 1.0397 (1.0856)  acc1: 76.5306 (77.2155)  acc5: 92.8571 (92.0801)  time: 0.4339  data: 0.0001  max mem: 2154
[2024-01-20 13:21:09 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:01:56  flops: 45.6860 (45.6860)  loss: 1.0793 (1.0955)  acc1: 77.5510 (77.1119)  acc5: 91.8367 (91.9746)  time: 0.6852  data: 0.0001  max mem: 2237
[2024-01-20 13:21:12 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:39  flops: 45.6860 (45.6860)  loss: 1.0848 (1.0844)  acc1: 76.5306 (77.2225)  acc5: 92.9293 (92.1060)  time: 0.4336  data: 0.0001  max mem: 2154
[2024-01-20 13:21:16 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:01:50  flops: 45.6860 (45.6860)  loss: 1.1059 (1.0942)  acc1: 77.0833 (77.1407)  acc5: 91.7526 (92.0081)  time: 0.6837  data: 0.0001  max mem: 2237
[2024-01-20 13:21:17 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:35  flops: 45.6860 (45.6860)  loss: 1.0892 (1.0864)  acc1: 76.5306 (77.1892)  acc5: 92.7835 (92.0827)  time: 0.4316  data: 0.0001  max mem: 2154
[2024-01-20 13:21:21 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:30  flops: 45.6860 (45.6860)  loss: 1.1466 (1.0862)  acc1: 76.5306 (77.2141)  acc5: 89.8990 (92.0605)  time: 0.4317  data: 0.0001  max mem: 2154
[2024-01-20 13:21:22 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:01:45  flops: 45.6860 (45.6860)  loss: 1.0503 (1.0926)  acc1: 79.1667 (77.1952)  acc5: 91.8367 (92.0313)  time: 0.6775  data: 0.0001  max mem: 2237
[2024-01-20 13:21:25 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:26  flops: 45.6860 (45.6860)  loss: 1.0847 (1.0873)  acc1: 78.5714 (77.2201)  acc5: 92.6316 (92.0595)  time: 0.4308  data: 0.0001  max mem: 2154
[2024-01-20 13:21:29 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:01:39  flops: 45.6860 (45.6860)  loss: 1.0623 (1.0920)  acc1: 78.3505 (77.2173)  acc5: 91.7526 (92.0235)  time: 0.6790  data: 0.0001  max mem: 2237
[2024-01-20 13:21:30 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:22  flops: 45.6860 (45.6860)  loss: 1.0838 (1.0883)  acc1: 76.5306 (77.1757)  acc5: 92.6316 (92.0493)  time: 0.4297  data: 0.0001  max mem: 2154
[2024-01-20 13:21:34 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:17  flops: 45.6860 (45.6860)  loss: 1.0954 (1.0865)  acc1: 76.0000 (77.1967)  acc5: 91.9192 (92.0660)  time: 0.4318  data: 0.0001  max mem: 2154
[2024-01-20 13:21:36 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:01:33  flops: 45.6860 (45.6860)  loss: 1.0594 (1.0904)  acc1: 77.7778 (77.2378)  acc5: 92.7835 (92.0557)  time: 0.6833  data: 0.0001  max mem: 2237
[2024-01-20 13:21:38 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:13  flops: 45.6860 (45.6860)  loss: 1.1063 (1.0870)  acc1: 77.7778 (77.1954)  acc5: 91.9192 (92.0597)  time: 0.4334  data: 0.0001  max mem: 2154
[2024-01-20 13:21:43 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:08  flops: 45.6860 (45.6860)  loss: 1.1323 (1.0879)  acc1: 76.5306 (77.1544)  acc5: 91.6667 (92.0538)  time: 0.4333  data: 0.0001  max mem: 2154
[2024-01-20 13:21:43 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:01:27  flops: 45.6860 (45.6860)  loss: 1.0574 (1.0904)  acc1: 77.8947 (77.2571)  acc5: 92.7835 (92.0410)  time: 0.6810  data: 0.0001  max mem: 2237
[2024-01-20 13:21:47 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:04  flops: 45.6860 (45.6860)  loss: 1.1686 (1.0887)  acc1: 75.0000 (77.1021)  acc5: 91.8367 (92.0500)  time: 0.4330  data: 0.0001  max mem: 2154
[2024-01-20 13:21:50 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:01:21  flops: 45.6860 (45.6860)  loss: 1.0688 (1.0889)  acc1: 77.8947 (77.2791)  acc5: 91.9192 (92.0448)  time: 0.6816  data: 0.0001  max mem: 2237
[2024-01-20 13:21:51 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 45.6860 (45.6860)  loss: 1.0373 (1.0868)  acc1: 75.7576 (77.1573)  acc5: 91.9192 (92.0633)  time: 0.4348  data: 0.0001  max mem: 2154
[2024-01-20 13:21:51 root] (utils.py 307): INFO Test: Total time: 0:03:40 (0.4404 s / it)
[2024-01-20 13:21:51 root] (engine.py 118): INFO * Acc@1 77.157 Acc@5 92.063 loss 1.087 flops 45.686
[2024-01-20 13:21:51 root] (main_tome.py 377): INFO Accuracy of the network on the 50000 test images: 77.2%
[2024-01-20 13:21:53 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:01:14  flops: 45.6860 (45.6860)  loss: 1.0293 (1.0877)  acc1: 78.5714 (77.2919)  acc5: 91.9192 (92.0645)  time: 0.5105  data: 0.0001  max mem: 2237
[2024-01-20 13:21:56 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:01:06  flops: 45.6860 (45.6860)  loss: 1.0172 (1.0866)  acc1: 78.5714 (77.2959)  acc5: 93.8775 (92.0873)  time: 0.3013  data: 0.0001  max mem: 2237
[2024-01-20 13:21:58 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:01:00  flops: 45.6860 (45.6860)  loss: 1.0325 (1.0864)  acc1: 76.5306 (77.2637)  acc5: 93.8775 (92.1081)  time: 0.2661  data: 0.0001  max mem: 2237
[2024-01-20 13:22:01 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:53  flops: 45.6860 (45.6860)  loss: 1.0687 (1.0853)  acc1: 77.0833 (77.2696)  acc5: 93.0000 (92.1283)  time: 0.2656  data: 0.0001  max mem: 2237
[2024-01-20 13:22:04 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:46  flops: 45.6860 (45.6860)  loss: 1.0742 (1.0871)  acc1: 77.3196 (77.2496)  acc5: 91.8367 (92.0997)  time: 0.2648  data: 0.0001  max mem: 2237
[2024-01-20 13:22:06 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:40  flops: 45.6860 (45.6860)  loss: 1.1065 (1.0868)  acc1: 77.5510 (77.2755)  acc5: 90.8163 (92.0888)  time: 0.2650  data: 0.0001  max mem: 2237
[2024-01-20 13:22:09 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:34  flops: 45.6860 (45.6860)  loss: 1.0692 (1.0877)  acc1: 77.3196 (77.2640)  acc5: 92.6316 (92.0964)  time: 0.2646  data: 0.0001  max mem: 2237
[2024-01-20 13:22:12 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:28  flops: 45.6860 (45.6860)  loss: 1.0733 (1.0885)  acc1: 77.3196 (77.2322)  acc5: 92.6316 (92.0945)  time: 0.2641  data: 0.0001  max mem: 2237
[2024-01-20 13:22:14 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:22  flops: 45.6860 (45.6860)  loss: 1.0733 (1.0868)  acc1: 77.0000 (77.2453)  acc5: 92.0000 (92.1213)  time: 0.2656  data: 0.0001  max mem: 2237
[2024-01-20 13:22:17 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:16  flops: 45.6860 (45.6860)  loss: 1.0723 (1.0874)  acc1: 77.0000 (77.2300)  acc5: 92.0000 (92.1051)  time: 0.2666  data: 0.0001  max mem: 2237
[2024-01-20 13:22:20 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:10  flops: 45.6860 (45.6860)  loss: 1.1220 (1.0879)  acc1: 76.7677 (77.2073)  acc5: 90.8163 (92.0961)  time: 0.2662  data: 0.0001  max mem: 2237
[2024-01-20 13:22:22 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:05  flops: 45.6860 (45.6860)  loss: 1.1220 (1.0884)  acc1: 74.7475 (77.1788)  acc5: 91.9192 (92.0936)  time: 0.2662  data: 0.0001  max mem: 2237
[2024-01-20 13:22:25 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 45.6860 (45.6860)  loss: 1.0294 (1.0867)  acc1: 77.5510 (77.2367)  acc5: 91.9192 (92.1081)  time: 0.2663  data: 0.0001  max mem: 2237
[2024-01-20 13:22:25 root] (utils.py 307): INFO Test: Total time: 0:04:26 (0.5340 s / it)
[2024-01-20 13:22:25 root] (engine.py 118): INFO * Acc@1 77.237 Acc@5 92.108 loss 1.087 flops 45.686
[2024-01-20 13:22:25 root] (main_tome.py 377): INFO Accuracy of the network on the 50000 test images: 77.2%
[2024-01-20 13:22:34 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:22:38 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:22:43 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 13:22:44 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:11:32  flops: 45.6860 (45.6860)  loss: 1.2397 (1.2397)  acc1: 74.7475 (74.7475)  acc5: 87.8788 (87.8788)  time: 1.3856  data: 0.0007  max mem: 2148
[2024-01-20 13:22:47 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:53  flops: 45.6860 (45.6860)  loss: 1.1692 (1.1714)  acc1: 75.2577 (75.2568)  acc5: 91.5789 (90.6629)  time: 0.3534  data: 0.0001  max mem: 2151
[2024-01-20 13:22:49 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:23  flops: 45.6860 (45.6860)  loss: 1.0702 (1.0884)  acc1: 75.7895 (76.7736)  acc5: 91.8367 (91.7881)  time: 0.2441  data: 0.0001  max mem: 2154
[2024-01-20 13:22:51 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:10  flops: 45.6860 (45.6860)  loss: 1.0241 (1.0775)  acc1: 76.7677 (77.0292)  acc5: 92.9293 (91.8501)  time: 0.2348  data: 0.0001  max mem: 2154
[2024-01-20 13:22:54 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:02  flops: 45.6860 (45.6860)  loss: 1.0514 (1.0794)  acc1: 77.3196 (77.1066)  acc5: 91.8367 (91.7226)  time: 0.2309  data: 0.0001  max mem: 2154
[2024-01-20 13:22:56 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:01:56  flops: 45.6860 (45.6860)  loss: 1.1107 (1.0881)  acc1: 75.7576 (76.8600)  acc5: 91.8367 (91.8600)  time: 0.2301  data: 0.0001  max mem: 2154
[2024-01-20 13:22:58 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:01:51  flops: 45.6860 (45.6860)  loss: 1.1107 (1.0801)  acc1: 77.7778 (77.1801)  acc5: 92.7083 (91.8978)  time: 0.2310  data: 0.0001  max mem: 2154
[2024-01-20 13:23:01 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:01:47  flops: 45.6860 (45.6860)  loss: 1.0571 (1.0807)  acc1: 78.0000 (77.1019)  acc5: 91.8367 (91.8795)  time: 0.2319  data: 0.0001  max mem: 2154
[2024-01-20 13:23:03 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:01:44  flops: 45.6860 (45.6860)  loss: 1.0748 (1.0759)  acc1: 78.0000 (77.3333)  acc5: 92.0000 (92.0629)  time: 0.2316  data: 0.0001  max mem: 2154
[2024-01-20 13:23:09 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:23:13 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:23:18 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 13:23:20 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:11:37  flops: 45.6860 (45.6860)  loss: 1.2158 (1.2158)  acc1: 74.7475 (74.7475)  acc5: 90.9091 (90.9091)  time: 1.3946  data: 0.0007  max mem: 2143
[2024-01-20 13:23:22 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:55  flops: 45.6860 (45.6860)  loss: 1.1662 (1.1660)  acc1: 75.7895 (75.3501)  acc5: 90.9091 (91.2232)  time: 0.3589  data: 0.0002  max mem: 2149
[2024-01-20 13:23:25 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:25  flops: 45.6860 (45.6860)  loss: 1.0947 (1.0960)  acc1: 75.7895 (76.2877)  acc5: 91.5789 (91.9339)  time: 0.2482  data: 0.0001  max mem: 2150
[2024-01-20 13:23:27 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:11  flops: 45.6860 (45.6860)  loss: 1.0405 (1.0807)  acc1: 75.7576 (76.8978)  acc5: 92.9293 (92.0802)  time: 0.2378  data: 0.0001  max mem: 2151
[2024-01-20 13:23:29 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:03  flops: 45.6860 (45.6860)  loss: 1.0626 (1.0819)  acc1: 77.0833 (76.9575)  acc5: 91.9192 (91.9712)  time: 0.2341  data: 0.0001  max mem: 2151
[2024-01-20 13:23:32 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:01:58  flops: 45.6860 (45.6860)  loss: 1.1322 (1.0916)  acc1: 75.5102 (76.5800)  acc5: 91.6667 (92.0200)  time: 0.2335  data: 0.0001  max mem: 2151
[2024-01-20 13:23:34 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:01:53  flops: 45.6860 (45.6860)  loss: 1.1322 (1.0838)  acc1: 75.7576 (76.9462)  acc5: 92.9293 (92.1483)  time: 0.2343  data: 0.0001  max mem: 2151
[2024-01-20 13:23:36 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:01:49  flops: 45.6860 (45.6860)  loss: 1.0579 (1.0833)  acc1: 78.0000 (76.9440)  acc5: 92.7835 (92.1808)  time: 0.2351  data: 0.0001  max mem: 2151
[2024-01-20 13:23:39 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:01:45  flops: 45.6860 (45.6860)  loss: 1.0609 (1.0793)  acc1: 76.5306 (77.0692)  acc5: 92.0000 (92.2893)  time: 0.2348  data: 0.0001  max mem: 2151
[2024-01-20 13:23:41 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:01:42  flops: 45.6860 (45.6860)  loss: 1.0718 (1.0796)  acc1: 77.0000 (77.1867)  acc5: 92.8571 (92.2836)  time: 0.2345  data: 0.0001  max mem: 2151
[2024-01-20 13:23:43 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:01:39  flops: 45.6860 (45.6860)  loss: 1.0460 (1.0746)  acc1: 77.7778 (77.3103)  acc5: 91.9192 (92.3426)  time: 0.2350  data: 0.0001  max mem: 2151
[2024-01-20 13:23:46 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:01:36  flops: 45.6860 (45.6860)  loss: 1.0304 (1.0715)  acc1: 77.7778 (77.3465)  acc5: 92.0000 (92.3754)  time: 0.2359  data: 0.0001  max mem: 2151
[2024-01-20 13:23:48 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:01:33  flops: 45.6860 (45.6860)  loss: 1.0469 (1.0794)  acc1: 77.0833 (77.2739)  acc5: 92.0000 (92.2928)  time: 0.2361  data: 0.0001  max mem: 2151
[2024-01-20 13:23:50 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:01:30  flops: 45.6860 (45.6860)  loss: 1.0469 (1.0737)  acc1: 78.5714 (77.2985)  acc5: 93.0000 (92.3525)  time: 0.2357  data: 0.0001  max mem: 2151
[2024-01-20 13:23:53 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:01:28  flops: 45.6860 (45.6860)  loss: 1.0623 (1.0749)  acc1: 76.7677 (77.2324)  acc5: 92.8571 (92.3194)  time: 0.2360  data: 0.0001  max mem: 2151
[2024-01-20 13:23:55 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:01:25  flops: 45.6860 (45.6860)  loss: 1.0424 (1.0720)  acc1: 76.7677 (77.3463)  acc5: 92.8571 (92.3611)  time: 0.2390  data: 0.0001  max mem: 2151
[2024-01-20 13:23:58 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:01:23  flops: 45.6860 (45.6860)  loss: 1.0424 (1.0750)  acc1: 79.1667 (77.3216)  acc5: 92.8571 (92.3077)  time: 0.2379  data: 0.0001  max mem: 2151
[2024-01-20 13:24:00 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:01:20  flops: 45.6860 (45.6860)  loss: 1.0831 (1.0741)  acc1: 76.7677 (77.3800)  acc5: 91.8367 (92.2793)  time: 0.2382  data: 0.0001  max mem: 2151
[2024-01-20 13:24:02 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:01:17  flops: 45.6860 (45.6860)  loss: 1.0790 (1.0794)  acc1: 75.7576 (77.2067)  acc5: 91.8367 (92.2146)  time: 0.2386  data: 0.0001  max mem: 2151
[2024-01-20 13:24:05 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:01:15  flops: 45.6860 (45.6860)  loss: 1.0759 (1.0802)  acc1: 75.7576 (77.2356)  acc5: 91.7526 (92.1879)  time: 0.2364  data: 0.0001  max mem: 2153
[2024-01-20 13:24:07 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:01:12  flops: 45.6860 (45.6860)  loss: 1.0374 (1.0805)  acc1: 79.0000 (77.2964)  acc5: 91.8367 (92.1721)  time: 0.2371  data: 0.0001  max mem: 2153
[2024-01-20 13:24:09 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:01:10  flops: 45.6860 (45.6860)  loss: 1.1002 (1.0828)  acc1: 77.3196 (77.2624)  acc5: 91.9192 (92.1618)  time: 0.2364  data: 0.0001  max mem: 2153
[2024-01-20 13:24:12 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:01:07  flops: 45.6860 (45.6860)  loss: 1.0873 (1.0816)  acc1: 77.3196 (77.2960)  acc5: 91.7526 (92.1156)  time: 0.2362  data: 0.0001  max mem: 2153
[2024-01-20 13:24:14 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:01:05  flops: 45.6860 (45.6860)  loss: 1.0911 (1.0870)  acc1: 76.7677 (77.1553)  acc5: 91.0000 (92.1015)  time: 0.2368  data: 0.0001  max mem: 2153
[2024-01-20 13:24:17 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:01:02  flops: 45.6860 (45.6860)  loss: 1.2279 (1.0877)  acc1: 75.0000 (77.1285)  acc5: 91.0000 (92.1072)  time: 0.2363  data: 0.0001  max mem: 2153
[2024-01-20 13:24:19 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:01:00  flops: 45.6860 (45.6860)  loss: 1.0357 (1.0899)  acc1: 75.5102 (77.0732)  acc5: 91.0000 (92.0764)  time: 0.2357  data: 0.0001  max mem: 2153
[2024-01-20 13:24:21 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:57  flops: 45.6860 (45.6860)  loss: 1.0611 (1.0915)  acc1: 75.7576 (77.0819)  acc5: 90.7216 (92.0471)  time: 0.2358  data: 0.0001  max mem: 2153
[2024-01-20 13:24:24 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:55  flops: 45.6860 (45.6860)  loss: 1.2395 (1.0965)  acc1: 75.7576 (76.9870)  acc5: 90.8163 (92.0334)  time: 0.2361  data: 0.0001  max mem: 2153
[2024-01-20 13:24:26 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:53  flops: 45.6860 (45.6860)  loss: 1.2108 (1.0969)  acc1: 77.0000 (77.0165)  acc5: 91.9192 (92.0284)  time: 0.2370  data: 0.0001  max mem: 2153
[2024-01-20 13:24:28 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:50  flops: 45.6860 (45.6860)  loss: 1.0742 (1.0971)  acc1: 77.0833 (77.0213)  acc5: 91.8367 (92.0092)  time: 0.2371  data: 0.0001  max mem: 2153
[2024-01-20 13:24:31 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:48  flops: 45.6860 (45.6860)  loss: 1.0535 (1.0947)  acc1: 77.8947 (77.1002)  acc5: 91.8367 (92.0252)  time: 0.2369  data: 0.0001  max mem: 2153
[2024-01-20 13:24:33 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:45  flops: 45.6860 (45.6860)  loss: 1.0825 (1.0977)  acc1: 76.7677 (77.0530)  acc5: 91.8367 (91.9910)  time: 0.2370  data: 0.0001  max mem: 2153
[2024-01-20 13:24:35 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:43  flops: 45.6860 (45.6860)  loss: 1.0816 (1.0961)  acc1: 77.7778 (77.0931)  acc5: 91.9192 (92.0240)  time: 0.2363  data: 0.0001  max mem: 2153
[2024-01-20 13:24:38 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:40  flops: 45.6860 (45.6860)  loss: 1.0666 (1.0945)  acc1: 78.5714 (77.1429)  acc5: 91.8367 (92.0436)  time: 0.2347  data: 0.0001  max mem: 2153
[2024-01-20 13:24:40 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:38  flops: 45.6860 (45.6860)  loss: 1.0637 (1.0939)  acc1: 78.3505 (77.1636)  acc5: 91.7526 (92.0385)  time: 0.2353  data: 0.0001  max mem: 2153
[2024-01-20 13:24:43 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:36  flops: 45.6860 (45.6860)  loss: 1.0637 (1.0925)  acc1: 78.5714 (77.1826)  acc5: 92.7835 (92.0673)  time: 0.2362  data: 0.0001  max mem: 2153
[2024-01-20 13:24:45 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:33  flops: 45.6860 (45.6860)  loss: 1.0662 (1.0925)  acc1: 78.5714 (77.2148)  acc5: 92.7835 (92.0494)  time: 0.2357  data: 0.0001  max mem: 2153
[2024-01-20 13:24:47 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:31  flops: 45.6860 (45.6860)  loss: 1.0677 (1.0907)  acc1: 77.8947 (77.2407)  acc5: 91.5789 (92.0613)  time: 0.2362  data: 0.0001  max mem: 2153
[2024-01-20 13:24:50 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:28  flops: 45.6860 (45.6860)  loss: 1.0365 (1.0896)  acc1: 78.5714 (77.2465)  acc5: 91.9192 (92.0778)  time: 0.2370  data: 0.0001  max mem: 2153
[2024-01-20 13:24:52 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:26  flops: 45.6860 (45.6860)  loss: 1.0290 (1.0883)  acc1: 78.5714 (77.2621)  acc5: 93.7500 (92.1003)  time: 0.2364  data: 0.0001  max mem: 2153
[2024-01-20 13:24:54 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:23  flops: 45.6860 (45.6860)  loss: 1.0338 (1.0880)  acc1: 77.3196 (77.2231)  acc5: 93.7500 (92.1284)  time: 0.2367  data: 0.0001  max mem: 2153
[2024-01-20 13:24:57 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:21  flops: 45.6860 (45.6860)  loss: 1.0769 (1.0868)  acc1: 77.0833 (77.2299)  acc5: 93.0000 (92.1556)  time: 0.2364  data: 0.0001  max mem: 2153
[2024-01-20 13:24:59 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:19  flops: 45.6860 (45.6860)  loss: 1.0805 (1.0888)  acc1: 76.7677 (77.2013)  acc5: 90.9091 (92.1311)  time: 0.2360  data: 0.0001  max mem: 2153
[2024-01-20 13:25:01 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:16  flops: 45.6860 (45.6860)  loss: 1.0961 (1.0885)  acc1: 77.3196 (77.2377)  acc5: 90.8163 (92.1219)  time: 0.2360  data: 0.0001  max mem: 2153
[2024-01-20 13:25:04 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:14  flops: 45.6860 (45.6860)  loss: 1.0726 (1.0893)  acc1: 77.3196 (77.2294)  acc5: 92.9293 (92.1311)  time: 0.2352  data: 0.0001  max mem: 2153
[2024-01-20 13:25:06 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:11  flops: 45.6860 (45.6860)  loss: 1.0726 (1.0902)  acc1: 76.8421 (77.1938)  acc5: 92.9293 (92.1216)  time: 0.2348  data: 0.0001  max mem: 2153
[2024-01-20 13:25:08 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:09  flops: 45.6860 (45.6860)  loss: 1.0740 (1.0885)  acc1: 77.5510 (77.2122)  acc5: 92.7083 (92.1411)  time: 0.2361  data: 0.0001  max mem: 2153
[2024-01-20 13:25:11 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:07  flops: 45.6860 (45.6860)  loss: 1.0740 (1.0892)  acc1: 77.7778 (77.2040)  acc5: 91.9192 (92.1267)  time: 0.2370  data: 0.0001  max mem: 2153
[2024-01-20 13:25:13 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:04  flops: 45.6860 (45.6860)  loss: 1.1308 (1.0899)  acc1: 77.0000 (77.1734)  acc5: 91.0000 (92.1194)  time: 0.2365  data: 0.0001  max mem: 2153
[2024-01-20 13:25:16 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:02  flops: 45.6860 (45.6860)  loss: 1.1336 (1.0903)  acc1: 75.5102 (77.1415)  acc5: 91.8367 (92.1164)  time: 0.2363  data: 0.0001  max mem: 2153
[2024-01-20 13:25:18 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 45.6860 (45.6860)  loss: 1.0341 (1.0884)  acc1: 75.7576 (77.2021)  acc5: 91.9192 (92.1325)  time: 0.2368  data: 0.0001  max mem: 2153
[2024-01-20 13:25:18 root] (utils.py 307): INFO Test: Total time: 0:01:59 (0.2390 s / it)
[2024-01-20 13:25:18 root] (engine.py 118): INFO * Acc@1 77.202 Acc@5 92.133 loss 1.088 flops 45.686
[2024-01-20 13:25:18 root] (main_tome.py 377): INFO Accuracy of the network on the 50000 test images: 77.2%
[2024-01-20 13:25:45 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:25:48 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:25:53 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 13:25:55 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:12:13  flops: 45.6860 (45.6860)  loss: 1.2164 (1.2164)  acc1: 74.7475 (74.7475)  acc5: 90.9091 (90.9091)  time: 1.4679  data: 0.0008  max mem: 2149
[2024-01-20 13:25:57 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:03:00  flops: 45.6860 (45.6860)  loss: 1.1614 (1.1619)  acc1: 75.2577 (75.6303)  acc5: 90.9091 (90.9430)  time: 0.3686  data: 0.0002  max mem: 2153
[2024-01-20 13:26:00 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:28  flops: 45.6860 (45.6860)  loss: 1.0750 (1.0910)  acc1: 76.2887 (76.6278)  acc5: 91.0000 (91.8367)  time: 0.2514  data: 0.0001  max mem: 2155
[2024-01-20 13:26:02 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:14  flops: 45.6860 (45.6860)  loss: 1.0316 (1.0769)  acc1: 76.7677 (77.2921)  acc5: 92.9293 (92.0145)  time: 0.2403  data: 0.0001  max mem: 2155
[2024-01-20 13:26:04 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:05  flops: 45.6860 (45.6860)  loss: 1.0511 (1.0747)  acc1: 77.3196 (77.4298)  acc5: 92.0000 (91.8966)  time: 0.2361  data: 0.0001  max mem: 2155
[2024-01-20 13:26:07 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:01:59  flops: 45.6860 (45.6860)  loss: 1.1236 (1.0845)  acc1: 75.5102 (76.9800)  acc5: 91.6667 (91.9600)  time: 0.2354  data: 0.0001  max mem: 2155
[2024-01-20 13:26:09 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:01:54  flops: 45.6860 (45.6860)  loss: 1.1269 (1.0792)  acc1: 75.7576 (77.3137)  acc5: 92.9293 (92.0815)  time: 0.2363  data: 0.0001  max mem: 2155
[2024-01-20 13:26:18 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:26:22 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:26:27 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 13:26:28 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:11:30  flops: 45.6860 (45.6860)  loss: 1.1872 (1.1872)  acc1: 72.7273 (72.7273)  acc5: 91.9192 (91.9192)  time: 1.3802  data: 0.0007  max mem: 2149
[2024-01-20 13:26:31 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:59  flops: 45.6860 (45.6860)  loss: 1.1702 (1.1651)  acc1: 75.7576 (75.4435)  acc5: 90.9091 (91.0364)  time: 0.3670  data: 0.0002  max mem: 2153
[2024-01-20 13:26:33 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:29  flops: 45.6860 (45.6860)  loss: 1.0591 (1.0901)  acc1: 76.0417 (76.4820)  acc5: 91.7526 (91.7881)  time: 0.2588  data: 0.0001  max mem: 2155
[2024-01-20 13:26:36 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:16  flops: 45.6860 (45.6860)  loss: 1.0293 (1.0750)  acc1: 76.7677 (76.9635)  acc5: 92.9293 (91.8173)  time: 0.2486  data: 0.0001  max mem: 2155
[2024-01-20 13:26:38 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:08  flops: 45.6860 (45.6860)  loss: 1.0584 (1.0795)  acc1: 77.3196 (76.9326)  acc5: 92.0000 (91.7475)  time: 0.2448  data: 0.0001  max mem: 2155
[2024-01-20 13:26:41 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:02:02  flops: 45.6860 (45.6860)  loss: 1.1211 (1.0879)  acc1: 76.7677 (76.7600)  acc5: 91.8367 (91.8200)  time: 0.2441  data: 0.0001  max mem: 2155
[2024-01-20 13:26:43 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:01:57  flops: 45.6860 (45.6860)  loss: 1.1051 (1.0805)  acc1: 77.3196 (77.1300)  acc5: 92.9293 (91.9980)  time: 0.2450  data: 0.0001  max mem: 2155
[2024-01-20 13:26:45 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:01:53  flops: 45.6860 (45.6860)  loss: 1.0675 (1.0805)  acc1: 77.7778 (77.0014)  acc5: 92.7835 (91.9943)  time: 0.2460  data: 0.0001  max mem: 2155
[2024-01-20 13:26:48 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:01:50  flops: 45.6860 (45.6860)  loss: 1.0805 (1.0773)  acc1: 76.2887 (77.0566)  acc5: 92.0000 (92.1006)  time: 0.2458  data: 0.0001  max mem: 2155
[2024-01-20 13:26:50 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:01:46  flops: 45.6860 (45.6860)  loss: 1.0834 (1.0780)  acc1: 77.0000 (77.2091)  acc5: 91.8367 (92.0708)  time: 0.2455  data: 0.0001  max mem: 2155
[2024-01-20 13:26:53 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:01:43  flops: 45.6860 (45.6860)  loss: 1.0648 (1.0724)  acc1: 77.3196 (77.3204)  acc5: 91.8367 (92.1106)  time: 0.2460  data: 0.0001  max mem: 2155
[2024-01-20 13:26:55 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:01:40  flops: 45.6860 (45.6860)  loss: 1.0238 (1.0692)  acc1: 78.1250 (77.3924)  acc5: 92.0000 (92.1736)  time: 0.2470  data: 0.0001  max mem: 2155
[2024-01-20 13:26:58 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:01:37  flops: 45.6860 (45.6860)  loss: 1.0269 (1.0761)  acc1: 78.1250 (77.2655)  acc5: 92.0000 (92.1414)  time: 0.2473  data: 0.0001  max mem: 2155
[2024-01-20 13:27:00 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:01:34  flops: 45.6860 (45.6860)  loss: 1.0269 (1.0711)  acc1: 78.5714 (77.2752)  acc5: 92.8571 (92.2049)  time: 0.2469  data: 0.0001  max mem: 2155
[2024-01-20 13:27:03 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:01:32  flops: 45.6860 (45.6860)  loss: 1.0408 (1.0724)  acc1: 77.7778 (77.2829)  acc5: 92.8571 (92.1678)  time: 0.2470  data: 0.0001  max mem: 2155
[2024-01-20 13:27:05 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:01:29  flops: 45.6860 (45.6860)  loss: 1.0433 (1.0689)  acc1: 77.7778 (77.3463)  acc5: 92.8571 (92.2195)  time: 0.2496  data: 0.0001  max mem: 2155
[2024-01-20 13:27:08 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:01:26  flops: 45.6860 (45.6860)  loss: 1.0433 (1.0720)  acc1: 77.5510 (77.3216)  acc5: 92.8571 (92.1748)  time: 0.2485  data: 0.0001  max mem: 2155
[2024-01-20 13:27:10 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:01:24  flops: 45.6860 (45.6860)  loss: 1.0789 (1.0708)  acc1: 75.7576 (77.3263)  acc5: 92.5532 (92.2018)  time: 0.2487  data: 0.0001  max mem: 2156
[2024-01-20 13:27:13 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:01:21  flops: 45.6860 (45.6860)  loss: 1.0682 (1.0761)  acc1: 75.5102 (77.2236)  acc5: 91.9192 (92.1189)  time: 0.2489  data: 0.0001  max mem: 2156
[2024-01-20 13:27:15 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:01:18  flops: 45.6860 (45.6860)  loss: 1.0682 (1.0762)  acc1: 77.7778 (77.2570)  acc5: 90.8163 (92.1079)  time: 0.2471  data: 0.0001  max mem: 2159
[2024-01-20 13:27:18 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:01:16  flops: 45.6860 (45.6860)  loss: 1.0314 (1.0772)  acc1: 79.3814 (77.2914)  acc5: 91.8367 (92.0809)  time: 0.2478  data: 0.0001  max mem: 2159
[2024-01-20 13:27:20 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:01:13  flops: 45.6860 (45.6860)  loss: 1.0977 (1.0797)  acc1: 78.7879 (77.2383)  acc5: 91.7526 (92.0556)  time: 0.2472  data: 0.0001  max mem: 2159
[2024-01-20 13:27:23 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:01:10  flops: 45.6860 (45.6860)  loss: 1.0826 (1.0783)  acc1: 77.3196 (77.2637)  acc5: 91.7526 (92.0557)  time: 0.2472  data: 0.0001  max mem: 2159
[2024-01-20 13:27:25 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:01:08  flops: 45.6860 (45.6860)  loss: 1.0836 (1.0835)  acc1: 75.7576 (77.1333)  acc5: 91.8367 (92.0575)  time: 0.2477  data: 0.0001  max mem: 2159
[2024-01-20 13:27:28 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:01:05  flops: 45.6860 (45.6860)  loss: 1.2283 (1.0846)  acc1: 75.0000 (77.0820)  acc5: 92.0000 (92.0691)  time: 0.2473  data: 0.0001  max mem: 2159
[2024-01-20 13:27:30 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:01:03  flops: 45.6860 (45.6860)  loss: 1.0474 (1.0865)  acc1: 75.5319 (77.0326)  acc5: 90.9091 (92.0399)  time: 0.2466  data: 0.0001  max mem: 2159
[2024-01-20 13:27:32 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:01:00  flops: 45.6860 (45.6860)  loss: 1.0629 (1.0879)  acc1: 75.7576 (77.0155)  acc5: 90.8163 (92.0120)  time: 0.2465  data: 0.0001  max mem: 2159
[2024-01-20 13:27:35 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:57  flops: 45.6860 (45.6860)  loss: 1.1899 (1.0925)  acc1: 75.5102 (76.9118)  acc5: 91.0000 (91.9958)  time: 0.2469  data: 0.0001  max mem: 2159
[2024-01-20 13:27:37 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:55  flops: 45.6860 (45.6860)  loss: 1.2067 (1.0929)  acc1: 74.0000 (76.9367)  acc5: 92.7083 (92.0030)  time: 0.2480  data: 0.0001  max mem: 2159
[2024-01-20 13:27:40 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:52  flops: 45.6860 (45.6860)  loss: 1.0798 (1.0931)  acc1: 76.5306 (76.9408)  acc5: 91.9192 (91.9742)  time: 0.2480  data: 0.0001  max mem: 2159
[2024-01-20 13:27:42 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:50  flops: 45.6860 (45.6860)  loss: 1.0448 (1.0903)  acc1: 77.7778 (77.0360)  acc5: 91.8367 (91.9846)  time: 0.2478  data: 0.0001  max mem: 2159
[2024-01-20 13:27:45 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:47  flops: 45.6860 (45.6860)  loss: 1.0628 (1.0932)  acc1: 77.5510 (77.0072)  acc5: 91.8367 (91.9419)  time: 0.2478  data: 0.0001  max mem: 2159
[2024-01-20 13:27:47 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:45  flops: 45.6860 (45.6860)  loss: 1.1039 (1.0913)  acc1: 77.0833 (77.0582)  acc5: 91.9192 (91.9669)  time: 0.2470  data: 0.0001  max mem: 2159
[2024-01-20 13:27:50 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:42  flops: 45.6860 (45.6860)  loss: 1.0338 (1.0895)  acc1: 79.3814 (77.1153)  acc5: 92.7083 (92.0005)  time: 0.2454  data: 0.0001  max mem: 2159
[2024-01-20 13:27:52 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:40  flops: 45.6860 (45.6860)  loss: 1.0548 (1.0890)  acc1: 78.1250 (77.1248)  acc5: 91.8367 (91.9937)  time: 0.2459  data: 0.0001  max mem: 2159
[2024-01-20 13:27:55 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:37  flops: 45.6860 (45.6860)  loss: 1.0548 (1.0877)  acc1: 77.5510 (77.1565)  acc5: 92.7835 (92.0209)  time: 0.2470  data: 0.0001  max mem: 2159
[2024-01-20 13:27:57 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:35  flops: 45.6860 (45.6860)  loss: 1.0418 (1.0878)  acc1: 77.7778 (77.1668)  acc5: 92.7835 (92.0015)  time: 0.2465  data: 0.0001  max mem: 2159
[2024-01-20 13:28:00 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:32  flops: 45.6860 (45.6860)  loss: 1.0468 (1.0861)  acc1: 77.0000 (77.1995)  acc5: 91.8367 (92.0091)  time: 0.2471  data: 0.0001  max mem: 2159
[2024-01-20 13:28:02 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:30  flops: 45.6860 (45.6860)  loss: 1.0354 (1.0849)  acc1: 77.7778 (77.2091)  acc5: 91.8367 (92.0217)  time: 0.2478  data: 0.0001  max mem: 2159
[2024-01-20 13:28:05 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:27  flops: 45.6860 (45.6860)  loss: 1.0053 (1.0838)  acc1: 77.3196 (77.2100)  acc5: 92.9293 (92.0430)  time: 0.2473  data: 0.0001  max mem: 2159
[2024-01-20 13:28:07 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:25  flops: 45.6860 (45.6860)  loss: 1.0154 (1.0832)  acc1: 77.0833 (77.1850)  acc5: 93.8144 (92.0776)  time: 0.2475  data: 0.0001  max mem: 2159
[2024-01-20 13:28:10 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:22  flops: 45.6860 (45.6860)  loss: 1.0650 (1.0820)  acc1: 76.7677 (77.1903)  acc5: 92.9293 (92.0837)  time: 0.2472  data: 0.0001  max mem: 2159
[2024-01-20 13:28:12 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:20  flops: 45.6860 (45.6860)  loss: 1.0650 (1.0840)  acc1: 76.7677 (77.1626)  acc5: 91.9192 (92.0585)  time: 0.2465  data: 0.0001  max mem: 2159
[2024-01-20 13:28:14 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:17  flops: 45.6860 (45.6860)  loss: 1.1347 (1.0835)  acc1: 77.7778 (77.1975)  acc5: 90.8163 (92.0558)  time: 0.2468  data: 0.0001  max mem: 2159
[2024-01-20 13:28:17 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:15  flops: 45.6860 (45.6860)  loss: 1.0672 (1.0846)  acc1: 78.5714 (77.2040)  acc5: 92.8571 (92.0618)  time: 0.2464  data: 0.0001  max mem: 2159
[2024-01-20 13:28:19 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:12  flops: 45.6860 (45.6860)  loss: 1.0777 (1.0855)  acc1: 77.3196 (77.1576)  acc5: 92.9293 (92.0629)  time: 0.2460  data: 0.0001  max mem: 2159
[2024-01-20 13:28:22 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:09  flops: 45.6860 (45.6860)  loss: 1.0900 (1.0838)  acc1: 76.0000 (77.1680)  acc5: 92.8571 (92.0749)  time: 0.2472  data: 0.0001  max mem: 2159
[2024-01-20 13:28:24 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:07  flops: 45.6860 (45.6860)  loss: 1.0674 (1.0842)  acc1: 76.5306 (77.1521)  acc5: 91.9192 (92.0662)  time: 0.2483  data: 0.0001  max mem: 2159
[2024-01-20 13:28:27 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:04  flops: 45.6860 (45.6860)  loss: 1.0849 (1.0848)  acc1: 76.5306 (77.1141)  acc5: 91.9192 (92.0644)  time: 0.2481  data: 0.0001  max mem: 2159
[2024-01-20 13:28:29 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:02  flops: 45.6860 (45.6860)  loss: 1.1348 (1.0853)  acc1: 75.7576 (77.0793)  acc5: 92.0000 (92.0645)  time: 0.2479  data: 0.0001  max mem: 2159
[2024-01-20 13:28:32 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 45.6860 (45.6860)  loss: 1.0431 (1.0837)  acc1: 76.5306 (77.1227)  acc5: 92.0000 (92.0694)  time: 0.2481  data: 0.0001  max mem: 2159
[2024-01-20 13:28:32 root] (utils.py 307): INFO Test: Total time: 0:02:04 (0.2498 s / it)
[2024-01-20 13:28:32 root] (engine.py 118): INFO * Acc@1 77.123 Acc@5 92.069 loss 1.084 flops 45.686
[2024-01-20 13:28:32 root] (main_tome.py 377): INFO Accuracy of the network on the 50000 test images: 77.1%
[2024-01-20 13:28:58 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:29:02 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:29:07 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 13:29:08 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:12:30  flops: 45.6860 (45.6860)  loss: 1.1884 (1.1884)  acc1: 72.7273 (72.7273)  acc5: 91.9192 (91.9192)  time: 1.5012  data: 0.0010  max mem: 2149
[2024-01-20 13:29:11 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:03:05  flops: 45.6860 (45.6860)  loss: 1.1687 (1.1651)  acc1: 75.7576 (75.5369)  acc5: 90.9091 (91.1298)  time: 0.3792  data: 0.0002  max mem: 2153
[2024-01-20 13:29:14 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:33  flops: 45.6860 (45.6860)  loss: 1.0578 (1.0906)  acc1: 76.7677 (76.5792)  acc5: 91.7526 (91.8367)  time: 0.2597  data: 0.0001  max mem: 2155
[2024-01-20 13:29:16 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:18  flops: 45.6860 (45.6860)  loss: 1.0279 (1.0748)  acc1: 77.3196 (77.1607)  acc5: 92.9293 (91.8173)  time: 0.2489  data: 0.0001  max mem: 2155
[2024-01-20 13:29:18 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:10  flops: 45.6860 (45.6860)  loss: 1.0562 (1.0792)  acc1: 77.7778 (77.0321)  acc5: 92.0000 (91.7226)  time: 0.2448  data: 0.0001  max mem: 2155
[2024-01-20 13:29:21 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:02:03  flops: 45.6860 (45.6860)  loss: 1.1198 (1.0875)  acc1: 76.0417 (76.8200)  acc5: 91.8367 (91.8000)  time: 0.2442  data: 0.0001  max mem: 2155
[2024-01-20 13:29:23 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:01:58  flops: 45.6860 (45.6860)  loss: 1.1030 (1.0799)  acc1: 77.3196 (77.1634)  acc5: 93.7500 (92.0147)  time: 0.2450  data: 0.0001  max mem: 2155
[2024-01-20 13:29:26 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:01:54  flops: 45.6860 (45.6860)  loss: 1.0656 (1.0798)  acc1: 77.7778 (77.0732)  acc5: 92.7835 (92.0230)  time: 0.2461  data: 0.0001  max mem: 2155
[2024-01-20 13:29:28 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:01:50  flops: 45.6860 (45.6860)  loss: 1.0840 (1.0767)  acc1: 76.2887 (77.1195)  acc5: 91.9192 (92.1258)  time: 0.2456  data: 0.0001  max mem: 2155
[2024-01-20 13:29:31 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:01:47  flops: 45.6860 (45.6860)  loss: 1.0857 (1.0774)  acc1: 77.3196 (77.2651)  acc5: 91.8367 (92.1044)  time: 0.2453  data: 0.0001  max mem: 2155
[2024-01-20 13:29:33 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:01:44  flops: 45.6860 (45.6860)  loss: 1.0631 (1.0717)  acc1: 77.3196 (77.3910)  acc5: 91.8367 (92.1408)  time: 0.2460  data: 0.0001  max mem: 2155
[2024-01-20 13:29:36 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:01:41  flops: 45.6860 (45.6860)  loss: 1.0233 (1.0685)  acc1: 78.5714 (77.4750)  acc5: 91.8367 (92.1919)  time: 0.2471  data: 0.0001  max mem: 2155
[2024-01-20 13:29:38 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:01:38  flops: 45.6860 (45.6860)  loss: 1.0281 (1.0756)  acc1: 78.1250 (77.3580)  acc5: 91.9192 (92.1582)  time: 0.2474  data: 0.0001  max mem: 2155
[2024-01-20 13:29:41 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:01:35  flops: 45.6860 (45.6860)  loss: 1.0281 (1.0706)  acc1: 78.0000 (77.3607)  acc5: 92.8571 (92.1971)  time: 0.2469  data: 0.0001  max mem: 2155
[2024-01-20 13:29:43 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:01:32  flops: 45.6860 (45.6860)  loss: 1.0361 (1.0720)  acc1: 77.7778 (77.3623)  acc5: 91.9192 (92.1533)  time: 0.2471  data: 0.0001  max mem: 2155
[2024-01-20 13:29:46 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:01:29  flops: 45.6860 (45.6860)  loss: 1.0397 (1.0684)  acc1: 77.7778 (77.4272)  acc5: 91.9192 (92.2060)  time: 0.2498  data: 0.0001  max mem: 2155
[2024-01-20 13:29:48 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:01:26  flops: 45.6860 (45.6860)  loss: 1.0397 (1.0716)  acc1: 77.5510 (77.3912)  acc5: 92.8571 (92.1495)  time: 0.2487  data: 0.0001  max mem: 2155
[2024-01-20 13:29:51 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:01:24  flops: 45.6860 (45.6860)  loss: 1.0783 (1.0704)  acc1: 75.5102 (77.3859)  acc5: 92.5532 (92.1780)  time: 0.2489  data: 0.0001  max mem: 2156
[2024-01-20 13:29:53 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:01:21  flops: 45.6860 (45.6860)  loss: 1.0758 (1.0758)  acc1: 75.2577 (77.2686)  acc5: 91.9192 (92.0964)  time: 0.2493  data: 0.0001  max mem: 2156
[2024-01-20 13:30:09 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:30:13 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:30:18 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 13:30:20 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:12:16  flops: 45.6860 (45.6860)  loss: 1.2128 (1.2128)  acc1: 73.7374 (73.7374)  acc5: 90.9091 (90.9091)  time: 1.4732  data: 0.0009  max mem: 2149
[2024-01-20 13:30:22 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:03:00  flops: 45.6860 (45.6860)  loss: 1.1628 (1.1612)  acc1: 76.0417 (75.6303)  acc5: 90.9091 (90.9430)  time: 0.3684  data: 0.0002  max mem: 2153
[2024-01-20 13:30:25 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:28  flops: 45.6860 (45.6860)  loss: 1.0769 (1.0900)  acc1: 76.2887 (76.6764)  acc5: 91.7526 (91.8367)  time: 0.2506  data: 0.0001  max mem: 2155
[2024-01-20 13:30:27 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:14  flops: 45.6860 (45.6860)  loss: 1.0274 (1.0752)  acc1: 76.7677 (77.3579)  acc5: 92.9293 (91.9159)  time: 0.2399  data: 0.0001  max mem: 2155
[2024-01-20 13:30:29 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:05  flops: 45.6860 (45.6860)  loss: 1.0466 (1.0732)  acc1: 77.3196 (77.4795)  acc5: 91.7526 (91.7972)  time: 0.2361  data: 0.0001  max mem: 2155
[2024-01-20 13:30:32 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:01:59  flops: 45.6860 (45.6860)  loss: 1.1192 (1.0835)  acc1: 75.7576 (77.0600)  acc5: 91.6667 (91.8800)  time: 0.2353  data: 0.0001  max mem: 2155
[2024-01-20 13:30:34 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:01:54  flops: 45.6860 (45.6860)  loss: 1.1313 (1.0780)  acc1: 76.5306 (77.3471)  acc5: 92.9293 (92.0314)  time: 0.2361  data: 0.0001  max mem: 2155
[2024-01-20 13:30:36 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:01:50  flops: 45.6860 (45.6860)  loss: 1.0579 (1.0772)  acc1: 78.7879 (77.3745)  acc5: 92.7835 (92.0516)  time: 0.2368  data: 0.0001  max mem: 2155
[2024-01-20 13:30:39 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:01:47  flops: 45.6860 (45.6860)  loss: 1.0670 (1.0733)  acc1: 77.3196 (77.4717)  acc5: 92.0000 (92.1509)  time: 0.2366  data: 0.0001  max mem: 2155
[2024-01-20 13:30:41 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:01:43  flops: 45.6860 (45.6860)  loss: 1.0708 (1.0744)  acc1: 77.7778 (77.5563)  acc5: 92.8571 (92.1716)  time: 0.2365  data: 0.0001  max mem: 2155
[2024-01-20 13:30:43 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:01:40  flops: 45.6860 (45.6860)  loss: 1.0427 (1.0695)  acc1: 77.7778 (77.6029)  acc5: 92.8571 (92.2619)  time: 0.2369  data: 0.0001  max mem: 2155
[2024-01-20 13:30:46 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:01:37  flops: 45.6860 (45.6860)  loss: 1.0198 (1.0664)  acc1: 78.0000 (77.6677)  acc5: 91.9192 (92.2929)  time: 0.2379  data: 0.0001  max mem: 2155
[2024-01-20 13:30:48 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:01:34  flops: 45.6860 (45.6860)  loss: 1.0383 (1.0741)  acc1: 78.0000 (77.5515)  acc5: 91.9192 (92.2339)  time: 0.2382  data: 0.0001  max mem: 2155
[2024-01-20 13:30:51 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:01:31  flops: 45.6860 (45.6860)  loss: 1.0383 (1.0688)  acc1: 77.7778 (77.5161)  acc5: 92.9293 (92.2904)  time: 0.2379  data: 0.0001  max mem: 2155
[2024-01-20 13:30:53 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:01:29  flops: 45.6860 (45.6860)  loss: 1.0515 (1.0704)  acc1: 76.7677 (77.4489)  acc5: 92.9293 (92.2760)  time: 0.2380  data: 0.0001  max mem: 2155
[2024-01-20 13:30:55 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:01:26  flops: 45.6860 (45.6860)  loss: 1.0373 (1.0676)  acc1: 76.7677 (77.5823)  acc5: 93.8144 (92.3274)  time: 0.2405  data: 0.0001  max mem: 2155
[2024-01-20 13:30:58 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:01:23  flops: 45.6860 (45.6860)  loss: 1.0373 (1.0706)  acc1: 79.5918 (77.5557)  acc5: 93.0000 (92.2761)  time: 0.2395  data: 0.0001  max mem: 2155
[2024-01-20 13:31:00 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:01:21  flops: 45.6860 (45.6860)  loss: 1.0835 (1.0697)  acc1: 76.7677 (77.5766)  acc5: 91.8367 (92.2614)  time: 0.2396  data: 0.0001  max mem: 2156
[2024-01-20 13:31:03 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:01:18  flops: 45.6860 (45.6860)  loss: 1.0951 (1.0752)  acc1: 75.7576 (77.4094)  acc5: 91.8367 (92.1864)  time: 0.2399  data: 0.0001  max mem: 2156
[2024-01-20 13:31:05 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:01:16  flops: 45.6860 (45.6860)  loss: 1.0849 (1.0757)  acc1: 74.7475 (77.4329)  acc5: 91.8367 (92.1719)  time: 0.2380  data: 0.0001  max mem: 2159
[2024-01-20 13:31:07 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:01:13  flops: 45.6860 (45.6860)  loss: 1.0269 (1.0761)  acc1: 79.7980 (77.4839)  acc5: 91.9192 (92.1366)  time: 0.2387  data: 0.0001  max mem: 2159
[2024-01-20 13:31:10 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:01:11  flops: 45.6860 (45.6860)  loss: 1.0935 (1.0787)  acc1: 77.3196 (77.4169)  acc5: 91.9192 (92.1521)  time: 0.2381  data: 0.0001  max mem: 2159
[2024-01-20 13:31:12 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:01:08  flops: 45.6860 (45.6860)  loss: 1.0812 (1.0769)  acc1: 77.3196 (77.4665)  acc5: 91.8367 (92.1294)  time: 0.2379  data: 0.0001  max mem: 2159
[2024-01-20 13:31:14 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:01:05  flops: 45.6860 (45.6860)  loss: 1.0812 (1.0822)  acc1: 76.5306 (77.3272)  acc5: 91.9192 (92.1324)  time: 0.2383  data: 0.0001  max mem: 2159
[2024-01-20 13:31:17 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:01:03  flops: 45.6860 (45.6860)  loss: 1.2303 (1.0831)  acc1: 75.7576 (77.3102)  acc5: 92.0000 (92.1367)  time: 0.2378  data: 0.0001  max mem: 2159
[2024-01-20 13:31:19 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:01:00  flops: 45.6860 (45.6860)  loss: 1.0509 (1.0853)  acc1: 77.3196 (77.2598)  acc5: 91.0000 (92.1048)  time: 0.2373  data: 0.0001  max mem: 2159
[2024-01-20 13:31:22 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:58  flops: 45.6860 (45.6860)  loss: 1.0567 (1.0869)  acc1: 76.5306 (77.2536)  acc5: 90.7216 (92.0745)  time: 0.2374  data: 0.0001  max mem: 2159
[2024-01-20 13:31:24 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:55  flops: 45.6860 (45.6860)  loss: 1.2312 (1.0919)  acc1: 76.0417 (77.1636)  acc5: 90.8163 (92.0597)  time: 0.2378  data: 0.0001  max mem: 2159
[2024-01-20 13:31:26 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:53  flops: 45.6860 (45.6860)  loss: 1.2039 (1.0922)  acc1: 76.0000 (77.2121)  acc5: 92.0000 (92.0538)  time: 0.2387  data: 0.0001  max mem: 2159
[2024-01-20 13:31:29 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:51  flops: 45.6860 (45.6860)  loss: 1.0792 (1.0925)  acc1: 77.7778 (77.2172)  acc5: 91.8367 (92.0302)  time: 0.2387  data: 0.0001  max mem: 2159
[2024-01-20 13:31:31 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:48  flops: 45.6860 (45.6860)  loss: 1.0567 (1.0900)  acc1: 77.8947 (77.2964)  acc5: 91.8367 (92.0455)  time: 0.2385  data: 0.0001  max mem: 2159
[2024-01-20 13:31:34 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:46  flops: 45.6860 (45.6860)  loss: 1.0672 (1.0930)  acc1: 77.7778 (77.2592)  acc5: 91.8367 (92.0171)  time: 0.2386  data: 0.0001  max mem: 2159
[2024-01-20 13:31:36 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:43  flops: 45.6860 (45.6860)  loss: 1.1071 (1.0915)  acc1: 76.7677 (77.2897)  acc5: 91.8367 (92.0493)  time: 0.2380  data: 0.0001  max mem: 2159
[2024-01-20 13:31:38 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:41  flops: 45.6860 (45.6860)  loss: 1.0523 (1.0900)  acc1: 78.3505 (77.3275)  acc5: 91.9192 (92.0805)  time: 0.2364  data: 0.0001  max mem: 2159
[2024-01-20 13:31:41 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:38  flops: 45.6860 (45.6860)  loss: 1.0622 (1.0893)  acc1: 78.3505 (77.3487)  acc5: 91.8367 (92.0743)  time: 0.2370  data: 0.0001  max mem: 2159
[2024-01-20 13:31:43 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:36  flops: 45.6860 (45.6860)  loss: 1.0622 (1.0879)  acc1: 77.7778 (77.3741)  acc5: 92.8571 (92.1050)  time: 0.2380  data: 0.0001  max mem: 2159
[2024-01-20 13:31:45 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:33  flops: 45.6860 (45.6860)  loss: 1.0674 (1.0880)  acc1: 77.7778 (77.3897)  acc5: 92.9293 (92.0889)  time: 0.2374  data: 0.0001  max mem: 2159
[2024-01-20 13:31:48 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:31  flops: 45.6860 (45.6860)  loss: 1.0674 (1.0864)  acc1: 77.7778 (77.4081)  acc5: 91.9192 (92.0970)  time: 0.2380  data: 0.0001  max mem: 2159
[2024-01-20 13:31:50 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:29  flops: 45.6860 (45.6860)  loss: 1.0216 (1.0854)  acc1: 78.7879 (77.4042)  acc5: 92.6316 (92.1072)  time: 0.2389  data: 0.0001  max mem: 2159
[2024-01-20 13:31:53 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:26  flops: 45.6860 (45.6860)  loss: 1.0152 (1.0840)  acc1: 78.5714 (77.4131)  acc5: 92.8571 (92.1264)  time: 0.2385  data: 0.0001  max mem: 2159
[2024-01-20 13:31:55 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:24  flops: 45.6860 (45.6860)  loss: 1.0363 (1.0839)  acc1: 77.3196 (77.3805)  acc5: 93.7500 (92.1462)  time: 0.2387  data: 0.0001  max mem: 2159
[2024-01-20 13:31:57 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:21  flops: 45.6860 (45.6860)  loss: 1.0733 (1.0827)  acc1: 76.2887 (77.3835)  acc5: 93.0000 (92.1705)  time: 0.2387  data: 0.0001  max mem: 2159
[2024-01-20 13:32:00 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:19  flops: 45.6860 (45.6860)  loss: 1.0780 (1.0848)  acc1: 76.2887 (77.3585)  acc5: 92.7083 (92.1432)  time: 0.2379  data: 0.0001  max mem: 2159
[2024-01-20 13:32:12 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:32:16 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:32:21 timm.models.helpers] (helpers.py 43): ERROR No checkpoint found at '/media/caduser/MyBook/chau//.vision_ckts/checkpoints/vit_large_patch16_mae.pth'
[2024-01-20 13:35:05 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='mae_finetuned_vit_large.pth', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:35:09 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:35:14 timm.models.helpers] (helpers.py 43): ERROR No checkpoint found at '/media/caduser/MyBook/chau//.vision_ckts/checkpoints/mae_finetuned_vit_large.pth.pth'
[2024-01-20 13:35:52 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='mae_finetuned_vit_large.pth', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:35:56 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:36:01 timm.models.helpers] (helpers.py 40): INFO Loaded state_dict from checkpoint '/media/caduser/MyBook/chau//.vision_ckts/checkpoints/mae_finetuned_vit_large.pth'
[2024-01-20 13:37:52 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='mae_finetuned_vit_large.pth', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:37:57 root] (main_tome.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:38:02 root] (main_tome.py 370): INFO number of params: 304326632
[2024-01-20 13:38:03 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:12:20  flops: 45.6860 (45.6860)  loss: 1.2139 (1.2139)  acc1: 73.7374 (73.7374)  acc5: 90.9091 (90.9091)  time: 1.4815  data: 0.0008  max mem: 2149
[2024-01-20 13:38:06 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:59  flops: 45.6860 (45.6860)  loss: 1.1619 (1.1613)  acc1: 76.0417 (75.5369)  acc5: 90.9091 (90.9430)  time: 0.3672  data: 0.0002  max mem: 2153
[2024-01-20 13:38:08 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:27  flops: 45.6860 (45.6860)  loss: 1.0778 (1.0905)  acc1: 76.2887 (76.5306)  acc5: 91.0000 (91.8367)  time: 0.2487  data: 0.0001  max mem: 2155
[2024-01-20 13:38:10 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:13  flops: 45.6860 (45.6860)  loss: 1.0194 (1.0758)  acc1: 76.7677 (77.2921)  acc5: 92.9293 (91.9816)  time: 0.2391  data: 0.0001  max mem: 2155
[2024-01-20 13:38:13 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:05  flops: 45.6860 (45.6860)  loss: 1.0546 (1.0738)  acc1: 77.7778 (77.4546)  acc5: 92.0000 (91.8717)  time: 0.2352  data: 0.0001  max mem: 2155
[2024-01-20 13:38:41 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='mae_finetuned_vit_large.pth', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:38:45 root] (main_tome.py 287): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 13:39:49 root] (main_tome.py 218): INFO Namespace(batch_size=100, epochs=300, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='mae_finetuned_vit_large.pth', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:39:53 root] (main_tome.py 288): INFO Creating model: deit_small_patch16_224
[2024-01-20 13:39:53 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-20 13:39:55 root] (main_tome.py 371): INFO number of params: 22050664
[2024-01-20 13:43:01 root] (main_tome.py 218): INFO Namespace(batch_size=100, epochs=300, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='mae_finetuned_vit_large.pth', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:43:05 root] (main_tome.py 288): INFO Creating model: deit_small_patch16_224
[2024-01-20 13:43:05 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-20 13:43:07 root] (main_tome.py 371): INFO number of params: 22050664
[2024-01-20 13:43:09 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:19:36  flops: 3.9257 (3.9257)  loss: 1.5049 (1.5049)  acc1: 70.7071 (70.7071)  acc5: 85.8586 (85.8586)  time: 2.3532  data: 0.1732  max mem: 436
[2024-01-20 13:43:09 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:08  flops: 3.9257 (3.9257)  loss: 1.4490 (1.4461)  acc1: 70.4082 (68.2540)  acc5: 86.5979 (86.7414)  time: 0.2627  data: 0.0159  max mem: 436
[2024-01-20 13:43:10 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:16  flops: 3.9257 (3.9257)  loss: 1.3723 (1.4024)  acc1: 69.6970 (69.0962)  acc5: 86.8687 (87.7065)  time: 0.0487  data: 0.0001  max mem: 440
[2024-01-20 13:43:10 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:00:56  flops: 3.9257 (3.9257)  loss: 1.3445 (1.3758)  acc1: 69.6970 (69.8653)  acc5: 89.0000 (87.9395)  time: 0.0423  data: 0.0001  max mem: 440
[2024-01-20 13:43:11 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:00:46  flops: 3.9257 (3.9257)  loss: 1.3963 (1.3827)  acc1: 69.6970 (70.0721)  acc5: 86.4583 (87.5466)  time: 0.0407  data: 0.0001  max mem: 440
[2024-01-20 13:43:11 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:41  flops: 3.9257 (3.9257)  loss: 1.3988 (1.3901)  acc1: 69.3878 (69.6000)  acc5: 86.4583 (87.8000)  time: 0.0465  data: 0.0060  max mem: 440
[2024-01-20 13:43:12 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:38  flops: 3.9257 (3.9257)  loss: 1.3936 (1.3879)  acc1: 69.0000 (69.8797)  acc5: 88.7755 (87.8216)  time: 0.0566  data: 0.0160  max mem: 440
[2024-01-20 13:43:12 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:35  flops: 3.9257 (3.9257)  loss: 1.3722 (1.3897)  acc1: 69.6970 (69.8565)  acc5: 87.8788 (87.6471)  time: 0.0567  data: 0.0159  max mem: 440
[2024-01-20 13:43:13 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:32  flops: 3.9257 (3.9257)  loss: 1.4291 (1.3957)  acc1: 66.6667 (69.5094)  acc5: 86.0000 (87.5346)  time: 0.0509  data: 0.0103  max mem: 440
[2024-01-20 13:43:13 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:30  flops: 3.9257 (3.9257)  loss: 1.4241 (1.3967)  acc1: 66.6667 (69.5487)  acc5: 87.5000 (87.5686)  time: 0.0508  data: 0.0103  max mem: 440
[2024-01-20 13:43:14 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:29  flops: 3.9257 (3.9257)  loss: 1.3939 (1.3949)  acc1: 69.3878 (69.4613)  acc5: 87.8788 (87.5706)  time: 0.0539  data: 0.0133  max mem: 440
[2024-01-20 13:43:15 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:28  flops: 3.9257 (3.9257)  loss: 1.3559 (1.3886)  acc1: 71.1340 (69.7312)  acc5: 87.7551 (87.5493)  time: 0.0594  data: 0.0188  max mem: 440
[2024-01-20 13:43:15 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:26  flops: 3.9257 (3.9257)  loss: 1.4200 (1.4002)  acc1: 69.0000 (69.5330)  acc5: 87.0000 (87.4632)  time: 0.0579  data: 0.0172  max mem: 440
[2024-01-20 13:43:16 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:25  flops: 3.9257 (3.9257)  loss: 1.4200 (1.3994)  acc1: 68.6869 (69.5656)  acc5: 86.7347 (87.5107)  time: 0.0526  data: 0.0119  max mem: 440
[2024-01-20 13:43:16 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:24  flops: 3.9257 (3.9257)  loss: 1.3452 (1.3991)  acc1: 69.7917 (69.5445)  acc5: 87.5000 (87.5189)  time: 0.0529  data: 0.0122  max mem: 440
[2024-01-20 13:43:17 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:23  flops: 3.9257 (3.9257)  loss: 1.4050 (1.4001)  acc1: 69.6970 (69.6332)  acc5: 87.6289 (87.4663)  time: 0.0532  data: 0.0108  max mem: 440
[2024-01-20 13:43:17 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:22  flops: 3.9257 (3.9257)  loss: 1.3964 (1.4048)  acc1: 68.7500 (69.4965)  acc5: 86.4583 (87.4178)  time: 0.0525  data: 0.0102  max mem: 440
[2024-01-20 13:43:18 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:21  flops: 3.9257 (3.9257)  loss: 1.3785 (1.4027)  acc1: 69.0000 (69.5520)  acc5: 87.8788 (87.5134)  time: 0.0529  data: 0.0106  max mem: 440
[2024-01-20 13:43:18 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:20  flops: 3.9257 (3.9257)  loss: 1.4237 (1.4081)  acc1: 68.6869 (69.4551)  acc5: 87.8788 (87.4240)  time: 0.0519  data: 0.0095  max mem: 440
[2024-01-20 13:43:19 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:19  flops: 3.9257 (3.9257)  loss: 1.4765 (1.4080)  acc1: 68.6869 (69.4982)  acc5: 86.8687 (87.4100)  time: 0.0532  data: 0.0125  max mem: 440
[2024-01-20 13:43:19 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:19  flops: 3.9257 (3.9257)  loss: 1.3432 (1.4084)  acc1: 69.3878 (69.5141)  acc5: 87.8788 (87.4196)  time: 0.0556  data: 0.0148  max mem: 440
[2024-01-20 13:43:20 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:18  flops: 3.9257 (3.9257)  loss: 1.4372 (1.4122)  acc1: 67.6768 (69.4290)  acc5: 86.8687 (87.3787)  time: 0.0553  data: 0.0146  max mem: 440
[2024-01-20 13:43:20 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:17  flops: 3.9257 (3.9257)  loss: 1.4214 (1.4084)  acc1: 68.3673 (69.4438)  acc5: 88.6598 (87.4568)  time: 0.0555  data: 0.0149  max mem: 440
[2024-01-20 13:43:21 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:16  flops: 3.9257 (3.9257)  loss: 1.4214 (1.4116)  acc1: 68.3673 (69.3935)  acc5: 88.8889 (87.4383)  time: 0.0553  data: 0.0145  max mem: 440
[2024-01-20 13:43:22 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:16  flops: 3.9257 (3.9257)  loss: 1.4355 (1.4122)  acc1: 67.6768 (69.3666)  acc5: 87.0000 (87.4467)  time: 0.0555  data: 0.0147  max mem: 440
[2024-01-20 13:43:22 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:15  flops: 3.9257 (3.9257)  loss: 1.3627 (1.4143)  acc1: 68.3673 (69.3363)  acc5: 87.0000 (87.4107)  time: 0.0561  data: 0.0154  max mem: 440
[2024-01-20 13:43:23 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:14  flops: 3.9257 (3.9257)  loss: 1.3799 (1.4153)  acc1: 70.4082 (69.3436)  acc5: 86.0000 (87.4034)  time: 0.0551  data: 0.0145  max mem: 440
[2024-01-20 13:43:23 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:14  flops: 3.9257 (3.9257)  loss: 1.4889 (1.4205)  acc1: 67.7083 (69.2721)  acc5: 85.8586 (87.3436)  time: 0.0556  data: 0.0151  max mem: 440
[2024-01-20 13:43:24 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:13  flops: 3.9257 (3.9257)  loss: 1.5332 (1.4213)  acc1: 66.6667 (69.2478)  acc5: 85.0000 (87.3324)  time: 0.0564  data: 0.0156  max mem: 440
[2024-01-20 13:43:24 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:12  flops: 3.9257 (3.9257)  loss: 1.4448 (1.4218)  acc1: 67.6768 (69.2160)  acc5: 86.7347 (87.3316)  time: 0.0546  data: 0.0137  max mem: 440
[2024-01-20 13:43:25 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:12  flops: 3.9257 (3.9257)  loss: 1.4357 (1.4219)  acc1: 68.0412 (69.2167)  acc5: 86.7347 (87.3275)  time: 0.0525  data: 0.0116  max mem: 440
[2024-01-20 13:43:25 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:11  flops: 3.9257 (3.9257)  loss: 1.3909 (1.4244)  acc1: 68.0412 (69.1421)  acc5: 86.7347 (87.2615)  time: 0.0550  data: 0.0141  max mem: 440
[2024-01-20 13:43:26 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:10  flops: 3.9257 (3.9257)  loss: 1.3909 (1.4236)  acc1: 68.6869 (69.1488)  acc5: 86.7347 (87.2828)  time: 0.0577  data: 0.0169  max mem: 440
[2024-01-20 13:43:27 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:10  flops: 3.9257 (3.9257)  loss: 1.3957 (1.4232)  acc1: 69.6970 (69.1650)  acc5: 87.8788 (87.2777)  time: 0.0543  data: 0.0137  max mem: 440
[2024-01-20 13:43:27 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:09  flops: 3.9257 (3.9257)  loss: 1.3957 (1.4221)  acc1: 69.6970 (69.1961)  acc5: 86.7347 (87.2693)  time: 0.0525  data: 0.0119  max mem: 440
[2024-01-20 13:43:28 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:08  flops: 3.9257 (3.9257)  loss: 1.3134 (1.4202)  acc1: 68.0412 (69.2006)  acc5: 87.8788 (87.2798)  time: 0.0516  data: 0.0108  max mem: 440
[2024-01-20 13:43:28 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:08  flops: 3.9257 (3.9257)  loss: 1.3134 (1.4199)  acc1: 68.0412 (69.1880)  acc5: 87.8788 (87.2842)  time: 0.0500  data: 0.0092  max mem: 440
[2024-01-20 13:43:29 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:07  flops: 3.9257 (3.9257)  loss: 1.3486 (1.4189)  acc1: 71.0000 (69.2196)  acc5: 87.0000 (87.3013)  time: 0.0528  data: 0.0121  max mem: 440
[2024-01-20 13:43:29 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:07  flops: 3.9257 (3.9257)  loss: 1.4057 (1.4195)  acc1: 69.6970 (69.1987)  acc5: 86.7347 (87.2855)  time: 0.0532  data: 0.0124  max mem: 440
[2024-01-20 13:43:30 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:06  flops: 3.9257 (3.9257)  loss: 1.3720 (1.4192)  acc1: 69.6970 (69.2374)  acc5: 87.5000 (87.2871)  time: 0.0521  data: 0.0114  max mem: 440
[2024-01-20 13:43:30 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:05  flops: 3.9257 (3.9257)  loss: 1.3720 (1.4187)  acc1: 70.0000 (69.2448)  acc5: 87.7551 (87.3038)  time: 0.0564  data: 0.0156  max mem: 440
[2024-01-20 13:43:31 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:05  flops: 3.9257 (3.9257)  loss: 1.3759 (1.4170)  acc1: 69.6970 (69.2740)  acc5: 88.5417 (87.3216)  time: 0.0584  data: 0.0175  max mem: 440
[2024-01-20 13:43:31 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:04  flops: 3.9257 (3.9257)  loss: 1.3500 (1.4180)  acc1: 69.6970 (69.2550)  acc5: 88.5417 (87.3246)  time: 0.0558  data: 0.0151  max mem: 440
[2024-01-20 13:43:32 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:04  flops: 3.9257 (3.9257)  loss: 1.4512 (1.4184)  acc1: 67.6768 (69.2202)  acc5: 86.7347 (87.3228)  time: 0.0561  data: 0.0154  max mem: 440
[2024-01-20 13:43:33 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:03  flops: 3.9257 (3.9257)  loss: 1.4512 (1.4198)  acc1: 67.3469 (69.1849)  acc5: 86.7347 (87.3109)  time: 0.0561  data: 0.0154  max mem: 440
[2024-01-20 13:43:33 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:02  flops: 3.9257 (3.9257)  loss: 1.4263 (1.4206)  acc1: 68.0412 (69.1731)  acc5: 86.0000 (87.3173)  time: 0.0521  data: 0.0114  max mem: 440
[2024-01-20 13:43:34 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:02  flops: 3.9257 (3.9257)  loss: 1.4088 (1.4196)  acc1: 68.6869 (69.1920)  acc5: 88.5417 (87.3688)  time: 0.0513  data: 0.0105  max mem: 440
[2024-01-20 13:43:34 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:01  flops: 3.9257 (3.9257)  loss: 1.3868 (1.4206)  acc1: 69.3878 (69.1815)  acc5: 88.7755 (87.3716)  time: 0.0542  data: 0.0131  max mem: 440
[2024-01-20 13:43:35 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 3.9257 (3.9257)  loss: 1.4060 (1.4205)  acc1: 69.3878 (69.1785)  acc5: 87.8788 (87.3936)  time: 0.0564  data: 0.0154  max mem: 440
[2024-01-20 13:43:35 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 3.9257 (3.9257)  loss: 1.4060 (1.4206)  acc1: 68.6869 (69.1604)  acc5: 87.8788 (87.3916)  time: 0.0547  data: 0.0137  max mem: 440
[2024-01-20 13:43:36 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 3.9257 (3.9257)  loss: 1.3977 (1.4190)  acc1: 68.6869 (69.1778)  acc5: 87.0000 (87.3954)  time: 0.0556  data: 0.0146  max mem: 440
[2024-01-20 13:43:36 root] (utils.py 307): INFO Test: Total time: 0:00:29 (0.0584 s / it)
[2024-01-20 13:43:36 root] (engine.py 118): INFO * Acc@1 69.178 Acc@5 87.395 loss 1.419 flops 3.926
[2024-01-20 13:43:36 root] (main_tome.py 379): INFO Accuracy of the network on the 50000 test images: 69.2%
[2024-01-20 13:44:22 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:44:26 root] (main.py 287): INFO Creating model: vit_large_patch16_mae
[2024-01-20 13:44:31 root] (main.py 373): INFO number of params: 304326632
[2024-01-20 13:44:33 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:11:30  flops: 42.2904 (42.2904)  loss: 1.2366 (1.2366)  acc1: 74.7475 (74.7475)  acc5: 90.9091 (90.9091)  time: 1.3807  data: 0.0007  max mem: 2168
[2024-01-20 13:44:35 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:52  flops: 42.2904 (42.2904)  loss: 1.1519 (1.1632)  acc1: 75.2577 (76.0971)  acc5: 91.6667 (91.1298)  time: 0.3519  data: 0.0002  max mem: 2170
[2024-01-20 13:44:37 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:02:22  flops: 42.2904 (42.2904)  loss: 1.0812 (1.0890)  acc1: 77.3196 (76.8707)  acc5: 91.7526 (91.7396)  time: 0.2420  data: 0.0001  max mem: 2179
[2024-01-20 13:44:40 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:02:09  flops: 42.2904 (42.2904)  loss: 1.0247 (1.0772)  acc1: 77.7778 (77.4236)  acc5: 92.9293 (91.8830)  time: 0.2320  data: 0.0001  max mem: 2179
[2024-01-20 13:44:42 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:02:01  flops: 42.2904 (42.2904)  loss: 1.0731 (1.0801)  acc1: 77.3196 (77.5541)  acc5: 91.9192 (91.8966)  time: 0.2287  data: 0.0001  max mem: 2179
[2024-01-20 13:44:44 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:01:55  flops: 42.2904 (42.2904)  loss: 1.1198 (1.0909)  acc1: 76.2887 (77.1600)  acc5: 92.0000 (92.0000)  time: 0.2281  data: 0.0001  max mem: 2179
[2024-01-20 13:44:46 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:01:50  flops: 42.2904 (42.2904)  loss: 1.1172 (1.0827)  acc1: 77.3196 (77.4641)  acc5: 92.9293 (92.1149)  time: 0.2288  data: 0.0001  max mem: 2179
[2024-01-20 13:44:49 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:01:46  flops: 42.2904 (42.2904)  loss: 1.0337 (1.0836)  acc1: 78.3505 (77.3171)  acc5: 91.8367 (92.1090)  time: 0.2296  data: 0.0001  max mem: 2179
[2024-01-20 13:44:51 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:01:43  flops: 42.2904 (42.2904)  loss: 1.0540 (1.0779)  acc1: 77.5510 (77.4214)  acc5: 91.7526 (92.2390)  time: 0.2284  data: 0.0001  max mem: 2179
[2024-01-20 13:44:53 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:01:40  flops: 42.2904 (42.2904)  loss: 1.0785 (1.0797)  acc1: 77.5510 (77.4891)  acc5: 92.8571 (92.2164)  time: 0.2274  data: 0.0001  max mem: 2179
[2024-01-20 13:44:56 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:01:37  flops: 42.2904 (42.2904)  loss: 1.0541 (1.0733)  acc1: 77.5510 (77.5424)  acc5: 92.9293 (92.3023)  time: 0.2278  data: 0.0001  max mem: 2179
[2024-01-20 13:44:58 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:01:34  flops: 42.2904 (42.2904)  loss: 1.0180 (1.0704)  acc1: 78.5714 (77.6585)  acc5: 92.0000 (92.3296)  time: 0.2288  data: 0.0001  max mem: 2179
[2024-01-20 13:45:00 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:01:31  flops: 42.2904 (42.2904)  loss: 1.0535 (1.0788)  acc1: 79.0000 (77.5263)  acc5: 92.0000 (92.2676)  time: 0.2294  data: 0.0001  max mem: 2179
[2024-01-20 13:45:03 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:01:28  flops: 42.2904 (42.2904)  loss: 1.0576 (1.0731)  acc1: 77.5510 (77.5084)  acc5: 92.9293 (92.3137)  time: 0.2290  data: 0.0001  max mem: 2179
[2024-01-20 13:45:05 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:01:25  flops: 42.2904 (42.2904)  loss: 1.0432 (1.0750)  acc1: 77.5510 (77.4850)  acc5: 92.9293 (92.3121)  time: 0.2292  data: 0.0001  max mem: 2179
[2024-01-20 13:45:07 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:01:23  flops: 42.2904 (42.2904)  loss: 1.0157 (1.0717)  acc1: 78.4946 (77.5755)  acc5: 92.8571 (92.3746)  time: 0.2321  data: 0.0001  max mem: 2179
[2024-01-20 13:45:09 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:01:20  flops: 42.2904 (42.2904)  loss: 1.0157 (1.0744)  acc1: 78.4946 (77.5493)  acc5: 92.8571 (92.3077)  time: 0.2313  data: 0.0001  max mem: 2179
[2024-01-20 13:45:12 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:01:18  flops: 42.2904 (42.2904)  loss: 1.0719 (1.0736)  acc1: 77.5510 (77.6004)  acc5: 91.6667 (92.2733)  time: 0.2316  data: 0.0001  max mem: 2179
[2024-01-20 13:45:14 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:01:15  flops: 42.2904 (42.2904)  loss: 1.0751 (1.0787)  acc1: 76.7677 (77.4657)  acc5: 90.9091 (92.1921)  time: 0.2319  data: 0.0001  max mem: 2179
[2024-01-20 13:45:16 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:01:13  flops: 42.2904 (42.2904)  loss: 1.0413 (1.0799)  acc1: 75.7576 (77.4543)  acc5: 91.8367 (92.1719)  time: 0.2299  data: 0.0001  max mem: 2179
[2024-01-20 13:45:34 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.9, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:45:38 root] (main.py 287): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 13:46:00 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.9, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:46:04 root] (main.py 287): INFO Creating model: deit_small_patch16_224
[2024-01-20 13:46:04 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-20 13:46:52 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.9, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:46:55 root] (main.py 287): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 13:46:57 root] (main.py 373): INFO number of params: 22050664
[2024-01-20 13:47:00 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:20:27  flops: 2.9053 (2.9053)  loss: 1.5522 (1.5522)  acc1: 69.6970 (69.6970)  acc5: 83.8384 (83.8384)  time: 2.4552  data: 0.3253  max mem: 457
[2024-01-20 13:47:00 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:10  flops: 2.9053 (2.9053)  loss: 1.4455 (1.4502)  acc1: 69.3878 (68.4407)  acc5: 86.4583 (86.4613)  time: 0.2670  data: 0.0297  max mem: 458
[2024-01-20 13:47:01 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:15  flops: 2.9053 (2.9053)  loss: 1.4138 (1.4122)  acc1: 70.0000 (69.3392)  acc5: 86.8687 (87.2206)  time: 0.0432  data: 0.0001  max mem: 461
[2024-01-20 13:47:01 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:00:55  flops: 2.9053 (2.9053)  loss: 1.3570 (1.3848)  acc1: 70.4082 (70.1939)  acc5: 88.7755 (87.5780)  time: 0.0365  data: 0.0001  max mem: 461
[2024-01-20 13:47:01 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:00:46  flops: 2.9053 (2.9053)  loss: 1.3896 (1.3943)  acc1: 70.0000 (70.1218)  acc5: 87.7551 (87.3478)  time: 0.0410  data: 0.0065  max mem: 461
[2024-01-20 13:47:02 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:41  flops: 2.9053 (2.9053)  loss: 1.4129 (1.4010)  acc1: 70.0000 (69.8000)  acc5: 87.0000 (87.5800)  time: 0.0512  data: 0.0170  max mem: 461
[2024-01-20 13:47:02 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:38  flops: 2.9053 (2.9053)  loss: 1.3930 (1.3989)  acc1: 69.0722 (69.8296)  acc5: 87.7551 (87.6712)  time: 0.0578  data: 0.0234  max mem: 461
[2024-01-20 13:47:03 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:35  flops: 2.9053 (2.9053)  loss: 1.3681 (1.4022)  acc1: 68.6869 (69.7848)  acc5: 86.8687 (87.4892)  time: 0.0561  data: 0.0215  max mem: 461
[2024-01-20 13:47:04 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:32  flops: 2.9053 (2.9053)  loss: 1.4522 (1.4081)  acc1: 65.6566 (69.4591)  acc5: 85.0000 (87.4340)  time: 0.0517  data: 0.0173  max mem: 461
[2024-01-20 13:47:04 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:30  flops: 2.9053 (2.9053)  loss: 1.4592 (1.4103)  acc1: 65.9794 (69.4815)  acc5: 86.7347 (87.4342)  time: 0.0532  data: 0.0188  max mem: 461
[2024-01-20 13:47:05 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:29  flops: 2.9053 (2.9053)  loss: 1.4180 (1.4079)  acc1: 68.6869 (69.4108)  acc5: 86.7347 (87.4395)  time: 0.0550  data: 0.0205  max mem: 461
[2024-01-20 13:47:05 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:28  flops: 2.9053 (2.9053)  loss: 1.3568 (1.4017)  acc1: 69.6970 (69.6211)  acc5: 86.7347 (87.4392)  time: 0.0601  data: 0.0256  max mem: 461
[2024-01-20 13:47:06 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:27  flops: 2.9053 (2.9053)  loss: 1.4336 (1.4159)  acc1: 69.0000 (69.3395)  acc5: 87.0000 (87.2865)  time: 0.0593  data: 0.0247  max mem: 461
[2024-01-20 13:47:06 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:25  flops: 2.9053 (2.9053)  loss: 1.4336 (1.4138)  acc1: 67.0000 (69.3635)  acc5: 87.6289 (87.3708)  time: 0.0535  data: 0.0188  max mem: 461
[2024-01-20 13:47:07 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:24  flops: 2.9053 (2.9053)  loss: 1.3355 (1.4127)  acc1: 69.7917 (69.3063)  acc5: 88.5417 (87.4395)  time: 0.0542  data: 0.0195  max mem: 461
[2024-01-20 13:47:07 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:23  flops: 2.9053 (2.9053)  loss: 1.4335 (1.4142)  acc1: 69.7917 (69.3770)  acc5: 88.5417 (87.4124)  time: 0.0545  data: 0.0180  max mem: 461
[2024-01-20 13:47:08 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:22  flops: 2.9053 (2.9053)  loss: 1.3842 (1.4183)  acc1: 70.4082 (69.2687)  acc5: 86.5979 (87.3988)  time: 0.0535  data: 0.0171  max mem: 461
[2024-01-20 13:47:09 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:21  flops: 2.9053 (2.9053)  loss: 1.3757 (1.4165)  acc1: 70.4082 (69.3554)  acc5: 86.7347 (87.4360)  time: 0.0540  data: 0.0176  max mem: 461
[2024-01-20 13:47:09 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:20  flops: 2.9053 (2.9053)  loss: 1.4407 (1.4214)  acc1: 68.3673 (69.2806)  acc5: 86.4583 (87.3452)  time: 0.0516  data: 0.0153  max mem: 461
[2024-01-20 13:47:10 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:20  flops: 2.9053 (2.9053)  loss: 1.4784 (1.4212)  acc1: 67.6768 (69.3222)  acc5: 86.7347 (87.3354)  time: 0.0542  data: 0.0196  max mem: 461
[2024-01-20 13:47:10 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:19  flops: 2.9053 (2.9053)  loss: 1.3482 (1.4209)  acc1: 69.0000 (69.3418)  acc5: 86.8687 (87.3233)  time: 0.0577  data: 0.0229  max mem: 461
[2024-01-20 13:47:11 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:18  flops: 2.9053 (2.9053)  loss: 1.4709 (1.4253)  acc1: 67.6768 (69.2456)  acc5: 86.5979 (87.2774)  time: 0.0543  data: 0.0197  max mem: 461
[2024-01-20 13:47:11 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:17  flops: 2.9053 (2.9053)  loss: 1.4203 (1.4206)  acc1: 68.3673 (69.2825)  acc5: 87.7551 (87.3646)  time: 0.0526  data: 0.0180  max mem: 461
[2024-01-20 13:47:12 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:17  flops: 2.9053 (2.9053)  loss: 1.3996 (1.4244)  acc1: 68.0412 (69.2260)  acc5: 87.8788 (87.3237)  time: 0.0539  data: 0.0192  max mem: 461
[2024-01-20 13:47:12 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:16  flops: 2.9053 (2.9053)  loss: 1.4288 (1.4253)  acc1: 67.0000 (69.1976)  acc5: 87.0000 (87.3452)  time: 0.0575  data: 0.0229  max mem: 461
[2024-01-20 13:47:13 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:15  flops: 2.9053 (2.9053)  loss: 1.4010 (1.4269)  acc1: 68.6869 (69.1618)  acc5: 88.5417 (87.2971)  time: 0.0591  data: 0.0246  max mem: 461
[2024-01-20 13:47:14 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:14  flops: 2.9053 (2.9053)  loss: 1.3797 (1.4275)  acc1: 70.4082 (69.2149)  acc5: 87.6289 (87.3098)  time: 0.0564  data: 0.0219  max mem: 461
[2024-01-20 13:47:14 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:14  flops: 2.9053 (2.9053)  loss: 1.4766 (1.4328)  acc1: 69.7917 (69.1556)  acc5: 85.8586 (87.2647)  time: 0.0562  data: 0.0215  max mem: 461
[2024-01-20 13:47:15 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:13  flops: 2.9053 (2.9053)  loss: 1.5483 (1.4337)  acc1: 67.0000 (69.1065)  acc5: 85.5670 (87.2672)  time: 0.0561  data: 0.0213  max mem: 461
[2024-01-20 13:47:15 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:12  flops: 2.9053 (2.9053)  loss: 1.4799 (1.4338)  acc1: 67.7083 (69.0865)  acc5: 85.8586 (87.2792)  time: 0.0532  data: 0.0184  max mem: 461
[2024-01-20 13:47:16 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:12  flops: 2.9053 (2.9053)  loss: 1.4632 (1.4336)  acc1: 69.0000 (69.0781)  acc5: 86.0000 (87.2734)  time: 0.0529  data: 0.0182  max mem: 461
[2024-01-20 13:47:16 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:11  flops: 2.9053 (2.9053)  loss: 1.4169 (1.4367)  acc1: 69.3878 (69.0276)  acc5: 86.7347 (87.2222)  time: 0.0527  data: 0.0182  max mem: 461
[2024-01-20 13:47:17 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:10  flops: 2.9053 (2.9053)  loss: 1.4169 (1.4357)  acc1: 69.6970 (69.0505)  acc5: 86.7347 (87.2352)  time: 0.0516  data: 0.0173  max mem: 461
[2024-01-20 13:47:17 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:10  flops: 2.9053 (2.9053)  loss: 1.4080 (1.4354)  acc1: 69.6970 (69.0634)  acc5: 86.8687 (87.2377)  time: 0.0514  data: 0.0174  max mem: 461
[2024-01-20 13:47:18 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:09  flops: 2.9053 (2.9053)  loss: 1.4080 (1.4340)  acc1: 69.3878 (69.0886)  acc5: 87.0968 (87.2394)  time: 0.0519  data: 0.0177  max mem: 461
[2024-01-20 13:47:18 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:09  flops: 2.9053 (2.9053)  loss: 1.3384 (1.4326)  acc1: 68.0000 (69.0933)  acc5: 87.8788 (87.2624)  time: 0.0542  data: 0.0199  max mem: 461
[2024-01-20 13:47:19 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:08  flops: 2.9053 (2.9053)  loss: 1.3384 (1.4323)  acc1: 68.6869 (69.0667)  acc5: 87.8788 (87.2644)  time: 0.0550  data: 0.0208  max mem: 461
[2024-01-20 13:47:19 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:07  flops: 2.9053 (2.9053)  loss: 1.3507 (1.4314)  acc1: 70.0000 (69.1015)  acc5: 86.3158 (87.2766)  time: 0.0564  data: 0.0221  max mem: 461
[2024-01-20 13:47:20 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:07  flops: 2.9053 (2.9053)  loss: 1.4267 (1.4317)  acc1: 68.6869 (69.0971)  acc5: 86.3158 (87.2508)  time: 0.0563  data: 0.0219  max mem: 461
[2024-01-20 13:47:21 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:06  flops: 2.9053 (2.9053)  loss: 1.3899 (1.4315)  acc1: 69.3878 (69.1384)  acc5: 86.7347 (87.2480)  time: 0.0526  data: 0.0182  max mem: 461
[2024-01-20 13:47:21 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:05  flops: 2.9053 (2.9053)  loss: 1.3646 (1.4305)  acc1: 70.0000 (69.1585)  acc5: 87.8788 (87.2607)  time: 0.0572  data: 0.0226  max mem: 461
[2024-01-20 13:47:22 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:05  flops: 2.9053 (2.9053)  loss: 1.3710 (1.4287)  acc1: 70.0000 (69.1873)  acc5: 87.8788 (87.2721)  time: 0.0558  data: 0.0211  max mem: 461
[2024-01-20 13:47:22 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:04  flops: 2.9053 (2.9053)  loss: 1.3710 (1.4295)  acc1: 70.8333 (69.1824)  acc5: 87.5000 (87.2787)  time: 0.0521  data: 0.0176  max mem: 461
[2024-01-20 13:47:23 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:04  flops: 2.9053 (2.9053)  loss: 1.4815 (1.4299)  acc1: 69.6970 (69.1304)  acc5: 87.6289 (87.2779)  time: 0.0542  data: 0.0197  max mem: 461
[2024-01-20 13:47:23 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:03  flops: 2.9053 (2.9053)  loss: 1.4815 (1.4314)  acc1: 66.3265 (69.0972)  acc5: 87.3684 (87.2739)  time: 0.0538  data: 0.0193  max mem: 461
[2024-01-20 13:47:24 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:02  flops: 2.9053 (2.9053)  loss: 1.4198 (1.4320)  acc1: 66.3265 (69.0805)  acc5: 86.8687 (87.2857)  time: 0.0534  data: 0.0188  max mem: 461
[2024-01-20 13:47:24 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:02  flops: 2.9053 (2.9053)  loss: 1.4214 (1.4313)  acc1: 70.7071 (69.1059)  acc5: 87.8788 (87.3246)  time: 0.0528  data: 0.0181  max mem: 461
[2024-01-20 13:47:25 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:01  flops: 2.9053 (2.9053)  loss: 1.4106 (1.4323)  acc1: 68.7500 (69.0907)  acc5: 88.0000 (87.3132)  time: 0.0522  data: 0.0174  max mem: 461
[2024-01-20 13:47:25 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 2.9053 (2.9053)  loss: 1.4009 (1.4321)  acc1: 68.7500 (69.0853)  acc5: 88.0000 (87.3428)  time: 0.0525  data: 0.0177  max mem: 461
[2024-01-20 13:47:26 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 2.9053 (2.9053)  loss: 1.4408 (1.4321)  acc1: 69.0722 (69.0650)  acc5: 88.0000 (87.3543)  time: 0.0534  data: 0.0186  max mem: 461
[2024-01-20 13:47:26 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 2.9053 (2.9053)  loss: 1.4358 (1.4306)  acc1: 69.0722 (69.0923)  acc5: 87.8788 (87.3628)  time: 0.0544  data: 0.0196  max mem: 461
[2024-01-20 13:47:26 root] (utils.py 307): INFO Test: Total time: 0:00:29 (0.0584 s / it)
[2024-01-20 13:47:26 root] (engine.py 118): INFO * Acc@1 69.092 Acc@5 87.363 loss 1.431 flops 2.905
[2024-01-20 13:47:26 root] (main.py 381): INFO Accuracy of the network on the 50000 test images: 69.1%
[2024-01-20 13:47:34 root] (main_tome.py 218): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:47:38 root] (main_tome.py 288): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 13:47:39 root] (main_tome.py 371): INFO number of params: 22050664
[2024-01-20 13:47:42 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:20:21  flops: 3.9257 (3.9257)  loss: 1.5049 (1.5049)  acc1: 70.7071 (70.7071)  acc5: 85.8586 (85.8586)  time: 2.4429  data: 0.2434  max mem: 411
[2024-01-20 13:47:42 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:12  flops: 3.9257 (3.9257)  loss: 1.4490 (1.4461)  acc1: 70.4082 (68.2540)  acc5: 86.5979 (86.7414)  time: 0.2708  data: 0.0222  max mem: 412
[2024-01-20 13:47:43 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:18  flops: 3.9257 (3.9257)  loss: 1.3723 (1.4024)  acc1: 69.6970 (69.0962)  acc5: 86.8687 (87.7065)  time: 0.0486  data: 0.0001  max mem: 416
[2024-01-20 13:47:43 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:00:57  flops: 3.9257 (3.9257)  loss: 1.3445 (1.3758)  acc1: 69.6970 (69.8653)  acc5: 89.0000 (87.9395)  time: 0.0423  data: 0.0001  max mem: 416
[2024-01-20 13:47:44 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:00:47  flops: 3.9257 (3.9257)  loss: 1.3962 (1.3827)  acc1: 69.6970 (70.0721)  acc5: 86.4583 (87.5466)  time: 0.0408  data: 0.0001  max mem: 416
[2024-01-20 13:47:44 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:41  flops: 3.9257 (3.9257)  loss: 1.3988 (1.3901)  acc1: 69.3878 (69.6000)  acc5: 86.4583 (87.8000)  time: 0.0461  data: 0.0058  max mem: 416
[2024-01-20 13:47:45 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:38  flops: 3.9257 (3.9257)  loss: 1.3936 (1.3879)  acc1: 69.0000 (69.8797)  acc5: 88.7755 (87.8216)  time: 0.0562  data: 0.0158  max mem: 416
[2024-01-20 13:47:45 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:35  flops: 3.9257 (3.9257)  loss: 1.3722 (1.3897)  acc1: 69.6970 (69.8565)  acc5: 87.8788 (87.6471)  time: 0.0567  data: 0.0160  max mem: 416
[2024-01-20 13:47:46 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:33  flops: 3.9257 (3.9257)  loss: 1.4291 (1.3957)  acc1: 66.6667 (69.5094)  acc5: 86.0000 (87.5346)  time: 0.0516  data: 0.0110  max mem: 416
[2024-01-20 13:47:46 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:31  flops: 3.9257 (3.9257)  loss: 1.4241 (1.3967)  acc1: 66.6667 (69.5487)  acc5: 87.5000 (87.5686)  time: 0.0526  data: 0.0120  max mem: 416
[2024-01-20 13:47:47 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:29  flops: 3.9257 (3.9257)  loss: 1.3939 (1.3949)  acc1: 69.3878 (69.4613)  acc5: 87.8788 (87.5706)  time: 0.0548  data: 0.0144  max mem: 416
[2024-01-20 13:47:47 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:28  flops: 3.9257 (3.9257)  loss: 1.3559 (1.3886)  acc1: 71.1340 (69.7312)  acc5: 87.7551 (87.5493)  time: 0.0541  data: 0.0136  max mem: 416
[2024-01-20 13:47:48 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:26  flops: 3.9257 (3.9257)  loss: 1.4200 (1.4002)  acc1: 69.0000 (69.5330)  acc5: 87.0000 (87.4632)  time: 0.0527  data: 0.0120  max mem: 416
[2024-01-20 13:47:48 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:25  flops: 3.9257 (3.9257)  loss: 1.4200 (1.3994)  acc1: 68.6869 (69.5656)  acc5: 86.7347 (87.5107)  time: 0.0556  data: 0.0153  max mem: 416
[2024-01-20 13:47:49 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:24  flops: 3.9257 (3.9257)  loss: 1.3452 (1.3991)  acc1: 69.7917 (69.5445)  acc5: 87.5000 (87.5189)  time: 0.0565  data: 0.0160  max mem: 416
[2024-01-20 13:47:50 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:23  flops: 3.9257 (3.9257)  loss: 1.4050 (1.4001)  acc1: 69.6970 (69.6332)  acc5: 87.6289 (87.4663)  time: 0.0558  data: 0.0139  max mem: 416
[2024-01-20 13:47:50 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:22  flops: 3.9257 (3.9257)  loss: 1.3964 (1.4048)  acc1: 68.7500 (69.4965)  acc5: 86.4583 (87.4178)  time: 0.0577  data: 0.0159  max mem: 416
[2024-01-20 13:47:51 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:21  flops: 3.9257 (3.9257)  loss: 1.3785 (1.4027)  acc1: 69.0000 (69.5520)  acc5: 87.8788 (87.5134)  time: 0.0525  data: 0.0105  max mem: 416
[2024-01-20 13:47:51 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:20  flops: 3.9257 (3.9257)  loss: 1.4237 (1.4081)  acc1: 68.6869 (69.4551)  acc5: 87.8788 (87.4240)  time: 0.0493  data: 0.0072  max mem: 416
[2024-01-20 13:47:52 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:20  flops: 3.9257 (3.9257)  loss: 1.4765 (1.4080)  acc1: 68.6869 (69.4982)  acc5: 86.8687 (87.4100)  time: 0.0514  data: 0.0107  max mem: 416
[2024-01-20 13:47:52 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:19  flops: 3.9257 (3.9257)  loss: 1.3432 (1.4084)  acc1: 69.3878 (69.5141)  acc5: 87.8788 (87.4196)  time: 0.0571  data: 0.0164  max mem: 416
[2024-01-20 13:47:53 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:18  flops: 3.9257 (3.9257)  loss: 1.4372 (1.4122)  acc1: 67.6768 (69.4290)  acc5: 86.8687 (87.3787)  time: 0.0592  data: 0.0188  max mem: 416
[2024-01-20 13:47:53 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:17  flops: 3.9257 (3.9257)  loss: 1.4215 (1.4084)  acc1: 68.3673 (69.4438)  acc5: 88.6598 (87.4568)  time: 0.0597  data: 0.0192  max mem: 416
[2024-01-20 13:47:54 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:17  flops: 3.9257 (3.9257)  loss: 1.4215 (1.4116)  acc1: 68.3673 (69.3935)  acc5: 88.8889 (87.4383)  time: 0.0603  data: 0.0196  max mem: 416
[2024-01-20 13:47:55 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:16  flops: 3.9257 (3.9257)  loss: 1.4355 (1.4122)  acc1: 67.6768 (69.3666)  acc5: 87.0000 (87.4467)  time: 0.0532  data: 0.0126  max mem: 416
[2024-01-20 13:47:55 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:15  flops: 3.9257 (3.9257)  loss: 1.3627 (1.4143)  acc1: 68.3673 (69.3363)  acc5: 87.0000 (87.4107)  time: 0.0513  data: 0.0108  max mem: 416
[2024-01-20 13:47:56 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:14  flops: 3.9257 (3.9257)  loss: 1.3799 (1.4153)  acc1: 70.4082 (69.3436)  acc5: 86.0000 (87.4034)  time: 0.0528  data: 0.0123  max mem: 416
[2024-01-20 13:47:56 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:14  flops: 3.9257 (3.9257)  loss: 1.4889 (1.4205)  acc1: 67.7083 (69.2721)  acc5: 85.8586 (87.3436)  time: 0.0549  data: 0.0144  max mem: 416
[2024-01-20 13:47:57 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:13  flops: 3.9257 (3.9257)  loss: 1.5332 (1.4213)  acc1: 66.6667 (69.2478)  acc5: 85.0000 (87.3324)  time: 0.0553  data: 0.0145  max mem: 416
[2024-01-20 13:47:57 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:12  flops: 3.9257 (3.9257)  loss: 1.4448 (1.4218)  acc1: 67.6768 (69.2160)  acc5: 86.7347 (87.3316)  time: 0.0525  data: 0.0118  max mem: 416
[2024-01-20 13:47:58 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:12  flops: 3.9257 (3.9257)  loss: 1.4357 (1.4219)  acc1: 68.0412 (69.2167)  acc5: 86.7347 (87.3275)  time: 0.0527  data: 0.0122  max mem: 416
[2024-01-20 13:47:58 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:11  flops: 3.9257 (3.9257)  loss: 1.3909 (1.4244)  acc1: 68.0412 (69.1421)  acc5: 86.7347 (87.2615)  time: 0.0531  data: 0.0126  max mem: 416
[2024-01-20 13:47:59 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:10  flops: 3.9257 (3.9257)  loss: 1.3909 (1.4236)  acc1: 68.6869 (69.1488)  acc5: 86.7347 (87.2828)  time: 0.0518  data: 0.0114  max mem: 416
[2024-01-20 13:47:59 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:10  flops: 3.9257 (3.9257)  loss: 1.3957 (1.4232)  acc1: 69.6970 (69.1650)  acc5: 87.8788 (87.2777)  time: 0.0558  data: 0.0156  max mem: 416
[2024-01-20 13:48:00 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:09  flops: 3.9257 (3.9257)  loss: 1.3957 (1.4221)  acc1: 69.6970 (69.1961)  acc5: 86.7347 (87.2693)  time: 0.0590  data: 0.0186  max mem: 416
[2024-01-20 13:48:01 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:09  flops: 3.9257 (3.9257)  loss: 1.3134 (1.4202)  acc1: 68.0412 (69.2006)  acc5: 87.8788 (87.2798)  time: 0.0556  data: 0.0151  max mem: 416
[2024-01-20 13:48:01 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:08  flops: 3.9257 (3.9257)  loss: 1.3134 (1.4199)  acc1: 68.0412 (69.1880)  acc5: 87.8788 (87.2842)  time: 0.0562  data: 0.0159  max mem: 416
[2024-01-20 13:48:02 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:07  flops: 3.9257 (3.9257)  loss: 1.3486 (1.4189)  acc1: 71.0000 (69.2196)  acc5: 87.0000 (87.3013)  time: 0.0560  data: 0.0155  max mem: 416
[2024-01-20 13:48:02 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:07  flops: 3.9257 (3.9257)  loss: 1.4057 (1.4195)  acc1: 69.6970 (69.1987)  acc5: 86.7347 (87.2855)  time: 0.0537  data: 0.0132  max mem: 416
[2024-01-20 13:48:03 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:06  flops: 3.9257 (3.9257)  loss: 1.3720 (1.4192)  acc1: 69.6970 (69.2374)  acc5: 87.5000 (87.2871)  time: 0.0552  data: 0.0148  max mem: 416
[2024-01-20 13:48:03 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:05  flops: 3.9257 (3.9257)  loss: 1.3720 (1.4187)  acc1: 70.0000 (69.2448)  acc5: 87.7551 (87.3038)  time: 0.0559  data: 0.0152  max mem: 416
[2024-01-20 13:48:04 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:05  flops: 3.9257 (3.9257)  loss: 1.3759 (1.4170)  acc1: 69.6970 (69.2740)  acc5: 88.5417 (87.3216)  time: 0.0512  data: 0.0103  max mem: 416
[2024-01-20 13:48:04 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:04  flops: 3.9257 (3.9257)  loss: 1.3500 (1.4180)  acc1: 69.6970 (69.2550)  acc5: 88.5417 (87.3246)  time: 0.0572  data: 0.0166  max mem: 416
[2024-01-20 13:48:05 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:04  flops: 3.9257 (3.9257)  loss: 1.4513 (1.4184)  acc1: 67.6768 (69.2202)  acc5: 86.7347 (87.3228)  time: 0.0676  data: 0.0271  max mem: 416
[2024-01-20 13:48:06 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:03  flops: 3.9257 (3.9257)  loss: 1.4513 (1.4198)  acc1: 67.3469 (69.1849)  acc5: 86.7347 (87.3109)  time: 0.0607  data: 0.0201  max mem: 416
[2024-01-20 13:48:06 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:02  flops: 3.9257 (3.9257)  loss: 1.4263 (1.4206)  acc1: 68.0412 (69.1731)  acc5: 86.0000 (87.3173)  time: 0.0522  data: 0.0115  max mem: 416
[2024-01-20 13:48:07 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:02  flops: 3.9257 (3.9257)  loss: 1.4088 (1.4196)  acc1: 68.6869 (69.1920)  acc5: 88.5417 (87.3688)  time: 0.0520  data: 0.0112  max mem: 416
[2024-01-20 13:48:07 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:01  flops: 3.9257 (3.9257)  loss: 1.3868 (1.4206)  acc1: 69.3878 (69.1815)  acc5: 88.7755 (87.3716)  time: 0.0545  data: 0.0136  max mem: 416
[2024-01-20 13:48:08 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 3.9257 (3.9257)  loss: 1.4060 (1.4205)  acc1: 69.3878 (69.1785)  acc5: 87.8788 (87.3936)  time: 0.0566  data: 0.0157  max mem: 416
[2024-01-20 13:48:08 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 3.9257 (3.9257)  loss: 1.4060 (1.4206)  acc1: 68.6869 (69.1604)  acc5: 87.8788 (87.3916)  time: 0.0559  data: 0.0151  max mem: 416
[2024-01-20 13:48:09 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 3.9257 (3.9257)  loss: 1.3977 (1.4190)  acc1: 68.6869 (69.1778)  acc5: 87.0000 (87.3954)  time: 0.0563  data: 0.0154  max mem: 416
[2024-01-20 13:48:09 root] (utils.py 307): INFO Test: Total time: 0:00:29 (0.0592 s / it)
[2024-01-20 13:48:09 root] (engine.py 118): INFO * Acc@1 69.178 Acc@5 87.395 loss 1.419 flops 3.926
[2024-01-20 13:48:09 root] (main_tome.py 379): INFO Accuracy of the network on the 50000 test images: 69.2%
[2024-01-20 13:48:35 root] (main_tome.py 218): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:48:39 root] (main_tome.py 288): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 13:48:40 root] (main_tome.py 371): INFO number of params: 22050664
[2024-01-20 13:48:43 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:20:13  flops: 3.3726 (3.3726)  loss: 1.5878 (1.5878)  acc1: 69.6970 (69.6970)  acc5: 82.8283 (82.8283)  time: 2.4272  data: 0.3459  max mem: 411
[2024-01-20 13:48:43 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:10  flops: 3.3726 (3.3726)  loss: 1.4783 (1.4817)  acc1: 68.3673 (67.8805)  acc5: 86.5979 (86.0878)  time: 0.2656  data: 0.0315  max mem: 412
[2024-01-20 13:48:44 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:15  flops: 3.3726 (3.3726)  loss: 1.3992 (1.4414)  acc1: 68.3673 (68.5617)  acc5: 86.7347 (86.8805)  time: 0.0443  data: 0.0001  max mem: 415
[2024-01-20 13:48:44 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:00:55  flops: 3.3726 (3.3726)  loss: 1.3950 (1.4120)  acc1: 69.6970 (69.1423)  acc5: 88.8889 (87.4137)  time: 0.0376  data: 0.0001  max mem: 415
[2024-01-20 13:48:44 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:00:46  flops: 3.3726 (3.3726)  loss: 1.3990 (1.4166)  acc1: 69.6970 (69.4258)  acc5: 87.6289 (87.1738)  time: 0.0426  data: 0.0070  max mem: 415
[2024-01-20 13:48:45 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:41  flops: 3.3726 (3.3726)  loss: 1.4189 (1.4253)  acc1: 68.3673 (68.9400)  acc5: 87.5000 (87.3600)  time: 0.0532  data: 0.0180  max mem: 415
[2024-01-20 13:48:46 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:38  flops: 3.3726 (3.3726)  loss: 1.4189 (1.4230)  acc1: 68.0412 (69.1113)  acc5: 87.7551 (87.3872)  time: 0.0588  data: 0.0234  max mem: 415
[2024-01-20 13:48:46 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:35  flops: 3.3726 (3.3726)  loss: 1.3766 (1.4252)  acc1: 69.6970 (69.1248)  acc5: 86.8687 (87.2166)  time: 0.0574  data: 0.0219  max mem: 415
[2024-01-20 13:48:47 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 1.4783 (1.4318)  acc1: 65.6566 (68.8302)  acc5: 86.5979 (87.1069)  time: 0.0524  data: 0.0169  max mem: 415
[2024-01-20 13:48:47 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:31  flops: 3.3726 (3.3726)  loss: 1.4783 (1.4330)  acc1: 65.6566 (68.8879)  acc5: 86.5979 (87.0870)  time: 0.0507  data: 0.0151  max mem: 415
[2024-01-20 13:48:48 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:29  flops: 3.3726 (3.3726)  loss: 1.4364 (1.4312)  acc1: 68.3673 (68.8559)  acc5: 86.5979 (87.1065)  time: 0.0529  data: 0.0174  max mem: 415
[2024-01-20 13:48:48 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 1.3857 (1.4247)  acc1: 70.1031 (69.0797)  acc5: 86.7347 (87.1181)  time: 0.0594  data: 0.0238  max mem: 415
[2024-01-20 13:48:49 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:27  flops: 3.3726 (3.3726)  loss: 1.4566 (1.4362)  acc1: 68.0000 (68.8851)  acc5: 87.0000 (87.0425)  time: 0.0595  data: 0.0238  max mem: 415
[2024-01-20 13:48:49 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 1.4566 (1.4355)  acc1: 68.0000 (68.8972)  acc5: 86.7347 (87.0755)  time: 0.0538  data: 0.0182  max mem: 415
[2024-01-20 13:48:50 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:24  flops: 3.3726 (3.3726)  loss: 1.3871 (1.4343)  acc1: 68.7500 (68.9454)  acc5: 86.8687 (87.1075)  time: 0.0537  data: 0.0181  max mem: 415
[2024-01-20 13:48:50 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:23  flops: 3.3726 (3.3726)  loss: 1.4047 (1.4351)  acc1: 68.8172 (69.0332)  acc5: 87.5000 (87.1022)  time: 0.0547  data: 0.0175  max mem: 415
[2024-01-20 13:48:51 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 1.4263 (1.4395)  acc1: 68.8172 (68.9081)  acc5: 86.7347 (87.0445)  time: 0.0538  data: 0.0168  max mem: 415
[2024-01-20 13:48:52 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:21  flops: 3.3726 (3.3726)  loss: 1.4234 (1.4372)  acc1: 68.3673 (68.9563)  acc5: 86.7347 (87.0964)  time: 0.0539  data: 0.0167  max mem: 415
[2024-01-20 13:48:52 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:20  flops: 3.3726 (3.3726)  loss: 1.4455 (1.4419)  acc1: 68.3673 (68.8921)  acc5: 86.8687 (87.0525)  time: 0.0516  data: 0.0144  max mem: 415
[2024-01-20 13:48:53 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:20  flops: 3.3726 (3.3726)  loss: 1.4825 (1.4409)  acc1: 68.0000 (68.9383)  acc5: 85.8586 (87.0527)  time: 0.0540  data: 0.0184  max mem: 415
[2024-01-20 13:48:53 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 1.3608 (1.4409)  acc1: 69.3878 (68.9720)  acc5: 87.8788 (87.0700)  time: 0.0570  data: 0.0212  max mem: 415
[2024-01-20 13:48:54 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:18  flops: 3.3726 (3.3726)  loss: 1.4526 (1.4443)  acc1: 67.3469 (68.8692)  acc5: 86.8687 (87.0361)  time: 0.0544  data: 0.0188  max mem: 415
[2024-01-20 13:48:54 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:17  flops: 3.3726 (3.3726)  loss: 1.4440 (1.4406)  acc1: 67.3469 (68.8586)  acc5: 87.6289 (87.0835)  time: 0.0561  data: 0.0206  max mem: 415
[2024-01-20 13:48:55 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:17  flops: 3.3726 (3.3726)  loss: 1.4440 (1.4439)  acc1: 67.3469 (68.7985)  acc5: 87.8788 (87.0681)  time: 0.0579  data: 0.0223  max mem: 415
[2024-01-20 13:48:55 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 1.4819 (1.4448)  acc1: 66.6667 (68.7751)  acc5: 86.7347 (87.0706)  time: 0.0558  data: 0.0201  max mem: 415
[2024-01-20 13:48:56 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:15  flops: 3.3726 (3.3726)  loss: 1.4028 (1.4472)  acc1: 68.3673 (68.7277)  acc5: 86.7347 (87.0131)  time: 0.0558  data: 0.0201  max mem: 415
[2024-01-20 13:48:57 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:15  flops: 3.3726 (3.3726)  loss: 1.4033 (1.4481)  acc1: 70.8333 (68.7427)  acc5: 86.5979 (87.0249)  time: 0.0563  data: 0.0208  max mem: 415
[2024-01-20 13:48:57 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 1.5227 (1.4527)  acc1: 67.3469 (68.6708)  acc5: 86.0000 (86.9753)  time: 0.0566  data: 0.0211  max mem: 415
[2024-01-20 13:48:58 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:13  flops: 3.3726 (3.3726)  loss: 1.5716 (1.4535)  acc1: 66.0000 (68.6499)  acc5: 86.0000 (86.9628)  time: 0.0565  data: 0.0209  max mem: 415
[2024-01-20 13:48:58 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:12  flops: 3.3726 (3.3726)  loss: 1.4881 (1.4538)  acc1: 68.3673 (68.6212)  acc5: 87.7551 (86.9748)  time: 0.0538  data: 0.0181  max mem: 415
[2024-01-20 13:48:59 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:12  flops: 3.3726 (3.3726)  loss: 1.4557 (1.4538)  acc1: 68.3673 (68.6080)  acc5: 87.7551 (86.9825)  time: 0.0535  data: 0.0180  max mem: 415
[2024-01-20 13:48:59 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 1.4209 (1.4564)  acc1: 67.0103 (68.5497)  acc5: 86.7347 (86.9342)  time: 0.0541  data: 0.0186  max mem: 415
[2024-01-20 13:49:06 root] (main_tome.py 218): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:49:09 root] (main_tome.py 288): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 13:49:11 root] (main_tome.py 371): INFO number of params: 22050664
[2024-01-20 13:49:13 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:20:32  flops: 3.3726 (3.3726)  loss: 1.5463 (1.5463)  acc1: 70.7071 (70.7071)  acc5: 82.8283 (82.8283)  time: 2.4646  data: 0.2662  max mem: 411
[2024-01-20 13:49:14 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:14  flops: 3.3726 (3.3726)  loss: 1.4652 (1.4487)  acc1: 69.6970 (69.0009)  acc5: 87.7551 (87.0215)  time: 0.2747  data: 0.0243  max mem: 412
[2024-01-20 13:49:14 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:19  flops: 3.3726 (3.3726)  loss: 1.3963 (1.4192)  acc1: 69.3878 (68.9504)  acc5: 87.8788 (87.5121)  time: 0.0505  data: 0.0001  max mem: 416
[2024-01-20 13:49:15 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:00:58  flops: 3.3726 (3.3726)  loss: 1.3855 (1.3922)  acc1: 69.0722 (69.7010)  acc5: 88.0000 (87.6438)  time: 0.0434  data: 0.0001  max mem: 416
[2024-01-20 13:49:15 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:00:48  flops: 3.3726 (3.3726)  loss: 1.3928 (1.4033)  acc1: 70.0000 (69.6247)  acc5: 87.0000 (87.3975)  time: 0.0413  data: 0.0001  max mem: 416
[2024-01-20 13:49:16 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:42  flops: 3.3726 (3.3726)  loss: 1.4404 (1.4149)  acc1: 68.0000 (69.1200)  acc5: 87.0000 (87.4200)  time: 0.0441  data: 0.0033  max mem: 416
[2024-01-20 13:49:16 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:38  flops: 3.3726 (3.3726)  loss: 1.3752 (1.4098)  acc1: 68.6869 (69.4287)  acc5: 87.0000 (87.4206)  time: 0.0532  data: 0.0123  max mem: 416
[2024-01-20 13:49:17 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:35  flops: 3.3726 (3.3726)  loss: 1.3752 (1.4125)  acc1: 70.1031 (69.4261)  acc5: 86.7347 (87.2740)  time: 0.0541  data: 0.0130  max mem: 416
[2024-01-20 13:49:17 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 1.4542 (1.4201)  acc1: 65.9794 (69.1069)  acc5: 86.5979 (87.1195)  time: 0.0515  data: 0.0107  max mem: 416
[2024-01-20 13:49:18 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:31  flops: 3.3726 (3.3726)  loss: 1.4595 (1.4221)  acc1: 65.9794 (69.1343)  acc5: 86.7347 (87.1318)  time: 0.0549  data: 0.0144  max mem: 416
[2024-01-20 13:49:18 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:29  flops: 3.3726 (3.3726)  loss: 1.4375 (1.4211)  acc1: 68.3673 (69.1485)  acc5: 86.7347 (87.1368)  time: 0.0566  data: 0.0160  max mem: 416
[2024-01-20 13:49:19 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 1.4080 (1.4152)  acc1: 69.6970 (69.3550)  acc5: 86.7347 (87.1823)  time: 0.0594  data: 0.0188  max mem: 416
[2024-01-20 13:49:20 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:27  flops: 3.3726 (3.3726)  loss: 1.4438 (1.4265)  acc1: 68.0412 (69.1292)  acc5: 88.0000 (87.1435)  time: 0.0581  data: 0.0174  max mem: 416
[2024-01-20 13:49:20 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:26  flops: 3.3726 (3.3726)  loss: 1.4438 (1.4264)  acc1: 68.0412 (69.0992)  acc5: 87.6289 (87.2231)  time: 0.0541  data: 0.0133  max mem: 416
[2024-01-20 13:49:21 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:24  flops: 3.3726 (3.3726)  loss: 1.3914 (1.4253)  acc1: 68.6869 (69.0969)  acc5: 87.5000 (87.2302)  time: 0.0540  data: 0.0131  max mem: 416
[2024-01-20 13:49:21 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:23  flops: 3.3726 (3.3726)  loss: 1.3953 (1.4262)  acc1: 69.6970 (69.1815)  acc5: 87.0968 (87.2371)  time: 0.0555  data: 0.0132  max mem: 416
[2024-01-20 13:49:22 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 1.3936 (1.4307)  acc1: 68.7500 (69.0157)  acc5: 87.0968 (87.2217)  time: 0.0542  data: 0.0121  max mem: 416
[2024-01-20 13:49:22 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 1.3936 (1.4281)  acc1: 68.6869 (69.1231)  acc5: 86.7347 (87.2632)  time: 0.0537  data: 0.0113  max mem: 416
[2024-01-20 13:49:23 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:21  flops: 3.3726 (3.3726)  loss: 1.4414 (1.4330)  acc1: 68.6869 (69.0948)  acc5: 85.8586 (87.1651)  time: 0.0520  data: 0.0096  max mem: 416
[2024-01-20 13:49:23 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:20  flops: 3.3726 (3.3726)  loss: 1.4870 (1.4325)  acc1: 68.6869 (69.1303)  acc5: 86.8687 (87.1860)  time: 0.0532  data: 0.0128  max mem: 416
[2024-01-20 13:49:24 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 1.3493 (1.4327)  acc1: 69.0000 (69.1240)  acc5: 87.6289 (87.1865)  time: 0.0564  data: 0.0161  max mem: 416
[2024-01-20 13:49:24 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:18  flops: 3.3726 (3.3726)  loss: 1.4918 (1.4362)  acc1: 68.3673 (69.0719)  acc5: 85.8586 (87.1374)  time: 0.0545  data: 0.0144  max mem: 416
[2024-01-20 13:49:25 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:17  flops: 3.3726 (3.3726)  loss: 1.4820 (1.4328)  acc1: 68.3673 (69.0705)  acc5: 87.6289 (87.2218)  time: 0.0532  data: 0.0128  max mem: 416
[2024-01-20 13:49:26 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:17  flops: 3.3726 (3.3726)  loss: 1.4178 (1.4364)  acc1: 68.0412 (68.9748)  acc5: 87.8788 (87.1959)  time: 0.0546  data: 0.0141  max mem: 416
[2024-01-20 13:49:26 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 1.4643 (1.4372)  acc1: 67.6768 (68.9610)  acc5: 87.6289 (87.2143)  time: 0.0589  data: 0.0185  max mem: 416
[2024-01-20 13:49:27 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:15  flops: 3.3726 (3.3726)  loss: 1.4127 (1.4396)  acc1: 69.0000 (68.9265)  acc5: 87.7551 (87.1835)  time: 0.0597  data: 0.0188  max mem: 416
[2024-01-20 13:49:27 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:15  flops: 3.3726 (3.3726)  loss: 1.4060 (1.4404)  acc1: 69.6970 (68.9690)  acc5: 86.7347 (87.1810)  time: 0.0569  data: 0.0158  max mem: 416
[2024-01-20 13:49:28 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 1.4741 (1.4450)  acc1: 68.7500 (68.9114)  acc5: 86.0000 (87.1294)  time: 0.0568  data: 0.0160  max mem: 416
[2024-01-20 13:49:28 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:13  flops: 3.3726 (3.3726)  loss: 1.5661 (1.4456)  acc1: 68.7500 (68.9180)  acc5: 85.8586 (87.1476)  time: 0.0566  data: 0.0157  max mem: 416
[2024-01-20 13:49:29 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:13  flops: 3.3726 (3.3726)  loss: 1.5079 (1.4460)  acc1: 69.0000 (68.8871)  acc5: 86.0000 (87.1497)  time: 0.0538  data: 0.0132  max mem: 416
[2024-01-20 13:49:30 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:12  flops: 3.3726 (3.3726)  loss: 1.5155 (1.4460)  acc1: 68.3673 (68.8718)  acc5: 86.0000 (87.1415)  time: 0.0533  data: 0.0126  max mem: 416
[2024-01-20 13:49:30 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 1.4329 (1.4492)  acc1: 69.0000 (68.8083)  acc5: 85.7143 (87.0716)  time: 0.0536  data: 0.0119  max mem: 416
[2024-01-20 13:49:31 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 1.4329 (1.4484)  acc1: 69.0722 (68.8317)  acc5: 86.5979 (87.0830)  time: 0.0523  data: 0.0107  max mem: 416
[2024-01-20 13:49:31 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:10  flops: 3.3726 (3.3726)  loss: 1.4429 (1.4488)  acc1: 68.6869 (68.8173)  acc5: 86.7347 (87.0900)  time: 0.0514  data: 0.0102  max mem: 416
[2024-01-20 13:49:32 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 1.4429 (1.4476)  acc1: 67.0103 (68.8377)  acc5: 86.7347 (87.0692)  time: 0.0517  data: 0.0105  max mem: 416
[2024-01-20 13:49:32 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 1.3413 (1.4463)  acc1: 67.6768 (68.8467)  acc5: 87.8788 (87.0854)  time: 0.0539  data: 0.0134  max mem: 416
[2024-01-20 13:49:33 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:08  flops: 3.3726 (3.3726)  loss: 1.3413 (1.4458)  acc1: 68.6869 (68.8466)  acc5: 87.6289 (87.0895)  time: 0.0541  data: 0.0141  max mem: 416
[2024-01-20 13:49:33 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 1.3880 (1.4444)  acc1: 70.4082 (68.8792)  acc5: 86.7347 (87.1092)  time: 0.0548  data: 0.0149  max mem: 416
[2024-01-20 13:49:34 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 1.4326 (1.4449)  acc1: 70.4082 (68.8619)  acc5: 86.7347 (87.0931)  time: 0.0548  data: 0.0146  max mem: 416
[2024-01-20 13:49:34 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:06  flops: 3.3726 (3.3726)  loss: 1.4214 (1.4446)  acc1: 69.6970 (68.9014)  acc5: 87.7551 (87.1022)  time: 0.0524  data: 0.0119  max mem: 416
[2024-01-20 13:49:35 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 1.4050 (1.4438)  acc1: 69.6970 (68.9173)  acc5: 87.6289 (87.1236)  time: 0.0576  data: 0.0172  max mem: 416
[2024-01-20 13:49:35 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 1.4050 (1.4423)  acc1: 69.0000 (68.9519)  acc5: 86.8687 (87.1358)  time: 0.0565  data: 0.0163  max mem: 416
[2024-01-20 13:49:36 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:04  flops: 3.3726 (3.3726)  loss: 1.3676 (1.4432)  acc1: 70.1031 (68.9357)  acc5: 87.7551 (87.1505)  time: 0.0520  data: 0.0121  max mem: 416
[2024-01-20 13:49:37 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:04  flops: 3.3726 (3.3726)  loss: 1.4821 (1.4433)  acc1: 67.6768 (68.9083)  acc5: 87.6289 (87.1550)  time: 0.0534  data: 0.0135  max mem: 416
[2024-01-20 13:49:37 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 1.4821 (1.4447)  acc1: 67.3684 (68.8870)  acc5: 86.7347 (87.1469)  time: 0.0554  data: 0.0154  max mem: 416
[2024-01-20 13:49:38 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:02  flops: 3.3726 (3.3726)  loss: 1.4414 (1.4451)  acc1: 68.0412 (68.8546)  acc5: 86.5979 (87.1547)  time: 0.0558  data: 0.0152  max mem: 416
[2024-01-20 13:49:38 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:02  flops: 3.3726 (3.3726)  loss: 1.4198 (1.4441)  acc1: 68.0412 (68.8694)  acc5: 87.8788 (87.2009)  time: 0.0522  data: 0.0113  max mem: 416
[2024-01-20 13:49:39 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 1.4198 (1.4455)  acc1: 69.0000 (68.8550)  acc5: 87.7551 (87.1856)  time: 0.0520  data: 0.0111  max mem: 416
[2024-01-20 13:49:39 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 1.4418 (1.4453)  acc1: 69.0000 (68.8567)  acc5: 87.7551 (87.2115)  time: 0.0530  data: 0.0121  max mem: 416
[2024-01-20 13:49:40 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 1.4289 (1.4450)  acc1: 68.0412 (68.8306)  acc5: 87.8788 (87.2050)  time: 0.0533  data: 0.0123  max mem: 416
[2024-01-20 13:49:40 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 1.4088 (1.4433)  acc1: 68.0412 (68.8621)  acc5: 87.8788 (87.2345)  time: 0.0525  data: 0.0116  max mem: 416
[2024-01-20 13:49:40 root] (utils.py 307): INFO Test: Total time: 0:00:29 (0.0586 s / it)
[2024-01-20 13:49:40 root] (engine.py 118): INFO * Acc@1 68.862 Acc@5 87.234 loss 1.443 flops 3.373
[2024-01-20 13:49:40 root] (main_tome.py 379): INFO Accuracy of the network on the 50000 test images: 68.9%
[2024-01-20 13:52:37 root] (main_tome.py 218): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:52:41 root] (main_tome.py 288): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 13:52:42 root] (main_tome.py 361): INFO number of params: 22050664
[2024-01-20 13:52:45 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:20:04  flops: 3.3726 (3.3726)  loss: 1.5467 (1.5467)  acc1: 70.7071 (70.7071)  acc5: 82.8283 (82.8283)  time: 2.4091  data: 0.2925  max mem: 411
[2024-01-20 13:52:45 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:11  flops: 3.3726 (3.3726)  loss: 1.4656 (1.4486)  acc1: 69.6970 (69.0943)  acc5: 87.7551 (86.9281)  time: 0.2686  data: 0.0267  max mem: 412
[2024-01-20 13:52:46 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:17  flops: 3.3726 (3.3726)  loss: 1.3967 (1.4196)  acc1: 69.3878 (68.9990)  acc5: 87.8788 (87.4636)  time: 0.0488  data: 0.0001  max mem: 416
[2024-01-20 13:52:46 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:00:57  flops: 3.3726 (3.3726)  loss: 1.3862 (1.3928)  acc1: 69.0722 (69.7338)  acc5: 88.0000 (87.6109)  time: 0.0416  data: 0.0001  max mem: 416
[2024-01-20 13:52:46 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:00:46  flops: 3.3726 (3.3726)  loss: 1.3933 (1.4035)  acc1: 70.0000 (69.6495)  acc5: 87.0000 (87.3726)  time: 0.0399  data: 0.0001  max mem: 416
[2024-01-20 13:52:47 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:41  flops: 3.3726 (3.3726)  loss: 1.4379 (1.4152)  acc1: 68.0000 (69.1400)  acc5: 87.0000 (87.4000)  time: 0.0463  data: 0.0067  max mem: 416
[2024-01-20 13:52:48 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:38  flops: 3.3726 (3.3726)  loss: 1.3751 (1.4100)  acc1: 68.6869 (69.4287)  acc5: 87.0000 (87.4039)  time: 0.0568  data: 0.0170  max mem: 416
[2024-01-20 13:52:48 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:35  flops: 3.3726 (3.3726)  loss: 1.3751 (1.4126)  acc1: 70.1031 (69.4261)  acc5: 86.7347 (87.2597)  time: 0.0557  data: 0.0157  max mem: 416
[2024-01-20 13:52:49 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:32  flops: 3.3726 (3.3726)  loss: 1.4570 (1.4202)  acc1: 65.9794 (69.1069)  acc5: 86.5979 (87.1195)  time: 0.0510  data: 0.0113  max mem: 416
[2024-01-20 13:52:49 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:30  flops: 3.3726 (3.3726)  loss: 1.4612 (1.4223)  acc1: 65.9794 (69.1119)  acc5: 86.7347 (87.1318)  time: 0.0521  data: 0.0121  max mem: 416
[2024-01-20 13:52:50 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:29  flops: 3.3726 (3.3726)  loss: 1.4367 (1.4214)  acc1: 68.3673 (69.1283)  acc5: 86.7347 (87.1267)  time: 0.0547  data: 0.0144  max mem: 416
[2024-01-20 13:52:50 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 1.4167 (1.4156)  acc1: 69.6970 (69.3275)  acc5: 86.7347 (87.1823)  time: 0.0588  data: 0.0188  max mem: 416
[2024-01-20 13:52:51 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:26  flops: 3.3726 (3.3726)  loss: 1.4415 (1.4268)  acc1: 68.6869 (69.1123)  acc5: 88.0000 (87.1350)  time: 0.0579  data: 0.0177  max mem: 416
[2024-01-20 13:52:51 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 1.4415 (1.4266)  acc1: 68.3673 (69.0837)  acc5: 87.5000 (87.2154)  time: 0.0540  data: 0.0138  max mem: 416
[2024-01-20 13:52:52 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:24  flops: 3.3726 (3.3726)  loss: 1.3919 (1.4255)  acc1: 68.6869 (69.0825)  acc5: 87.5000 (87.2302)  time: 0.0546  data: 0.0142  max mem: 416
[2024-01-20 13:52:53 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:23  flops: 3.3726 (3.3726)  loss: 1.3987 (1.4264)  acc1: 69.6970 (69.1545)  acc5: 87.0968 (87.2371)  time: 0.0546  data: 0.0127  max mem: 416
[2024-01-20 13:52:53 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 1.3921 (1.4310)  acc1: 68.7500 (68.9967)  acc5: 87.0968 (87.2217)  time: 0.0533  data: 0.0119  max mem: 416
[2024-01-20 13:52:54 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:21  flops: 3.3726 (3.3726)  loss: 1.3921 (1.4282)  acc1: 68.6869 (69.0992)  acc5: 86.7347 (87.2632)  time: 0.0541  data: 0.0123  max mem: 416
[2024-01-20 13:52:54 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:20  flops: 3.3726 (3.3726)  loss: 1.4403 (1.4332)  acc1: 68.6869 (69.0723)  acc5: 85.8586 (87.1651)  time: 0.0524  data: 0.0103  max mem: 416
[2024-01-20 13:52:55 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:20  flops: 3.3726 (3.3726)  loss: 1.4883 (1.4327)  acc1: 68.6869 (69.1089)  acc5: 86.8687 (87.1860)  time: 0.0530  data: 0.0126  max mem: 416
[2024-01-20 13:52:55 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 1.3450 (1.4329)  acc1: 69.0000 (69.1037)  acc5: 87.6289 (87.1865)  time: 0.0553  data: 0.0149  max mem: 416
[2024-01-20 13:52:56 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:18  flops: 3.3726 (3.3726)  loss: 1.4893 (1.4365)  acc1: 68.3673 (69.0526)  acc5: 85.8586 (87.1278)  time: 0.0558  data: 0.0150  max mem: 416
[2024-01-20 13:52:56 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:17  flops: 3.3726 (3.3726)  loss: 1.4813 (1.4330)  acc1: 68.3673 (69.0521)  acc5: 87.7551 (87.2172)  time: 0.0530  data: 0.0123  max mem: 416
[2024-01-20 13:52:57 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 1.4163 (1.4366)  acc1: 68.0412 (68.9572)  acc5: 87.8788 (87.1915)  time: 0.0524  data: 0.0124  max mem: 416
[2024-01-20 13:52:57 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 1.4636 (1.4374)  acc1: 67.6768 (68.9483)  acc5: 87.6289 (87.2100)  time: 0.0579  data: 0.0179  max mem: 416
[2024-01-20 13:52:58 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:15  flops: 3.3726 (3.3726)  loss: 1.4134 (1.4397)  acc1: 69.0000 (68.9143)  acc5: 87.7551 (87.1835)  time: 0.0591  data: 0.0189  max mem: 416
[2024-01-20 13:52:59 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 1.4067 (1.4405)  acc1: 69.6970 (68.9612)  acc5: 86.7347 (87.1810)  time: 0.0565  data: 0.0164  max mem: 416
[2024-01-20 13:52:59 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 1.4746 (1.4451)  acc1: 68.7500 (68.9038)  acc5: 86.0000 (87.1294)  time: 0.0564  data: 0.0159  max mem: 416
[2024-01-20 13:53:00 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:13  flops: 3.3726 (3.3726)  loss: 1.5661 (1.4457)  acc1: 68.7500 (68.9144)  acc5: 85.8586 (87.1476)  time: 0.0565  data: 0.0159  max mem: 416
[2024-01-20 13:53:00 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:12  flops: 3.3726 (3.3726)  loss: 1.5079 (1.4461)  acc1: 69.0000 (68.8836)  acc5: 86.0000 (87.1497)  time: 0.0541  data: 0.0136  max mem: 416
[2024-01-20 13:53:01 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:12  flops: 3.3726 (3.3726)  loss: 1.5144 (1.4461)  acc1: 68.0000 (68.8616)  acc5: 86.0000 (87.1449)  time: 0.0533  data: 0.0128  max mem: 416
[2024-01-20 13:53:01 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 1.4329 (1.4493)  acc1: 68.0000 (68.8018)  acc5: 85.7143 (87.0749)  time: 0.0548  data: 0.0145  max mem: 416
[2024-01-20 13:53:02 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:10  flops: 3.3726 (3.3726)  loss: 1.4329 (1.4485)  acc1: 69.6970 (68.8253)  acc5: 86.5979 (87.0893)  time: 0.0558  data: 0.0153  max mem: 416
[2024-01-20 13:53:02 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:10  flops: 3.3726 (3.3726)  loss: 1.4429 (1.4488)  acc1: 68.6869 (68.8142)  acc5: 86.7347 (87.0962)  time: 0.0536  data: 0.0134  max mem: 416
[2024-01-20 13:53:07 root] (main_tome.py 218): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:53:12 root] (main_tome.py 288): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 13:53:13 root] (main_tome.py 357): INFO number of params: 22050664
[2024-01-20 13:53:15 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:19:24  flops: 3.3726 (3.3726)  loss: 1.5455 (1.5455)  acc1: 70.7071 (70.7071)  acc5: 82.8283 (82.8283)  time: 2.3283  data: 0.2439  max mem: 411
[2024-01-20 13:53:16 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:08  flops: 3.3726 (3.3726)  loss: 1.4652 (1.4485)  acc1: 69.6970 (69.0009)  acc5: 87.7551 (87.0215)  time: 0.2631  data: 0.0223  max mem: 412
[2024-01-20 13:53:16 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:16  flops: 3.3726 (3.3726)  loss: 1.3970 (1.4193)  acc1: 69.3878 (68.9504)  acc5: 87.8788 (87.5121)  time: 0.0499  data: 0.0001  max mem: 416
[2024-01-20 13:53:17 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:00:56  flops: 3.3726 (3.3726)  loss: 1.3855 (1.3924)  acc1: 69.0722 (69.7010)  acc5: 88.0000 (87.6438)  time: 0.0415  data: 0.0001  max mem: 416
[2024-01-20 13:53:17 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:00:46  flops: 3.3726 (3.3726)  loss: 1.3923 (1.4034)  acc1: 70.0000 (69.6247)  acc5: 87.0000 (87.3975)  time: 0.0400  data: 0.0001  max mem: 416
[2024-01-20 13:53:18 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:41  flops: 3.3726 (3.3726)  loss: 1.4407 (1.4151)  acc1: 68.0000 (69.1200)  acc5: 87.0000 (87.4200)  time: 0.0480  data: 0.0081  max mem: 416
[2024-01-20 13:53:18 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:38  flops: 3.3726 (3.3726)  loss: 1.3772 (1.4100)  acc1: 68.6869 (69.4454)  acc5: 87.0000 (87.4206)  time: 0.0587  data: 0.0188  max mem: 416
[2024-01-20 13:53:19 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:35  flops: 3.3726 (3.3726)  loss: 1.3772 (1.4126)  acc1: 70.1031 (69.4405)  acc5: 86.7347 (87.2740)  time: 0.0576  data: 0.0177  max mem: 416
[2024-01-20 13:53:19 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:32  flops: 3.3726 (3.3726)  loss: 1.4538 (1.4202)  acc1: 65.9794 (69.1321)  acc5: 86.5979 (87.1195)  time: 0.0531  data: 0.0131  max mem: 416
[2024-01-20 13:53:20 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:30  flops: 3.3726 (3.3726)  loss: 1.4593 (1.4222)  acc1: 65.9794 (69.1567)  acc5: 86.7347 (87.1318)  time: 0.0506  data: 0.0109  max mem: 416
[2024-01-20 13:53:21 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:29  flops: 3.3726 (3.3726)  loss: 1.4367 (1.4212)  acc1: 68.3673 (69.1687)  acc5: 86.7347 (87.1267)  time: 0.0518  data: 0.0121  max mem: 416
[2024-01-20 13:53:21 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 1.4107 (1.4154)  acc1: 69.6970 (69.3733)  acc5: 86.7347 (87.1731)  time: 0.0561  data: 0.0162  max mem: 416
[2024-01-20 13:53:22 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:26  flops: 3.3726 (3.3726)  loss: 1.4438 (1.4267)  acc1: 68.6869 (69.1544)  acc5: 88.0000 (87.1350)  time: 0.0561  data: 0.0158  max mem: 416
[2024-01-20 13:53:22 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 1.4438 (1.4265)  acc1: 68.3673 (69.1303)  acc5: 87.6289 (87.2154)  time: 0.0547  data: 0.0137  max mem: 416
[2024-01-20 13:53:23 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:24  flops: 3.3726 (3.3726)  loss: 1.3914 (1.4255)  acc1: 68.6869 (69.1258)  acc5: 87.5000 (87.2230)  time: 0.0537  data: 0.0124  max mem: 416
[2024-01-20 13:53:23 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:23  flops: 3.3726 (3.3726)  loss: 1.3945 (1.4264)  acc1: 69.6970 (69.2017)  acc5: 87.0968 (87.2303)  time: 0.0560  data: 0.0134  max mem: 416
[2024-01-20 13:53:24 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 1.3939 (1.4310)  acc1: 68.7500 (69.0347)  acc5: 87.0968 (87.2153)  time: 0.0559  data: 0.0137  max mem: 416
[2024-01-20 13:53:24 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:21  flops: 3.3726 (3.3726)  loss: 1.3939 (1.4283)  acc1: 68.6869 (69.1350)  acc5: 86.7347 (87.2572)  time: 0.0523  data: 0.0096  max mem: 416
[2024-01-20 13:53:25 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:20  flops: 3.3726 (3.3726)  loss: 1.4404 (1.4332)  acc1: 68.6869 (69.1061)  acc5: 85.8586 (87.1594)  time: 0.0506  data: 0.0078  max mem: 416
[2024-01-20 13:53:25 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 1.4870 (1.4327)  acc1: 68.6869 (69.1409)  acc5: 86.8687 (87.1807)  time: 0.0519  data: 0.0107  max mem: 416
[2024-01-20 13:53:26 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 1.3469 (1.4329)  acc1: 69.0000 (69.1341)  acc5: 87.6289 (87.1814)  time: 0.0554  data: 0.0141  max mem: 416
[2024-01-20 13:53:27 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:18  flops: 3.3726 (3.3726)  loss: 1.4925 (1.4364)  acc1: 68.3673 (69.0815)  acc5: 85.8586 (87.1278)  time: 0.0551  data: 0.0141  max mem: 416
[2024-01-20 13:53:27 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:17  flops: 3.3726 (3.3726)  loss: 1.4835 (1.4330)  acc1: 68.3673 (69.0798)  acc5: 87.6289 (87.2126)  time: 0.0579  data: 0.0171  max mem: 416
[2024-01-20 13:53:28 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:17  flops: 3.3726 (3.3726)  loss: 1.4145 (1.4366)  acc1: 68.0412 (68.9880)  acc5: 87.8788 (87.1871)  time: 0.0596  data: 0.0188  max mem: 416
[2024-01-20 13:53:28 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 1.4636 (1.4374)  acc1: 67.6768 (68.9737)  acc5: 87.6289 (87.2058)  time: 0.0539  data: 0.0132  max mem: 416
[2024-01-20 13:53:29 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:15  flops: 3.3726 (3.3726)  loss: 1.4137 (1.4397)  acc1: 69.0000 (68.9346)  acc5: 87.7551 (87.1754)  time: 0.0520  data: 0.0113  max mem: 416
[2024-01-20 13:53:29 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 1.4053 (1.4405)  acc1: 69.6970 (68.9768)  acc5: 86.7347 (87.1732)  time: 0.0532  data: 0.0123  max mem: 416
[2024-01-20 13:53:30 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 1.4745 (1.4451)  acc1: 68.7500 (68.9189)  acc5: 86.0000 (87.1219)  time: 0.0559  data: 0.0146  max mem: 416
[2024-01-20 13:53:30 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:13  flops: 3.3726 (3.3726)  loss: 1.5659 (1.4457)  acc1: 68.7500 (68.9217)  acc5: 85.8586 (87.1404)  time: 0.0569  data: 0.0155  max mem: 416
[2024-01-20 13:53:31 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:12  flops: 3.3726 (3.3726)  loss: 1.5076 (1.4461)  acc1: 69.0000 (68.8906)  acc5: 86.0000 (87.1462)  time: 0.0534  data: 0.0124  max mem: 416
[2024-01-20 13:53:31 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:12  flops: 3.3726 (3.3726)  loss: 1.5135 (1.4461)  acc1: 68.3673 (68.8751)  acc5: 86.0000 (87.1347)  time: 0.0521  data: 0.0112  max mem: 416
[2024-01-20 13:53:32 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 1.4326 (1.4493)  acc1: 69.0000 (68.8148)  acc5: 85.7143 (87.0618)  time: 0.0527  data: 0.0118  max mem: 416
[2024-01-20 13:53:32 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:10  flops: 3.3726 (3.3726)  loss: 1.4326 (1.4485)  acc1: 69.6970 (68.8348)  acc5: 86.5979 (87.0766)  time: 0.0518  data: 0.0110  max mem: 416
[2024-01-20 13:53:33 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:10  flops: 3.3726 (3.3726)  loss: 1.4434 (1.4489)  acc1: 68.6869 (68.8204)  acc5: 86.7347 (87.0839)  time: 0.0504  data: 0.0100  max mem: 416
[2024-01-20 13:53:34 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 1.4434 (1.4477)  acc1: 67.0103 (68.8407)  acc5: 86.7347 (87.0662)  time: 0.0529  data: 0.0123  max mem: 416
[2024-01-20 13:53:34 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:08  flops: 3.3726 (3.3726)  loss: 1.3412 (1.4463)  acc1: 67.6768 (68.8496)  acc5: 87.8788 (87.0854)  time: 0.0539  data: 0.0132  max mem: 416
[2024-01-20 13:53:35 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:08  flops: 3.3726 (3.3726)  loss: 1.3412 (1.4459)  acc1: 68.6869 (68.8551)  acc5: 87.6289 (87.0895)  time: 0.0561  data: 0.0156  max mem: 416
[2024-01-20 13:53:35 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 1.3877 (1.4444)  acc1: 70.0000 (68.8819)  acc5: 86.7347 (87.1092)  time: 0.0562  data: 0.0154  max mem: 416
[2024-01-20 13:53:36 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 1.4316 (1.4450)  acc1: 69.3878 (68.8619)  acc5: 86.7347 (87.0931)  time: 0.0526  data: 0.0117  max mem: 416
[2024-01-20 13:53:36 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:06  flops: 3.3726 (3.3726)  loss: 1.4211 (1.4447)  acc1: 69.6970 (68.8988)  acc5: 87.7551 (87.1022)  time: 0.0539  data: 0.0133  max mem: 416
[2024-01-20 13:53:37 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 1.4045 (1.4439)  acc1: 69.6970 (68.9147)  acc5: 87.6289 (87.1236)  time: 0.0568  data: 0.0163  max mem: 416
[2024-01-20 13:53:37 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 1.4045 (1.4424)  acc1: 69.0000 (68.9495)  acc5: 87.6289 (87.1383)  time: 0.0538  data: 0.0132  max mem: 416
[2024-01-20 13:53:38 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:04  flops: 3.3726 (3.3726)  loss: 1.3674 (1.4432)  acc1: 70.1031 (68.9332)  acc5: 87.8788 (87.1529)  time: 0.0544  data: 0.0139  max mem: 416
[2024-01-20 13:53:39 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:04  flops: 3.3726 (3.3726)  loss: 1.4881 (1.4434)  acc1: 67.6768 (68.9060)  acc5: 87.6289 (87.1574)  time: 0.0630  data: 0.0225  max mem: 416
[2024-01-20 13:53:39 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 1.4867 (1.4447)  acc1: 67.3684 (68.8847)  acc5: 86.7347 (87.1492)  time: 0.0598  data: 0.0193  max mem: 416
[2024-01-20 13:53:40 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:02  flops: 3.3726 (3.3726)  loss: 1.4409 (1.4452)  acc1: 68.0412 (68.8523)  acc5: 86.5979 (87.1570)  time: 0.0521  data: 0.0118  max mem: 416
[2024-01-20 13:53:40 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:02  flops: 3.3726 (3.3726)  loss: 1.4199 (1.4442)  acc1: 68.0412 (68.8672)  acc5: 87.8788 (87.2031)  time: 0.0509  data: 0.0102  max mem: 416
[2024-01-20 13:53:41 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 1.4199 (1.4455)  acc1: 69.0000 (68.8528)  acc5: 87.7551 (87.1878)  time: 0.0544  data: 0.0134  max mem: 416
[2024-01-20 13:53:41 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 1.4402 (1.4453)  acc1: 69.0000 (68.8524)  acc5: 87.7551 (87.2136)  time: 0.0569  data: 0.0162  max mem: 416
[2024-01-20 13:53:42 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 1.4283 (1.4451)  acc1: 68.0412 (68.8244)  acc5: 87.8788 (87.2070)  time: 0.0548  data: 0.0141  max mem: 416
[2024-01-20 13:53:42 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 1.4088 (1.4434)  acc1: 68.0412 (68.8540)  acc5: 87.8788 (87.2365)  time: 0.0557  data: 0.0148  max mem: 416
[2024-01-20 13:53:42 root] (utils.py 307): INFO Test: Total time: 0:00:29 (0.0585 s / it)
[2024-01-20 13:53:42 root] (engine.py 118): INFO * Acc@1 68.854 Acc@5 87.237 loss 1.443 flops 3.373
[2024-01-20 13:53:42 root] (main_tome.py 365): INFO Accuracy of the network on the 50000 test images: 68.9%
[2024-01-20 13:59:32 root] (main_tome.py 214): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:59:35 root] (main_tome.py 284): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 13:59:37 root] (main_tome.py 367): INFO number of params: 22050664
[2024-01-20 13:59:39 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:20:33  flops: 3.9257 (3.9257)  loss: 0.8998 (0.8998)  acc1: 79.7980 (79.7980)  acc5: 93.9394 (93.9394)  time: 2.4672  data: 0.2714  max mem: 411
[2024-01-20 13:59:40 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:13  flops: 3.9257 (3.9257)  loss: 0.9181 (0.9124)  acc1: 79.1667 (79.5518)  acc5: 93.8775 (93.9309)  time: 0.2724  data: 0.0248  max mem: 412
[2024-01-20 13:59:40 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:18  flops: 3.9257 (3.9257)  loss: 0.8927 (0.8854)  acc1: 79.3814 (80.1263)  acc5: 94.7917 (94.5092)  time: 0.0484  data: 0.0001  max mem: 416
[2024-01-20 13:59:41 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:00:58  flops: 3.9257 (3.9257)  loss: 0.8486 (0.8694)  acc1: 80.8081 (80.5455)  acc5: 94.8980 (94.6434)  time: 0.0423  data: 0.0001  max mem: 416
[2024-01-20 13:59:41 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:00:47  flops: 3.9257 (3.9257)  loss: 0.8552 (0.8636)  acc1: 81.2500 (80.8352)  acc5: 94.8980 (94.7552)  time: 0.0407  data: 0.0001  max mem: 416
[2024-01-20 13:59:42 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:42  flops: 3.9257 (3.9257)  loss: 0.8628 (0.8691)  acc1: 80.6122 (80.6800)  acc5: 94.9495 (94.7600)  time: 0.0491  data: 0.0088  max mem: 416
[2024-01-20 13:59:42 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:39  flops: 3.9257 (3.9257)  loss: 0.8845 (0.8696)  acc1: 80.4124 (80.6382)  acc5: 94.9495 (94.8714)  time: 0.0603  data: 0.0199  max mem: 416
[2024-01-20 13:59:43 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:36  flops: 3.9257 (3.9257)  loss: 0.8142 (0.8650)  acc1: 81.0000 (80.7461)  acc5: 95.0000 (94.9498)  time: 0.0573  data: 0.0168  max mem: 416
[2024-01-20 13:59:43 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:33  flops: 3.9257 (3.9257)  loss: 0.8003 (0.8681)  acc1: 79.1667 (80.6164)  acc5: 95.8763 (94.9434)  time: 0.0524  data: 0.0119  max mem: 416
[2024-01-20 13:59:44 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:31  flops: 3.9257 (3.9257)  loss: 0.8416 (0.8690)  acc1: 79.5918 (80.5689)  acc5: 95.8333 (94.9938)  time: 0.0525  data: 0.0121  max mem: 416
[2024-01-20 13:59:45 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:29  flops: 3.9257 (3.9257)  loss: 0.8416 (0.8712)  acc1: 79.5918 (80.4782)  acc5: 94.8980 (94.9859)  time: 0.0531  data: 0.0125  max mem: 416
[2024-01-20 13:59:45 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:28  flops: 3.9257 (3.9257)  loss: 0.8250 (0.8648)  acc1: 82.2917 (80.8056)  acc5: 94.8980 (94.9628)  time: 0.0553  data: 0.0146  max mem: 416
[2024-01-20 13:59:46 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:27  flops: 3.9257 (3.9257)  loss: 0.8715 (0.8749)  acc1: 82.2917 (80.5301)  acc5: 94.7917 (94.9180)  time: 0.0539  data: 0.0131  max mem: 416
[2024-01-20 13:59:46 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:26  flops: 3.9257 (3.9257)  loss: 0.8907 (0.8744)  acc1: 78.3505 (80.4461)  acc5: 95.0000 (95.0105)  time: 0.0570  data: 0.0163  max mem: 416
[2024-01-20 13:59:47 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:25  flops: 3.9257 (3.9257)  loss: 0.8697 (0.8734)  acc1: 80.2083 (80.4447)  acc5: 95.9184 (94.9903)  time: 0.0584  data: 0.0177  max mem: 416
[2024-01-20 13:59:47 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:24  flops: 3.9257 (3.9257)  loss: 0.8135 (0.8691)  acc1: 80.8081 (80.4814)  acc5: 95.8763 (95.0243)  time: 0.0555  data: 0.0131  max mem: 416
[2024-01-20 13:59:48 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:23  flops: 3.9257 (3.9257)  loss: 0.8655 (0.8701)  acc1: 80.6122 (80.4023)  acc5: 95.8763 (95.0405)  time: 0.0559  data: 0.0136  max mem: 416
[2024-01-20 13:59:48 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:22  flops: 3.9257 (3.9257)  loss: 0.8739 (0.8707)  acc1: 79.7980 (80.3527)  acc5: 94.7917 (94.9839)  time: 0.0529  data: 0.0107  max mem: 416
[2024-01-20 13:59:49 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:21  flops: 3.9257 (3.9257)  loss: 0.8777 (0.8755)  acc1: 78.7879 (80.1565)  acc5: 93.8775 (94.9336)  time: 0.0511  data: 0.0088  max mem: 416
[2024-01-20 13:59:49 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:20  flops: 3.9257 (3.9257)  loss: 0.8853 (0.8751)  acc1: 78.0000 (80.1632)  acc5: 94.9495 (94.9448)  time: 0.0539  data: 0.0132  max mem: 416
[2024-01-20 13:59:50 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:19  flops: 3.9257 (3.9257)  loss: 0.8565 (0.8763)  acc1: 80.6122 (80.1540)  acc5: 94.9495 (94.9182)  time: 0.0603  data: 0.0196  max mem: 416
[2024-01-20 13:59:51 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:18  flops: 3.9257 (3.9257)  loss: 0.9474 (0.8779)  acc1: 77.7778 (80.0618)  acc5: 94.9495 (94.9370)  time: 0.0590  data: 0.0183  max mem: 416
[2024-01-20 13:59:51 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:18  flops: 3.9257 (3.9257)  loss: 0.8569 (0.8743)  acc1: 79.7980 (80.1299)  acc5: 95.9184 (94.9956)  time: 0.0597  data: 0.0191  max mem: 416
[2024-01-20 13:59:52 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:17  flops: 3.9257 (3.9257)  loss: 0.8569 (0.8793)  acc1: 79.7980 (79.9542)  acc5: 95.9596 (95.0018)  time: 0.0624  data: 0.0216  max mem: 416
[2024-01-20 13:59:52 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:16  flops: 3.9257 (3.9257)  loss: 0.9329 (0.8825)  acc1: 75.7576 (79.8454)  acc5: 95.0000 (95.0057)  time: 0.0559  data: 0.0152  max mem: 416
[2024-01-20 13:59:53 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:15  flops: 3.9257 (3.9257)  loss: 0.9234 (0.8848)  acc1: 79.0000 (79.7752)  acc5: 93.8144 (94.9611)  time: 0.0529  data: 0.0122  max mem: 416
[2024-01-20 13:59:53 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:15  flops: 3.9257 (3.9257)  loss: 0.9176 (0.8869)  acc1: 79.7980 (79.7510)  acc5: 93.8775 (94.9114)  time: 0.0533  data: 0.0126  max mem: 416
[2024-01-20 13:59:54 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:14  flops: 3.9257 (3.9257)  loss: 0.9037 (0.8892)  acc1: 79.1667 (79.6400)  acc5: 94.9495 (94.9081)  time: 0.0559  data: 0.0152  max mem: 416
[2024-01-20 13:59:55 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:13  flops: 3.9257 (3.9257)  loss: 0.8983 (0.8897)  acc1: 79.1667 (79.6869)  acc5: 93.9394 (94.8656)  time: 0.0561  data: 0.0154  max mem: 416
[2024-01-20 13:59:55 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:13  flops: 3.9257 (3.9257)  loss: 0.8983 (0.8919)  acc1: 79.5918 (79.6522)  acc5: 93.9394 (94.8466)  time: 0.0522  data: 0.0114  max mem: 416
[2024-01-20 13:59:56 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:12  flops: 3.9257 (3.9257)  loss: 0.9257 (0.8918)  acc1: 79.5918 (79.7078)  acc5: 94.8980 (94.8559)  time: 0.0520  data: 0.0110  max mem: 416
[2024-01-20 13:59:56 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:11  flops: 3.9257 (3.9257)  loss: 0.9257 (0.8946)  acc1: 80.0000 (79.6681)  acc5: 93.9394 (94.7959)  time: 0.0542  data: 0.0133  max mem: 416
[2024-01-20 13:59:57 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:11  flops: 3.9257 (3.9257)  loss: 0.9169 (0.8929)  acc1: 80.0000 (79.7032)  acc5: 94.7917 (94.8402)  time: 0.0540  data: 0.0132  max mem: 416
[2024-01-20 13:59:57 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.9, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 13:59:57 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:10  flops: 3.9257 (3.9257)  loss: 0.8722 (0.8933)  acc1: 79.7980 (79.7120)  acc5: 94.8980 (94.8403)  time: 0.0618  data: 0.0207  max mem: 416
[2024-01-20 13:59:58 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:09  flops: 3.9257 (3.9257)  loss: 0.9028 (0.8931)  acc1: 78.1250 (79.7169)  acc5: 94.8980 (94.8396)  time: 0.0638  data: 0.0225  max mem: 416
[2024-01-20 13:59:59 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:09  flops: 3.9257 (3.9257)  loss: 0.8818 (0.8911)  acc1: 78.3505 (79.7331)  acc5: 94.9495 (94.8644)  time: 0.0542  data: 0.0134  max mem: 416
[2024-01-20 13:59:59 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:08  flops: 3.9257 (3.9257)  loss: 0.7998 (0.8903)  acc1: 80.2083 (79.7568)  acc5: 95.8333 (94.8821)  time: 0.0573  data: 0.0166  max mem: 416
[2024-01-20 14:00:00 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:07  flops: 3.9257 (3.9257)  loss: 0.8410 (0.8893)  acc1: 81.6327 (79.8100)  acc5: 95.8333 (94.8997)  time: 0.0582  data: 0.0174  max mem: 416
[2024-01-20 14:00:00 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:07  flops: 3.9257 (3.9257)  loss: 0.8834 (0.8902)  acc1: 82.6531 (79.7883)  acc5: 94.8980 (94.8923)  time: 0.0520  data: 0.0112  max mem: 416
[2024-01-20 14:00:01 root] (main.py 287): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 14:00:01 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:06  flops: 3.9257 (3.9257)  loss: 0.8711 (0.8898)  acc1: 80.2083 (79.7937)  acc5: 94.8980 (94.8924)  time: 0.0570  data: 0.0152  max mem: 416
[2024-01-20 14:00:01 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:06  flops: 3.9257 (3.9257)  loss: 0.8811 (0.8914)  acc1: 79.5918 (79.7420)  acc5: 94.8980 (94.8784)  time: 0.0619  data: 0.0193  max mem: 416
[2024-01-20 14:00:02 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:05  flops: 3.9257 (3.9257)  loss: 0.8943 (0.8900)  acc1: 78.3505 (79.7844)  acc5: 94.0000 (94.8736)  time: 0.0595  data: 0.0158  max mem: 416
[2024-01-20 14:00:03 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:04  flops: 3.9257 (3.9257)  loss: 0.8292 (0.8906)  acc1: 80.8081 (79.7629)  acc5: 94.9495 (94.9008)  time: 0.0653  data: 0.0206  max mem: 416
[2024-01-20 14:00:03 root] (main.py 373): INFO number of params: 22050664
[2024-01-20 14:00:03 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:04  flops: 3.9257 (3.9257)  loss: 0.8754 (0.8910)  acc1: 78.5714 (79.7590)  acc5: 95.9184 (94.8960)  time: 0.0717  data: 0.0283  max mem: 416
[2024-01-20 14:00:04 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:03  flops: 3.9257 (3.9257)  loss: 0.8922 (0.8916)  acc1: 78.7879 (79.7376)  acc5: 94.9495 (94.8865)  time: 0.0635  data: 0.0216  max mem: 416
[2024-01-20 14:00:05 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:03  flops: 3.9257 (3.9257)  loss: 0.8686 (0.8915)  acc1: 80.6122 (79.7416)  acc5: 94.9495 (94.8953)  time: 0.0540  data: 0.0105  max mem: 416
[2024-01-20 14:00:05 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:02  flops: 3.9257 (3.9257)  loss: 0.8716 (0.8918)  acc1: 80.6122 (79.7331)  acc5: 95.8763 (94.8874)  time: 0.0526  data: 0.0069  max mem: 416
[2024-01-20 14:00:06 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:01  flops: 3.9257 (3.9257)  loss: 0.8768 (0.8922)  acc1: 80.8081 (79.7384)  acc5: 95.9184 (94.8773)  time: 0.0566  data: 0.0107  max mem: 416
[2024-01-20 14:00:06 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 3.9257 (3.9257)  loss: 0.9224 (0.8929)  acc1: 79.7980 (79.7311)  acc5: 94.8980 (94.8719)  time: 0.0582  data: 0.0122  max mem: 416
[2024-01-20 14:00:07 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 3.9257 (3.9257)  loss: 0.9429 (0.8940)  acc1: 78.3505 (79.6926)  acc5: 93.8775 (94.8666)  time: 0.0574  data: 0.0093  max mem: 416
[2024-01-20 14:00:07 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:30:41  flops: 2.9053 (2.9053)  loss: 0.9265 (0.9265)  acc1: 78.7879 (78.7879)  acc5: 94.9495 (94.9495)  time: 3.6824  data: 0.1066  max mem: 457
[2024-01-20 14:00:07 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 3.9257 (3.9257)  loss: 0.8351 (0.8922)  acc1: 79.7980 (79.7275)  acc5: 94.9495 (94.8779)  time: 0.0616  data: 0.0046  max mem: 416
[2024-01-20 14:00:07 root] (utils.py 307): INFO Test: Total time: 0:00:30 (0.0610 s / it)
[2024-01-20 14:00:07 root] (engine.py 118): INFO * Acc@1 79.728 Acc@5 94.878 loss 0.892 flops 3.926
[2024-01-20 14:00:07 root] (main_tome.py 375): INFO Accuracy of the network on the 50000 test images: 79.7%
[2024-01-20 14:00:08 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:03:19  flops: 2.9053 (2.9053)  loss: 0.9265 (0.9142)  acc1: 78.1250 (79.4584)  acc5: 94.7917 (94.0243)  time: 0.4065  data: 0.0098  max mem: 458
[2024-01-20 14:00:08 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:51  flops: 2.9053 (2.9053)  loss: 0.8922 (0.8928)  acc1: 79.0000 (79.8834)  acc5: 94.8454 (94.6550)  time: 0.0587  data: 0.0001  max mem: 461
[2024-01-20 14:00:08 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:01:18  flops: 2.9053 (2.9053)  loss: 0.8710 (0.8755)  acc1: 79.3814 (80.6112)  acc5: 95.8333 (94.8735)  time: 0.0369  data: 0.0001  max mem: 461
[2024-01-20 14:00:09 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:01:04  flops: 2.9053 (2.9053)  loss: 0.8296 (0.8696)  acc1: 80.6122 (80.8103)  acc5: 94.9495 (94.9540)  time: 0.0442  data: 0.0093  max mem: 461
[2024-01-20 14:00:09 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:55  flops: 2.9053 (2.9053)  loss: 0.8659 (0.8743)  acc1: 79.5918 (80.5200)  acc5: 95.9596 (95.0000)  time: 0.0558  data: 0.0212  max mem: 461
[2024-01-20 14:00:10 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:50  flops: 2.9053 (2.9053)  loss: 0.8619 (0.8757)  acc1: 79.3814 (80.5212)  acc5: 95.9596 (95.0384)  time: 0.0627  data: 0.0281  max mem: 461
[2024-01-20 14:00:11 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:45  flops: 2.9053 (2.9053)  loss: 0.8379 (0.8727)  acc1: 80.4124 (80.5452)  acc5: 95.8763 (95.0359)  time: 0.0599  data: 0.0252  max mem: 461
[2024-01-20 14:00:11 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:41  flops: 2.9053 (2.9053)  loss: 0.8117 (0.8765)  acc1: 79.3814 (80.4403)  acc5: 94.9495 (95.0063)  time: 0.0518  data: 0.0171  max mem: 461
[2024-01-20 14:00:12 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:38  flops: 2.9053 (2.9053)  loss: 0.8422 (0.8768)  acc1: 79.3814 (80.3785)  acc5: 94.9495 (95.0386)  time: 0.0523  data: 0.0177  max mem: 461
[2024-01-20 14:00:12 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:36  flops: 2.9053 (2.9053)  loss: 0.8422 (0.8786)  acc1: 79.5918 (80.2663)  acc5: 94.9495 (95.0464)  time: 0.0541  data: 0.0194  max mem: 461
[2024-01-20 14:00:13 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:34  flops: 2.9053 (2.9053)  loss: 0.8230 (0.8714)  acc1: 80.6122 (80.5303)  acc5: 94.8980 (95.0454)  time: 0.0565  data: 0.0217  max mem: 461
[2024-01-20 14:00:13 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:32  flops: 2.9053 (2.9053)  loss: 0.8825 (0.8818)  acc1: 80.6122 (80.2440)  acc5: 94.9495 (95.0021)  time: 0.0555  data: 0.0207  max mem: 461
[2024-01-20 14:00:14 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:30  flops: 2.9053 (2.9053)  loss: 0.9026 (0.8807)  acc1: 78.5714 (80.2518)  acc5: 95.0000 (95.0571)  time: 0.0577  data: 0.0231  max mem: 461
[2024-01-20 14:00:15 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:29  flops: 2.9053 (2.9053)  loss: 0.8663 (0.8790)  acc1: 79.7980 (80.2642)  acc5: 95.9184 (95.0697)  time: 0.0594  data: 0.0248  max mem: 461
[2024-01-20 14:00:15 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:27  flops: 2.9053 (2.9053)  loss: 0.8323 (0.8751)  acc1: 80.8081 (80.3533)  acc5: 95.9184 (95.1052)  time: 0.0575  data: 0.0212  max mem: 461
[2024-01-20 14:00:16 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:26  flops: 2.9053 (2.9053)  loss: 0.8360 (0.8752)  acc1: 80.8081 (80.3327)  acc5: 95.0000 (95.0848)  time: 0.0569  data: 0.0207  max mem: 461
[2024-01-20 14:00:16 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:25  flops: 2.9053 (2.9053)  loss: 0.8679 (0.8766)  acc1: 79.7980 (80.2633)  acc5: 93.9394 (95.0197)  time: 0.0532  data: 0.0166  max mem: 461
[2024-01-20 14:00:17 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:24  flops: 2.9053 (2.9053)  loss: 0.8808 (0.8812)  acc1: 77.7778 (80.0889)  acc5: 93.9394 (94.9786)  time: 0.0524  data: 0.0160  max mem: 461
[2024-01-20 14:00:17 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:22  flops: 2.9053 (2.9053)  loss: 0.8808 (0.8808)  acc1: 78.0000 (80.0565)  acc5: 94.8980 (94.9981)  time: 0.0538  data: 0.0191  max mem: 461
[2024-01-20 14:00:18 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:22  flops: 2.9053 (2.9053)  loss: 0.8549 (0.8822)  acc1: 80.4124 (80.0324)  acc5: 94.8980 (94.9739)  time: 0.0595  data: 0.0247  max mem: 461
[2024-01-20 14:00:19 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:21  flops: 2.9053 (2.9053)  loss: 0.9385 (0.8842)  acc1: 79.3814 (79.9411)  acc5: 94.8980 (94.9853)  time: 0.0600  data: 0.0253  max mem: 461
[2024-01-20 14:00:19 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:20  flops: 2.9053 (2.9053)  loss: 0.8463 (0.8802)  acc1: 79.3814 (80.0055)  acc5: 95.8763 (95.0417)  time: 0.0613  data: 0.0266  max mem: 461
[2024-01-20 14:00:20 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:19  flops: 2.9053 (2.9053)  loss: 0.8456 (0.8855)  acc1: 79.3814 (79.8352)  acc5: 95.0000 (95.0502)  time: 0.0642  data: 0.0294  max mem: 461
[2024-01-20 14:00:20 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:18  flops: 2.9053 (2.9053)  loss: 0.9500 (0.8893)  acc1: 76.7677 (79.7017)  acc5: 94.9495 (95.0395)  time: 0.0569  data: 0.0221  max mem: 461
[2024-01-20 14:00:21 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:17  flops: 2.9053 (2.9053)  loss: 0.9330 (0.8915)  acc1: 77.6596 (79.6454)  acc5: 93.8144 (95.0016)  time: 0.0532  data: 0.0185  max mem: 461
[2024-01-20 14:00:21 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:16  flops: 2.9053 (2.9053)  loss: 0.9330 (0.8942)  acc1: 80.0000 (79.5871)  acc5: 93.7500 (94.9504)  time: 0.0534  data: 0.0187  max mem: 461
[2024-01-20 14:00:22 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:15  flops: 2.9053 (2.9053)  loss: 0.9097 (0.8970)  acc1: 80.0000 (79.5122)  acc5: 94.8980 (94.9419)  time: 0.0568  data: 0.0220  max mem: 461
[2024-01-20 14:00:23 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:15  flops: 2.9053 (2.9053)  loss: 0.9080 (0.8975)  acc1: 80.6122 (79.5492)  acc5: 94.9495 (94.9235)  time: 0.0571  data: 0.0222  max mem: 461
[2024-01-20 14:00:23 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:14  flops: 2.9053 (2.9053)  loss: 0.9018 (0.8992)  acc1: 79.7980 (79.5018)  acc5: 94.9495 (94.9201)  time: 0.0526  data: 0.0177  max mem: 461
[2024-01-20 14:00:24 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:13  flops: 2.9053 (2.9053)  loss: 0.9018 (0.8991)  acc1: 78.5714 (79.5319)  acc5: 94.8980 (94.9134)  time: 0.0523  data: 0.0175  max mem: 461
[2024-01-20 14:00:24 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:12  flops: 2.9053 (2.9053)  loss: 0.9557 (0.9019)  acc1: 79.3814 (79.5274)  acc5: 93.8775 (94.8548)  time: 0.0542  data: 0.0194  max mem: 461
[2024-01-20 14:00:25 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:12  flops: 2.9053 (2.9053)  loss: 0.9244 (0.9004)  acc1: 79.3814 (79.5541)  acc5: 94.7917 (94.8814)  time: 0.0543  data: 0.0196  max mem: 461
[2024-01-20 14:00:25 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:11  flops: 2.9053 (2.9053)  loss: 0.9217 (0.9007)  acc1: 79.7980 (79.5643)  acc5: 94.8980 (94.8742)  time: 0.0597  data: 0.0252  max mem: 461
[2024-01-20 14:00:26 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:10  flops: 2.9053 (2.9053)  loss: 0.8885 (0.9001)  acc1: 79.5918 (79.5736)  acc5: 94.7917 (94.8725)  time: 0.0616  data: 0.0270  max mem: 461
[2024-01-20 14:00:26 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:09  flops: 2.9053 (2.9053)  loss: 0.8762 (0.8984)  acc1: 79.3814 (79.5996)  acc5: 94.8980 (94.9021)  time: 0.0547  data: 0.0199  max mem: 461
[2024-01-20 14:00:27 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:09  flops: 2.9053 (2.9053)  loss: 0.8388 (0.8973)  acc1: 80.6122 (79.6411)  acc5: 95.8333 (94.9159)  time: 0.0572  data: 0.0226  max mem: 461
[2024-01-20 14:00:28 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:08  flops: 2.9053 (2.9053)  loss: 0.8388 (0.8963)  acc1: 81.6327 (79.6865)  acc5: 95.0000 (94.9216)  time: 0.0587  data: 0.0239  max mem: 461
[2024-01-20 14:00:28 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:07  flops: 2.9053 (2.9053)  loss: 0.9098 (0.8970)  acc1: 80.6122 (79.6654)  acc5: 94.8980 (94.9137)  time: 0.0532  data: 0.0183  max mem: 461
[2024-01-20 14:00:29 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:07  flops: 2.9053 (2.9053)  loss: 0.8783 (0.8964)  acc1: 79.5918 (79.6661)  acc5: 94.8980 (94.9133)  time: 0.0533  data: 0.0185  max mem: 461
[2024-01-20 14:00:29 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:06  flops: 2.9053 (2.9053)  loss: 0.9193 (0.8983)  acc1: 78.0000 (79.5998)  acc5: 94.8980 (94.8987)  time: 0.0545  data: 0.0197  max mem: 461
[2024-01-20 14:00:30 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:05  flops: 2.9053 (2.9053)  loss: 0.9017 (0.8966)  acc1: 78.0000 (79.6606)  acc5: 94.8980 (94.9009)  time: 0.0519  data: 0.0171  max mem: 461
[2024-01-20 14:00:30 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:05  flops: 2.9053 (2.9053)  loss: 0.8399 (0.8971)  acc1: 79.7980 (79.6275)  acc5: 95.8333 (94.9202)  time: 0.0603  data: 0.0256  max mem: 461
[2024-01-20 14:00:31 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:04  flops: 2.9053 (2.9053)  loss: 0.8814 (0.8972)  acc1: 77.5510 (79.6219)  acc5: 95.9184 (94.9244)  time: 0.0702  data: 0.0357  max mem: 461
[2024-01-20 14:00:32 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:03  flops: 2.9053 (2.9053)  loss: 0.8977 (0.8981)  acc1: 78.3505 (79.6037)  acc5: 94.8980 (94.9142)  time: 0.0623  data: 0.0279  max mem: 461
[2024-01-20 14:00:32 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:03  flops: 2.9053 (2.9053)  loss: 0.8785 (0.8979)  acc1: 79.3814 (79.5970)  acc5: 94.8980 (94.9269)  time: 0.0537  data: 0.0193  max mem: 461
[2024-01-20 14:00:33 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:02  flops: 2.9053 (2.9053)  loss: 0.8595 (0.8980)  acc1: 79.7980 (79.6094)  acc5: 94.8980 (94.9117)  time: 0.0533  data: 0.0186  max mem: 461
[2024-01-20 14:00:33 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:01  flops: 2.9053 (2.9053)  loss: 0.8595 (0.8984)  acc1: 79.7980 (79.6108)  acc5: 94.8980 (94.9032)  time: 0.0585  data: 0.0237  max mem: 461
[2024-01-20 14:00:34 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 2.9053 (2.9053)  loss: 0.9395 (0.8991)  acc1: 79.0000 (79.6147)  acc5: 94.8980 (94.8888)  time: 0.0583  data: 0.0235  max mem: 461
[2024-01-20 14:00:34 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 2.9053 (2.9053)  loss: 0.9431 (0.9001)  acc1: 77.7778 (79.5827)  acc5: 94.8980 (94.8936)  time: 0.0543  data: 0.0196  max mem: 461
[2024-01-20 14:00:35 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 2.9053 (2.9053)  loss: 0.8264 (0.8984)  acc1: 80.4124 (79.6277)  acc5: 95.7895 (94.9003)  time: 0.0584  data: 0.0237  max mem: 461
[2024-01-20 14:00:35 root] (utils.py 307): INFO Test: Total time: 0:00:31 (0.0638 s / it)
[2024-01-20 14:00:35 root] (engine.py 118): INFO * Acc@1 79.628 Acc@5 94.900 loss 0.898 flops 2.905
[2024-01-20 14:00:35 root] (main.py 381): INFO Accuracy of the network on the 50000 test images: 79.6%
[2024-01-20 14:01:07 root] (main_tome.py 214): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 14:01:11 root] (main_tome.py 284): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 14:01:12 root] (main_tome.py 367): INFO number of params: 22050664
[2024-01-20 14:01:15 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:20:14  flops: 3.9257 (3.9257)  loss: 0.8889 (0.8889)  acc1: 78.7879 (78.7879)  acc5: 94.9495 (94.9495)  time: 2.4298  data: 0.4406  max mem: 411
[2024-01-20 14:01:15 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:14  flops: 3.9257 (3.9257)  loss: 0.9425 (0.9117)  acc1: 78.7879 (79.5518)  acc5: 93.8775 (93.6508)  time: 0.2737  data: 0.0402  max mem: 412
[2024-01-20 14:01:16 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:20  flops: 3.9257 (3.9257)  loss: 0.9195 (0.8878)  acc1: 79.3814 (79.9806)  acc5: 93.8775 (94.3635)  time: 0.0537  data: 0.0001  max mem: 416
[2024-01-20 14:01:16 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:01:00  flops: 3.9257 (3.9257)  loss: 0.8592 (0.8695)  acc1: 80.8081 (80.8084)  acc5: 94.9495 (94.6434)  time: 0.0475  data: 0.0001  max mem: 416
[2024-01-20 14:01:17 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:00:49  flops: 3.9257 (3.9257)  loss: 0.8583 (0.8627)  acc1: 81.6327 (80.8601)  acc5: 94.8980 (94.7800)  time: 0.0456  data: 0.0002  max mem: 416
[2024-01-20 14:01:17 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:42  flops: 3.9257 (3.9257)  loss: 0.8583 (0.8657)  acc1: 80.6122 (80.7800)  acc5: 94.8980 (94.8400)  time: 0.0454  data: 0.0002  max mem: 416
[2024-01-20 14:01:18 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:39  flops: 3.9257 (3.9257)  loss: 0.8672 (0.8677)  acc1: 80.4124 (80.6883)  acc5: 95.0000 (94.9215)  time: 0.0520  data: 0.0066  max mem: 416
[2024-01-20 14:01:18 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:36  flops: 3.9257 (3.9257)  loss: 0.8323 (0.8630)  acc1: 78.3505 (80.6887)  acc5: 94.9495 (95.0359)  time: 0.0552  data: 0.0095  max mem: 416
[2024-01-20 14:01:19 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:33  flops: 3.9257 (3.9257)  loss: 0.8052 (0.8660)  acc1: 78.3505 (80.5660)  acc5: 94.9495 (95.0566)  time: 0.0511  data: 0.0056  max mem: 416
[2024-01-20 14:01:19 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:31  flops: 3.9257 (3.9257)  loss: 0.8478 (0.8651)  acc1: 78.7879 (80.4681)  acc5: 94.9495 (95.0722)  time: 0.0560  data: 0.0103  max mem: 416
[2024-01-20 14:01:20 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:30  flops: 3.9257 (3.9257)  loss: 0.8448 (0.8674)  acc1: 78.7879 (80.3168)  acc5: 94.9495 (95.0565)  time: 0.0564  data: 0.0105  max mem: 416
[2024-01-20 14:01:20 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:28  flops: 3.9257 (3.9257)  loss: 0.8325 (0.8616)  acc1: 80.6122 (80.5395)  acc5: 94.9495 (95.0271)  time: 0.0528  data: 0.0072  max mem: 416
[2024-01-20 14:01:21 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:27  flops: 3.9257 (3.9257)  loss: 0.8588 (0.8715)  acc1: 79.7980 (80.2440)  acc5: 94.7917 (94.9600)  time: 0.0533  data: 0.0076  max mem: 416
[2024-01-20 14:01:21 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:26  flops: 3.9257 (3.9257)  loss: 0.8752 (0.8711)  acc1: 78.5714 (80.2129)  acc5: 94.9495 (95.0183)  time: 0.0561  data: 0.0103  max mem: 416
[2024-01-20 14:01:22 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:24  flops: 3.9257 (3.9257)  loss: 0.8413 (0.8700)  acc1: 79.5918 (80.2425)  acc5: 95.8333 (95.0191)  time: 0.0561  data: 0.0103  max mem: 416
[2024-01-20 14:01:23 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:23  flops: 3.9257 (3.9257)  loss: 0.8262 (0.8658)  acc1: 80.8081 (80.3263)  acc5: 95.8763 (95.0850)  time: 0.0540  data: 0.0068  max mem: 416
[2024-01-20 14:01:23 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:22  flops: 3.9257 (3.9257)  loss: 0.8350 (0.8670)  acc1: 79.1667 (80.2062)  acc5: 95.9184 (95.1164)  time: 0.0545  data: 0.0077  max mem: 416
[2024-01-20 14:01:24 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:22  flops: 3.9257 (3.9257)  loss: 0.8560 (0.8678)  acc1: 79.3814 (80.1918)  acc5: 94.8980 (95.0673)  time: 0.0540  data: 0.0070  max mem: 416
[2024-01-20 14:01:24 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:21  flops: 3.9257 (3.9257)  loss: 0.8714 (0.8731)  acc1: 79.3814 (79.9932)  acc5: 93.9394 (95.0236)  time: 0.0579  data: 0.0105  max mem: 416
[2024-01-20 14:01:25 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:20  flops: 3.9257 (3.9257)  loss: 0.8714 (0.8723)  acc1: 78.7879 (80.0192)  acc5: 94.9495 (95.0461)  time: 0.0593  data: 0.0136  max mem: 416
[2024-01-20 14:01:25 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:19  flops: 3.9257 (3.9257)  loss: 0.8399 (0.8735)  acc1: 80.8081 (79.9868)  acc5: 94.9495 (95.0043)  time: 0.0551  data: 0.0095  max mem: 416
[2024-01-20 14:01:26 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:18  flops: 3.9257 (3.9257)  loss: 0.9339 (0.8751)  acc1: 79.5918 (79.9218)  acc5: 94.9495 (95.0287)  time: 0.0575  data: 0.0117  max mem: 416
[2024-01-20 14:01:26 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:18  flops: 3.9257 (3.9257)  loss: 0.8576 (0.8713)  acc1: 80.6122 (79.9687)  acc5: 95.8763 (95.0786)  time: 0.0569  data: 0.0112  max mem: 416
[2024-01-20 14:01:27 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:17  flops: 3.9257 (3.9257)  loss: 0.8576 (0.8761)  acc1: 78.7879 (79.8219)  acc5: 95.9596 (95.0943)  time: 0.0527  data: 0.0068  max mem: 416
[2024-01-20 14:01:28 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:16  flops: 3.9257 (3.9257)  loss: 0.9344 (0.8796)  acc1: 78.0000 (79.7101)  acc5: 94.9495 (95.0775)  time: 0.0526  data: 0.0068  max mem: 416
[2024-01-20 14:01:28 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:15  flops: 3.9257 (3.9257)  loss: 0.9330 (0.8821)  acc1: 78.7234 (79.6454)  acc5: 93.6170 (95.0260)  time: 0.0527  data: 0.0073  max mem: 416
[2024-01-20 14:01:29 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:15  flops: 3.9257 (3.9257)  loss: 0.9011 (0.8842)  acc1: 80.0000 (79.6535)  acc5: 92.9293 (94.9700)  time: 0.0547  data: 0.0094  max mem: 416
[2024-01-20 14:01:29 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:14  flops: 3.9257 (3.9257)  loss: 0.8915 (0.8866)  acc1: 80.2083 (79.5836)  acc5: 94.9495 (94.9570)  time: 0.0563  data: 0.0109  max mem: 416
[2024-01-20 14:01:30 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:13  flops: 3.9257 (3.9257)  loss: 0.8889 (0.8874)  acc1: 79.7980 (79.6108)  acc5: 94.0000 (94.9235)  time: 0.0574  data: 0.0118  max mem: 416
[2024-01-20 14:01:30 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:13  flops: 3.9257 (3.9257)  loss: 0.9128 (0.8897)  acc1: 79.5918 (79.5543)  acc5: 94.0000 (94.9166)  time: 0.0554  data: 0.0099  max mem: 416
[2024-01-20 14:01:31 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:12  flops: 3.9257 (3.9257)  loss: 0.9128 (0.8898)  acc1: 77.8947 (79.5894)  acc5: 94.8980 (94.9236)  time: 0.0556  data: 0.0100  max mem: 416
[2024-01-20 14:01:32 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:11  flops: 3.9257 (3.9257)  loss: 0.9338 (0.8928)  acc1: 79.7980 (79.5634)  acc5: 93.9394 (94.8843)  time: 0.0651  data: 0.0191  max mem: 416
[2024-01-20 14:01:32 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:11  flops: 3.9257 (3.9257)  loss: 0.9116 (0.8913)  acc1: 79.7980 (79.5858)  acc5: 94.7917 (94.9194)  time: 0.0637  data: 0.0180  max mem: 416
[2024-01-20 14:01:33 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:10  flops: 3.9257 (3.9257)  loss: 0.8968 (0.8917)  acc1: 80.2083 (79.5951)  acc5: 94.9495 (94.9234)  time: 0.0532  data: 0.0082  max mem: 416
[2024-01-20 14:01:33 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:09  flops: 3.9257 (3.9257)  loss: 0.8741 (0.8911)  acc1: 78.7879 (79.6273)  acc5: 94.8980 (94.9233)  time: 0.0528  data: 0.0076  max mem: 416
[2024-01-20 14:01:34 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:09  flops: 3.9257 (3.9257)  loss: 0.8741 (0.8897)  acc1: 78.5714 (79.6286)  acc5: 94.9495 (94.9427)  time: 0.0534  data: 0.0081  max mem: 416
[2024-01-20 14:01:34 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:08  flops: 3.9257 (3.9257)  loss: 0.8231 (0.8888)  acc1: 80.0000 (79.6693)  acc5: 95.7895 (94.9611)  time: 0.0518  data: 0.0067  max mem: 416
[2024-01-20 14:01:35 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:07  flops: 3.9257 (3.9257)  loss: 0.8506 (0.8877)  acc1: 82.1053 (79.7167)  acc5: 94.8980 (94.9710)  time: 0.0533  data: 0.0079  max mem: 416
[2024-01-20 14:01:35 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:07  flops: 3.9257 (3.9257)  loss: 0.9209 (0.8884)  acc1: 81.6327 (79.6948)  acc5: 94.8980 (94.9645)  time: 0.0530  data: 0.0076  max mem: 416
[2024-01-20 14:01:36 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:06  flops: 3.9257 (3.9257)  loss: 0.8775 (0.8879)  acc1: 80.6122 (79.7208)  acc5: 94.9495 (94.9601)  time: 0.0515  data: 0.0063  max mem: 416
[2024-01-20 14:01:36 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:06  flops: 3.9257 (3.9257)  loss: 0.8777 (0.8893)  acc1: 79.3814 (79.6684)  acc5: 95.0000 (94.9647)  time: 0.0557  data: 0.0102  max mem: 416
[2024-01-20 14:01:37 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:05  flops: 3.9257 (3.9257)  loss: 0.8914 (0.8878)  acc1: 77.7778 (79.7151)  acc5: 95.0000 (94.9628)  time: 0.0563  data: 0.0110  max mem: 416
[2024-01-20 14:01:38 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:04  flops: 3.9257 (3.9257)  loss: 0.8516 (0.8885)  acc1: 79.7980 (79.6831)  acc5: 95.8763 (94.9903)  time: 0.0557  data: 0.0104  max mem: 416
[2024-01-20 14:01:38 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:04  flops: 3.9257 (3.9257)  loss: 0.8732 (0.8889)  acc1: 78.5714 (79.6905)  acc5: 95.9184 (94.9811)  time: 0.0629  data: 0.0174  max mem: 416
[2024-01-20 14:01:39 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:03  flops: 3.9257 (3.9257)  loss: 0.8832 (0.8894)  acc1: 78.9474 (79.6891)  acc5: 94.9495 (94.9881)  time: 0.0604  data: 0.0153  max mem: 416
[2024-01-20 14:01:39 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:03  flops: 3.9257 (3.9257)  loss: 0.8692 (0.8892)  acc1: 79.3814 (79.6829)  acc5: 95.8763 (95.0015)  time: 0.0528  data: 0.0077  max mem: 416
[2024-01-20 14:01:40 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:02  flops: 3.9257 (3.9257)  loss: 0.8748 (0.8894)  acc1: 78.7879 (79.6801)  acc5: 95.8763 (94.9891)  time: 0.0525  data: 0.0072  max mem: 416
[2024-01-20 14:01:40 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:01  flops: 3.9257 (3.9257)  loss: 0.8790 (0.8899)  acc1: 77.7778 (79.6648)  acc5: 94.9495 (94.9811)  time: 0.0563  data: 0.0109  max mem: 416
[2024-01-20 14:01:41 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 3.9257 (3.9257)  loss: 0.9392 (0.8905)  acc1: 78.3505 (79.6591)  acc5: 94.8980 (94.9756)  time: 0.0578  data: 0.0123  max mem: 416
[2024-01-20 14:01:42 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 3.9257 (3.9257)  loss: 0.9303 (0.8915)  acc1: 77.5510 (79.6138)  acc5: 93.9394 (94.9703)  time: 0.0547  data: 0.0090  max mem: 416
[2024-01-20 14:01:42 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 3.9257 (3.9257)  loss: 0.8295 (0.8898)  acc1: 79.3814 (79.6542)  acc5: 95.0000 (94.9797)  time: 0.0574  data: 0.0117  max mem: 416
[2024-01-20 14:01:42 root] (utils.py 307): INFO Test: Total time: 0:00:29 (0.0598 s / it)
[2024-01-20 14:01:42 root] (engine.py 118): INFO * Acc@1 79.654 Acc@5 94.980 loss 0.890 flops 3.926
[2024-01-20 14:01:42 root] (main_tome.py 375): INFO Accuracy of the network on the 50000 test images: 79.7%
[2024-01-20 14:36:02 root] (main_tome.py 214): INFO Namespace(batch_size=100, epochs=300, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 14:36:06 root] (main_tome.py 284): INFO Creating model: vit_huge_patch14_mae
[2024-01-20 14:38:51 root] (main_tome.py 214): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 14:38:55 root] (main_tome.py 284): INFO Creating model: vit_large_patch16_mae
[2024-01-20 14:39:20 root] (main_tome.py 214): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 14:39:23 root] (main_tome.py 284): INFO Creating model: vit_large_patch16_mae
[2024-01-20 14:39:48 root] (main_tome.py 214): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 14:39:52 root] (main_tome.py 284): INFO Creating model: vit_deit_small_patch16_224
[2024-01-20 14:41:33 root] (main_tome.py 214): INFO Namespace(batch_size=100, epochs=300, model='vit_base_patch16_224.mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 14:41:37 root] (main_tome.py 284): INFO Creating model: vit_base_patch16_224.mae
[2024-01-20 14:41:38 timm.models._builder] (_builder.py 186): INFO Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.mae)
[2024-01-20 14:41:41 timm.models._hub] (_hub.py 180): INFO [timm/vit_base_patch16_224.mae] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[2024-01-20 14:41:41 root] (main_tome.py 367): INFO number of params: 86567656
[2024-01-20 14:42:50 root] (main_tome.py 214): INFO Namespace(batch_size=100, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 14:42:53 root] (main_tome.py 284): INFO Creating model: vit_large_patch16_mae
[2024-01-20 14:43:37 root] (main_tome.py 214): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 14:43:41 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 14:43:42 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 14:43:46 root] (main_tome.py 367): INFO number of params: 86567656
[2024-01-20 14:43:47 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:12:12  flops: 15.0360 (15.0360)  loss: 0.8379 (0.8379)  acc1: 82.8283 (82.8283)  acc5: 92.9293 (92.9293)  time: 1.4655  data: 0.0008  max mem: 977
[2024-01-20 14:43:49 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:01:54  flops: 15.0360 (15.0360)  loss: 0.8379 (0.8426)  acc1: 81.8182 (82.0728)  acc5: 94.7368 (94.4911)  time: 0.2344  data: 0.0002  max mem: 978
[2024-01-20 14:43:50 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:21  flops: 15.0360 (15.0360)  loss: 0.8000 (0.8076)  acc1: 81.8182 (82.7017)  acc5: 94.9495 (95.0923)  time: 0.1042  data: 0.0001  max mem: 984
[2024-01-20 14:43:50 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:01:07  flops: 15.0360 (15.0360)  loss: 0.7548 (0.7993)  acc1: 82.0000 (82.8130)  acc5: 95.8763 (95.2678)  time: 0.0949  data: 0.0001  max mem: 984
[2024-01-20 14:43:51 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:01:00  flops: 15.0360 (15.0360)  loss: 0.8185 (0.7967)  acc1: 82.0000 (82.7243)  acc5: 95.8333 (95.2523)  time: 0.0922  data: 0.0001  max mem: 984
[2024-01-20 14:43:52 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:55  flops: 15.0360 (15.0360)  loss: 0.8369 (0.8135)  acc1: 79.7980 (82.1800)  acc5: 95.0000 (95.3000)  time: 0.0916  data: 0.0001  max mem: 984
[2024-01-20 14:43:53 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:52  flops: 15.0360 (15.0360)  loss: 0.8594 (0.8152)  acc1: 80.6122 (82.2252)  acc5: 95.8763 (95.3892)  time: 0.0919  data: 0.0001  max mem: 984
[2024-01-20 14:43:54 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:49  flops: 15.0360 (15.0360)  loss: 0.7453 (0.8145)  acc1: 82.6531 (82.3673)  acc5: 95.9184 (95.3515)  time: 0.0923  data: 0.0001  max mem: 984
[2024-01-20 14:43:55 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:47  flops: 15.0360 (15.0360)  loss: 0.7427 (0.8149)  acc1: 81.8182 (82.2516)  acc5: 95.9184 (95.4717)  time: 0.0921  data: 0.0001  max mem: 984
[2024-01-20 14:43:56 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:45  flops: 15.0360 (15.0360)  loss: 0.7738 (0.8133)  acc1: 81.6327 (82.2041)  acc5: 95.9184 (95.4978)  time: 0.0918  data: 0.0001  max mem: 984
[2024-01-20 14:43:57 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:43  flops: 15.0360 (15.0360)  loss: 0.7887 (0.8171)  acc1: 81.4433 (81.9613)  acc5: 95.9184 (95.5206)  time: 0.0920  data: 0.0001  max mem: 984
[2024-01-20 14:43:58 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:41  flops: 15.0360 (15.0360)  loss: 0.7513 (0.8109)  acc1: 83.6735 (82.3103)  acc5: 95.8763 (95.4675)  time: 0.0925  data: 0.0001  max mem: 984
[2024-01-20 14:43:59 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:40  flops: 15.0360 (15.0360)  loss: 0.7784 (0.8179)  acc1: 82.8283 (82.1960)  acc5: 95.8333 (95.4985)  time: 0.0925  data: 0.0001  max mem: 984
[2024-01-20 14:44:00 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:38  flops: 15.0360 (15.0360)  loss: 0.7870 (0.8189)  acc1: 82.0000 (82.1248)  acc5: 95.9596 (95.5312)  time: 0.0926  data: 0.0001  max mem: 984
[2024-01-20 14:44:01 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:37  flops: 15.0360 (15.0360)  loss: 0.7846 (0.8190)  acc1: 80.8081 (82.0833)  acc5: 95.9596 (95.6038)  time: 0.0926  data: 0.0001  max mem: 984
[2024-01-20 14:44:02 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:36  flops: 15.0360 (15.0360)  loss: 0.7817 (0.8135)  acc1: 82.6531 (82.2681)  acc5: 96.9072 (95.6850)  time: 0.0942  data: 0.0001  max mem: 984
[2024-01-20 14:44:02 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:34  flops: 15.0360 (15.0360)  loss: 0.8207 (0.8170)  acc1: 83.3333 (82.1862)  acc5: 96.8750 (95.7110)  time: 0.0939  data: 0.0001  max mem: 984
[2024-01-20 14:44:03 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:33  flops: 15.0360 (15.0360)  loss: 0.8454 (0.8172)  acc1: 81.6327 (82.1816)  acc5: 94.9495 (95.6750)  time: 0.0940  data: 0.0001  max mem: 984
[2024-01-20 14:44:04 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:32  flops: 15.0360 (15.0360)  loss: 0.8302 (0.8210)  acc1: 81.6327 (82.0986)  acc5: 94.7368 (95.6204)  time: 0.0945  data: 0.0001  max mem: 984
[2024-01-20 14:44:05 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:31  flops: 15.0360 (15.0360)  loss: 0.8295 (0.8199)  acc1: 80.8081 (82.0935)  acc5: 94.8980 (95.6327)  time: 0.0929  data: 0.0001  max mem: 984
[2024-01-20 14:44:06 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:30  flops: 15.0360 (15.0360)  loss: 0.8295 (0.8208)  acc1: 83.0000 (82.0996)  acc5: 94.8980 (95.5819)  time: 0.0934  data: 0.0001  max mem: 984
[2024-01-20 14:44:07 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:29  flops: 15.0360 (15.0360)  loss: 0.8440 (0.8232)  acc1: 81.8182 (82.0310)  acc5: 94.8980 (95.5548)  time: 0.0933  data: 0.0001  max mem: 984
[2024-01-20 14:44:08 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:28  flops: 15.0360 (15.0360)  loss: 0.8009 (0.8183)  acc1: 81.8182 (82.1160)  acc5: 95.9184 (95.6039)  time: 0.0934  data: 0.0001  max mem: 984
[2024-01-20 14:44:09 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:26  flops: 15.0360 (15.0360)  loss: 0.8009 (0.8234)  acc1: 81.8182 (82.0346)  acc5: 95.9596 (95.5924)  time: 0.0935  data: 0.0001  max mem: 984
[2024-01-20 14:44:10 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:25  flops: 15.0360 (15.0360)  loss: 0.8932 (0.8249)  acc1: 80.6122 (81.9960)  acc5: 95.9184 (95.6099)  time: 0.0931  data: 0.0001  max mem: 984
[2024-01-20 14:44:11 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:24  flops: 15.0360 (15.0360)  loss: 0.8307 (0.8260)  acc1: 80.2083 (81.9661)  acc5: 94.8980 (95.5777)  time: 0.0931  data: 0.0001  max mem: 984
[2024-01-20 14:44:12 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:23  flops: 15.0360 (15.0360)  loss: 0.8365 (0.8294)  acc1: 79.5918 (81.8934)  acc5: 94.8980 (95.5514)  time: 0.0931  data: 0.0001  max mem: 984
[2024-01-20 14:44:13 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:22  flops: 15.0360 (15.0360)  loss: 0.8950 (0.8329)  acc1: 80.2083 (81.8158)  acc5: 95.8763 (95.5582)  time: 0.0934  data: 0.0001  max mem: 984
[2024-01-20 14:44:14 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:21  flops: 15.0360 (15.0360)  loss: 0.8336 (0.8331)  acc1: 81.8182 (81.8067)  acc5: 95.8763 (95.5468)  time: 0.0937  data: 0.0001  max mem: 984
[2024-01-20 14:44:15 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:20  flops: 15.0360 (15.0360)  loss: 0.8045 (0.8334)  acc1: 82.0000 (81.8249)  acc5: 95.0000 (95.5393)  time: 0.0937  data: 0.0001  max mem: 984
[2024-01-20 14:44:16 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:19  flops: 15.0360 (15.0360)  loss: 0.8360 (0.8335)  acc1: 82.0000 (81.8114)  acc5: 94.9495 (95.5425)  time: 0.0934  data: 0.0001  max mem: 984
[2024-01-20 14:44:17 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:18  flops: 15.0360 (15.0360)  loss: 0.8657 (0.8359)  acc1: 81.6327 (81.7759)  acc5: 94.9495 (95.5062)  time: 0.0934  data: 0.0001  max mem: 984
[2024-01-20 14:44:17 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:17  flops: 15.0360 (15.0360)  loss: 0.8787 (0.8348)  acc1: 81.6327 (81.8121)  acc5: 94.8454 (95.5030)  time: 0.0935  data: 0.0001  max mem: 984
[2024-01-20 14:44:18 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:16  flops: 15.0360 (15.0360)  loss: 0.8019 (0.8354)  acc1: 82.2917 (81.7827)  acc5: 95.8763 (95.5080)  time: 0.0928  data: 0.0001  max mem: 984
[2024-01-20 14:44:19 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:15  flops: 15.0360 (15.0360)  loss: 0.8126 (0.8344)  acc1: 81.4433 (81.8223)  acc5: 94.8980 (95.4996)  time: 0.0928  data: 0.0001  max mem: 984
[2024-01-20 14:44:20 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:14  flops: 15.0360 (15.0360)  loss: 0.7799 (0.8324)  acc1: 83.0000 (81.8424)  acc5: 95.9184 (95.5375)  time: 0.0928  data: 0.0001  max mem: 984
[2024-01-20 14:44:21 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:13  flops: 15.0360 (15.0360)  loss: 0.7799 (0.8326)  acc1: 81.8182 (81.8361)  acc5: 95.9184 (95.5310)  time: 0.0923  data: 0.0001  max mem: 984
[2024-01-20 14:44:22 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:12  flops: 15.0360 (15.0360)  loss: 0.8101 (0.8310)  acc1: 81.8182 (81.8579)  acc5: 95.9184 (95.5640)  time: 0.0926  data: 0.0001  max mem: 984
[2024-01-20 14:44:23 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:11  flops: 15.0360 (15.0360)  loss: 0.8101 (0.8317)  acc1: 81.8182 (81.8330)  acc5: 95.9596 (95.5792)  time: 0.0929  data: 0.0001  max mem: 984
[2024-01-20 14:44:24 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:10  flops: 15.0360 (15.0360)  loss: 0.7966 (0.8314)  acc1: 81.8182 (81.8279)  acc5: 95.9184 (95.5826)  time: 0.0926  data: 0.0001  max mem: 984
[2024-01-20 14:44:25 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:09  flops: 15.0360 (15.0360)  loss: 0.8351 (0.8323)  acc1: 80.8081 (81.7836)  acc5: 95.8763 (95.5792)  time: 0.0931  data: 0.0001  max mem: 984
[2024-01-20 14:44:26 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:08  flops: 15.0360 (15.0360)  loss: 0.7872 (0.8299)  acc1: 80.8081 (81.8186)  acc5: 95.9596 (95.6021)  time: 0.0929  data: 0.0001  max mem: 984
[2024-01-20 14:44:27 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:07  flops: 15.0360 (15.0360)  loss: 0.7747 (0.8311)  acc1: 81.2500 (81.7562)  acc5: 95.9596 (95.5926)  time: 0.0922  data: 0.0001  max mem: 984
[2024-01-20 14:44:28 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:06  flops: 15.0360 (15.0360)  loss: 0.8098 (0.8309)  acc1: 80.4124 (81.7746)  acc5: 95.9184 (95.5955)  time: 0.0925  data: 0.0001  max mem: 984
[2024-01-20 14:44:29 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:05  flops: 15.0360 (15.0360)  loss: 0.8181 (0.8316)  acc1: 80.8081 (81.7609)  acc5: 95.8763 (95.5909)  time: 0.0926  data: 0.0001  max mem: 984
[2024-01-20 14:44:29 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:04  flops: 15.0360 (15.0360)  loss: 0.8288 (0.8316)  acc1: 81.2500 (81.7564)  acc5: 95.7895 (95.5887)  time: 0.0924  data: 0.0001  max mem: 984
[2024-01-20 14:44:30 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:03  flops: 15.0360 (15.0360)  loss: 0.7976 (0.8312)  acc1: 81.6327 (81.7680)  acc5: 95.9184 (95.6055)  time: 0.0928  data: 0.0001  max mem: 984
[2024-01-20 14:44:31 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:02  flops: 15.0360 (15.0360)  loss: 0.8290 (0.8320)  acc1: 81.6327 (81.7537)  acc5: 95.9184 (95.5952)  time: 0.0932  data: 0.0001  max mem: 984
[2024-01-20 14:44:32 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 15.0360 (15.0360)  loss: 0.8290 (0.8329)  acc1: 81.4433 (81.7362)  acc5: 94.9495 (95.5960)  time: 0.0933  data: 0.0001  max mem: 984
[2024-01-20 14:44:33 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 15.0360 (15.0360)  loss: 0.8688 (0.8339)  acc1: 80.6122 (81.6983)  acc5: 94.9495 (95.5760)  time: 0.0933  data: 0.0001  max mem: 984
[2024-01-20 14:44:34 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 15.0360 (15.0360)  loss: 0.8137 (0.8323)  acc1: 80.6122 (81.7478)  acc5: 95.7895 (95.5704)  time: 0.0934  data: 0.0001  max mem: 984
[2024-01-20 14:44:34 root] (utils.py 307): INFO Test: Total time: 0:00:48 (0.0962 s / it)
[2024-01-20 14:44:34 root] (engine.py 118): INFO * Acc@1 81.748 Acc@5 95.570 loss 0.832 flops 15.036
[2024-01-20 14:44:34 root] (main_tome.py 375): INFO Accuracy of the network on the 50000 test images: 81.7%
[2024-01-20 14:47:24 root] (main_tome.py 214): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 14:47:28 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 14:47:30 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 14:47:30 root] (main_tome.py 367): INFO number of params: 86567656
[2024-01-20 14:47:32 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:18:02  flops: 12.9405 (12.9405)  loss: 0.8549 (0.8549)  acc1: 80.8081 (80.8081)  acc5: 93.9394 (93.9394)  time: 2.1642  data: 0.2918  max mem: 957
[2024-01-20 14:47:33 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:20  flops: 12.9405 (12.9405)  loss: 0.8549 (0.8686)  acc1: 80.6122 (81.3259)  acc5: 93.9394 (94.6779)  time: 0.2866  data: 0.0266  max mem: 958
[2024-01-20 14:47:34 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:32  flops: 12.9405 (12.9405)  loss: 0.8535 (0.8359)  acc1: 80.6122 (81.9728)  acc5: 94.9495 (95.1409)  time: 0.0932  data: 0.0001  max mem: 964
[2024-01-20 14:47:35 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:01:13  flops: 12.9405 (12.9405)  loss: 0.8262 (0.8307)  acc1: 81.8182 (81.9586)  acc5: 95.0000 (95.2021)  time: 0.0851  data: 0.0001  max mem: 964
[2024-01-20 14:47:36 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:01:03  flops: 12.9405 (12.9405)  loss: 0.8400 (0.8292)  acc1: 80.6122 (81.9786)  acc5: 94.9495 (95.1529)  time: 0.0823  data: 0.0001  max mem: 964
[2024-01-20 14:47:37 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8785 (0.8477)  acc1: 80.4124 (81.5400)  acc5: 94.8980 (95.1800)  time: 0.0820  data: 0.0001  max mem: 964
[2024-01-20 14:47:38 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:52  flops: 12.9405 (12.9405)  loss: 0.8830 (0.8490)  acc1: 80.4124 (81.6405)  acc5: 94.9495 (95.2556)  time: 0.0822  data: 0.0001  max mem: 964
[2024-01-20 14:47:38 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:49  flops: 12.9405 (12.9405)  loss: 0.8085 (0.8488)  acc1: 81.8182 (81.7791)  acc5: 95.9184 (95.2367)  time: 0.0823  data: 0.0001  max mem: 964
[2024-01-20 14:47:39 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:46  flops: 12.9405 (12.9405)  loss: 0.7997 (0.8500)  acc1: 80.6122 (81.6226)  acc5: 95.9184 (95.2956)  time: 0.0822  data: 0.0001  max mem: 964
[2024-01-20 14:47:40 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:44  flops: 12.9405 (12.9405)  loss: 0.8076 (0.8478)  acc1: 80.6122 (81.7001)  acc5: 95.9596 (95.3858)  time: 0.0821  data: 0.0001  max mem: 964
[2024-01-20 14:47:41 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:42  flops: 12.9405 (12.9405)  loss: 0.8142 (0.8520)  acc1: 81.4433 (81.4669)  acc5: 95.9184 (95.4197)  time: 0.0824  data: 0.0001  max mem: 964
[2024-01-20 14:47:42 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8077 (0.8459)  acc1: 81.8182 (81.8057)  acc5: 94.9495 (95.3757)  time: 0.0829  data: 0.0001  max mem: 964
[2024-01-20 14:47:43 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:38  flops: 12.9405 (12.9405)  loss: 0.8173 (0.8529)  acc1: 82.8283 (81.6828)  acc5: 94.9495 (95.3976)  time: 0.0827  data: 0.0001  max mem: 964
[2024-01-20 14:47:43 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:36  flops: 12.9405 (12.9405)  loss: 0.8271 (0.8543)  acc1: 81.4433 (81.6119)  acc5: 95.9184 (95.3991)  time: 0.0823  data: 0.0001  max mem: 964
[2024-01-20 14:47:44 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8133 (0.8534)  acc1: 80.8081 (81.5924)  acc5: 95.9596 (95.4522)  time: 0.0822  data: 0.0001  max mem: 964
[2024-01-20 14:47:45 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8013 (0.8480)  acc1: 81.7204 (81.7691)  acc5: 96.7742 (95.5030)  time: 0.0843  data: 0.0001  max mem: 964
[2024-01-20 14:47:46 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:32  flops: 12.9405 (12.9405)  loss: 0.8613 (0.8512)  acc1: 81.2500 (81.6359)  acc5: 96.8750 (95.5339)  time: 0.0839  data: 0.0001  max mem: 964
[2024-01-20 14:47:47 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8899 (0.8512)  acc1: 80.0000 (81.6454)  acc5: 95.8763 (95.5379)  time: 0.0842  data: 0.0001  max mem: 965
[2024-01-20 14:47:48 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8249 (0.8548)  acc1: 80.8081 (81.5638)  acc5: 94.8980 (95.4740)  time: 0.0844  data: 0.0001  max mem: 965
[2024-01-20 14:47:48 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8321 (0.8534)  acc1: 80.8081 (81.5923)  acc5: 93.9394 (95.4781)  time: 0.0825  data: 0.0001  max mem: 965
[2024-01-20 14:47:49 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:28  flops: 12.9405 (12.9405)  loss: 0.8399 (0.8538)  acc1: 82.4742 (81.6031)  acc5: 94.9495 (95.4299)  time: 0.0830  data: 0.0001  max mem: 965
[2024-01-20 14:47:50 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8805 (0.8566)  acc1: 80.8081 (81.5242)  acc5: 93.9394 (95.3762)  time: 0.0829  data: 0.0001  max mem: 965
[2024-01-20 14:47:51 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8249 (0.8521)  acc1: 80.8081 (81.5907)  acc5: 94.9495 (95.4196)  time: 0.0829  data: 0.0001  max mem: 965
[2024-01-20 14:47:52 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8249 (0.8571)  acc1: 80.6122 (81.4792)  acc5: 95.9184 (95.4161)  time: 0.0832  data: 0.0001  max mem: 965
[2024-01-20 14:47:53 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:24  flops: 12.9405 (12.9405)  loss: 0.9237 (0.8585)  acc1: 79.5918 (81.4467)  acc5: 95.7447 (95.4071)  time: 0.0831  data: 0.0001  max mem: 965
[2024-01-20 14:47:53 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8639 (0.8596)  acc1: 79.7980 (81.4103)  acc5: 94.8980 (95.3708)  time: 0.0831  data: 0.0001  max mem: 965
[2024-01-20 14:47:54 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:21  flops: 12.9405 (12.9405)  loss: 0.8739 (0.8627)  acc1: 79.7980 (81.3588)  acc5: 94.7917 (95.3407)  time: 0.0831  data: 0.0001  max mem: 965
[2024-01-20 14:47:55 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:21  flops: 12.9405 (12.9405)  loss: 0.8939 (0.8665)  acc1: 80.2083 (81.2935)  acc5: 94.9495 (95.3365)  time: 0.0835  data: 0.0001  max mem: 965
[2024-01-20 14:47:56 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.8825 (0.8667)  acc1: 80.2083 (81.2849)  acc5: 95.0000 (95.3221)  time: 0.0838  data: 0.0001  max mem: 965
[2024-01-20 14:47:57 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8323 (0.8670)  acc1: 81.0000 (81.2931)  acc5: 95.0000 (95.3259)  time: 0.0833  data: 0.0001  max mem: 965
[2024-01-20 14:47:58 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:18  flops: 12.9405 (12.9405)  loss: 0.8593 (0.8668)  acc1: 82.6531 (81.3007)  acc5: 95.9184 (95.3396)  time: 0.0833  data: 0.0001  max mem: 965
[2024-01-20 14:47:58 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:17  flops: 12.9405 (12.9405)  loss: 0.8794 (0.8695)  acc1: 80.8081 (81.2326)  acc5: 94.8980 (95.3000)  time: 0.0836  data: 0.0001  max mem: 965
[2024-01-20 14:47:59 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.9049 (0.8686)  acc1: 79.7980 (81.2476)  acc5: 94.8980 (95.3000)  time: 0.0833  data: 0.0001  max mem: 965
[2024-01-20 14:48:00 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8363 (0.8691)  acc1: 80.4124 (81.2258)  acc5: 94.9495 (95.3049)  time: 0.0825  data: 0.0001  max mem: 965
[2024-01-20 14:48:01 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:14  flops: 12.9405 (12.9405)  loss: 0.8481 (0.8678)  acc1: 80.8081 (81.2519)  acc5: 94.8980 (95.3174)  time: 0.0828  data: 0.0001  max mem: 965
[2024-01-20 14:48:02 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8693 (0.8660)  acc1: 81.0526 (81.2825)  acc5: 95.9184 (95.3460)  time: 0.0828  data: 0.0001  max mem: 965
[2024-01-20 14:48:03 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8693 (0.8663)  acc1: 81.8182 (81.2860)  acc5: 95.8763 (95.3363)  time: 0.0824  data: 0.0001  max mem: 965
[2024-01-20 14:48:03 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:11  flops: 12.9405 (12.9405)  loss: 0.8500 (0.8650)  acc1: 81.6327 (81.3253)  acc5: 95.0000 (95.3444)  time: 0.0829  data: 0.0001  max mem: 965
[2024-01-20 14:48:04 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8500 (0.8656)  acc1: 81.8182 (81.2984)  acc5: 95.9184 (95.3600)  time: 0.0831  data: 0.0001  max mem: 965
[2024-01-20 14:48:05 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:09  flops: 12.9405 (12.9405)  loss: 0.8205 (0.8649)  acc1: 81.6327 (81.2966)  acc5: 95.9184 (95.3717)  time: 0.0830  data: 0.0001  max mem: 965
[2024-01-20 14:48:06 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:08  flops: 12.9405 (12.9405)  loss: 0.8478 (0.8659)  acc1: 80.0000 (81.2656)  acc5: 95.8333 (95.3837)  time: 0.0835  data: 0.0001  max mem: 965
[2024-01-20 14:48:07 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8352 (0.8634)  acc1: 80.0000 (81.2958)  acc5: 95.0000 (95.4063)  time: 0.0835  data: 0.0001  max mem: 965
[2024-01-20 14:48:08 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.7989 (0.8645)  acc1: 81.2500 (81.2675)  acc5: 95.8333 (95.4040)  time: 0.0830  data: 0.0001  max mem: 965
[2024-01-20 14:48:08 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:06  flops: 12.9405 (12.9405)  loss: 0.8489 (0.8643)  acc1: 80.6122 (81.2807)  acc5: 95.8333 (95.3970)  time: 0.0830  data: 0.0001  max mem: 965
[2024-01-20 14:48:09 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:05  flops: 12.9405 (12.9405)  loss: 0.8521 (0.8648)  acc1: 80.8081 (81.2828)  acc5: 95.8763 (95.3900)  time: 0.0827  data: 0.0001  max mem: 965
[2024-01-20 14:48:10 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8718 (0.8644)  acc1: 81.6327 (81.2956)  acc5: 94.9495 (95.3809)  time: 0.0826  data: 0.0001  max mem: 965
[2024-01-20 14:48:11 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:03  flops: 12.9405 (12.9405)  loss: 0.8122 (0.8640)  acc1: 81.2500 (81.3172)  acc5: 95.9184 (95.3845)  time: 0.0828  data: 0.0001  max mem: 965
[2024-01-20 14:48:12 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:02  flops: 12.9405 (12.9405)  loss: 0.8617 (0.8649)  acc1: 80.8081 (81.3082)  acc5: 95.9184 (95.3725)  time: 0.0832  data: 0.0001  max mem: 965
[2024-01-20 14:48:13 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8777 (0.8656)  acc1: 80.8081 (81.2810)  acc5: 93.9394 (95.3589)  time: 0.0832  data: 0.0002  max mem: 965
[2024-01-20 14:48:13 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8914 (0.8668)  acc1: 79.0000 (81.2337)  acc5: 94.7368 (95.3416)  time: 0.0832  data: 0.0002  max mem: 965
[2024-01-20 14:48:14 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8389 (0.8653)  acc1: 79.7980 (81.2814)  acc5: 95.0000 (95.3423)  time: 0.0832  data: 0.0001  max mem: 965
[2024-01-20 14:48:14 root] (utils.py 307): INFO Test: Total time: 0:00:43 (0.0876 s / it)
[2024-01-20 14:48:14 root] (engine.py 118): INFO * Acc@1 81.281 Acc@5 95.342 loss 0.865 flops 12.940
[2024-01-20 14:48:14 root] (main_tome.py 375): INFO Accuracy of the network on the 50000 test images: 81.3%
[2024-01-20 14:49:46 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.9, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 14:49:49 root] (main.py 287): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 14:49:51 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 14:50:13 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=11.5, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 14:50:17 root] (main.py 287): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 14:50:19 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 14:50:19 root] (main.py 373): INFO number of params: 86567656
[2024-01-20 14:50:22 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:17:57  flops: 11.5172 (11.5172)  loss: 0.8763 (0.8763)  acc1: 83.8384 (83.8384)  acc5: 93.9394 (93.9394)  time: 2.1544  data: 0.0929  max mem: 1089
[2024-01-20 14:50:22 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:18  flops: 11.5172 (11.5172)  loss: 0.8763 (0.8710)  acc1: 80.8081 (81.7927)  acc5: 94.7368 (94.3044)  time: 0.2819  data: 0.0085  max mem: 1091
[2024-01-20 14:50:23 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:29  flops: 11.5172 (11.5172)  loss: 0.8550 (0.8403)  acc1: 82.4742 (82.5073)  acc5: 94.7917 (95.0437)  time: 0.0882  data: 0.0001  max mem: 1096
[2024-01-20 14:50:24 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:01:11  flops: 11.5172 (11.5172)  loss: 0.7681 (0.8292)  acc1: 82.4742 (82.5501)  acc5: 95.0000 (95.1364)  time: 0.0793  data: 0.0001  max mem: 1096
[2024-01-20 14:50:25 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:01:01  flops: 11.5172 (11.5172)  loss: 0.8212 (0.8252)  acc1: 80.0000 (82.3763)  acc5: 94.9495 (95.2026)  time: 0.0767  data: 0.0001  max mem: 1096
[2024-01-20 14:50:26 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:54  flops: 11.5172 (11.5172)  loss: 0.8434 (0.8397)  acc1: 80.6122 (81.9000)  acc5: 94.8980 (95.2800)  time: 0.0763  data: 0.0001  max mem: 1096
[2024-01-20 14:50:26 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:50  flops: 11.5172 (11.5172)  loss: 0.9005 (0.8402)  acc1: 80.6122 (82.0247)  acc5: 95.8333 (95.3558)  time: 0.0764  data: 0.0001  max mem: 1096
[2024-01-20 14:50:27 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:46  flops: 11.5172 (11.5172)  loss: 0.7652 (0.8375)  acc1: 81.8182 (82.1234)  acc5: 95.9184 (95.4232)  time: 0.0768  data: 0.0001  max mem: 1096
[2024-01-20 14:50:28 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:44  flops: 11.5172 (11.5172)  loss: 0.7652 (0.8385)  acc1: 80.8081 (81.8742)  acc5: 94.9495 (95.4340)  time: 0.0766  data: 0.0001  max mem: 1096
[2024-01-20 14:50:29 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:41  flops: 11.5172 (11.5172)  loss: 0.8084 (0.8356)  acc1: 80.8081 (81.8569)  acc5: 95.8763 (95.4754)  time: 0.0764  data: 0.0001  max mem: 1096
[2024-01-20 14:50:29 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:39  flops: 11.5172 (11.5172)  loss: 0.8184 (0.8383)  acc1: 81.6327 (81.7191)  acc5: 95.9184 (95.5105)  time: 0.0768  data: 0.0001  max mem: 1096
[2024-01-20 14:50:30 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:38  flops: 11.5172 (11.5172)  loss: 0.7613 (0.8325)  acc1: 82.8283 (82.0534)  acc5: 95.8763 (95.4950)  time: 0.0771  data: 0.0001  max mem: 1096
[2024-01-20 14:50:31 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:36  flops: 11.5172 (11.5172)  loss: 0.7949 (0.8400)  acc1: 82.8283 (81.9100)  acc5: 95.8333 (95.4817)  time: 0.0772  data: 0.0001  max mem: 1096
[2024-01-20 14:50:32 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:34  flops: 11.5172 (11.5172)  loss: 0.7972 (0.8398)  acc1: 81.8182 (81.8683)  acc5: 96.0000 (95.5234)  time: 0.0772  data: 0.0001  max mem: 1096
[2024-01-20 14:50:33 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:33  flops: 11.5172 (11.5172)  loss: 0.7972 (0.8407)  acc1: 81.4433 (81.8162)  acc5: 95.8763 (95.5028)  time: 0.0773  data: 0.0001  max mem: 1096
[2024-01-20 14:50:33 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:32  flops: 11.5172 (11.5172)  loss: 0.8242 (0.8359)  acc1: 82.4742 (81.9444)  acc5: 95.8763 (95.5569)  time: 0.0795  data: 0.0001  max mem: 1096
[2024-01-20 14:50:34 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:31  flops: 11.5172 (11.5172)  loss: 0.8709 (0.8397)  acc1: 82.0000 (81.8510)  acc5: 95.0000 (95.5402)  time: 0.0789  data: 0.0001  max mem: 1097
[2024-01-20 14:50:35 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:29  flops: 11.5172 (11.5172)  loss: 0.8900 (0.8405)  acc1: 80.8081 (81.8718)  acc5: 94.9495 (95.5201)  time: 0.0791  data: 0.0001  max mem: 1097
[2024-01-20 14:50:36 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:28  flops: 11.5172 (11.5172)  loss: 0.8900 (0.8438)  acc1: 80.8081 (81.8228)  acc5: 94.0000 (95.4796)  time: 0.0793  data: 0.0001  max mem: 1097
[2024-01-20 14:50:36 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:27  flops: 11.5172 (11.5172)  loss: 0.8331 (0.8434)  acc1: 80.0000 (81.7789)  acc5: 94.9495 (95.4727)  time: 0.0774  data: 0.0001  max mem: 1097
[2024-01-20 14:50:37 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:26  flops: 11.5172 (11.5172)  loss: 0.8331 (0.8438)  acc1: 80.8081 (81.8057)  acc5: 94.0000 (95.4248)  time: 0.0776  data: 0.0001  max mem: 1097
[2024-01-20 14:50:38 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:25  flops: 11.5172 (11.5172)  loss: 0.8662 (0.8464)  acc1: 81.4433 (81.7704)  acc5: 94.0000 (95.3859)  time: 0.0773  data: 0.0001  max mem: 1097
[2024-01-20 14:50:39 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:24  flops: 11.5172 (11.5172)  loss: 0.8234 (0.8409)  acc1: 81.8182 (81.8672)  acc5: 95.8763 (95.4380)  time: 0.0775  data: 0.0001  max mem: 1097
[2024-01-20 14:50:40 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:23  flops: 11.5172 (11.5172)  loss: 0.7992 (0.8471)  acc1: 82.4742 (81.7260)  acc5: 94.9495 (95.4117)  time: 0.0778  data: 0.0001  max mem: 1097
[2024-01-20 14:50:40 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:22  flops: 11.5172 (11.5172)  loss: 0.9347 (0.8491)  acc1: 80.4124 (81.6665)  acc5: 94.9495 (95.4367)  time: 0.0775  data: 0.0001  max mem: 1097
[2024-01-20 14:50:41 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:21  flops: 11.5172 (11.5172)  loss: 0.8293 (0.8502)  acc1: 80.4124 (81.6415)  acc5: 95.8763 (95.4236)  time: 0.0774  data: 0.0001  max mem: 1097
[2024-01-20 14:50:42 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:20  flops: 11.5172 (11.5172)  loss: 0.8348 (0.8532)  acc1: 80.6122 (81.5968)  acc5: 94.8980 (95.4031)  time: 0.0772  data: 0.0001  max mem: 1097
[2024-01-20 14:50:43 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:19  flops: 11.5172 (11.5172)  loss: 0.9061 (0.8571)  acc1: 80.6122 (81.5152)  acc5: 95.8763 (95.4229)  time: 0.0773  data: 0.0001  max mem: 1097
[2024-01-20 14:50:43 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:18  flops: 11.5172 (11.5172)  loss: 0.8535 (0.8570)  acc1: 81.2500 (81.5313)  acc5: 95.8763 (95.4127)  time: 0.0777  data: 0.0001  max mem: 1097
[2024-01-20 14:50:44 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:17  flops: 11.5172 (11.5172)  loss: 0.8437 (0.8569)  acc1: 81.0526 (81.5450)  acc5: 95.0000 (95.4099)  time: 0.0778  data: 0.0001  max mem: 1097
[2024-01-20 14:50:45 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:17  flops: 11.5172 (11.5172)  loss: 0.8473 (0.8566)  acc1: 81.0000 (81.5341)  acc5: 95.9596 (95.4309)  time: 0.0777  data: 0.0001  max mem: 1097
[2024-01-20 14:50:46 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:16  flops: 11.5172 (11.5172)  loss: 0.8834 (0.8593)  acc1: 80.8081 (81.5010)  acc5: 94.9495 (95.3949)  time: 0.0776  data: 0.0001  max mem: 1097
[2024-01-20 14:50:47 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:15  flops: 11.5172 (11.5172)  loss: 0.8834 (0.8580)  acc1: 82.0000 (81.5489)  acc5: 94.8980 (95.3983)  time: 0.0772  data: 0.0001  max mem: 1097
[2024-01-20 14:50:47 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:14  flops: 11.5172 (11.5172)  loss: 0.8291 (0.8584)  acc1: 81.8182 (81.5334)  acc5: 95.9596 (95.4064)  time: 0.0766  data: 0.0001  max mem: 1097
[2024-01-20 14:50:48 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:13  flops: 11.5172 (11.5172)  loss: 0.8380 (0.8572)  acc1: 81.2500 (81.5624)  acc5: 96.0000 (95.4130)  time: 0.0768  data: 0.0001  max mem: 1097
[2024-01-20 14:50:49 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:12  flops: 11.5172 (11.5172)  loss: 0.8323 (0.8555)  acc1: 81.0000 (81.5668)  acc5: 96.0000 (95.4476)  time: 0.0769  data: 0.0001  max mem: 1097
[2024-01-20 14:50:50 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:11  flops: 11.5172 (11.5172)  loss: 0.8004 (0.8559)  acc1: 81.0526 (81.5681)  acc5: 95.8763 (95.4379)  time: 0.0766  data: 0.0001  max mem: 1097
[2024-01-20 14:50:50 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:10  flops: 11.5172 (11.5172)  loss: 0.8326 (0.8545)  acc1: 82.0000 (81.5971)  acc5: 95.8763 (95.4679)  time: 0.0769  data: 0.0001  max mem: 1097
[2024-01-20 14:50:51 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:10  flops: 11.5172 (11.5172)  loss: 0.8451 (0.8555)  acc1: 82.8283 (81.5871)  acc5: 95.9184 (95.4616)  time: 0.0771  data: 0.0001  max mem: 1097
[2024-01-20 14:50:52 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:09  flops: 11.5172 (11.5172)  loss: 0.8226 (0.8547)  acc1: 82.6531 (81.5987)  acc5: 95.8333 (95.4654)  time: 0.0770  data: 0.0001  max mem: 1097
[2024-01-20 14:50:53 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:08  flops: 11.5172 (11.5172)  loss: 0.8257 (0.8554)  acc1: 80.4124 (81.5830)  acc5: 95.0000 (95.4522)  time: 0.0771  data: 0.0001  max mem: 1097
[2024-01-20 14:50:53 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:07  flops: 11.5172 (11.5172)  loss: 0.8169 (0.8527)  acc1: 81.6327 (81.6303)  acc5: 95.0000 (95.4782)  time: 0.0769  data: 0.0001  max mem: 1097
[2024-01-20 14:50:54 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:06  flops: 11.5172 (11.5172)  loss: 0.7851 (0.8539)  acc1: 82.2917 (81.5772)  acc5: 95.0000 (95.4644)  time: 0.0766  data: 0.0001  max mem: 1097
[2024-01-20 14:50:55 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:05  flops: 11.5172 (11.5172)  loss: 0.8285 (0.8536)  acc1: 80.6122 (81.6021)  acc5: 95.9184 (95.4726)  time: 0.0768  data: 0.0001  max mem: 1097
[2024-01-20 14:50:56 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:04  flops: 11.5172 (11.5172)  loss: 0.8342 (0.8547)  acc1: 80.8081 (81.5876)  acc5: 95.9596 (95.4685)  time: 0.0768  data: 0.0001  max mem: 1097
[2024-01-20 14:50:57 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:04  flops: 11.5172 (11.5172)  loss: 0.8339 (0.8544)  acc1: 80.8081 (81.5825)  acc5: 95.8763 (95.4781)  time: 0.0768  data: 0.0001  max mem: 1097
[2024-01-20 14:50:57 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:03  flops: 11.5172 (11.5172)  loss: 0.8309 (0.8541)  acc1: 81.6327 (81.5934)  acc5: 95.9184 (95.4906)  time: 0.0772  data: 0.0001  max mem: 1097
[2024-01-20 14:50:58 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:02  flops: 11.5172 (11.5172)  loss: 0.8274 (0.8548)  acc1: 81.2500 (81.5742)  acc5: 95.9596 (95.4849)  time: 0.0775  data: 0.0001  max mem: 1097
[2024-01-20 14:50:59 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 11.5172 (11.5172)  loss: 0.8421 (0.8556)  acc1: 80.6122 (81.5541)  acc5: 95.0000 (95.4838)  time: 0.0774  data: 0.0002  max mem: 1097
[2024-01-20 14:51:00 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 11.5172 (11.5172)  loss: 0.9139 (0.8566)  acc1: 79.7980 (81.5220)  acc5: 94.9495 (95.4681)  time: 0.0776  data: 0.0002  max mem: 1097
[2024-01-20 14:51:00 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 11.5172 (11.5172)  loss: 0.8288 (0.8548)  acc1: 81.0000 (81.5829)  acc5: 95.0000 (95.4644)  time: 0.0776  data: 0.0002  max mem: 1097
[2024-01-20 14:51:00 root] (utils.py 307): INFO Test: Total time: 0:00:40 (0.0819 s / it)
[2024-01-20 14:51:00 root] (engine.py 118): INFO * Acc@1 81.583 Acc@5 95.464 loss 0.855 flops 11.517
[2024-01-20 14:51:00 root] (main.py 381): INFO Accuracy of the network on the 50000 test images: 81.6%
[2024-01-20 15:11:14 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:11:18 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:11:19 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:11:21 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:11:26 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:34  flops: 12.9405 (12.9405)  loss: 0.8787 (0.8787)  acc1: 81.8493 (81.8493)  acc5: 94.1781 (94.1781)  time: 4.8747  data: 0.9750  max mem: 2126
[2024-01-20 15:11:28 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:51  flops: 12.9405 (12.9405)  loss: 0.8254 (0.8303)  acc1: 82.5939 (82.6798)  acc5: 94.9324 (95.1837)  time: 0.7071  data: 0.0887  max mem: 2169
[2024-01-20 15:11:31 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:11  flops: 12.9405 (12.9405)  loss: 0.8576 (0.8491)  acc1: 81.6054 (81.9903)  acc5: 94.9324 (95.2751)  time: 0.2641  data: 0.0001  max mem: 2169
[2024-01-20 15:11:33 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8576 (0.8437)  acc1: 81.4815 (81.8521)  acc5: 95.5172 (95.4411)  time: 0.2379  data: 0.0001  max mem: 2169
[2024-01-20 15:11:36 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:46  flops: 12.9405 (12.9405)  loss: 0.8494 (0.8532)  acc1: 81.7568 (81.7000)  acc5: 95.2218 (95.3733)  time: 0.2388  data: 0.0001  max mem: 2169
[2024-01-20 15:11:38 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:39  flops: 12.9405 (12.9405)  loss: 0.8494 (0.8463)  acc1: 81.0811 (81.7474)  acc5: 95.2862 (95.5150)  time: 0.2344  data: 0.0001  max mem: 2169
[2024-01-20 15:11:40 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8621 (0.8523)  acc1: 81.0811 (81.5499)  acc5: 95.2862 (95.4571)  time: 0.2289  data: 0.0002  max mem: 2169
[2024-01-20 15:11:43 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8683 (0.8529)  acc1: 81.3793 (81.5196)  acc5: 95.1890 (95.4098)  time: 0.2288  data: 0.0001  max mem: 2169
[2024-01-20 15:11:45 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8620 (0.8570)  acc1: 81.2081 (81.4064)  acc5: 94.9495 (95.4197)  time: 0.2289  data: 0.0001  max mem: 2169
[2024-01-20 15:11:47 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8812 (0.8639)  acc1: 81.0169 (81.2749)  acc5: 94.9324 (95.3672)  time: 0.2345  data: 0.0001  max mem: 2170
[2024-01-20 15:11:50 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8722 (0.8652)  acc1: 80.9524 (81.2168)  acc5: 94.9324 (95.3403)  time: 0.2349  data: 0.0001  max mem: 2170
[2024-01-20 15:11:52 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8722 (0.8670)  acc1: 80.6228 (81.1726)  acc5: 94.9153 (95.2993)  time: 0.2293  data: 0.0001  max mem: 2170
[2024-01-20 15:11:54 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8625 (0.8640)  acc1: 81.3559 (81.2498)  acc5: 95.2218 (95.3307)  time: 0.2291  data: 0.0001  max mem: 2170
[2024-01-20 15:11:56 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8436 (0.8625)  acc1: 81.3559 (81.2469)  acc5: 95.8621 (95.3798)  time: 0.2299  data: 0.0001  max mem: 2170
[2024-01-20 15:11:59 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8581 (0.8613)  acc1: 80.4054 (81.2413)  acc5: 95.9322 (95.4138)  time: 0.2301  data: 0.0001  max mem: 2170
[2024-01-20 15:12:01 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8597 (0.8631)  acc1: 80.6228 (81.2215)  acc5: 95.5631 (95.4150)  time: 0.2294  data: 0.0002  max mem: 2170
[2024-01-20 15:12:03 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8929 (0.8647)  acc1: 81.4815 (81.2217)  acc5: 95.2218 (95.3992)  time: 0.2290  data: 0.0002  max mem: 2170
[2024-01-20 15:12:05 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8686 (0.8631)  acc1: 81.8792 (81.2672)  acc5: 94.8980 (95.3769)  time: 0.2296  data: 0.0001  max mem: 2170
[2024-01-20 15:12:05 root] (utils.py 307): INFO Test: Total time: 0:00:43 (0.2631 s / it)
[2024-01-20 15:12:05 root] (engine.py 118): INFO * Acc@1 81.267 Acc@5 95.377 loss 0.863 flops 12.940
[2024-01-20 15:12:05 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.3%
[2024-01-20 15:13:11 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:13:15 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:13:16 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:13:18 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:13:23 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:18  flops: 12.9405 (12.9405)  loss: 0.8969 (0.8969)  acc1: 81.8493 (81.8493)  acc5: 93.4931 (93.4931)  time: 4.7800  data: 1.3965  max mem: 2126
[2024-01-20 15:13:26 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:49  flops: 12.9405 (12.9405)  loss: 0.8190 (0.8317)  acc1: 82.4324 (82.4637)  acc5: 95.5326 (95.1220)  time: 0.7004  data: 0.1271  max mem: 2169
[2024-01-20 15:13:28 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:10  flops: 12.9405 (12.9405)  loss: 0.8505 (0.8528)  acc1: 81.8182 (81.9256)  acc5: 95.1724 (95.1456)  time: 0.2651  data: 0.0001  max mem: 2169
[2024-01-20 15:13:31 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8502 (0.8498)  acc1: 81.6327 (81.8301)  acc5: 95.1724 (95.3863)  time: 0.2382  data: 0.0001  max mem: 2169
[2024-01-20 15:13:33 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:46  flops: 12.9405 (12.9405)  loss: 0.8572 (0.8593)  acc1: 81.6327 (81.6752)  acc5: 95.5631 (95.3071)  time: 0.2394  data: 0.0001  max mem: 2169
[2024-01-20 15:13:35 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:39  flops: 12.9405 (12.9405)  loss: 0.8585 (0.8514)  acc1: 80.4124 (81.7075)  acc5: 95.2703 (95.4818)  time: 0.2347  data: 0.0001  max mem: 2169
[2024-01-20 15:13:38 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8719 (0.8579)  acc1: 80.4124 (81.5499)  acc5: 95.2381 (95.3680)  time: 0.2287  data: 0.0001  max mem: 2169
[2024-01-20 15:13:40 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8869 (0.8588)  acc1: 81.3793 (81.5243)  acc5: 94.4828 (95.2950)  time: 0.2288  data: 0.0001  max mem: 2169
[2024-01-20 15:13:42 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8699 (0.8620)  acc1: 80.3390 (81.4231)  acc5: 94.9495 (95.3024)  time: 0.2298  data: 0.0001  max mem: 2169
[2024-01-20 15:13:45 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8757 (0.8687)  acc1: 80.0000 (81.2936)  acc5: 94.9153 (95.2367)  time: 0.2347  data: 0.0001  max mem: 2170
[2024-01-20 15:13:47 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8953 (0.8702)  acc1: 81.0169 (81.2336)  acc5: 94.8630 (95.2261)  time: 0.2342  data: 0.0001  max mem: 2170
[2024-01-20 15:13:49 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8956 (0.8719)  acc1: 80.9689 (81.2307)  acc5: 95.2055 (95.2014)  time: 0.2282  data: 0.0001  max mem: 2170
[2024-01-20 15:13:51 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8541 (0.8683)  acc1: 80.9689 (81.2863)  acc5: 95.2542 (95.2577)  time: 0.2279  data: 0.0001  max mem: 2170
[2024-01-20 15:13:54 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8442 (0.8665)  acc1: 80.6897 (81.2806)  acc5: 95.9322 (95.2994)  time: 0.2289  data: 0.0001  max mem: 2170
[2024-01-20 15:13:56 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8543 (0.8653)  acc1: 80.6780 (81.2581)  acc5: 95.8904 (95.3320)  time: 0.2290  data: 0.0001  max mem: 2170
[2024-01-20 15:13:58 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8543 (0.8663)  acc1: 81.3559 (81.2619)  acc5: 95.5782 (95.3205)  time: 0.2290  data: 0.0002  max mem: 2170
[2024-01-20 15:14:01 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8729 (0.8683)  acc1: 81.2925 (81.2385)  acc5: 95.2218 (95.3086)  time: 0.2299  data: 0.0002  max mem: 2170
[2024-01-20 15:14:02 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8502 (0.8665)  acc1: 81.8182 (81.2855)  acc5: 94.9324 (95.3036)  time: 0.2307  data: 0.0002  max mem: 2170
[2024-01-20 15:14:02 root] (utils.py 307): INFO Test: Total time: 0:00:43 (0.2626 s / it)
[2024-01-20 15:14:02 root] (engine.py 118): INFO * Acc@1 81.286 Acc@5 95.304 loss 0.867 flops 12.940
[2024-01-20 15:14:02 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.3%
[2024-01-20 15:14:25 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:14:29 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:14:30 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:14:32 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:14:37 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:17  flops: 12.9405 (12.9405)  loss: 0.9028 (0.9028)  acc1: 80.8219 (80.8219)  acc5: 94.1781 (94.1781)  time: 4.7776  data: 1.2037  max mem: 2126
[2024-01-20 15:14:40 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:50  flops: 12.9405 (12.9405)  loss: 0.8230 (0.8296)  acc1: 81.8182 (82.2476)  acc5: 95.2703 (95.2146)  time: 0.7016  data: 0.1096  max mem: 2169
[2024-01-20 15:14:42 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:10  flops: 12.9405 (12.9405)  loss: 0.8587 (0.8503)  acc1: 81.4189 (81.6667)  acc5: 95.2381 (95.2104)  time: 0.2668  data: 0.0001  max mem: 2169
[2024-01-20 15:14:44 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8587 (0.8439)  acc1: 81.1448 (81.7205)  acc5: 95.2862 (95.4082)  time: 0.2400  data: 0.0001  max mem: 2169
[2024-01-20 15:14:47 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:46  flops: 12.9405 (12.9405)  loss: 0.8512 (0.8511)  acc1: 80.8874 (81.6338)  acc5: 95.5479 (95.3898)  time: 0.2409  data: 0.0001  max mem: 2169
[2024-01-20 15:14:49 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:39  flops: 12.9405 (12.9405)  loss: 0.8554 (0.8453)  acc1: 80.8874 (81.6542)  acc5: 95.6229 (95.5483)  time: 0.2356  data: 0.0001  max mem: 2169
[2024-01-20 15:14:51 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8621 (0.8523)  acc1: 80.8081 (81.5388)  acc5: 95.5782 (95.4960)  time: 0.2288  data: 0.0001  max mem: 2169
[2024-01-20 15:14:54 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8667 (0.8535)  acc1: 80.8081 (81.5339)  acc5: 95.2703 (95.4624)  time: 0.2280  data: 0.0001  max mem: 2169
[2024-01-20 15:14:56 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8507 (0.8567)  acc1: 81.3559 (81.4776)  acc5: 95.2542 (95.4574)  time: 0.2289  data: 0.0001  max mem: 2169
[2024-01-20 15:14:58 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8774 (0.8633)  acc1: 80.8081 (81.3458)  acc5: 95.2542 (95.4120)  time: 0.2350  data: 0.0001  max mem: 2170
[2024-01-20 15:15:01 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8779 (0.8646)  acc1: 80.7432 (81.2840)  acc5: 94.6309 (95.3739)  time: 0.2352  data: 0.0001  max mem: 2170
[2024-01-20 15:15:03 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8846 (0.8671)  acc1: 80.5369 (81.2521)  acc5: 94.8980 (95.3298)  time: 0.2296  data: 0.0001  max mem: 2170
[2024-01-20 15:15:05 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8670 (0.8641)  acc1: 81.7241 (81.3172)  acc5: 94.8980 (95.3616)  time: 0.2290  data: 0.0001  max mem: 2170
[2024-01-20 15:15:07 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8548 (0.8633)  acc1: 81.7869 (81.3013)  acc5: 95.5932 (95.3901)  time: 0.2290  data: 0.0001  max mem: 2170
[2024-01-20 15:15:10 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8568 (0.8620)  acc1: 80.6122 (81.2678)  acc5: 95.6081 (95.4187)  time: 0.2290  data: 0.0001  max mem: 2170
[2024-01-20 15:15:12 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8673 (0.8638)  acc1: 80.6122 (81.2462)  acc5: 95.6229 (95.4060)  time: 0.2294  data: 0.0002  max mem: 2170
[2024-01-20 15:15:14 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8790 (0.8652)  acc1: 81.1448 (81.2364)  acc5: 95.2703 (95.4035)  time: 0.2299  data: 0.0002  max mem: 2170
[2024-01-20 15:15:16 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8526 (0.8634)  acc1: 81.4189 (81.2713)  acc5: 95.2703 (95.3871)  time: 0.2310  data: 0.0001  max mem: 2170
[2024-01-20 15:15:16 root] (utils.py 307): INFO Test: Total time: 0:00:43 (0.2632 s / it)
[2024-01-20 15:15:16 root] (engine.py 118): INFO * Acc@1 81.271 Acc@5 95.387 loss 0.863 flops 12.940
[2024-01-20 15:15:16 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.3%
[2024-01-20 15:15:45 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:15:48 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:15:50 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:15:51 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:15:56 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:10  flops: 12.9405 (12.9405)  loss: 0.9192 (0.9192)  acc1: 80.4795 (80.4795)  acc5: 93.4931 (93.4931)  time: 4.7346  data: 1.0403  max mem: 2126
[2024-01-20 15:15:59 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:49  flops: 12.9405 (12.9405)  loss: 0.8220 (0.8326)  acc1: 82.5939 (82.4946)  acc5: 94.5946 (94.8750)  time: 0.6967  data: 0.0947  max mem: 2169
[2024-01-20 15:16:02 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:10  flops: 12.9405 (12.9405)  loss: 0.8421 (0.8566)  acc1: 81.3793 (81.7476)  acc5: 94.6128 (94.9676)  time: 0.2658  data: 0.0001  max mem: 2169
[2024-01-20 15:16:04 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8599 (0.8522)  acc1: 80.7432 (81.6986)  acc5: 95.1724 (95.1781)  time: 0.2393  data: 0.0001  max mem: 2169
[2024-01-20 15:16:06 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:45  flops: 12.9405 (12.9405)  loss: 0.8634 (0.8585)  acc1: 81.9113 (81.6256)  acc5: 95.3020 (95.1829)  time: 0.2399  data: 0.0001  max mem: 2169
[2024-01-20 15:16:09 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:39  flops: 12.9405 (12.9405)  loss: 0.8654 (0.8519)  acc1: 80.8874 (81.6676)  acc5: 95.6081 (95.3620)  time: 0.2339  data: 0.0001  max mem: 2169
[2024-01-20 15:16:11 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8684 (0.8604)  acc1: 80.4124 (81.4720)  acc5: 95.5932 (95.2678)  time: 0.2276  data: 0.0001  max mem: 2169
[2024-01-20 15:16:13 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8930 (0.8607)  acc1: 81.2287 (81.4956)  acc5: 94.8454 (95.2376)  time: 0.2282  data: 0.0001  max mem: 2169
[2024-01-20 15:16:15 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8640 (0.8646)  acc1: 81.5069 (81.3728)  acc5: 94.9153 (95.2311)  time: 0.2289  data: 0.0001  max mem: 2169
[2024-01-20 15:16:18 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8948 (0.8713)  acc1: 80.7432 (81.2563)  acc5: 94.9153 (95.1994)  time: 0.2343  data: 0.0001  max mem: 2170
[2024-01-20 15:16:20 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8864 (0.8717)  acc1: 80.7432 (81.2067)  acc5: 94.6128 (95.1891)  time: 0.2348  data: 0.0001  max mem: 2170
[2024-01-20 15:16:22 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8883 (0.8748)  acc1: 80.6122 (81.1726)  acc5: 94.8980 (95.1739)  time: 0.2285  data: 0.0001  max mem: 2170
[2024-01-20 15:16:25 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8652 (0.8715)  acc1: 81.0997 (81.2358)  acc5: 95.1724 (95.2100)  time: 0.2276  data: 0.0001  max mem: 2170
[2024-01-20 15:16:27 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8329 (0.8697)  acc1: 81.0997 (81.2495)  acc5: 95.2542 (95.2476)  time: 0.2287  data: 0.0001  max mem: 2170
[2024-01-20 15:16:29 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8563 (0.8687)  acc1: 80.3390 (81.2100)  acc5: 95.2862 (95.2718)  time: 0.2291  data: 0.0001  max mem: 2170
[2024-01-20 15:16:32 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8706 (0.8699)  acc1: 80.9524 (81.1967)  acc5: 95.2862 (95.2666)  time: 0.2293  data: 0.0002  max mem: 2170
[2024-01-20 15:16:34 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8740 (0.8716)  acc1: 80.9524 (81.1500)  acc5: 94.9495 (95.2453)  time: 0.2298  data: 0.0002  max mem: 2170
[2024-01-20 15:16:35 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8622 (0.8701)  acc1: 81.0345 (81.1837)  acc5: 94.9495 (95.2302)  time: 0.2302  data: 0.0001  max mem: 2170
[2024-01-20 15:16:35 root] (utils.py 307): INFO Test: Total time: 0:00:43 (0.2623 s / it)
[2024-01-20 15:16:35 root] (engine.py 118): INFO * Acc@1 81.184 Acc@5 95.230 loss 0.870 flops 12.940
[2024-01-20 15:16:35 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-20 15:16:42 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:16:45 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:16:47 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:16:48 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:16:53 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:11  flops: 12.9405 (12.9405)  loss: 0.8966 (0.8966)  acc1: 81.1644 (81.1644)  acc5: 93.4931 (93.4931)  time: 4.7421  data: 0.8361  max mem: 2126
[2024-01-20 15:16:56 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:49  flops: 12.9405 (12.9405)  loss: 0.8277 (0.8343)  acc1: 82.5939 (82.4946)  acc5: 95.5631 (95.1220)  time: 0.6982  data: 0.0761  max mem: 2169
[2024-01-20 15:16:58 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:10  flops: 12.9405 (12.9405)  loss: 0.8552 (0.8556)  acc1: 81.8182 (81.8123)  acc5: 95.5631 (95.1456)  time: 0.2663  data: 0.0001  max mem: 2169
[2024-01-20 15:17:01 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8552 (0.8485)  acc1: 81.3559 (81.7973)  acc5: 95.5782 (95.3863)  time: 0.2388  data: 0.0001  max mem: 2169
[2024-01-20 15:17:03 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:46  flops: 12.9405 (12.9405)  loss: 0.8613 (0.8570)  acc1: 81.6327 (81.7249)  acc5: 95.2218 (95.3071)  time: 0.2392  data: 0.0001  max mem: 2169
[2024-01-20 15:17:05 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:39  flops: 12.9405 (12.9405)  loss: 0.8593 (0.8485)  acc1: 81.0997 (81.8339)  acc5: 95.2703 (95.4618)  time: 0.2343  data: 0.0001  max mem: 2169
[2024-01-20 15:17:08 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8593 (0.8545)  acc1: 81.0997 (81.6724)  acc5: 95.2703 (95.4459)  time: 0.2281  data: 0.0001  max mem: 2169
[2024-01-20 15:17:10 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8605 (0.8551)  acc1: 81.2081 (81.6200)  acc5: 95.1724 (95.4146)  time: 0.2280  data: 0.0001  max mem: 2169
[2024-01-20 15:17:12 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8487 (0.8581)  acc1: 80.4054 (81.4734)  acc5: 95.5172 (95.4448)  time: 0.2297  data: 0.0001  max mem: 2169
[2024-01-20 15:17:15 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8487 (0.8644)  acc1: 80.2721 (81.3122)  acc5: 95.5017 (95.4194)  time: 0.2359  data: 0.0002  max mem: 2170
[2024-01-20 15:17:17 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8750 (0.8658)  acc1: 80.9524 (81.3008)  acc5: 94.9324 (95.3907)  time: 0.2353  data: 0.0001  max mem: 2170
[2024-01-20 15:17:19 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8820 (0.8685)  acc1: 80.8219 (81.2643)  acc5: 94.8980 (95.3360)  time: 0.2291  data: 0.0001  max mem: 2170
[2024-01-20 15:17:22 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8768 (0.8661)  acc1: 81.7241 (81.3593)  acc5: 95.2381 (95.3784)  time: 0.2288  data: 0.0001  max mem: 2170
[2024-01-20 15:17:24 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8444 (0.8644)  acc1: 81.6609 (81.3247)  acc5: 95.5932 (95.4290)  time: 0.2290  data: 0.0001  max mem: 2170
[2024-01-20 15:17:26 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8461 (0.8626)  acc1: 80.7432 (81.3015)  acc5: 95.6229 (95.4596)  time: 0.2295  data: 0.0001  max mem: 2170
[2024-01-20 15:17:29 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8663 (0.8638)  acc1: 80.7432 (81.2709)  acc5: 95.5782 (95.4465)  time: 0.2289  data: 0.0001  max mem: 2170
[2024-01-20 15:17:31 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8844 (0.8656)  acc1: 80.9524 (81.2765)  acc5: 94.8805 (95.4119)  time: 0.2290  data: 0.0001  max mem: 2170
[2024-01-20 15:17:32 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8663 (0.8643)  acc1: 81.9113 (81.3079)  acc5: 95.2055 (95.3932)  time: 0.2299  data: 0.0001  max mem: 2170
[2024-01-20 15:17:32 root] (utils.py 307): INFO Test: Total time: 0:00:43 (0.2626 s / it)
[2024-01-20 15:17:32 root] (engine.py 118): INFO * Acc@1 81.308 Acc@5 95.393 loss 0.864 flops 12.940
[2024-01-20 15:17:32 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.3%
[2024-01-20 15:18:41 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:18:46 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:18:47 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:18:49 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:18:53 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:23  flops: 12.9405 (12.9405)  loss: 0.8955 (0.8955)  acc1: 80.8219 (80.8219)  acc5: 93.4931 (93.4931)  time: 4.8132  data: 1.3995  max mem: 2126
[2024-01-20 15:18:56 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:50  flops: 12.9405 (12.9405)  loss: 0.8278 (0.8335)  acc1: 82.5939 (82.4946)  acc5: 95.5631 (95.1837)  time: 0.7030  data: 0.1273  max mem: 2169
[2024-01-20 15:18:59 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:10  flops: 12.9405 (12.9405)  loss: 0.8535 (0.8550)  acc1: 81.8182 (81.8285)  acc5: 95.5631 (95.1780)  time: 0.2650  data: 0.0001  max mem: 2169
[2024-01-20 15:19:01 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8535 (0.8478)  acc1: 81.3559 (81.8301)  acc5: 95.5782 (95.4192)  time: 0.2388  data: 0.0001  max mem: 2169
[2024-01-20 15:19:04 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:46  flops: 12.9405 (12.9405)  loss: 0.8599 (0.8565)  acc1: 81.6327 (81.7249)  acc5: 95.2703 (95.3236)  time: 0.2404  data: 0.0001  max mem: 2169
[2024-01-20 15:19:06 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:39  flops: 12.9405 (12.9405)  loss: 0.8588 (0.8481)  acc1: 81.0811 (81.8472)  acc5: 95.2703 (95.4685)  time: 0.2350  data: 0.0001  max mem: 2169
[2024-01-20 15:19:08 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8585 (0.8541)  acc1: 81.0811 (81.7003)  acc5: 95.2703 (95.4571)  time: 0.2285  data: 0.0001  max mem: 2169
[2024-01-20 15:19:10 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8626 (0.8547)  acc1: 81.5436 (81.6678)  acc5: 95.1724 (95.4289)  time: 0.2290  data: 0.0001  max mem: 2169
[2024-01-20 15:19:13 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8525 (0.8577)  acc1: 80.2721 (81.5321)  acc5: 95.2703 (95.4490)  time: 0.2288  data: 0.0001  max mem: 2169
[2024-01-20 15:19:15 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8525 (0.8639)  acc1: 80.2721 (81.3794)  acc5: 95.2703 (95.4157)  time: 0.2331  data: 0.0001  max mem: 2170
[2024-01-20 15:19:17 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8708 (0.8654)  acc1: 80.8081 (81.3478)  acc5: 94.9324 (95.3907)  time: 0.2336  data: 0.0001  max mem: 2170
[2024-01-20 15:19:20 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8838 (0.8683)  acc1: 80.7432 (81.3072)  acc5: 94.8980 (95.3329)  time: 0.2278  data: 0.0001  max mem: 2170
[2024-01-20 15:19:22 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8810 (0.8660)  acc1: 81.6609 (81.3985)  acc5: 95.1724 (95.3728)  time: 0.2274  data: 0.0001  max mem: 2170
[2024-01-20 15:19:24 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8471 (0.8643)  acc1: 81.6609 (81.3609)  acc5: 95.9322 (95.4186)  time: 0.2282  data: 0.0001  max mem: 2170
[2024-01-20 15:19:26 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8521 (0.8626)  acc1: 80.7432 (81.3472)  acc5: 95.6229 (95.4451)  time: 0.2286  data: 0.0001  max mem: 2170
[2024-01-20 15:19:29 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8605 (0.8638)  acc1: 80.9524 (81.3204)  acc5: 95.5782 (95.4352)  time: 0.2281  data: 0.0002  max mem: 2170
[2024-01-20 15:19:31 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8832 (0.8655)  acc1: 81.0811 (81.3165)  acc5: 94.5946 (95.4014)  time: 0.2287  data: 0.0002  max mem: 2170
[2024-01-20 15:19:32 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8649 (0.8643)  acc1: 81.7568 (81.3425)  acc5: 95.2055 (95.3830)  time: 0.2301  data: 0.0002  max mem: 2170
[2024-01-20 15:19:32 root] (utils.py 307): INFO Test: Total time: 0:00:43 (0.2625 s / it)
[2024-01-20 15:19:32 root] (engine.py 118): INFO * Acc@1 81.343 Acc@5 95.383 loss 0.864 flops 12.940
[2024-01-20 15:19:32 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.3%
[2024-01-20 15:24:51 root] (main.py 217): INFO Namespace(batch_size=100, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=12.5, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:24:55 root] (main.py 287): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:24:56 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:24:57 root] (main.py 373): INFO number of params: 86567656
[2024-01-20 15:24:59 root] (utils.py 293): INFO Test:  [  0/500]  eta: 0:18:08  flops: 12.5229 (12.5229)  loss: 0.8354 (0.8354)  acc1: 84.8485 (84.8485)  acc5: 93.9394 (93.9394)  time: 2.1778  data: 0.3117  max mem: 1093
[2024-01-20 15:25:00 root] (utils.py 293): INFO Test:  [ 10/500]  eta: 0:02:22  flops: 12.5229 (12.5229)  loss: 0.8550 (0.8436)  acc1: 81.4433 (81.6993)  acc5: 94.7368 (94.6779)  time: 0.2909  data: 0.0284  max mem: 1096
[2024-01-20 15:25:01 root] (utils.py 293): INFO Test:  [ 20/500]  eta: 0:01:33  flops: 12.5229 (12.5229)  loss: 0.8128 (0.8083)  acc1: 82.6531 (82.6045)  acc5: 94.9495 (95.2867)  time: 0.0954  data: 0.0001  max mem: 1100
[2024-01-20 15:25:02 root] (utils.py 293): INFO Test:  [ 30/500]  eta: 0:01:14  flops: 12.5229 (12.5229)  loss: 0.7448 (0.7991)  acc1: 82.8283 (82.6816)  acc5: 95.9596 (95.4321)  time: 0.0863  data: 0.0001  max mem: 1100
[2024-01-20 15:25:03 root] (utils.py 293): INFO Test:  [ 40/500]  eta: 0:01:04  flops: 12.5229 (12.5229)  loss: 0.8016 (0.7930)  acc1: 81.2500 (82.7740)  acc5: 95.8763 (95.5009)  time: 0.0837  data: 0.0001  max mem: 1100
[2024-01-20 15:25:03 root] (utils.py 293): INFO Test:  [ 50/500]  eta: 0:00:58  flops: 12.5229 (12.5229)  loss: 0.8109 (0.8092)  acc1: 80.8081 (82.3400)  acc5: 95.0000 (95.4600)  time: 0.0833  data: 0.0001  max mem: 1100
[2024-01-20 15:25:04 root] (utils.py 293): INFO Test:  [ 60/500]  eta: 0:00:53  flops: 12.5229 (12.5229)  loss: 0.8443 (0.8131)  acc1: 80.8081 (82.3421)  acc5: 95.8333 (95.5062)  time: 0.0836  data: 0.0001  max mem: 1100
[2024-01-20 15:25:05 root] (utils.py 293): INFO Test:  [ 70/500]  eta: 0:00:50  flops: 12.5229 (12.5229)  loss: 0.7346 (0.8115)  acc1: 81.8182 (82.4964)  acc5: 95.9184 (95.4806)  time: 0.0837  data: 0.0001  max mem: 1100
[2024-01-20 15:25:06 root] (utils.py 293): INFO Test:  [ 80/500]  eta: 0:00:47  flops: 12.5229 (12.5229)  loss: 0.7371 (0.8120)  acc1: 81.4433 (82.2893)  acc5: 95.9184 (95.5975)  time: 0.0834  data: 0.0001  max mem: 1100
[2024-01-20 15:25:07 root] (utils.py 293): INFO Test:  [ 90/500]  eta: 0:00:44  flops: 12.5229 (12.5229)  loss: 0.7836 (0.8101)  acc1: 81.4433 (82.2489)  acc5: 95.9184 (95.6322)  time: 0.0832  data: 0.0001  max mem: 1100
[2024-01-20 15:25:08 root] (utils.py 293): INFO Test:  [100/500]  eta: 0:00:42  flops: 12.5229 (12.5229)  loss: 0.8122 (0.8135)  acc1: 81.6327 (82.0521)  acc5: 95.9184 (95.6921)  time: 0.0834  data: 0.0001  max mem: 1100
[2024-01-20 15:25:08 root] (utils.py 293): INFO Test:  [110/500]  eta: 0:00:40  flops: 12.5229 (12.5229)  loss: 0.7430 (0.8077)  acc1: 83.5051 (82.4112)  acc5: 95.9596 (95.6785)  time: 0.0838  data: 0.0001  max mem: 1100
[2024-01-20 15:25:09 root] (utils.py 293): INFO Test:  [120/500]  eta: 0:00:39  flops: 12.5229 (12.5229)  loss: 0.7745 (0.8158)  acc1: 83.3333 (82.2465)  acc5: 95.9596 (95.6752)  time: 0.0841  data: 0.0001  max mem: 1100
[2024-01-20 15:25:10 root] (utils.py 293): INFO Test:  [130/500]  eta: 0:00:37  flops: 12.5229 (12.5229)  loss: 0.7800 (0.8148)  acc1: 81.8182 (82.2181)  acc5: 96.9072 (95.7177)  time: 0.0840  data: 0.0001  max mem: 1100
[2024-01-20 15:25:11 root] (utils.py 293): INFO Test:  [140/500]  eta: 0:00:36  flops: 12.5229 (12.5229)  loss: 0.7800 (0.8164)  acc1: 81.6327 (82.1266)  acc5: 95.9184 (95.7049)  time: 0.0840  data: 0.0001  max mem: 1100
[2024-01-20 15:25:12 root] (utils.py 293): INFO Test:  [150/500]  eta: 0:00:34  flops: 12.5229 (12.5229)  loss: 0.7819 (0.8120)  acc1: 81.8182 (82.2748)  acc5: 96.8750 (95.7659)  time: 0.0864  data: 0.0001  max mem: 1100
[2024-01-20 15:25:13 root] (utils.py 293): INFO Test:  [160/500]  eta: 0:00:33  flops: 12.5229 (12.5229)  loss: 0.8111 (0.8160)  acc1: 82.2917 (82.2115)  acc5: 96.9072 (95.7680)  time: 0.0859  data: 0.0001  max mem: 1101
[2024-01-20 15:25:14 root] (utils.py 293): INFO Test:  [170/500]  eta: 0:00:32  flops: 12.5229 (12.5229)  loss: 0.8712 (0.8174)  acc1: 80.8081 (82.1697)  acc5: 94.9495 (95.7465)  time: 0.0861  data: 0.0001  max mem: 1101
[2024-01-20 15:25:14 root] (utils.py 293): INFO Test:  [180/500]  eta: 0:00:31  flops: 12.5229 (12.5229)  loss: 0.8408 (0.8208)  acc1: 80.6122 (82.0705)  acc5: 94.8980 (95.6935)  time: 0.0864  data: 0.0001  max mem: 1101
[2024-01-20 15:25:15 root] (utils.py 293): INFO Test:  [190/500]  eta: 0:00:29  flops: 12.5229 (12.5229)  loss: 0.8222 (0.8199)  acc1: 80.0000 (82.0455)  acc5: 94.9495 (95.6807)  time: 0.0842  data: 0.0001  max mem: 1101
[2024-01-20 15:25:16 root] (utils.py 293): INFO Test:  [200/500]  eta: 0:00:28  flops: 12.5229 (12.5229)  loss: 0.8176 (0.8201)  acc1: 80.8081 (82.1199)  acc5: 94.0000 (95.6275)  time: 0.0845  data: 0.0001  max mem: 1101
[2024-01-20 15:25:17 root] (utils.py 293): INFO Test:  [210/500]  eta: 0:00:27  flops: 12.5229 (12.5229)  loss: 0.8505 (0.8224)  acc1: 81.8182 (82.0648)  acc5: 93.9394 (95.5886)  time: 0.0840  data: 0.0001  max mem: 1101
[2024-01-20 15:25:18 root] (utils.py 293): INFO Test:  [220/500]  eta: 0:00:26  flops: 12.5229 (12.5229)  loss: 0.7904 (0.8172)  acc1: 81.8182 (82.1575)  acc5: 94.9495 (95.6269)  time: 0.0839  data: 0.0001  max mem: 1101
[2024-01-20 15:25:19 root] (utils.py 293): INFO Test:  [230/500]  eta: 0:00:25  flops: 12.5229 (12.5229)  loss: 0.7795 (0.8230)  acc1: 81.6327 (82.0301)  acc5: 95.9184 (95.6232)  time: 0.0843  data: 0.0001  max mem: 1101
[2024-01-20 15:25:19 root] (utils.py 293): INFO Test:  [240/500]  eta: 0:00:24  flops: 12.5229 (12.5229)  loss: 0.9103 (0.8249)  acc1: 80.6122 (81.9960)  acc5: 95.9184 (95.6522)  time: 0.0842  data: 0.0001  max mem: 1101
[2024-01-20 15:25:20 root] (utils.py 293): INFO Test:  [250/500]  eta: 0:00:23  flops: 12.5229 (12.5229)  loss: 0.8244 (0.8264)  acc1: 80.2083 (81.9701)  acc5: 94.8980 (95.6061)  time: 0.0839  data: 0.0001  max mem: 1101
[2024-01-20 15:25:21 root] (utils.py 293): INFO Test:  [260/500]  eta: 0:00:22  flops: 12.5229 (12.5229)  loss: 0.8456 (0.8298)  acc1: 80.6122 (81.9051)  acc5: 94.7917 (95.5826)  time: 0.0839  data: 0.0001  max mem: 1101
[2024-01-20 15:25:22 root] (utils.py 293): INFO Test:  [270/500]  eta: 0:00:21  flops: 12.5229 (12.5229)  loss: 0.8922 (0.8333)  acc1: 80.6122 (81.8383)  acc5: 95.8333 (95.5958)  time: 0.0840  data: 0.0001  max mem: 1101
[2024-01-20 15:25:23 root] (utils.py 293): INFO Test:  [280/500]  eta: 0:00:20  flops: 12.5229 (12.5229)  loss: 0.8136 (0.8335)  acc1: 81.8182 (81.8393)  acc5: 95.9596 (95.5975)  time: 0.0844  data: 0.0001  max mem: 1101
[2024-01-20 15:25:24 root] (utils.py 293): INFO Test:  [290/500]  eta: 0:00:19  flops: 12.5229 (12.5229)  loss: 0.8357 (0.8340)  acc1: 81.0000 (81.8074)  acc5: 96.0000 (95.5883)  time: 0.0845  data: 0.0001  max mem: 1101
[2024-01-20 15:25:24 root] (utils.py 293): INFO Test:  [300/500]  eta: 0:00:18  flops: 12.5229 (12.5229)  loss: 0.8366 (0.8335)  acc1: 80.6122 (81.7776)  acc5: 95.7895 (95.6169)  time: 0.0845  data: 0.0001  max mem: 1101
[2024-01-20 15:25:25 root] (utils.py 293): INFO Test:  [310/500]  eta: 0:00:17  flops: 12.5229 (12.5229)  loss: 0.8610 (0.8366)  acc1: 79.7980 (81.7399)  acc5: 94.9495 (95.5684)  time: 0.0845  data: 0.0001  max mem: 1101
[2024-01-20 15:25:26 root] (utils.py 293): INFO Test:  [320/500]  eta: 0:00:16  flops: 12.5229 (12.5229)  loss: 0.8616 (0.8353)  acc1: 80.8081 (81.7677)  acc5: 95.8333 (95.5854)  time: 0.0842  data: 0.0001  max mem: 1101
[2024-01-20 15:25:27 root] (utils.py 293): INFO Test:  [330/500]  eta: 0:00:15  flops: 12.5229 (12.5229)  loss: 0.8032 (0.8358)  acc1: 81.2500 (81.7488)  acc5: 95.9596 (95.5941)  time: 0.0836  data: 0.0001  max mem: 1101
[2024-01-20 15:25:28 root] (utils.py 293): INFO Test:  [340/500]  eta: 0:00:14  flops: 12.5229 (12.5229)  loss: 0.8344 (0.8347)  acc1: 81.0000 (81.7834)  acc5: 95.0000 (95.5892)  time: 0.0839  data: 0.0001  max mem: 1101
[2024-01-20 15:25:29 root] (utils.py 293): INFO Test:  [350/500]  eta: 0:00:13  flops: 12.5229 (12.5229)  loss: 0.7938 (0.8328)  acc1: 83.1579 (81.8076)  acc5: 95.8763 (95.6158)  time: 0.0842  data: 0.0001  max mem: 1101
[2024-01-20 15:25:30 root] (utils.py 293): INFO Test:  [360/500]  eta: 0:00:12  flops: 12.5229 (12.5229)  loss: 0.7855 (0.8330)  acc1: 83.0000 (81.8136)  acc5: 95.8763 (95.6072)  time: 0.0842  data: 0.0001  max mem: 1101
[2024-01-20 15:25:30 root] (utils.py 293): INFO Test:  [370/500]  eta: 0:00:11  flops: 12.5229 (12.5229)  loss: 0.7855 (0.8315)  acc1: 82.6531 (81.8496)  acc5: 95.9184 (95.6408)  time: 0.0844  data: 0.0001  max mem: 1101
[2024-01-20 15:25:31 root] (utils.py 293): INFO Test:  [380/500]  eta: 0:00:10  flops: 12.5229 (12.5229)  loss: 0.8231 (0.8324)  acc1: 83.6735 (81.8437)  acc5: 96.9388 (95.6514)  time: 0.0844  data: 0.0001  max mem: 1101
[2024-01-20 15:25:32 root] (utils.py 293): INFO Test:  [390/500]  eta: 0:00:09  flops: 12.5229 (12.5229)  loss: 0.8011 (0.8317)  acc1: 83.3333 (81.8617)  acc5: 95.9184 (95.6478)  time: 0.0840  data: 0.0001  max mem: 1101
[2024-01-20 15:25:33 root] (utils.py 293): INFO Test:  [400/500]  eta: 0:00:09  flops: 12.5229 (12.5229)  loss: 0.8116 (0.8325)  acc1: 81.4433 (81.8369)  acc5: 95.0000 (95.6376)  time: 0.0840  data: 0.0001  max mem: 1101
[2024-01-20 15:25:34 root] (utils.py 293): INFO Test:  [410/500]  eta: 0:00:08  flops: 12.5229 (12.5229)  loss: 0.7778 (0.8298)  acc1: 82.2917 (81.8781)  acc5: 95.8333 (95.6640)  time: 0.0839  data: 0.0001  max mem: 1101
[2024-01-20 15:25:35 root] (utils.py 293): INFO Test:  [420/500]  eta: 0:00:07  flops: 12.5229 (12.5229)  loss: 0.7778 (0.8312)  acc1: 82.2917 (81.8118)  acc5: 95.9184 (95.6531)  time: 0.0837  data: 0.0001  max mem: 1101
[2024-01-20 15:25:35 root] (utils.py 293): INFO Test:  [430/500]  eta: 0:00:06  flops: 12.5229 (12.5229)  loss: 0.8145 (0.8311)  acc1: 79.5918 (81.8266)  acc5: 95.9184 (95.6593)  time: 0.0838  data: 0.0001  max mem: 1101
[2024-01-20 15:25:36 root] (utils.py 293): INFO Test:  [440/500]  eta: 0:00:05  flops: 12.5229 (12.5229)  loss: 0.8381 (0.8321)  acc1: 80.8081 (81.8117)  acc5: 95.9596 (95.6533)  time: 0.0835  data: 0.0001  max mem: 1101
[2024-01-20 15:25:37 root] (utils.py 293): INFO Test:  [450/500]  eta: 0:00:04  flops: 12.5229 (12.5229)  loss: 0.8261 (0.8317)  acc1: 81.2500 (81.8174)  acc5: 95.9596 (95.6520)  time: 0.0834  data: 0.0001  max mem: 1101
[2024-01-20 15:25:38 root] (utils.py 293): INFO Test:  [460/500]  eta: 0:00:03  flops: 12.5229 (12.5229)  loss: 0.8087 (0.8313)  acc1: 81.2500 (81.8188)  acc5: 96.0000 (95.6696)  time: 0.0839  data: 0.0001  max mem: 1101
[2024-01-20 15:25:39 root] (utils.py 293): INFO Test:  [470/500]  eta: 0:00:02  flops: 12.5229 (12.5229)  loss: 0.8132 (0.8321)  acc1: 81.6327 (81.8078)  acc5: 95.9596 (95.6536)  time: 0.0844  data: 0.0001  max mem: 1101
[2024-01-20 15:25:40 root] (utils.py 293): INFO Test:  [480/500]  eta: 0:00:01  flops: 12.5229 (12.5229)  loss: 0.8333 (0.8330)  acc1: 81.2500 (81.7828)  acc5: 94.9495 (95.6511)  time: 0.0843  data: 0.0001  max mem: 1101
[2024-01-20 15:25:40 root] (utils.py 293): INFO Test:  [490/500]  eta: 0:00:00  flops: 12.5229 (12.5229)  loss: 0.8744 (0.8339)  acc1: 80.0000 (81.7522)  acc5: 95.7895 (95.6361)  time: 0.0843  data: 0.0001  max mem: 1101
[2024-01-20 15:25:41 root] (utils.py 293): INFO Test:  [499/500]  eta: 0:00:00  flops: 12.5229 (12.5229)  loss: 0.8191 (0.8323)  acc1: 80.4124 (81.8089)  acc5: 95.9184 (95.6355)  time: 0.0843  data: 0.0001  max mem: 1101
[2024-01-20 15:25:41 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.0889 s / it)
[2024-01-20 15:25:41 root] (engine.py 118): INFO * Acc@1 81.809 Acc@5 95.636 loss 0.832 flops 12.523
[2024-01-20 15:25:41 root] (main.py 381): INFO Accuracy of the network on the 50000 test images: 81.8%
[2024-01-20 15:28:32 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:28:36 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:28:37 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:28:39 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:28:43 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:21  flops: 12.9405 (12.9405)  loss: 0.8889 (0.8889)  acc1: 79.4521 (79.4521)  acc5: 95.2055 (95.2055)  time: 4.8001  data: 0.9516  max mem: 2126
[2024-01-20 15:28:46 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 12.9405 (12.9405)  loss: 0.8442 (0.8304)  acc1: 81.7869 (82.0006)  acc5: 95.2055 (95.3689)  time: 0.7134  data: 0.0866  max mem: 2169
[2024-01-20 15:28:49 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 0.8613 (0.8485)  acc1: 81.4815 (81.6181)  acc5: 94.8980 (95.3074)  time: 0.2777  data: 0.0001  max mem: 2169
[2024-01-20 15:28:52 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:56  flops: 12.9405 (12.9405)  loss: 0.8540 (0.8405)  acc1: 81.0169 (81.7534)  acc5: 95.2055 (95.4301)  time: 0.2514  data: 0.0001  max mem: 2169
[2024-01-20 15:28:54 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8467 (0.8490)  acc1: 81.5700 (81.6421)  acc5: 95.2703 (95.3567)  time: 0.2524  data: 0.0001  max mem: 2169
[2024-01-20 15:28:56 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8508 (0.8417)  acc1: 81.5700 (81.7407)  acc5: 95.2862 (95.5150)  time: 0.2472  data: 0.0001  max mem: 2169
[2024-01-20 15:28:59 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8518 (0.8482)  acc1: 81.7869 (81.6000)  acc5: 95.2862 (95.4571)  time: 0.2413  data: 0.0001  max mem: 2169
[2024-01-20 15:29:01 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8645 (0.8486)  acc1: 81.6949 (81.5865)  acc5: 95.1724 (95.4241)  time: 0.2421  data: 0.0001  max mem: 2169
[2024-01-20 15:29:04 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8490 (0.8521)  acc1: 81.4189 (81.4944)  acc5: 95.2703 (95.4197)  time: 0.2430  data: 0.0001  max mem: 2169
[2024-01-20 15:29:06 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.8609 (0.8591)  acc1: 81.0169 (81.3980)  acc5: 95.1724 (95.3821)  time: 0.2482  data: 0.0001  max mem: 2170
[2024-01-20 15:29:09 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8609 (0.8620)  acc1: 81.2081 (81.3478)  acc5: 94.8980 (95.3370)  time: 0.2488  data: 0.0001  max mem: 2170
[2024-01-20 15:29:11 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8920 (0.8654)  acc1: 80.5369 (81.3102)  acc5: 94.8980 (95.2870)  time: 0.2433  data: 0.0001  max mem: 2170
[2024-01-20 15:29:14 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8442 (0.8619)  acc1: 81.2287 (81.3733)  acc5: 95.1724 (95.3139)  time: 0.2419  data: 0.0001  max mem: 2170
[2024-01-20 15:29:16 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8214 (0.8607)  acc1: 81.2287 (81.4024)  acc5: 95.2862 (95.3512)  time: 0.2421  data: 0.0001  max mem: 2170
[2024-01-20 15:29:18 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8547 (0.8593)  acc1: 80.2721 (81.3424)  acc5: 95.6081 (95.3874)  time: 0.2427  data: 0.0001  max mem: 2170
[2024-01-20 15:29:21 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8547 (0.8615)  acc1: 80.4054 (81.2934)  acc5: 95.6081 (95.3768)  time: 0.2421  data: 0.0002  max mem: 2170
[2024-01-20 15:29:23 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8775 (0.8640)  acc1: 81.3559 (81.2617)  acc5: 94.9324 (95.3655)  time: 0.2425  data: 0.0002  max mem: 2170
[2024-01-20 15:29:25 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8694 (0.8623)  acc1: 81.6949 (81.2875)  acc5: 95.2055 (95.3524)  time: 0.2430  data: 0.0002  max mem: 2170
[2024-01-20 15:29:25 root] (utils.py 307): INFO Test: Total time: 0:00:46 (0.2759 s / it)
[2024-01-20 15:29:25 root] (engine.py 118): INFO * Acc@1 81.288 Acc@5 95.352 loss 0.862 flops 12.940
[2024-01-20 15:29:25 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.3%
[2024-01-20 15:32:46 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:32:49 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:32:51 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:32:52 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:32:57 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:04  flops: 12.9405 (12.9405)  loss: 0.9013 (0.9013)  acc1: 80.8219 (80.8219)  acc5: 92.4658 (92.4658)  time: 4.6958  data: 0.4371  max mem: 2127
[2024-01-20 15:33:00 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:47  flops: 12.9405 (12.9405)  loss: 0.8238 (0.8130)  acc1: 82.0946 (82.0624)  acc5: 94.8980 (94.9058)  time: 0.6865  data: 0.0399  max mem: 2169
[2024-01-20 15:33:02 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:09  flops: 12.9405 (12.9405)  loss: 0.8308 (0.8393)  acc1: 81.4189 (81.6990)  acc5: 94.8980 (95.0162)  time: 0.2591  data: 0.0001  max mem: 2169
[2024-01-20 15:33:05 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:53  flops: 12.9405 (12.9405)  loss: 0.8342 (0.8349)  acc1: 81.0811 (81.7863)  acc5: 95.2542 (95.1781)  time: 0.2328  data: 0.0001  max mem: 2169
[2024-01-20 15:33:07 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:45  flops: 12.9405 (12.9405)  loss: 0.8528 (0.8459)  acc1: 81.0811 (81.6421)  acc5: 94.9324 (95.1001)  time: 0.2340  data: 0.0001  max mem: 2169
[2024-01-20 15:33:09 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:38  flops: 12.9405 (12.9405)  loss: 0.8565 (0.8387)  acc1: 80.5369 (81.6409)  acc5: 95.1890 (95.2888)  time: 0.2289  data: 0.0001  max mem: 2169
[2024-01-20 15:33:11 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:33  flops: 12.9405 (12.9405)  loss: 0.8630 (0.8462)  acc1: 80.3448 (81.4442)  acc5: 95.1890 (95.2010)  time: 0.2224  data: 0.0001  max mem: 2169
[2024-01-20 15:33:14 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8664 (0.8471)  acc1: 80.7432 (81.4383)  acc5: 94.8276 (95.1372)  time: 0.2228  data: 0.0001  max mem: 2169
[2024-01-20 15:33:16 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8520 (0.8505)  acc1: 80.3390 (81.2974)  acc5: 95.2542 (95.1724)  time: 0.2237  data: 0.0001  max mem: 2169
[2024-01-20 15:33:18 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:21  flops: 12.9405 (12.9405)  loss: 0.8438 (0.8571)  acc1: 80.0000 (81.1817)  acc5: 95.2381 (95.1173)  time: 0.2293  data: 0.0001  max mem: 2170
[2024-01-20 15:33:21 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:18  flops: 12.9405 (12.9405)  loss: 0.8438 (0.8586)  acc1: 80.6780 (81.1597)  acc5: 94.6488 (95.0984)  time: 0.2296  data: 0.0001  max mem: 2170
[2024-01-20 15:33:23 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8694 (0.8603)  acc1: 80.7432 (81.1726)  acc5: 94.5763 (95.0760)  time: 0.2240  data: 0.0001  max mem: 2170
[2024-01-20 15:33:25 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8522 (0.8574)  acc1: 81.3793 (81.2274)  acc5: 94.9153 (95.1090)  time: 0.2238  data: 0.0001  max mem: 2170
[2024-01-20 15:33:27 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:09  flops: 12.9405 (12.9405)  loss: 0.8370 (0.8557)  acc1: 81.2287 (81.2210)  acc5: 95.2542 (95.1439)  time: 0.2247  data: 0.0001  max mem: 2170
[2024-01-20 15:33:29 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8520 (0.8538)  acc1: 80.4714 (81.2268)  acc5: 95.2703 (95.1659)  time: 0.2243  data: 0.0001  max mem: 2170
[2024-01-20 15:33:32 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8520 (0.8558)  acc1: 81.0169 (81.2057)  acc5: 95.2381 (95.1429)  time: 0.2230  data: 0.0002  max mem: 2170
[2024-01-20 15:33:34 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8825 (0.8578)  acc1: 81.0811 (81.1795)  acc5: 94.9324 (95.1188)  time: 0.2234  data: 0.0001  max mem: 2170
[2024-01-20 15:33:35 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8543 (0.8560)  acc1: 81.3793 (81.2183)  acc5: 94.9324 (95.1060)  time: 0.2242  data: 0.0001  max mem: 2170
[2024-01-20 15:33:35 root] (utils.py 307): INFO Test: Total time: 0:00:42 (0.2567 s / it)
[2024-01-20 15:33:35 root] (engine.py 118): INFO * Acc@1 81.218 Acc@5 95.106 loss 0.856 flops 12.940
[2024-01-20 15:33:35 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-20 15:38:12 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:38:16 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:38:17 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:38:19 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:38:30 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:38:34 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:38:35 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:38:36 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:38:41 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:44  flops: 12.9405 (12.9405)  loss: 0.9150 (0.9150)  acc1: 81.8493 (81.8493)  acc5: 92.1233 (92.1233)  time: 4.9376  data: 1.1747  max mem: 2126
[2024-01-20 15:38:44 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:53  flops: 12.9405 (12.9405)  loss: 0.8718 (0.8756)  acc1: 81.4189 (81.4758)  acc5: 94.8805 (94.5971)  time: 0.7258  data: 0.1069  max mem: 2169
[2024-01-20 15:38:47 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:13  flops: 12.9405 (12.9405)  loss: 0.8781 (0.8919)  acc1: 80.3448 (81.0518)  acc5: 94.6128 (94.7573)  time: 0.2781  data: 0.0001  max mem: 2169
[2024-01-20 15:38:49 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8867 (0.8939)  acc1: 80.3448 (80.8548)  acc5: 94.6128 (94.7616)  time: 0.2519  data: 0.0001  max mem: 2169
[2024-01-20 15:38:52 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8759 (0.9035)  acc1: 78.9830 (80.5413)  acc5: 94.6309 (94.7111)  time: 0.2532  data: 0.0001  max mem: 2169
[2024-01-20 15:38:54 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.9125 (0.9011)  acc1: 79.0541 (80.5763)  acc5: 94.8454 (94.8563)  time: 0.2485  data: 0.0001  max mem: 2169
[2024-01-20 15:38:57 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.9408 (0.9103)  acc1: 79.4521 (80.4365)  acc5: 94.5946 (94.7667)  time: 0.2423  data: 0.0001  max mem: 2169
[2024-01-20 15:38:59 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.9467 (0.9102)  acc1: 80.0687 (80.4868)  acc5: 94.1379 (94.6926)  time: 0.2429  data: 0.0001  max mem: 2169
[2024-01-20 15:39:02 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.9415 (0.9149)  acc1: 79.9320 (80.3378)  acc5: 94.2373 (94.6905)  time: 0.2441  data: 0.0001  max mem: 2169
[2024-01-20 15:39:04 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.9612 (0.9220)  acc1: 78.9830 (80.1932)  acc5: 94.2761 (94.6436)  time: 0.2497  data: 0.0001  max mem: 2170
[2024-01-20 15:39:07 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.9256 (0.9223)  acc1: 79.8658 (80.1586)  acc5: 94.5946 (94.6483)  time: 0.2501  data: 0.0001  max mem: 2170
[2024-01-20 15:39:09 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.9256 (0.9240)  acc1: 79.8658 (80.1572)  acc5: 94.2953 (94.6111)  time: 0.2444  data: 0.0001  max mem: 2170
[2024-01-20 15:39:12 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.9053 (0.9204)  acc1: 79.9320 (80.2032)  acc5: 94.8097 (94.6460)  time: 0.2438  data: 0.0001  max mem: 2170
[2024-01-20 15:39:14 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8959 (0.9197)  acc1: 80.5461 (80.2493)  acc5: 94.8454 (94.6646)  time: 0.2440  data: 0.0001  max mem: 2170
[2024-01-20 15:39:16 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.9155 (0.9170)  acc1: 80.0000 (80.2446)  acc5: 94.9495 (94.7133)  time: 0.2437  data: 0.0001  max mem: 2170
[2024-01-20 15:39:19 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8932 (0.9173)  acc1: 79.6610 (80.2231)  acc5: 95.5782 (94.7247)  time: 0.2431  data: 0.0002  max mem: 2170
[2024-01-20 15:39:21 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.9375 (0.9201)  acc1: 79.3919 (80.1569)  acc5: 94.2373 (94.6845)  time: 0.2438  data: 0.0002  max mem: 2170
[2024-01-20 15:39:23 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8961 (0.9171)  acc1: 80.1347 (80.2305)  acc5: 94.2373 (94.6885)  time: 0.2448  data: 0.0002  max mem: 2170
[2024-01-20 15:39:23 root] (utils.py 307): INFO Test: Total time: 0:00:46 (0.2779 s / it)
[2024-01-20 15:39:23 root] (engine.py 118): INFO * Acc@1 80.231 Acc@5 94.688 loss 0.917 flops 12.940
[2024-01-20 15:39:23 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 80.2%
[2024-01-20 15:39:35 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:39:38 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:39:40 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:39:41 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:39:46 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:17  flops: 12.9405 (12.9405)  loss: 0.8940 (0.8940)  acc1: 79.4521 (79.4521)  acc5: 94.8630 (94.8630)  time: 4.7776  data: 1.0388  max mem: 2126
[2024-01-20 15:39:49 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 12.9405 (12.9405)  loss: 0.8200 (0.8431)  acc1: 81.6054 (81.9697)  acc5: 95.2703 (94.9985)  time: 0.7160  data: 0.0945  max mem: 2169
[2024-01-20 15:39:52 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 0.8417 (0.8607)  acc1: 81.0811 (81.4239)  acc5: 95.2218 (95.1780)  time: 0.2824  data: 0.0001  max mem: 2169
[2024-01-20 15:39:54 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8705 (0.8566)  acc1: 80.4795 (81.4247)  acc5: 95.2218 (95.3425)  time: 0.2552  data: 0.0001  max mem: 2169
[2024-01-20 15:39:57 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8684 (0.8638)  acc1: 80.7432 (81.3028)  acc5: 95.5932 (95.3816)  time: 0.2554  data: 0.0001  max mem: 2169
[2024-01-20 15:39:59 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8756 (0.8594)  acc1: 80.7432 (81.3348)  acc5: 95.6081 (95.4418)  time: 0.2494  data: 0.0001  max mem: 2169
[2024-01-20 15:40:02 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8880 (0.8666)  acc1: 80.2721 (81.1213)  acc5: 95.2381 (95.3736)  time: 0.2431  data: 0.0001  max mem: 2169
[2024-01-20 15:40:04 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8920 (0.8663)  acc1: 80.2721 (81.0892)  acc5: 94.8276 (95.3572)  time: 0.2436  data: 0.0001  max mem: 2169
[2024-01-20 15:40:07 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8920 (0.8704)  acc1: 80.0000 (80.9873)  acc5: 94.5946 (95.3568)  time: 0.2444  data: 0.0001  max mem: 2169
[2024-01-20 15:40:09 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.9080 (0.8773)  acc1: 79.7980 (80.8534)  acc5: 95.2055 (95.3001)  time: 0.2495  data: 0.0001  max mem: 2170
[2024-01-20 15:40:12 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.8742 (0.8781)  acc1: 80.6780 (80.8103)  acc5: 95.2055 (95.2933)  time: 0.2500  data: 0.0001  max mem: 2170
[2024-01-20 15:40:14 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8827 (0.8811)  acc1: 80.8081 (80.8209)  acc5: 94.9324 (95.2289)  time: 0.2443  data: 0.0001  max mem: 2170
[2024-01-20 15:40:16 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8656 (0.8776)  acc1: 80.9689 (80.8794)  acc5: 94.8276 (95.2549)  time: 0.2437  data: 0.0002  max mem: 2170
[2024-01-20 15:40:19 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8538 (0.8771)  acc1: 81.0811 (80.8790)  acc5: 95.2542 (95.2606)  time: 0.2447  data: 0.0001  max mem: 2170
[2024-01-20 15:40:21 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8565 (0.8750)  acc1: 80.6780 (80.8513)  acc5: 95.2703 (95.3031)  time: 0.2453  data: 0.0001  max mem: 2170
[2024-01-20 15:40:29 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:40:33 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:40:35 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:40:37 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:40:41 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:19  flops: 12.9405 (12.9405)  loss: 0.9233 (0.9233)  acc1: 80.8219 (80.8219)  acc5: 93.4931 (93.4931)  time: 4.7892  data: 1.2135  max mem: 2126
[2024-01-20 15:40:44 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 12.9405 (12.9405)  loss: 0.8846 (0.8809)  acc1: 80.9524 (81.1362)  acc5: 94.9495 (94.8750)  time: 0.7146  data: 0.1104  max mem: 2169
[2024-01-20 15:40:47 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 0.8868 (0.9009)  acc1: 80.7432 (80.4693)  acc5: 94.9324 (94.8220)  time: 0.2801  data: 0.0001  max mem: 2169
[2024-01-20 15:40:49 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8824 (0.8994)  acc1: 80.0000 (80.4055)  acc5: 94.9324 (94.8712)  time: 0.2534  data: 0.0001  max mem: 2169
[2024-01-20 15:40:52 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8932 (0.9112)  acc1: 80.0000 (80.2268)  acc5: 94.5946 (94.8022)  time: 0.2543  data: 0.0001  max mem: 2169
[2024-01-20 15:40:54 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.9096 (0.9063)  acc1: 79.0541 (80.2103)  acc5: 94.8454 (94.9361)  time: 0.2492  data: 0.0001  max mem: 2169
[2024-01-20 15:40:57 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.9326 (0.9129)  acc1: 79.3103 (80.1024)  acc5: 94.5763 (94.7946)  time: 0.2432  data: 0.0001  max mem: 2169
[2024-01-20 15:40:59 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.9362 (0.9132)  acc1: 79.5302 (80.1281)  acc5: 93.9394 (94.7404)  time: 0.2436  data: 0.0001  max mem: 2169
[2024-01-20 15:41:02 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.9362 (0.9162)  acc1: 79.1946 (79.9858)  acc5: 94.5578 (94.7534)  time: 0.2446  data: 0.0001  max mem: 2169
[2024-01-20 15:41:04 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.9568 (0.9244)  acc1: 78.6441 (79.9023)  acc5: 94.6488 (94.6846)  time: 0.2498  data: 0.0001  max mem: 2170
[2024-01-20 15:41:07 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.9622 (0.9274)  acc1: 79.1946 (79.8394)  acc5: 93.9394 (94.6247)  time: 0.2502  data: 0.0001  max mem: 2170
[2024-01-20 15:41:09 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.9621 (0.9299)  acc1: 79.1946 (79.8238)  acc5: 93.8356 (94.5714)  time: 0.2445  data: 0.0001  max mem: 2170
[2024-01-20 15:41:12 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.9078 (0.9258)  acc1: 80.0687 (79.9141)  acc5: 94.1781 (94.6067)  time: 0.2440  data: 0.0001  max mem: 2170
[2024-01-20 15:41:14 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8909 (0.9246)  acc1: 80.3390 (79.9565)  acc5: 94.9153 (94.6386)  time: 0.2450  data: 0.0001  max mem: 2170
[2024-01-20 15:41:17 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.9122 (0.9230)  acc1: 79.4613 (79.9461)  acc5: 94.8980 (94.6772)  time: 0.2452  data: 0.0001  max mem: 2170
[2024-01-20 15:41:19 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.9264 (0.9243)  acc1: 79.4613 (79.9285)  acc5: 94.8980 (94.6572)  time: 0.2445  data: 0.0001  max mem: 2170
[2024-01-20 15:41:21 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.9382 (0.9273)  acc1: 79.0541 (79.8448)  acc5: 94.8097 (94.6149)  time: 0.2449  data: 0.0001  max mem: 2170
[2024-01-20 15:41:23 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.9080 (0.9248)  acc1: 79.4613 (79.9006)  acc5: 93.9189 (94.6050)  time: 0.2456  data: 0.0001  max mem: 2170
[2024-01-20 15:41:23 root] (utils.py 307): INFO Test: Total time: 0:00:46 (0.2779 s / it)
[2024-01-20 15:41:23 root] (engine.py 118): INFO * Acc@1 79.901 Acc@5 94.605 loss 0.925 flops 12.940
[2024-01-20 15:41:23 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 79.9%
[2024-01-20 15:41:52 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:41:56 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:41:57 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:41:59 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:42:04 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:23  flops: 12.9405 (12.9405)  loss: 0.9264 (0.9264)  acc1: 80.8219 (80.8219)  acc5: 93.1507 (93.1507)  time: 4.8100  data: 1.5898  max mem: 2126
[2024-01-20 15:42:07 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 12.9405 (12.9405)  loss: 0.8865 (0.8809)  acc1: 81.1448 (81.1670)  acc5: 94.9324 (94.7823)  time: 0.7181  data: 0.1446  max mem: 2169
[2024-01-20 15:42:10 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:13  flops: 12.9405 (12.9405)  loss: 0.8928 (0.9035)  acc1: 80.2048 (80.5016)  acc5: 94.9324 (94.7411)  time: 0.2818  data: 0.0001  max mem: 2169
[2024-01-20 15:42:13 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8900 (0.9020)  acc1: 79.9320 (80.3288)  acc5: 94.9324 (94.8274)  time: 0.2547  data: 0.0001  max mem: 2169
[2024-01-20 15:42:15 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8935 (0.9125)  acc1: 79.3220 (80.1523)  acc5: 94.6128 (94.7360)  time: 0.2551  data: 0.0001  max mem: 2169
[2024-01-20 15:42:18 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.9054 (0.9063)  acc1: 78.9116 (80.1637)  acc5: 94.6128 (94.8762)  time: 0.2495  data: 0.0001  max mem: 2169
[2024-01-20 15:42:20 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.9177 (0.9121)  acc1: 79.3919 (80.0690)  acc5: 94.5578 (94.7389)  time: 0.2433  data: 0.0001  max mem: 2169
[2024-01-20 15:42:23 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.9302 (0.9121)  acc1: 79.9320 (80.1329)  acc5: 93.9394 (94.7021)  time: 0.2438  data: 0.0001  max mem: 2169
[2024-01-20 15:42:25 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.9378 (0.9153)  acc1: 80.0000 (80.0151)  acc5: 94.5763 (94.7115)  time: 0.2445  data: 0.0001  max mem: 2169
[2024-01-20 15:42:28 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.9548 (0.9230)  acc1: 78.7879 (79.9097)  acc5: 94.5763 (94.6473)  time: 0.2496  data: 0.0001  max mem: 2170
[2024-01-20 15:42:30 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.9612 (0.9260)  acc1: 79.1946 (79.8797)  acc5: 93.9597 (94.5945)  time: 0.2501  data: 0.0001  max mem: 2170
[2024-01-20 15:42:46 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:42:50 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:42:51 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:42:53 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:42:57 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:22  flops: 12.9405 (12.9405)  loss: 0.9181 (0.9181)  acc1: 81.5069 (81.5069)  acc5: 93.1507 (93.1507)  time: 4.8066  data: 1.4144  max mem: 2126
[2024-01-20 15:43:01 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 12.9405 (12.9405)  loss: 0.8668 (0.8772)  acc1: 81.5069 (81.5066)  acc5: 94.5392 (94.6588)  time: 0.7183  data: 0.1287  max mem: 2169
[2024-01-20 15:43:03 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:13  flops: 12.9405 (12.9405)  loss: 0.8762 (0.8904)  acc1: 80.8874 (81.1165)  acc5: 94.5946 (94.8382)  time: 0.2817  data: 0.0001  max mem: 2169
[2024-01-20 15:43:06 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8848 (0.8931)  acc1: 80.6897 (80.8438)  acc5: 94.6128 (94.8274)  time: 0.2536  data: 0.0001  max mem: 2169
[2024-01-20 15:43:08 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8840 (0.9027)  acc1: 79.3220 (80.5247)  acc5: 94.6309 (94.7691)  time: 0.2541  data: 0.0001  max mem: 2169
[2024-01-20 15:43:11 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.9116 (0.9010)  acc1: 78.6942 (80.4964)  acc5: 94.6309 (94.8829)  time: 0.2492  data: 0.0001  max mem: 2169
[2024-01-20 15:43:13 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.9340 (0.9095)  acc1: 79.7297 (80.3864)  acc5: 94.5017 (94.8001)  time: 0.2428  data: 0.0001  max mem: 2169
[2024-01-20 15:43:15 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.9397 (0.9092)  acc1: 80.4124 (80.4246)  acc5: 94.2568 (94.7308)  time: 0.2430  data: 0.0001  max mem: 2169
[2024-01-20 15:43:18 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.9459 (0.9140)  acc1: 79.5302 (80.2498)  acc5: 94.2373 (94.7366)  time: 0.2439  data: 0.0001  max mem: 2169
[2024-01-20 15:43:20 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.9500 (0.9211)  acc1: 78.9830 (80.1000)  acc5: 94.5946 (94.6884)  time: 0.2493  data: 0.0001  max mem: 2170
[2024-01-20 15:43:23 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.9278 (0.9213)  acc1: 79.9331 (80.0813)  acc5: 94.5946 (94.6852)  time: 0.2499  data: 0.0001  max mem: 2170
[2024-01-20 15:43:25 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.9278 (0.9235)  acc1: 79.5918 (80.0777)  acc5: 94.5946 (94.6417)  time: 0.2442  data: 0.0001  max mem: 2170
[2024-01-20 15:43:28 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.9113 (0.9199)  acc1: 80.1370 (80.1330)  acc5: 94.4637 (94.6769)  time: 0.2436  data: 0.0001  max mem: 2170
[2024-01-20 15:43:30 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8961 (0.9190)  acc1: 80.6122 (80.1845)  acc5: 94.8454 (94.7086)  time: 0.2446  data: 0.0001  max mem: 2170
[2024-01-20 15:43:33 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.9144 (0.9164)  acc1: 80.0000 (80.1892)  acc5: 94.9324 (94.7446)  time: 0.2449  data: 0.0001  max mem: 2170
[2024-01-20 15:43:35 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.9054 (0.9170)  acc1: 79.7980 (80.1691)  acc5: 94.9324 (94.7539)  time: 0.2443  data: 0.0001  max mem: 2170
[2024-01-20 15:43:38 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.9383 (0.9200)  acc1: 79.3919 (80.0978)  acc5: 93.9189 (94.7098)  time: 0.2446  data: 0.0001  max mem: 2170
[2024-01-20 15:43:39 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8989 (0.9171)  acc1: 79.7980 (80.1633)  acc5: 93.9597 (94.7068)  time: 0.2452  data: 0.0001  max mem: 2170
[2024-01-20 15:43:39 root] (utils.py 307): INFO Test: Total time: 0:00:46 (0.2779 s / it)
[2024-01-20 15:43:39 root] (engine.py 118): INFO * Acc@1 80.163 Acc@5 94.707 loss 0.917 flops 12.940
[2024-01-20 15:43:39 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 80.2%
[2024-01-20 15:45:00 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:45:05 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:45:06 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:45:07 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:45:12 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:18  flops: 12.9405 (12.9405)  loss: 0.8874 (0.8874)  acc1: 79.4521 (79.4521)  acc5: 95.2055 (95.2055)  time: 4.7815  data: 1.0413  max mem: 2126
[2024-01-20 15:45:15 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:51  flops: 12.9405 (12.9405)  loss: 0.8442 (0.8303)  acc1: 81.7869 (82.0006)  acc5: 95.2055 (95.3689)  time: 0.7132  data: 0.0948  max mem: 2169
[2024-01-20 15:45:18 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 0.8614 (0.8482)  acc1: 81.4815 (81.6181)  acc5: 94.8980 (95.3074)  time: 0.2795  data: 0.0001  max mem: 2169
[2024-01-20 15:45:20 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8536 (0.8403)  acc1: 81.1448 (81.7315)  acc5: 95.2703 (95.4411)  time: 0.2530  data: 0.0001  max mem: 2169
[2024-01-20 15:45:23 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8464 (0.8487)  acc1: 81.5700 (81.6173)  acc5: 95.2703 (95.3816)  time: 0.2538  data: 0.0001  max mem: 2169
[2024-01-20 15:45:25 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8501 (0.8416)  acc1: 81.5700 (81.7274)  acc5: 95.2862 (95.5350)  time: 0.2487  data: 0.0001  max mem: 2169
[2024-01-20 15:45:28 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8507 (0.8481)  acc1: 81.4433 (81.5833)  acc5: 95.2862 (95.4793)  time: 0.2427  data: 0.0001  max mem: 2169
[2024-01-20 15:45:30 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8661 (0.8484)  acc1: 81.5700 (81.5722)  acc5: 95.1724 (95.4480)  time: 0.2426  data: 0.0001  max mem: 2169
[2024-01-20 15:45:33 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8497 (0.8519)  acc1: 81.5700 (81.4692)  acc5: 95.2703 (95.4364)  time: 0.2425  data: 0.0001  max mem: 2169
[2024-01-20 15:45:42 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:45:46 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:45:47 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:45:49 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:45:54 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:17  flops: 12.9405 (12.9405)  loss: 0.8842 (0.8842)  acc1: 80.4795 (80.4795)  acc5: 94.5205 (94.5205)  time: 4.7744  data: 1.0374  max mem: 2126
[2024-01-20 15:45:57 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 12.9405 (12.9405)  loss: 0.8092 (0.8281)  acc1: 82.6087 (82.3711)  acc5: 94.9324 (95.1220)  time: 0.7143  data: 0.0944  max mem: 2169
[2024-01-20 15:46:00 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 0.8473 (0.8453)  acc1: 82.4916 (81.9903)  acc5: 95.2055 (95.1618)  time: 0.2809  data: 0.0001  max mem: 2169
[2024-01-20 15:46:02 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8471 (0.8358)  acc1: 82.4916 (82.1370)  acc5: 95.5631 (95.3753)  time: 0.2531  data: 0.0001  max mem: 2169
[2024-01-20 15:46:05 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8285 (0.8422)  acc1: 81.9113 (81.9980)  acc5: 95.5631 (95.3153)  time: 0.2531  data: 0.0001  max mem: 2169
[2024-01-20 15:46:07 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8550 (0.8372)  acc1: 81.4189 (82.0136)  acc5: 95.9184 (95.4818)  time: 0.2481  data: 0.0001  max mem: 2169
[2024-01-20 15:46:10 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8438 (0.8447)  acc1: 80.6897 (81.8060)  acc5: 95.8763 (95.4682)  time: 0.2421  data: 0.0001  max mem: 2169
[2024-01-20 15:46:12 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8744 (0.8451)  acc1: 81.1448 (81.8112)  acc5: 95.2862 (95.5006)  time: 0.2423  data: 0.0001  max mem: 2169
[2024-01-20 15:46:15 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8498 (0.8490)  acc1: 81.9728 (81.6704)  acc5: 95.2703 (95.4867)  time: 0.2431  data: 0.0001  max mem: 2169
[2024-01-20 15:46:17 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.8666 (0.8563)  acc1: 80.1347 (81.5025)  acc5: 94.9833 (95.4418)  time: 0.2483  data: 0.0001  max mem: 2170
[2024-01-20 15:46:20 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8666 (0.8580)  acc1: 81.0811 (81.4755)  acc5: 94.9664 (95.4075)  time: 0.2488  data: 0.0001  max mem: 2170
[2024-01-20 15:46:22 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8839 (0.8617)  acc1: 81.3559 (81.4111)  acc5: 94.9324 (95.3696)  time: 0.2436  data: 0.0001  max mem: 2170
[2024-01-20 15:46:24 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8467 (0.8590)  acc1: 81.6609 (81.4855)  acc5: 94.9153 (95.3784)  time: 0.2431  data: 0.0001  max mem: 2170
[2024-01-20 15:46:27 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8340 (0.8586)  acc1: 81.3793 (81.4594)  acc5: 95.6229 (95.4264)  time: 0.2439  data: 0.0001  max mem: 2170
[2024-01-20 15:46:29 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8601 (0.8570)  acc1: 80.1347 (81.4218)  acc5: 95.8904 (95.4403)  time: 0.2442  data: 0.0001  max mem: 2170
[2024-01-20 15:46:32 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8546 (0.8584)  acc1: 80.7432 (81.4014)  acc5: 95.9044 (95.4600)  time: 0.2436  data: 0.0002  max mem: 2170
[2024-01-20 15:46:34 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8550 (0.8601)  acc1: 81.2925 (81.3777)  acc5: 94.9324 (95.4393)  time: 0.2440  data: 0.0002  max mem: 2170
[2024-01-20 15:46:36 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8544 (0.8582)  acc1: 81.6327 (81.4057)  acc5: 94.9324 (95.4237)  time: 0.2445  data: 0.0001  max mem: 2170
[2024-01-20 15:46:36 root] (utils.py 307): INFO Test: Total time: 0:00:46 (0.2769 s / it)
[2024-01-20 15:46:36 root] (engine.py 118): INFO * Acc@1 81.406 Acc@5 95.424 loss 0.858 flops 12.940
[2024-01-20 15:46:36 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.4%
[2024-01-20 15:46:53 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:46:57 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:46:58 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:47:00 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:47:04 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:14  flops: 12.9405 (12.9405)  loss: 1.2537 (1.2537)  acc1: 72.6027 (72.6027)  acc5: 90.0685 (90.0685)  time: 4.7583  data: 0.8368  max mem: 2126
[2024-01-20 15:47:07 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:51  flops: 12.9405 (12.9405)  loss: 1.2537 (1.2837)  acc1: 72.7273 (72.6150)  acc5: 90.2357 (90.1204)  time: 0.7123  data: 0.0762  max mem: 2169
[2024-01-20 15:47:10 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 1.3015 (1.3247)  acc1: 71.8213 (72.0065)  acc5: 89.7611 (89.3689)  time: 0.2806  data: 0.0001  max mem: 2169
[2024-01-20 15:47:13 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 1.3397 (1.3168)  acc1: 71.6724 (72.0767)  acc5: 89.5270 (89.5562)  time: 0.2534  data: 0.0001  max mem: 2169
[2024-01-20 15:47:21 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:47:25 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:47:26 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:47:28 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:47:33 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:23  flops: 12.9405 (12.9405)  loss: 1.2623 (1.2623)  acc1: 72.2603 (72.2603)  acc5: 90.0685 (90.0685)  time: 4.8094  data: 1.1974  max mem: 2126
[2024-01-20 15:47:36 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 12.9405 (12.9405)  loss: 1.2623 (1.2838)  acc1: 72.3906 (72.6768)  acc5: 90.0685 (89.9969)  time: 0.7187  data: 0.1090  max mem: 2169
[2024-01-20 15:47:38 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:13  flops: 12.9405 (12.9405)  loss: 1.2983 (1.3231)  acc1: 71.9595 (72.0065)  acc5: 89.4198 (89.3689)  time: 0.2816  data: 0.0001  max mem: 2169
[2024-01-20 15:47:46 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:47:49 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:47:50 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:47:52 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:47:57 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:20  flops: 12.9405 (12.9405)  loss: 0.8810 (0.8810)  acc1: 80.1370 (80.1370)  acc5: 94.5205 (94.5205)  time: 4.7916  data: 1.4017  max mem: 2126
[2024-01-20 15:48:00 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 12.9405 (12.9405)  loss: 0.8110 (0.8291)  acc1: 82.5939 (82.3402)  acc5: 94.8980 (95.1837)  time: 0.7151  data: 0.1275  max mem: 2169
[2024-01-20 15:48:03 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 0.8507 (0.8449)  acc1: 82.4742 (81.9579)  acc5: 94.9495 (95.2104)  time: 0.2807  data: 0.0001  max mem: 2169
[2024-01-20 15:48:05 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8365 (0.8360)  acc1: 82.3729 (82.0822)  acc5: 95.5172 (95.3753)  time: 0.2535  data: 0.0001  max mem: 2169
[2024-01-20 15:48:08 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8298 (0.8418)  acc1: 81.9113 (81.9566)  acc5: 95.2703 (95.3319)  time: 0.2534  data: 0.0001  max mem: 2169
[2024-01-20 15:48:10 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8464 (0.8373)  acc1: 81.4189 (81.9870)  acc5: 95.9184 (95.5017)  time: 0.2482  data: 0.0001  max mem: 2169
[2024-01-20 15:48:13 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8431 (0.8449)  acc1: 80.6897 (81.7782)  acc5: 95.8763 (95.4738)  time: 0.2424  data: 0.0001  max mem: 2169
[2024-01-20 15:48:15 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8783 (0.8455)  acc1: 81.0997 (81.7586)  acc5: 95.1890 (95.4958)  time: 0.2432  data: 0.0001  max mem: 2169
[2024-01-20 15:48:17 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8524 (0.8492)  acc1: 81.7568 (81.6327)  acc5: 95.2542 (95.4867)  time: 0.2438  data: 0.0001  max mem: 2169
[2024-01-20 15:48:20 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.8641 (0.8565)  acc1: 80.1347 (81.4614)  acc5: 95.2381 (95.4456)  time: 0.2487  data: 0.0001  max mem: 2170
[2024-01-20 15:48:22 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.8641 (0.8581)  acc1: 80.8081 (81.4318)  acc5: 95.2381 (95.4075)  time: 0.2491  data: 0.0001  max mem: 2170
[2024-01-20 15:48:25 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8816 (0.8618)  acc1: 81.6949 (81.3806)  acc5: 95.2055 (95.3818)  time: 0.2437  data: 0.0001  max mem: 2170
[2024-01-20 15:48:27 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8444 (0.8589)  acc1: 81.6949 (81.4519)  acc5: 95.2055 (95.3924)  time: 0.2434  data: 0.0001  max mem: 2170
[2024-01-20 15:48:30 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8393 (0.8584)  acc1: 81.0997 (81.4128)  acc5: 95.5932 (95.4368)  time: 0.2446  data: 0.0001  max mem: 2170
[2024-01-20 15:48:32 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8599 (0.8568)  acc1: 80.1347 (81.3665)  acc5: 95.5932 (95.4548)  time: 0.2448  data: 0.0001  max mem: 2170
[2024-01-20 15:48:35 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8547 (0.8583)  acc1: 81.0169 (81.3564)  acc5: 95.8478 (95.4645)  time: 0.2439  data: 0.0002  max mem: 2170
[2024-01-20 15:48:37 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8558 (0.8599)  acc1: 81.3559 (81.3376)  acc5: 94.9324 (95.4435)  time: 0.2443  data: 0.0002  max mem: 2170
[2024-01-20 15:48:39 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8521 (0.8580)  acc1: 81.6327 (81.3711)  acc5: 95.2055 (95.4319)  time: 0.2448  data: 0.0001  max mem: 2170
[2024-01-20 15:48:39 root] (utils.py 307): INFO Test: Total time: 0:00:46 (0.2773 s / it)
[2024-01-20 15:48:39 root] (engine.py 118): INFO * Acc@1 81.371 Acc@5 95.432 loss 0.858 flops 12.940
[2024-01-20 15:48:39 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.4%
[2024-01-20 15:49:25 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:49:29 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:49:30 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:49:32 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:49:37 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:12  flops: 12.9405 (12.9405)  loss: 0.8790 (0.8790)  acc1: 80.4795 (80.4795)  acc5: 94.1781 (94.1781)  time: 4.7456  data: 0.8326  max mem: 2126
[2024-01-20 15:49:40 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:51  flops: 12.9405 (12.9405)  loss: 0.8021 (0.8256)  acc1: 82.2742 (82.2476)  acc5: 94.9324 (95.0911)  time: 0.7127  data: 0.0758  max mem: 2169
[2024-01-20 15:49:42 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 0.8486 (0.8468)  acc1: 82.1549 (81.8447)  acc5: 94.9495 (95.1133)  time: 0.2816  data: 0.0001  max mem: 2169
[2024-01-20 15:49:45 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8486 (0.8388)  acc1: 81.4189 (81.9397)  acc5: 95.2862 (95.3863)  time: 0.2542  data: 0.0001  max mem: 2169
[2024-01-20 15:49:47 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8391 (0.8451)  acc1: 81.4189 (81.9566)  acc5: 95.5631 (95.3485)  time: 0.2555  data: 0.0001  max mem: 2169
[2024-01-20 15:49:50 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8521 (0.8401)  acc1: 82.0946 (81.9736)  acc5: 95.5631 (95.4751)  time: 0.2504  data: 0.0001  max mem: 2169
[2024-01-20 15:49:52 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8596 (0.8474)  acc1: 81.4433 (81.7281)  acc5: 95.2381 (95.3958)  time: 0.2434  data: 0.0001  max mem: 2169
[2024-01-20 15:49:55 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8851 (0.8475)  acc1: 81.4189 (81.7013)  acc5: 94.9324 (95.3906)  time: 0.2430  data: 0.0001  max mem: 2169
[2024-01-20 15:49:57 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8664 (0.8509)  acc1: 81.4189 (81.6327)  acc5: 95.5782 (95.4155)  time: 0.2439  data: 0.0001  max mem: 2169
[2024-01-20 15:50:00 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.8685 (0.8579)  acc1: 80.3390 (81.4838)  acc5: 95.2542 (95.4045)  time: 0.2493  data: 0.0001  max mem: 2170
[2024-01-20 15:50:02 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.8786 (0.8595)  acc1: 80.8081 (81.4285)  acc5: 94.8980 (95.3706)  time: 0.2496  data: 0.0001  max mem: 2170
[2024-01-20 15:50:05 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8848 (0.8631)  acc1: 81.0811 (81.3744)  acc5: 94.8980 (95.3268)  time: 0.2438  data: 0.0001  max mem: 2170
[2024-01-20 15:50:07 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8482 (0.8603)  acc1: 81.8493 (81.4519)  acc5: 94.9664 (95.3588)  time: 0.2435  data: 0.0001  max mem: 2170
[2024-01-20 15:50:10 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8403 (0.8600)  acc1: 81.7869 (81.4076)  acc5: 95.9322 (95.4005)  time: 0.2447  data: 0.0001  max mem: 2170
[2024-01-20 15:50:12 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8630 (0.8579)  acc1: 80.6780 (81.3905)  acc5: 95.6081 (95.4235)  time: 0.2450  data: 0.0001  max mem: 2170
[2024-01-20 15:50:14 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8563 (0.8594)  acc1: 81.2287 (81.3609)  acc5: 95.5631 (95.4330)  time: 0.2442  data: 0.0002  max mem: 2170
[2024-01-20 15:50:17 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8621 (0.8607)  acc1: 80.9524 (81.3187)  acc5: 95.2703 (95.4351)  time: 0.2448  data: 0.0002  max mem: 2170
[2024-01-20 15:50:18 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8451 (0.8587)  acc1: 81.6949 (81.3548)  acc5: 95.6229 (95.4278)  time: 0.2452  data: 0.0001  max mem: 2170
[2024-01-20 15:50:18 root] (utils.py 307): INFO Test: Total time: 0:00:46 (0.2777 s / it)
[2024-01-20 15:50:18 root] (engine.py 118): INFO * Acc@1 81.355 Acc@5 95.428 loss 0.859 flops 12.940
[2024-01-20 15:50:18 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.4%
[2024-01-20 15:51:02 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:51:06 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:51:07 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:51:09 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:51:13 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:22  flops: 12.9405 (12.9405)  loss: 0.9555 (0.9555)  acc1: 79.1096 (79.1096)  acc5: 92.4658 (92.4658)  time: 4.8039  data: 1.0407  max mem: 2126
[2024-01-20 15:51:16 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 12.9405 (12.9405)  loss: 0.8604 (0.8762)  acc1: 81.7568 (81.2596)  acc5: 94.8805 (94.7823)  time: 0.7156  data: 0.0947  max mem: 2169
[2024-01-20 15:51:19 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 0.8671 (0.8930)  acc1: 81.0811 (80.8738)  acc5: 95.1890 (94.7573)  time: 0.2801  data: 0.0001  max mem: 2169
[2024-01-20 15:51:22 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8754 (0.8884)  acc1: 80.4714 (80.8877)  acc5: 95.2055 (94.8384)  time: 0.2537  data: 0.0001  max mem: 2169
[2024-01-20 15:51:24 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8886 (0.8941)  acc1: 80.0000 (80.6158)  acc5: 94.9324 (94.8684)  time: 0.2548  data: 0.0001  max mem: 2169
[2024-01-20 15:51:27 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8886 (0.8843)  acc1: 80.0676 (80.6162)  acc5: 95.2862 (95.0625)  time: 0.2500  data: 0.0001  max mem: 2169
[2024-01-20 15:51:29 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8830 (0.8883)  acc1: 80.0676 (80.4977)  acc5: 95.2381 (94.9894)  time: 0.2436  data: 0.0001  max mem: 2169
[2024-01-20 15:51:49 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:51:52 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:51:54 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:51:55 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:53:15 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:53:18 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:53:20 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:53:21 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:53:26 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:43  flops: 12.9405 (12.9405)  loss: 0.8946 (0.8946)  acc1: 79.7945 (79.7945)  acc5: 94.1781 (94.1781)  time: 4.9291  data: 1.3493  max mem: 2126
[2024-01-20 15:53:29 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:55  flops: 12.9405 (12.9405)  loss: 0.8192 (0.8281)  acc1: 82.8179 (82.5563)  acc5: 95.2703 (95.2763)  time: 0.7348  data: 0.1228  max mem: 2169
[2024-01-20 15:53:32 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:14  flops: 12.9405 (12.9405)  loss: 0.8598 (0.8475)  acc1: 82.4916 (81.9903)  acc5: 95.2703 (95.2104)  time: 0.2870  data: 0.0001  max mem: 2169
[2024-01-20 15:53:34 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:58  flops: 12.9405 (12.9405)  loss: 0.8598 (0.8401)  acc1: 81.2925 (81.9945)  acc5: 95.2862 (95.3973)  time: 0.2593  data: 0.0001  max mem: 2169
[2024-01-20 15:53:37 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:49  flops: 12.9405 (12.9405)  loss: 0.8347 (0.8459)  acc1: 82.2526 (81.9566)  acc5: 95.5631 (95.3816)  time: 0.2601  data: 0.0001  max mem: 2169
[2024-01-20 15:53:40 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:42  flops: 12.9405 (12.9405)  loss: 0.8588 (0.8423)  acc1: 82.2526 (81.9803)  acc5: 95.9044 (95.4884)  time: 0.2548  data: 0.0001  max mem: 2169
[2024-01-20 15:53:42 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:36  flops: 12.9405 (12.9405)  loss: 0.8590 (0.8491)  acc1: 80.7560 (81.7671)  acc5: 95.5479 (95.4404)  time: 0.2495  data: 0.0001  max mem: 2169
[2024-01-20 15:53:45 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8846 (0.8488)  acc1: 80.7560 (81.7395)  acc5: 95.2381 (95.4385)  time: 0.2505  data: 0.0001  max mem: 2169
[2024-01-20 15:53:47 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8583 (0.8525)  acc1: 81.8792 (81.5949)  acc5: 95.5172 (95.4700)  time: 0.2509  data: 0.0001  max mem: 2169
[2024-01-20 15:53:50 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:24  flops: 12.9405 (12.9405)  loss: 0.8583 (0.8591)  acc1: 80.7432 (81.4353)  acc5: 95.2862 (95.4381)  time: 0.2557  data: 0.0001  max mem: 2170
[2024-01-20 15:53:52 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.8488 (0.8605)  acc1: 80.8081 (81.4251)  acc5: 95.2218 (95.4243)  time: 0.2555  data: 0.0001  max mem: 2170
[2024-01-20 15:53:55 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:17  flops: 12.9405 (12.9405)  loss: 0.8917 (0.8646)  acc1: 81.0811 (81.3867)  acc5: 95.2218 (95.3635)  time: 0.2492  data: 0.0001  max mem: 2170
[2024-01-20 15:53:57 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8532 (0.8620)  acc1: 81.0997 (81.4378)  acc5: 95.2218 (95.3896)  time: 0.2488  data: 0.0001  max mem: 2170
[2024-01-20 15:54:00 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8334 (0.8612)  acc1: 81.0345 (81.4205)  acc5: 95.5932 (95.4290)  time: 0.2501  data: 0.0001  max mem: 2170
[2024-01-20 15:54:02 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8539 (0.8593)  acc1: 80.4054 (81.3833)  acc5: 95.6081 (95.4716)  time: 0.2505  data: 0.0001  max mem: 2170
[2024-01-20 15:54:05 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8613 (0.8606)  acc1: 80.9524 (81.3744)  acc5: 95.6081 (95.4824)  time: 0.2499  data: 0.0002  max mem: 2170
[2024-01-20 15:54:07 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8661 (0.8626)  acc1: 81.3559 (81.3440)  acc5: 95.6081 (95.4857)  time: 0.2502  data: 0.0002  max mem: 2170
[2024-01-20 15:54:09 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8573 (0.8605)  acc1: 81.4815 (81.3833)  acc5: 95.6229 (95.4828)  time: 0.2505  data: 0.0001  max mem: 2170
[2024-01-20 15:54:09 root] (utils.py 307): INFO Test: Total time: 0:00:47 (0.2844 s / it)
[2024-01-20 15:54:09 root] (engine.py 118): INFO * Acc@1 81.383 Acc@5 95.483 loss 0.861 flops 12.940
[2024-01-20 15:54:09 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.4%
[2024-01-20 15:55:05 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:55:09 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:55:10 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:55:12 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:55:17 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:20  flops: 12.9405 (12.9405)  loss: 0.8907 (0.8907)  acc1: 80.8219 (80.8219)  acc5: 93.8356 (93.8356)  time: 4.7923  data: 1.1886  max mem: 2126
[2024-01-20 15:55:20 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:53  flops: 12.9405 (12.9405)  loss: 0.8264 (0.8500)  acc1: 82.1306 (81.8771)  acc5: 95.1890 (95.0602)  time: 0.7202  data: 0.1082  max mem: 2169
[2024-01-20 15:55:23 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:13  flops: 12.9405 (12.9405)  loss: 0.8595 (0.8675)  acc1: 81.4433 (81.5049)  acc5: 95.2218 (95.1942)  time: 0.2865  data: 0.0001  max mem: 2169
[2024-01-20 15:55:26 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:58  flops: 12.9405 (12.9405)  loss: 0.8662 (0.8627)  acc1: 81.0811 (81.4575)  acc5: 95.2862 (95.3205)  time: 0.2601  data: 0.0001  max mem: 2169
[2024-01-20 15:55:28 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8662 (0.8697)  acc1: 80.2048 (81.3690)  acc5: 94.8980 (95.2657)  time: 0.2612  data: 0.0001  max mem: 2169
[2024-01-20 15:55:31 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8878 (0.8659)  acc1: 81.0811 (81.4213)  acc5: 95.2703 (95.3154)  time: 0.2564  data: 0.0001  max mem: 2169
[2024-01-20 15:55:33 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:36  flops: 12.9405 (12.9405)  loss: 0.9063 (0.8752)  acc1: 80.6122 (81.2103)  acc5: 95.2703 (95.2177)  time: 0.2498  data: 0.0001  max mem: 2169
[2024-01-20 15:55:36 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.9071 (0.8745)  acc1: 80.6122 (81.1944)  acc5: 94.9664 (95.1850)  time: 0.2491  data: 0.0001  max mem: 2169
[2024-01-20 15:55:38 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8843 (0.8797)  acc1: 80.6122 (81.0502)  acc5: 94.9153 (95.1683)  time: 0.2493  data: 0.0001  max mem: 2169
[2024-01-20 15:55:41 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.9031 (0.8865)  acc1: 79.4613 (80.9542)  acc5: 94.9153 (95.1434)  time: 0.2546  data: 0.0001  max mem: 2170
[2024-01-20 15:55:43 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.8885 (0.8869)  acc1: 80.2013 (80.8809)  acc5: 94.8980 (95.1455)  time: 0.2549  data: 0.0001  max mem: 2170
[2024-01-20 15:55:46 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:17  flops: 12.9405 (12.9405)  loss: 0.8906 (0.8901)  acc1: 80.2013 (80.8698)  acc5: 94.5392 (95.0852)  time: 0.2493  data: 0.0001  max mem: 2170
[2024-01-20 15:55:48 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8715 (0.8871)  acc1: 81.0811 (80.9355)  acc5: 94.5392 (95.1230)  time: 0.2490  data: 0.0001  max mem: 2170
[2024-01-20 15:55:51 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8562 (0.8868)  acc1: 80.8874 (80.9463)  acc5: 95.3020 (95.1388)  time: 0.2503  data: 0.0001  max mem: 2170
[2024-01-20 15:55:53 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8644 (0.8845)  acc1: 80.4054 (80.9644)  acc5: 95.2703 (95.1779)  time: 0.2510  data: 0.0001  max mem: 2170
[2024-01-20 15:55:56 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8715 (0.8853)  acc1: 80.8081 (80.9246)  acc5: 95.2381 (95.1901)  time: 0.2505  data: 0.0001  max mem: 2170
[2024-01-20 15:55:58 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8951 (0.8874)  acc1: 80.4054 (80.9075)  acc5: 94.9153 (95.1673)  time: 0.2509  data: 0.0001  max mem: 2170
[2024-01-20 15:56:00 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8871 (0.8850)  acc1: 81.0169 (80.9271)  acc5: 94.9324 (95.1630)  time: 0.2514  data: 0.0001  max mem: 2170
[2024-01-20 15:56:00 root] (utils.py 307): INFO Test: Total time: 0:00:47 (0.2836 s / it)
[2024-01-20 15:56:00 root] (engine.py 118): INFO * Acc@1 80.927 Acc@5 95.163 loss 0.885 flops 12.940
[2024-01-20 15:56:00 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 80.9%
[2024-01-20 15:56:34 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:56:38 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:56:40 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:56:42 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:56:46 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:24  flops: 12.9405 (12.9405)  loss: 0.8618 (0.8618)  acc1: 82.1918 (82.1918)  acc5: 94.5205 (94.5205)  time: 4.8152  data: 1.0439  max mem: 2126
[2024-01-20 15:56:49 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:53  flops: 12.9405 (12.9405)  loss: 0.8132 (0.8229)  acc1: 82.4742 (82.5563)  acc5: 95.6081 (95.5542)  time: 0.7236  data: 0.0950  max mem: 2169
[2024-01-20 15:56:52 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:13  flops: 12.9405 (12.9405)  loss: 0.8464 (0.8439)  acc1: 81.9113 (81.9256)  acc5: 95.2218 (95.3398)  time: 0.2872  data: 0.0001  max mem: 2169
[2024-01-20 15:56:55 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:58  flops: 12.9405 (12.9405)  loss: 0.8480 (0.8363)  acc1: 81.7568 (82.0055)  acc5: 95.5479 (95.5068)  time: 0.2604  data: 0.0001  max mem: 2169
[2024-01-20 15:56:57 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8405 (0.8416)  acc1: 81.5700 (82.0394)  acc5: 95.5782 (95.4892)  time: 0.2609  data: 0.0001  max mem: 2169
[2024-01-20 15:57:00 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8328 (0.8351)  acc1: 81.7568 (82.0402)  acc5: 95.6081 (95.6215)  time: 0.2553  data: 0.0001  max mem: 2169
[2024-01-20 15:57:02 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:36  flops: 12.9405 (12.9405)  loss: 0.8365 (0.8421)  acc1: 81.0345 (81.8394)  acc5: 95.5782 (95.5684)  time: 0.2489  data: 0.0001  max mem: 2169
[2024-01-20 15:57:05 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8506 (0.8420)  acc1: 81.0345 (81.8351)  acc5: 95.2862 (95.5437)  time: 0.2492  data: 0.0001  max mem: 2169
[2024-01-20 15:57:07 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8448 (0.8459)  acc1: 81.2287 (81.7248)  acc5: 95.3020 (95.5119)  time: 0.2496  data: 0.0001  max mem: 2169
[2024-01-20 15:57:10 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.8641 (0.8530)  acc1: 80.1347 (81.5622)  acc5: 95.2218 (95.4791)  time: 0.2547  data: 0.0001  max mem: 2170
[2024-01-20 15:57:12 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.8630 (0.8550)  acc1: 80.5369 (81.5225)  acc5: 95.2055 (95.4613)  time: 0.2555  data: 0.0001  max mem: 2170
[2024-01-20 15:57:15 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:17  flops: 12.9405 (12.9405)  loss: 0.8708 (0.8584)  acc1: 81.6609 (81.4815)  acc5: 94.8805 (95.3971)  time: 0.2504  data: 0.0001  max mem: 2170
[2024-01-20 15:57:17 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8409 (0.8556)  acc1: 81.7568 (81.5080)  acc5: 95.2218 (95.4289)  time: 0.2499  data: 0.0001  max mem: 2170
[2024-01-20 15:57:20 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8381 (0.8547)  acc1: 81.6327 (81.4698)  acc5: 95.8478 (95.4679)  time: 0.2508  data: 0.0001  max mem: 2170
[2024-01-20 15:57:22 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8417 (0.8528)  acc1: 80.7432 (81.4170)  acc5: 96.2329 (95.5053)  time: 0.2512  data: 0.0001  max mem: 2170
[2024-01-20 15:57:25 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8534 (0.8544)  acc1: 80.8081 (81.3991)  acc5: 95.5479 (95.5004)  time: 0.2505  data: 0.0001  max mem: 2170
[2024-01-20 15:57:27 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8599 (0.8565)  acc1: 81.4189 (81.3608)  acc5: 95.2218 (95.4815)  time: 0.2508  data: 0.0001  max mem: 2170
[2024-01-20 15:57:29 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8556 (0.8549)  acc1: 81.6949 (81.4036)  acc5: 95.2862 (95.4645)  time: 0.2514  data: 0.0001  max mem: 2170
[2024-01-20 15:57:29 root] (utils.py 307): INFO Test: Total time: 0:00:47 (0.2839 s / it)
[2024-01-20 15:57:29 root] (engine.py 118): INFO * Acc@1 81.404 Acc@5 95.464 loss 0.855 flops 12.940
[2024-01-20 15:57:29 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.4%
[2024-01-20 15:58:44 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 15:58:48 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 15:58:49 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 15:58:51 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 15:58:56 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:24  flops: 12.9405 (12.9405)  loss: 0.8623 (0.8623)  acc1: 81.1644 (81.1644)  acc5: 94.5205 (94.5205)  time: 4.8203  data: 1.2314  max mem: 2126
[2024-01-20 15:58:59 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:53  flops: 12.9405 (12.9405)  loss: 0.8025 (0.8263)  acc1: 82.4916 (82.4946)  acc5: 95.2703 (95.2454)  time: 0.7240  data: 0.1120  max mem: 2169
[2024-01-20 15:59:01 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:13  flops: 12.9405 (12.9405)  loss: 0.8454 (0.8496)  acc1: 81.7869 (81.6828)  acc5: 95.2381 (95.1618)  time: 0.2870  data: 0.0001  max mem: 2169
[2024-01-20 15:59:04 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:58  flops: 12.9405 (12.9405)  loss: 0.8459 (0.8420)  acc1: 81.0811 (81.8082)  acc5: 95.2218 (95.2877)  time: 0.2601  data: 0.0001  max mem: 2169
[2024-01-20 15:59:07 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8710 (0.8476)  acc1: 80.8874 (81.7828)  acc5: 95.6081 (95.3567)  time: 0.2613  data: 0.0001  max mem: 2169
[2024-01-20 15:59:09 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8639 (0.8418)  acc1: 81.0811 (81.8206)  acc5: 95.6229 (95.5150)  time: 0.2564  data: 0.0001  max mem: 2169
[2024-01-20 15:59:12 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:36  flops: 12.9405 (12.9405)  loss: 0.8592 (0.8485)  acc1: 81.0811 (81.6557)  acc5: 95.2862 (95.4515)  time: 0.2501  data: 0.0001  max mem: 2169
[2024-01-20 15:59:14 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8592 (0.8475)  acc1: 80.7432 (81.5769)  acc5: 95.1890 (95.4528)  time: 0.2494  data: 0.0001  max mem: 2169
[2024-01-20 15:59:17 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8490 (0.8504)  acc1: 80.7432 (81.4483)  acc5: 95.2542 (95.4658)  time: 0.2495  data: 0.0001  max mem: 2169
[2024-01-20 15:59:19 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:24  flops: 12.9405 (12.9405)  loss: 0.8710 (0.8577)  acc1: 80.8081 (81.3011)  acc5: 95.2381 (95.4008)  time: 0.2548  data: 0.0001  max mem: 2170
[2024-01-20 15:59:22 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.8638 (0.8591)  acc1: 81.0811 (81.2739)  acc5: 94.9495 (95.3840)  time: 0.2556  data: 0.0001  max mem: 2170
[2024-01-20 15:59:24 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:17  flops: 12.9405 (12.9405)  loss: 0.8638 (0.8619)  acc1: 81.0811 (81.2307)  acc5: 95.2381 (95.3421)  time: 0.2500  data: 0.0001  max mem: 2170
[2024-01-20 15:59:27 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8487 (0.8585)  acc1: 81.6609 (81.2947)  acc5: 95.2542 (95.3896)  time: 0.2494  data: 0.0001  max mem: 2170
[2024-01-20 15:59:29 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8302 (0.8578)  acc1: 81.4433 (81.2987)  acc5: 95.3020 (95.4264)  time: 0.2505  data: 0.0001  max mem: 2170
[2024-01-20 15:59:32 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8507 (0.8560)  acc1: 81.0811 (81.2846)  acc5: 95.8904 (95.4596)  time: 0.2510  data: 0.0001  max mem: 2170
[2024-01-20 15:59:34 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8498 (0.8569)  acc1: 81.0169 (81.2664)  acc5: 95.5631 (95.4622)  time: 0.2507  data: 0.0002  max mem: 2170
[2024-01-20 15:59:37 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8505 (0.8590)  acc1: 80.8874 (81.2069)  acc5: 95.2862 (95.4625)  time: 0.2511  data: 0.0001  max mem: 2170
[2024-01-20 15:59:38 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8543 (0.8574)  acc1: 80.8874 (81.2550)  acc5: 95.5479 (95.4502)  time: 0.2513  data: 0.0001  max mem: 2170
[2024-01-20 15:59:38 root] (utils.py 307): INFO Test: Total time: 0:00:47 (0.2840 s / it)
[2024-01-20 15:59:38 root] (engine.py 118): INFO * Acc@1 81.255 Acc@5 95.450 loss 0.857 flops 12.940
[2024-01-20 15:59:38 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.3%
[2024-01-20 16:00:16 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:00:20 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 16:00:21 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 16:00:23 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 16:00:27 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:19  flops: 12.9405 (12.9405)  loss: 0.9235 (0.9235)  acc1: 80.4795 (80.4795)  acc5: 93.1507 (93.1507)  time: 4.7896  data: 1.2472  max mem: 2126
[2024-01-20 16:00:30 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:50  flops: 12.9405 (12.9405)  loss: 0.8162 (0.8357)  acc1: 82.1549 (81.9389)  acc5: 95.5631 (95.0602)  time: 0.7065  data: 0.1135  max mem: 2169
[2024-01-20 16:00:33 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:11  flops: 12.9405 (12.9405)  loss: 0.8524 (0.8585)  acc1: 81.4189 (81.3916)  acc5: 95.2703 (95.0000)  time: 0.2713  data: 0.0001  max mem: 2169
[2024-01-20 16:00:35 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8568 (0.8569)  acc1: 80.6780 (81.3918)  acc5: 95.2381 (95.2110)  time: 0.2446  data: 0.0001  max mem: 2169
[2024-01-20 16:00:43 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:00:47 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 16:00:48 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 16:00:50 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 16:00:55 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:18  flops: 12.9405 (12.9405)  loss: 0.8856 (0.8856)  acc1: 81.1644 (81.1644)  acc5: 93.8356 (93.8356)  time: 4.7803  data: 1.0466  max mem: 2126
[2024-01-20 16:00:58 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:50  flops: 12.9405 (12.9405)  loss: 0.8100 (0.8251)  acc1: 82.9352 (82.5563)  acc5: 95.2703 (95.0602)  time: 0.7069  data: 0.0952  max mem: 2169
[2024-01-20 16:01:00 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:11  flops: 12.9405 (12.9405)  loss: 0.8426 (0.8469)  acc1: 81.1448 (81.7799)  acc5: 94.8454 (95.0324)  time: 0.2722  data: 0.0001  max mem: 2169
[2024-01-20 16:01:03 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:56  flops: 12.9405 (12.9405)  loss: 0.8491 (0.8478)  acc1: 80.7432 (81.5452)  acc5: 95.2055 (95.1671)  time: 0.2455  data: 0.0001  max mem: 2169
[2024-01-20 16:01:05 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:46  flops: 12.9405 (12.9405)  loss: 0.8491 (0.8549)  acc1: 81.7568 (81.5097)  acc5: 95.2703 (95.1995)  time: 0.2461  data: 0.0001  max mem: 2169
[2024-01-20 16:01:08 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8475 (0.8476)  acc1: 80.5461 (81.5810)  acc5: 95.8763 (95.3753)  time: 0.2399  data: 0.0001  max mem: 2169
[2024-01-20 16:01:10 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8529 (0.8539)  acc1: 80.6780 (81.4831)  acc5: 95.2381 (95.3012)  time: 0.2335  data: 0.0001  max mem: 2169
[2024-01-20 16:01:12 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8770 (0.8551)  acc1: 80.9524 (81.4383)  acc5: 94.8980 (95.2902)  time: 0.2338  data: 0.0001  max mem: 2169
[2024-01-20 16:01:15 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8746 (0.8589)  acc1: 81.0345 (81.3603)  acc5: 95.5782 (95.3233)  time: 0.2344  data: 0.0001  max mem: 2169
[2024-01-20 16:01:17 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8873 (0.8664)  acc1: 81.1448 (81.2302)  acc5: 95.2542 (95.2665)  time: 0.2395  data: 0.0001  max mem: 2170
[2024-01-20 16:01:19 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8798 (0.8672)  acc1: 81.0169 (81.2067)  acc5: 94.6309 (95.2463)  time: 0.2401  data: 0.0001  max mem: 2170
[2024-01-20 16:01:22 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8834 (0.8697)  acc1: 80.7432 (81.1695)  acc5: 94.6309 (95.1983)  time: 0.2345  data: 0.0001  max mem: 2170
[2024-01-20 16:01:24 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8526 (0.8661)  acc1: 81.2081 (81.2133)  acc5: 94.9324 (95.2521)  time: 0.2336  data: 0.0001  max mem: 2170
[2024-01-20 16:01:26 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8424 (0.8646)  acc1: 81.2287 (81.2340)  acc5: 95.5932 (95.2916)  time: 0.2345  data: 0.0001  max mem: 2170
[2024-01-20 16:01:29 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8505 (0.8634)  acc1: 81.0169 (81.2292)  acc5: 95.5932 (95.3296)  time: 0.2353  data: 0.0001  max mem: 2170
[2024-01-20 16:01:31 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8505 (0.8645)  acc1: 80.4714 (81.2147)  acc5: 95.5631 (95.3340)  time: 0.2352  data: 0.0002  max mem: 2170
[2024-01-20 16:01:34 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8718 (0.8659)  acc1: 81.0811 (81.1921)  acc5: 95.5017 (95.3297)  time: 0.2356  data: 0.0002  max mem: 2170
[2024-01-20 16:01:35 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8718 (0.8647)  acc1: 81.0811 (81.2203)  acc5: 94.9495 (95.3137)  time: 0.2362  data: 0.0002  max mem: 2170
[2024-01-20 16:01:35 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.2684 s / it)
[2024-01-20 16:01:35 root] (engine.py 118): INFO * Acc@1 81.220 Acc@5 95.314 loss 0.865 flops 12.940
[2024-01-20 16:01:35 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-20 16:01:46 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:01:49 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 16:01:51 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 16:01:52 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 16:01:57 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:16  flops: 12.9405 (12.9405)  loss: 0.8947 (0.8947)  acc1: 80.8219 (80.8219)  acc5: 93.1507 (93.1507)  time: 4.7675  data: 0.8395  max mem: 2126
[2024-01-20 16:02:00 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:50  flops: 12.9405 (12.9405)  loss: 0.8021 (0.8252)  acc1: 82.1549 (82.0932)  acc5: 95.5782 (95.3998)  time: 0.7059  data: 0.0764  max mem: 2169
[2024-01-20 16:02:03 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:11  flops: 12.9405 (12.9405)  loss: 0.8521 (0.8499)  acc1: 81.9728 (81.6828)  acc5: 95.1890 (95.2265)  time: 0.2717  data: 0.0001  max mem: 2169
[2024-01-20 16:02:05 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8600 (0.8480)  acc1: 81.1448 (81.6000)  acc5: 95.1724 (95.3534)  time: 0.2443  data: 0.0001  max mem: 2169
[2024-01-20 16:02:07 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:46  flops: 12.9405 (12.9405)  loss: 0.8600 (0.8559)  acc1: 82.0946 (81.5925)  acc5: 95.2381 (95.3485)  time: 0.2451  data: 0.0001  max mem: 2169
[2024-01-20 16:02:10 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8484 (0.8494)  acc1: 82.0946 (81.6875)  acc5: 95.9044 (95.4618)  time: 0.2399  data: 0.0001  max mem: 2169
[2024-01-20 16:02:12 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8759 (0.8573)  acc1: 81.0345 (81.5054)  acc5: 95.2381 (95.3513)  time: 0.2340  data: 0.0001  max mem: 2169
[2024-01-20 16:02:14 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8897 (0.8576)  acc1: 81.0345 (81.5004)  acc5: 94.5946 (95.3333)  time: 0.2342  data: 0.0001  max mem: 2169
[2024-01-20 16:02:17 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8671 (0.8616)  acc1: 80.8725 (81.3561)  acc5: 94.9153 (95.3107)  time: 0.2347  data: 0.0001  max mem: 2169
[2024-01-20 16:02:19 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8840 (0.8679)  acc1: 80.0000 (81.2115)  acc5: 94.9153 (95.2665)  time: 0.2397  data: 0.0001  max mem: 2170
[2024-01-20 16:02:22 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8889 (0.8692)  acc1: 80.3390 (81.1597)  acc5: 94.9324 (95.2698)  time: 0.2402  data: 0.0001  max mem: 2170
[2024-01-20 16:02:24 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8893 (0.8715)  acc1: 80.3390 (81.1298)  acc5: 94.8980 (95.2320)  time: 0.2347  data: 0.0001  max mem: 2170
[2024-01-20 16:02:26 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8739 (0.8693)  acc1: 80.8874 (81.1713)  acc5: 94.9153 (95.2521)  time: 0.2342  data: 0.0001  max mem: 2170
[2024-01-20 16:02:29 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8409 (0.8678)  acc1: 80.8874 (81.1847)  acc5: 95.5017 (95.2839)  time: 0.2352  data: 0.0001  max mem: 2170
[2024-01-20 16:02:31 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8569 (0.8667)  acc1: 80.7432 (81.1907)  acc5: 95.8904 (95.3175)  time: 0.2357  data: 0.0001  max mem: 2170
[2024-01-20 16:02:33 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8624 (0.8685)  acc1: 81.0169 (81.1540)  acc5: 95.9044 (95.3250)  time: 0.2353  data: 0.0002  max mem: 2170
[2024-01-20 16:02:36 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8678 (0.8704)  acc1: 80.7432 (81.1183)  acc5: 95.2542 (95.3107)  time: 0.2358  data: 0.0002  max mem: 2170
[2024-01-20 16:02:37 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8631 (0.8688)  acc1: 81.0811 (81.1429)  acc5: 94.8980 (95.2995)  time: 0.2362  data: 0.0001  max mem: 2170
[2024-01-20 16:02:37 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.2684 s / it)
[2024-01-20 16:02:37 root] (engine.py 118): INFO * Acc@1 81.143 Acc@5 95.299 loss 0.869 flops 12.940
[2024-01-20 16:02:37 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.1%
[2024-01-20 16:03:01 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:03:05 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 16:03:06 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 16:03:08 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 16:03:13 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:38  flops: 12.9405 (12.9405)  loss: 0.8977 (0.8977)  acc1: 80.4795 (80.4795)  acc5: 93.4931 (93.4931)  time: 4.9008  data: 1.1646  max mem: 2126
[2024-01-20 16:03:16 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 12.9405 (12.9405)  loss: 0.8130 (0.8215)  acc1: 81.7869 (82.1241)  acc5: 94.5578 (94.9367)  time: 0.7171  data: 0.1060  max mem: 2169
[2024-01-20 16:03:18 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 0.8553 (0.8470)  acc1: 81.4815 (81.6019)  acc5: 94.9495 (95.0809)  time: 0.2718  data: 0.0001  max mem: 2169
[2024-01-20 16:03:21 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:56  flops: 12.9405 (12.9405)  loss: 0.8553 (0.8470)  acc1: 81.2925 (81.7096)  acc5: 95.1724 (95.2548)  time: 0.2455  data: 0.0001  max mem: 2169
[2024-01-20 16:03:23 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8431 (0.8550)  acc1: 81.9113 (81.6338)  acc5: 95.2542 (95.2574)  time: 0.2455  data: 0.0001  max mem: 2169
[2024-01-20 16:03:26 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8628 (0.8469)  acc1: 81.9113 (81.7940)  acc5: 95.6081 (95.4552)  time: 0.2393  data: 0.0001  max mem: 2169
[2024-01-20 16:03:28 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8734 (0.8558)  acc1: 80.3448 (81.5388)  acc5: 95.5326 (95.3624)  time: 0.2334  data: 0.0001  max mem: 2169
[2024-01-20 16:03:30 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8851 (0.8567)  acc1: 80.5369 (81.5387)  acc5: 94.8454 (95.3476)  time: 0.2337  data: 0.0001  max mem: 2169
[2024-01-20 16:03:33 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8673 (0.8602)  acc1: 81.0169 (81.4315)  acc5: 95.2862 (95.3526)  time: 0.2343  data: 0.0001  max mem: 2169
[2024-01-20 16:03:35 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8685 (0.8668)  acc1: 80.1347 (81.3160)  acc5: 95.1557 (95.2889)  time: 0.2398  data: 0.0001  max mem: 2170
[2024-01-20 16:03:42 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:03:46 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 16:03:47 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 16:03:48 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 16:03:53 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:23  flops: 12.9405 (12.9405)  loss: 0.8970 (0.8970)  acc1: 81.1644 (81.1644)  acc5: 93.4931 (93.4931)  time: 4.8100  data: 1.0661  max mem: 2126
[2024-01-20 16:03:56 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:51  flops: 12.9405 (12.9405)  loss: 0.8264 (0.8272)  acc1: 81.9113 (82.1550)  acc5: 95.5326 (95.0911)  time: 0.7086  data: 0.0970  max mem: 2169
[2024-01-20 16:03:59 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:11  flops: 12.9405 (12.9405)  loss: 0.8403 (0.8513)  acc1: 81.4815 (81.6181)  acc5: 95.2703 (95.0647)  time: 0.2710  data: 0.0001  max mem: 2169
[2024-01-20 16:04:01 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8600 (0.8503)  acc1: 81.1448 (81.5890)  acc5: 95.2218 (95.2438)  time: 0.2437  data: 0.0001  max mem: 2169
[2024-01-20 16:04:04 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:46  flops: 12.9405 (12.9405)  loss: 0.8615 (0.8569)  acc1: 81.9113 (81.5097)  acc5: 95.2542 (95.2491)  time: 0.2445  data: 0.0001  max mem: 2169
[2024-01-20 16:04:06 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8538 (0.8494)  acc1: 81.7869 (81.6742)  acc5: 95.9322 (95.4285)  time: 0.2397  data: 0.0001  max mem: 2169
[2024-01-20 16:04:08 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8617 (0.8566)  acc1: 81.4815 (81.5277)  acc5: 95.5479 (95.3513)  time: 0.2338  data: 0.0001  max mem: 2169
[2024-01-20 16:04:11 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8836 (0.8569)  acc1: 81.0169 (81.5387)  acc5: 94.9495 (95.3189)  time: 0.2342  data: 0.0001  max mem: 2169
[2024-01-20 16:04:13 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8836 (0.8599)  acc1: 80.7432 (81.3686)  acc5: 95.5932 (95.3526)  time: 0.2349  data: 0.0001  max mem: 2169
[2024-01-20 16:04:15 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8935 (0.8672)  acc1: 80.6122 (81.2339)  acc5: 95.2218 (95.2964)  time: 0.2402  data: 0.0001  max mem: 2170
[2024-01-20 16:04:18 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8832 (0.8683)  acc1: 80.8081 (81.2370)  acc5: 94.8097 (95.2563)  time: 0.2406  data: 0.0001  max mem: 2170
[2024-01-20 16:04:20 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8908 (0.8711)  acc1: 80.9524 (81.2429)  acc5: 94.9153 (95.2167)  time: 0.2348  data: 0.0001  max mem: 2170
[2024-01-20 16:04:22 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8773 (0.8686)  acc1: 81.4433 (81.3003)  acc5: 94.9153 (95.2325)  time: 0.2346  data: 0.0001  max mem: 2170
[2024-01-20 16:04:25 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8472 (0.8671)  acc1: 81.4433 (81.3039)  acc5: 95.5932 (95.2683)  time: 0.2353  data: 0.0001  max mem: 2170
[2024-01-20 16:04:27 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8650 (0.8660)  acc1: 80.1347 (81.2533)  acc5: 95.5932 (95.3224)  time: 0.2353  data: 0.0001  max mem: 2170
[2024-01-20 16:04:30 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8825 (0.8676)  acc1: 80.1347 (81.2260)  acc5: 95.5479 (95.3160)  time: 0.2347  data: 0.0001  max mem: 2170
[2024-01-20 16:04:32 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8891 (0.8697)  acc1: 81.0811 (81.1964)  acc5: 95.2542 (95.3107)  time: 0.2352  data: 0.0002  max mem: 2170
[2024-01-20 16:04:33 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8599 (0.8680)  acc1: 81.1448 (81.2326)  acc5: 95.2703 (95.3015)  time: 0.2360  data: 0.0001  max mem: 2170
[2024-01-20 16:04:33 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.2685 s / it)
[2024-01-20 16:04:33 root] (engine.py 118): INFO * Acc@1 81.233 Acc@5 95.302 loss 0.868 flops 12.940
[2024-01-20 16:04:33 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-20 16:05:10 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:05:13 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 16:05:15 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 16:05:16 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 16:05:21 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:32  flops: 12.9405 (12.9405)  loss: 0.9022 (0.9022)  acc1: 80.4795 (80.4795)  acc5: 92.8082 (92.8082)  time: 4.8660  data: 1.3701  max mem: 2126
[2024-01-20 16:05:24 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:51  flops: 12.9405 (12.9405)  loss: 0.8258 (0.8284)  acc1: 82.4742 (82.4637)  acc5: 94.9324 (94.9058)  time: 0.7088  data: 0.1247  max mem: 2169
[2024-01-20 16:05:32 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:05:35 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 16:05:37 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 16:05:39 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 16:05:43 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:18  flops: 12.9405 (12.9405)  loss: 0.8801 (0.8801)  acc1: 80.1370 (80.1370)  acc5: 93.8356 (93.8356)  time: 4.7824  data: 1.3966  max mem: 2126
[2024-01-20 16:05:46 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:50  flops: 12.9405 (12.9405)  loss: 0.8682 (0.8672)  acc1: 81.4815 (81.1362)  acc5: 94.9324 (94.8750)  time: 0.7030  data: 0.1271  max mem: 2169
[2024-01-20 16:05:49 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:10  flops: 12.9405 (12.9405)  loss: 0.8836 (0.8896)  acc1: 80.4054 (80.8252)  acc5: 94.9324 (94.9029)  time: 0.2673  data: 0.0001  max mem: 2169
[2024-01-20 16:05:51 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8656 (0.8858)  acc1: 80.4054 (80.7562)  acc5: 95.1724 (95.1342)  time: 0.2397  data: 0.0001  max mem: 2169
[2024-01-20 16:05:53 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:46  flops: 12.9405 (12.9405)  loss: 0.8777 (0.8945)  acc1: 80.4795 (80.8062)  acc5: 94.9664 (95.0339)  time: 0.2405  data: 0.0001  max mem: 2169
[2024-01-20 16:05:56 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:39  flops: 12.9405 (12.9405)  loss: 0.8777 (0.8883)  acc1: 80.7432 (80.8158)  acc5: 95.2218 (95.1491)  time: 0.2347  data: 0.0001  max mem: 2169
[2024-01-20 16:05:58 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8936 (0.8929)  acc1: 80.6780 (80.6981)  acc5: 95.1724 (95.1008)  time: 0.2277  data: 0.0001  max mem: 2169
[2024-01-20 16:06:00 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.9216 (0.8940)  acc1: 80.0676 (80.6780)  acc5: 94.8980 (95.0559)  time: 0.2281  data: 0.0001  max mem: 2169
[2024-01-20 16:06:03 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.9200 (0.8974)  acc1: 80.0000 (80.5515)  acc5: 94.5763 (95.0425)  time: 0.2286  data: 0.0001  max mem: 2169
[2024-01-20 16:06:05 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.9200 (0.9058)  acc1: 79.1246 (80.3648)  acc5: 94.5578 (94.9681)  time: 0.2339  data: 0.0001  max mem: 2170
[2024-01-20 16:06:07 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.9289 (0.9078)  acc1: 79.9320 (80.3400)  acc5: 94.5578 (94.9271)  time: 0.2348  data: 0.0001  max mem: 2170
[2024-01-20 16:06:10 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.9245 (0.9107)  acc1: 79.6552 (80.3254)  acc5: 94.2373 (94.8527)  time: 0.2297  data: 0.0001  max mem: 2170
[2024-01-20 16:06:18 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:06:22 root] (main_tome.py 284): INFO Creating model: vit_deit_base_patch16_224
[2024-01-20 16:06:23 timm.models.helpers] (helpers.py 176): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-20 16:06:25 root] (main_tome.py 368): INFO number of params: 86567656
[2024-01-20 16:06:29 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:13  flops: 12.9405 (12.9405)  loss: 0.8831 (0.8831)  acc1: 81.5069 (81.5069)  acc5: 93.8356 (93.8356)  time: 4.7506  data: 1.0528  max mem: 2126
[2024-01-20 16:06:32 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:49  flops: 12.9405 (12.9405)  loss: 0.8175 (0.8281)  acc1: 81.8182 (82.4637)  acc5: 95.1890 (95.2763)  time: 0.6980  data: 0.0958  max mem: 2169
[2024-01-20 16:06:35 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:10  flops: 12.9405 (12.9405)  loss: 0.8510 (0.8473)  acc1: 81.8182 (81.9903)  acc5: 95.2381 (95.3074)  time: 0.2651  data: 0.0001  max mem: 2169
[2024-01-20 16:06:37 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:54  flops: 12.9405 (12.9405)  loss: 0.8485 (0.8420)  acc1: 81.7568 (81.9288)  acc5: 95.6081 (95.4521)  time: 0.2378  data: 0.0001  max mem: 2169
[2024-01-20 16:06:39 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:45  flops: 12.9405 (12.9405)  loss: 0.8478 (0.8504)  acc1: 81.0811 (81.7828)  acc5: 95.6081 (95.4064)  time: 0.2392  data: 0.0001  max mem: 2169
[2024-01-20 16:06:42 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:39  flops: 12.9405 (12.9405)  loss: 0.8478 (0.8438)  acc1: 81.0811 (81.8073)  acc5: 95.6081 (95.6082)  time: 0.2340  data: 0.0001  max mem: 2169
[2024-01-20 16:06:44 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8702 (0.8507)  acc1: 81.0811 (81.6446)  acc5: 95.5326 (95.5740)  time: 0.2276  data: 0.0001  max mem: 2169
[2024-01-20 16:06:46 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8702 (0.8516)  acc1: 81.4189 (81.6726)  acc5: 95.2381 (95.4958)  time: 0.2282  data: 0.0001  max mem: 2169
[2024-01-20 16:06:48 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8611 (0.8555)  acc1: 81.4189 (81.5824)  acc5: 94.8980 (95.4700)  time: 0.2291  data: 0.0001  max mem: 2169
[2024-01-20 16:06:51 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8710 (0.8621)  acc1: 81.2925 (81.4503)  acc5: 94.9153 (95.4456)  time: 0.2345  data: 0.0001  max mem: 2170
[2024-01-20 16:06:53 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8795 (0.8640)  acc1: 80.8081 (81.3747)  acc5: 95.3020 (95.4142)  time: 0.2344  data: 0.0001  max mem: 2170
[2024-01-20 16:06:55 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8899 (0.8672)  acc1: 80.6122 (81.3408)  acc5: 94.9153 (95.3665)  time: 0.2284  data: 0.0001  max mem: 2170
[2024-01-20 16:06:58 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8659 (0.8641)  acc1: 81.4433 (81.4238)  acc5: 94.9153 (95.4065)  time: 0.2289  data: 0.0001  max mem: 2170
[2024-01-20 16:07:00 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8492 (0.8632)  acc1: 81.4433 (81.4024)  acc5: 95.6229 (95.4316)  time: 0.2303  data: 0.0001  max mem: 2170
[2024-01-20 16:07:02 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8539 (0.8614)  acc1: 80.7432 (81.4050)  acc5: 95.5932 (95.4475)  time: 0.2303  data: 0.0001  max mem: 2170
[2024-01-20 16:07:05 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8614 (0.8626)  acc1: 81.2925 (81.4059)  acc5: 95.5631 (95.4330)  time: 0.2292  data: 0.0002  max mem: 2170
[2024-01-20 16:07:07 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8782 (0.8643)  acc1: 81.4189 (81.3735)  acc5: 95.2218 (95.4267)  time: 0.2290  data: 0.0001  max mem: 2170
[2024-01-20 16:07:08 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8720 (0.8628)  acc1: 81.4189 (81.3996)  acc5: 95.2055 (95.4115)  time: 0.2299  data: 0.0001  max mem: 2170
[2024-01-20 16:07:08 root] (utils.py 307): INFO Test: Total time: 0:00:43 (0.2624 s / it)
[2024-01-20 16:07:08 root] (engine.py 118): INFO * Acc@1 81.400 Acc@5 95.411 loss 0.863 flops 12.940
[2024-01-20 16:07:08 root] (main_tome.py 376): INFO Accuracy of the network on the 50000 test images: 81.4%
[2024-01-20 16:08:38 root] (main_tome.py 214): INFO Namespace(batch_size=300, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:08:42 root] (main_tome.py 284): INFO Creating model: vit_large_patch16_mae
[2024-01-20 16:13:17 root] (main_tome.py 215): INFO Namespace(batch_size=300, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:13:21 root] (main_tome.py 285): INFO Creating model: vit_large_patch16_mae
[2024-01-20 16:13:27 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 16:13:29 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:42  flops: 34.8324 (34.8324)  loss: 0.7759 (0.7759)  acc1: 83.9041 (83.9041)  acc5: 96.9178 (96.9178)  time: 1.6943  data: 0.0008  max mem: 3396
[2024-01-20 16:13:35 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:49  flops: 34.8324 (34.8324)  loss: 0.6886 (0.7086)  acc1: 85.9107 (85.7055)  acc5: 97.6190 (97.3140)  time: 0.6954  data: 0.0002  max mem: 3450
[2024-01-20 16:13:40 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:30  flops: 34.8324 (34.8324)  loss: 0.6886 (0.7112)  acc1: 85.1351 (85.3074)  acc5: 97.2696 (97.3948)  time: 0.5611  data: 0.0001  max mem: 3450
[2024-01-20 16:13:46 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:20  flops: 34.8324 (34.8324)  loss: 0.7128 (0.7089)  acc1: 84.9315 (85.3041)  acc5: 97.2881 (97.4247)  time: 0.5283  data: 0.0001  max mem: 3450
[2024-01-20 16:13:51 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:12  flops: 34.8324 (34.8324)  loss: 0.7174 (0.7197)  acc1: 84.9315 (85.1597)  acc5: 97.2881 (97.3349)  time: 0.5316  data: 0.0001  max mem: 3450
[2024-01-20 16:13:56 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:05  flops: 34.8324 (34.8324)  loss: 0.7164 (0.7177)  acc1: 84.4068 (85.1011)  acc5: 97.2881 (97.3915)  time: 0.5262  data: 0.0001  max mem: 3450
[2024-01-20 16:14:01 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:59  flops: 34.8324 (34.8324)  loss: 0.7164 (0.7206)  acc1: 84.7973 (85.1074)  acc5: 97.2881 (97.3500)  time: 0.5184  data: 0.0001  max mem: 3450
[2024-01-20 16:14:07 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:53  flops: 34.8324 (34.8324)  loss: 0.7422 (0.7247)  acc1: 84.6939 (85.0531)  acc5: 96.8966 (97.2793)  time: 0.5184  data: 0.0001  max mem: 3450
[2024-01-20 16:14:12 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:47  flops: 34.8324 (34.8324)  loss: 0.7548 (0.7282)  acc1: 84.3003 (84.9097)  acc5: 97.2973 (97.2887)  time: 0.5187  data: 0.0001  max mem: 3450
[2024-01-20 16:14:17 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:41  flops: 34.8324 (34.8324)  loss: 0.7636 (0.7338)  acc1: 83.2776 (84.8148)  acc5: 97.3064 (97.2808)  time: 0.5253  data: 0.0001  max mem: 3450
[2024-01-20 16:14:22 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:36  flops: 34.8324 (34.8324)  loss: 0.7636 (0.7342)  acc1: 84.5638 (84.8149)  acc5: 96.9900 (97.2687)  time: 0.5265  data: 0.0001  max mem: 3450
[2024-01-20 16:14:27 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:30  flops: 34.8324 (34.8324)  loss: 0.7232 (0.7359)  acc1: 84.5638 (84.8365)  acc5: 96.9388 (97.2138)  time: 0.5188  data: 0.0001  max mem: 3450
[2024-01-20 16:14:33 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:25  flops: 34.8324 (34.8324)  loss: 0.6991 (0.7314)  acc1: 86.0068 (84.9538)  acc5: 97.5779 (97.2585)  time: 0.5183  data: 0.0001  max mem: 3450
[2024-01-20 16:14:38 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:19  flops: 34.8324 (34.8324)  loss: 0.6991 (0.7297)  acc1: 86.0068 (84.9913)  acc5: 97.6271 (97.2662)  time: 0.5214  data: 0.0001  max mem: 3450
[2024-01-20 16:14:43 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:14  flops: 34.8324 (34.8324)  loss: 0.7057 (0.7281)  acc1: 84.5890 (85.0089)  acc5: 97.6027 (97.2892)  time: 0.5225  data: 0.0001  max mem: 3450
[2024-01-20 16:14:48 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:09  flops: 34.8324 (34.8324)  loss: 0.7354 (0.7289)  acc1: 84.7458 (85.0060)  acc5: 97.3064 (97.2859)  time: 0.5210  data: 0.0001  max mem: 3450
[2024-01-20 16:14:54 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 34.8324 (34.8324)  loss: 0.7376 (0.7303)  acc1: 84.4595 (84.9368)  acc5: 97.2881 (97.2800)  time: 0.5220  data: 0.0001  max mem: 3450
[2024-01-20 16:14:57 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 34.8324 (34.8324)  loss: 0.7119 (0.7289)  acc1: 84.4595 (84.9453)  acc5: 97.2881 (97.2730)  time: 0.5201  data: 0.0001  max mem: 3450
[2024-01-20 16:14:57 root] (utils.py 307): INFO Test: Total time: 0:01:29 (0.5339 s / it)
[2024-01-20 16:14:57 root] (engine.py 118): INFO * Acc@1 84.945 Acc@5 97.273 loss 0.729 flops 34.832
[2024-01-20 16:14:57 root] (main_tome.py 377): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-01-20 16:15:25 root] (main_tome.py 215): INFO Namespace(batch_size=300, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:15:29 root] (main_tome.py 285): INFO Creating model: vit_large_patch16_mae
[2024-01-20 16:15:35 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 16:15:37 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:18  flops: 45.6860 (45.6860)  loss: 0.7490 (0.7490)  acc1: 84.5890 (84.5890)  acc5: 96.2329 (96.2329)  time: 1.9066  data: 0.0008  max mem: 3396
[2024-01-20 16:15:45 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:14  flops: 45.6860 (45.6860)  loss: 0.6269 (0.6555)  acc1: 86.1487 (86.2612)  acc5: 97.9592 (97.6227)  time: 0.8573  data: 0.0002  max mem: 3450
[2024-01-20 16:15:52 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:53  flops: 45.6860 (45.6860)  loss: 0.6296 (0.6605)  acc1: 86.0544 (85.9547)  acc5: 97.6351 (97.7346)  time: 0.7161  data: 0.0001  max mem: 3450
[2024-01-20 16:15:59 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:41  flops: 45.6860 (45.6860)  loss: 0.6315 (0.6539)  acc1: 85.6655 (85.9288)  acc5: 97.9522 (97.8192)  time: 0.6805  data: 0.0001  max mem: 3450
[2024-01-20 16:16:05 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:32  flops: 45.6860 (45.6860)  loss: 0.6695 (0.6654)  acc1: 84.9829 (85.7308)  acc5: 97.6109 (97.6328)  time: 0.6828  data: 0.0001  max mem: 3450
[2024-01-20 16:16:12 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:23  flops: 45.6860 (45.6860)  loss: 0.6695 (0.6606)  acc1: 85.3242 (85.7666)  acc5: 97.2973 (97.6444)  time: 0.6773  data: 0.0001  max mem: 3450
[2024-01-20 16:16:19 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:15  flops: 45.6860 (45.6860)  loss: 0.6621 (0.6642)  acc1: 85.3242 (85.7533)  acc5: 97.2789 (97.5838)  time: 0.6694  data: 0.0001  max mem: 3450
[2024-01-20 16:16:26 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:08  flops: 45.6860 (45.6860)  loss: 0.6711 (0.6691)  acc1: 85.1724 (85.7081)  acc5: 96.9072 (97.4849)  time: 0.6712  data: 0.0001  max mem: 3450
[2024-01-20 16:16:32 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:00  flops: 45.6860 (45.6860)  loss: 0.6711 (0.6717)  acc1: 85.1724 (85.6850)  acc5: 97.6271 (97.4982)  time: 0.6733  data: 0.0001  max mem: 3450
[2024-01-20 16:16:39 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:53  flops: 45.6860 (45.6860)  loss: 0.7058 (0.6767)  acc1: 84.7458 (85.5757)  acc5: 97.6431 (97.5008)  time: 0.6801  data: 0.0001  max mem: 3450
[2024-01-20 16:16:46 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:46  flops: 45.6860 (45.6860)  loss: 0.6930 (0.6776)  acc1: 85.1211 (85.5909)  acc5: 97.6431 (97.4871)  time: 0.6818  data: 0.0001  max mem: 3450
[2024-01-20 16:16:53 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:39  flops: 45.6860 (45.6860)  loss: 0.6930 (0.6793)  acc1: 85.7627 (85.5981)  acc5: 97.6271 (97.4554)  time: 0.6738  data: 0.0001  max mem: 3450
[2024-01-20 16:16:59 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:32  flops: 45.6860 (45.6860)  loss: 0.6387 (0.6753)  acc1: 86.0068 (85.6806)  acc5: 97.9239 (97.4858)  time: 0.6721  data: 0.0001  max mem: 3450
[2024-01-20 16:17:06 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:25  flops: 45.6860 (45.6860)  loss: 0.6387 (0.6737)  acc1: 85.9107 (85.7350)  acc5: 97.9239 (97.5072)  time: 0.6749  data: 0.0001  max mem: 3450
[2024-01-20 16:17:13 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:18  flops: 45.6860 (45.6860)  loss: 0.6412 (0.6718)  acc1: 85.4237 (85.7335)  acc5: 97.9661 (97.5372)  time: 0.6758  data: 0.0001  max mem: 3450
[2024-01-20 16:17:20 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:11  flops: 45.6860 (45.6860)  loss: 0.6696 (0.6734)  acc1: 85.4730 (85.7480)  acc5: 97.6271 (97.5242)  time: 0.6736  data: 0.0001  max mem: 3450
[2024-01-20 16:17:26 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:04  flops: 45.6860 (45.6860)  loss: 0.7032 (0.6753)  acc1: 85.3242 (85.6812)  acc5: 97.2881 (97.5099)  time: 0.6746  data: 0.0001  max mem: 3450
[2024-01-20 16:17:30 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 45.6860 (45.6860)  loss: 0.6576 (0.6739)  acc1: 84.8485 (85.6968)  acc5: 97.2881 (97.5072)  time: 0.6703  data: 0.0001  max mem: 3450
[2024-01-20 16:17:30 root] (utils.py 307): INFO Test: Total time: 0:01:54 (0.6873 s / it)
[2024-01-20 16:17:30 root] (engine.py 118): INFO * Acc@1 85.697 Acc@5 97.507 loss 0.674 flops 45.686
[2024-01-20 16:17:30 root] (main_tome.py 377): INFO Accuracy of the network on the 50000 test images: 85.7%
[2024-01-20 16:18:34 root] (main_tome.py 215): INFO Namespace(batch_size=300, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:18:38 root] (main_tome.py 285): INFO Creating model: vit_large_patch16_mae
[2024-01-20 16:18:44 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 16:18:46 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:56  flops: 39.7595 (39.7595)  loss: 0.7358 (0.7358)  acc1: 85.2740 (85.2740)  acc5: 96.2329 (96.2329)  time: 1.7767  data: 0.0008  max mem: 3396
[2024-01-20 16:18:53 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:01  flops: 39.7595 (39.7595)  loss: 0.6510 (0.6712)  acc1: 86.0068 (86.2612)  acc5: 97.6190 (97.5919)  time: 0.7718  data: 0.0002  max mem: 3450
[2024-01-20 16:18:59 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:41  flops: 39.7595 (39.7595)  loss: 0.6510 (0.6782)  acc1: 85.9589 (85.9547)  acc5: 97.6431 (97.6375)  time: 0.6360  data: 0.0001  max mem: 3450
[2024-01-20 16:19:05 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:30  flops: 39.7595 (39.7595)  loss: 0.6682 (0.6737)  acc1: 85.9589 (85.9507)  acc5: 97.6431 (97.7205)  time: 0.6005  data: 0.0001  max mem: 3450
[2024-01-20 16:19:11 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:22  flops: 39.7595 (39.7595)  loss: 0.6900 (0.6871)  acc1: 85.2349 (85.6895)  acc5: 97.6271 (97.5832)  time: 0.6014  data: 0.0001  max mem: 3450
[2024-01-20 16:19:17 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:14  flops: 39.7595 (39.7595)  loss: 0.6881 (0.6833)  acc1: 84.7973 (85.6601)  acc5: 97.6109 (97.6178)  time: 0.5950  data: 0.0001  max mem: 3450
[2024-01-20 16:19:23 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:07  flops: 39.7595 (39.7595)  loss: 0.6785 (0.6863)  acc1: 85.2234 (85.6363)  acc5: 97.2789 (97.5615)  time: 0.5871  data: 0.0001  max mem: 3450
[2024-01-20 16:19:29 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:00  flops: 39.7595 (39.7595)  loss: 0.7028 (0.6916)  acc1: 84.9829 (85.5408)  acc5: 96.9388 (97.4610)  time: 0.5888  data: 0.0001  max mem: 3450
[2024-01-20 16:19:34 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:53  flops: 39.7595 (39.7595)  loss: 0.7143 (0.6949)  acc1: 84.7458 (85.4503)  acc5: 97.6190 (97.4521)  time: 0.5907  data: 0.0001  max mem: 3450
[2024-01-20 16:19:40 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:47  flops: 39.7595 (39.7595)  loss: 0.7307 (0.7003)  acc1: 84.4828 (85.3258)  acc5: 97.6190 (97.4374)  time: 0.5976  data: 0.0001  max mem: 3450
[2024-01-20 16:19:46 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:41  flops: 39.7595 (39.7595)  loss: 0.7005 (0.7009)  acc1: 84.7973 (85.2953)  acc5: 97.3064 (97.4165)  time: 0.5988  data: 0.0001  max mem: 3450
[2024-01-20 16:19:52 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:34  flops: 39.7595 (39.7595)  loss: 0.7005 (0.7022)  acc1: 85.2349 (85.3014)  acc5: 97.5862 (97.4004)  time: 0.5906  data: 0.0001  max mem: 3450
[2024-01-20 16:19:58 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:28  flops: 39.7595 (39.7595)  loss: 0.6719 (0.6980)  acc1: 86.0068 (85.3860)  acc5: 97.5862 (97.4381)  time: 0.5892  data: 0.0001  max mem: 3450
[2024-01-20 16:20:04 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:22  flops: 39.7595 (39.7595)  loss: 0.6552 (0.6965)  acc1: 85.7143 (85.4111)  acc5: 97.9661 (97.4683)  time: 0.5915  data: 0.0001  max mem: 3450
[2024-01-20 16:20:10 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:16  flops: 39.7595 (39.7595)  loss: 0.6738 (0.6947)  acc1: 85.0847 (85.4061)  acc5: 97.9661 (97.4915)  time: 0.5925  data: 0.0001  max mem: 3450
[2024-01-20 16:20:16 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:10  flops: 39.7595 (39.7595)  loss: 0.6944 (0.6963)  acc1: 85.1351 (85.4040)  acc5: 97.2973 (97.4635)  time: 0.5909  data: 0.0002  max mem: 3450
[2024-01-20 16:20:22 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:04  flops: 39.7595 (39.7595)  loss: 0.7200 (0.6981)  acc1: 84.4595 (85.3375)  acc5: 97.2696 (97.4466)  time: 0.5918  data: 0.0002  max mem: 3450
[2024-01-20 16:20:26 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 39.7595 (39.7595)  loss: 0.6836 (0.6968)  acc1: 84.7973 (85.3567)  acc5: 97.2881 (97.4420)  time: 0.5888  data: 0.0001  max mem: 3450
[2024-01-20 16:20:26 root] (utils.py 307): INFO Test: Total time: 0:01:41 (0.6060 s / it)
[2024-01-20 16:20:26 root] (engine.py 118): INFO * Acc@1 85.357 Acc@5 97.442 loss 0.697 flops 39.760
[2024-01-20 16:20:26 root] (main_tome.py 377): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-01-20 16:21:51 root] (main_tome.py 215): INFO Namespace(batch_size=300, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:21:56 root] (main_tome.py 285): INFO Creating model: vit_large_patch16_mae
[2024-01-20 16:22:02 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 16:22:04 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:15  flops: 39.7595 (39.7595)  loss: 0.7723 (0.7723)  acc1: 84.2466 (84.2466)  acc5: 97.2603 (97.2603)  time: 1.8873  data: 0.0008  max mem: 3396
[2024-01-20 16:22:11 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:01  flops: 39.7595 (39.7595)  loss: 0.6719 (0.6894)  acc1: 85.4730 (85.4585)  acc5: 97.2973 (97.2214)  time: 0.7716  data: 0.0002  max mem: 3450
[2024-01-20 16:22:17 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:40  flops: 39.7595 (39.7595)  loss: 0.6719 (0.6931)  acc1: 85.1852 (85.4207)  acc5: 97.2973 (97.3463)  time: 0.6255  data: 0.0001  max mem: 3450
[2024-01-20 16:22:23 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:29  flops: 39.7595 (39.7595)  loss: 0.6693 (0.6878)  acc1: 85.0340 (85.4356)  acc5: 97.3064 (97.4904)  time: 0.5913  data: 0.0001  max mem: 3450
[2024-01-20 16:22:29 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:21  flops: 39.7595 (39.7595)  loss: 0.6917 (0.6999)  acc1: 85.0340 (85.2508)  acc5: 97.2696 (97.3266)  time: 0.5921  data: 0.0001  max mem: 3450
[2024-01-20 16:22:34 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:13  flops: 39.7595 (39.7595)  loss: 0.7037 (0.6981)  acc1: 84.5638 (85.1743)  acc5: 96.9492 (97.3849)  time: 0.5848  data: 0.0001  max mem: 3450
[2024-01-20 16:22:40 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:06  flops: 39.7595 (39.7595)  loss: 0.7086 (0.7006)  acc1: 84.1924 (85.0462)  acc5: 97.2973 (97.3778)  time: 0.5763  data: 0.0001  max mem: 3450
[2024-01-20 16:22:46 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:59  flops: 39.7595 (39.7595)  loss: 0.7154 (0.7052)  acc1: 84.5638 (85.0148)  acc5: 97.2789 (97.3080)  time: 0.5779  data: 0.0001  max mem: 3450
[2024-01-20 16:22:52 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:53  flops: 39.7595 (39.7595)  loss: 0.7222 (0.7085)  acc1: 84.6416 (84.9726)  acc5: 97.3064 (97.3180)  time: 0.5805  data: 0.0001  max mem: 3450
[2024-01-20 16:22:58 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:46  flops: 39.7595 (39.7595)  loss: 0.7402 (0.7134)  acc1: 84.4068 (84.8857)  acc5: 97.6190 (97.3367)  time: 0.5872  data: 0.0001  max mem: 3450
[2024-01-20 16:23:03 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:40  flops: 39.7595 (39.7595)  loss: 0.7324 (0.7144)  acc1: 84.8993 (84.9258)  acc5: 97.2973 (97.3191)  time: 0.5883  data: 0.0001  max mem: 3450
[2024-01-20 16:23:09 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:34  flops: 39.7595 (39.7595)  loss: 0.7324 (0.7165)  acc1: 85.4237 (84.9405)  acc5: 96.9799 (97.2719)  time: 0.5806  data: 0.0001  max mem: 3450
[2024-01-20 16:23:15 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:28  flops: 39.7595 (39.7595)  loss: 0.6833 (0.7124)  acc1: 85.8621 (85.0380)  acc5: 97.5945 (97.3174)  time: 0.5791  data: 0.0001  max mem: 3450
[2024-01-20 16:23:21 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:22  flops: 39.7595 (39.7595)  loss: 0.6775 (0.7109)  acc1: 85.9107 (85.1157)  acc5: 97.6271 (97.3258)  time: 0.5814  data: 0.0001  max mem: 3450
[2024-01-20 16:23:27 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:16  flops: 39.7595 (39.7595)  loss: 0.6889 (0.7095)  acc1: 85.0847 (85.1269)  acc5: 97.6271 (97.3639)  time: 0.5824  data: 0.0001  max mem: 3450
[2024-01-20 16:23:32 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:10  flops: 39.7595 (39.7595)  loss: 0.7184 (0.7108)  acc1: 84.5118 (85.1049)  acc5: 97.2789 (97.3421)  time: 0.5806  data: 0.0001  max mem: 3450
[2024-01-20 16:23:38 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:04  flops: 39.7595 (39.7595)  loss: 0.7287 (0.7124)  acc1: 84.1216 (85.0507)  acc5: 97.2318 (97.3391)  time: 0.5816  data: 0.0001  max mem: 3450
[2024-01-20 16:23:42 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 39.7595 (39.7595)  loss: 0.6893 (0.7106)  acc1: 85.1852 (85.0981)  acc5: 97.2881 (97.3361)  time: 0.5785  data: 0.0001  max mem: 3450
[2024-01-20 16:23:42 root] (utils.py 307): INFO Test: Total time: 0:01:39 (0.5955 s / it)
[2024-01-20 16:23:42 root] (engine.py 118): INFO * Acc@1 85.098 Acc@5 97.336 loss 0.711 flops 39.760
[2024-01-20 16:23:42 root] (main_tome.py 377): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-01-20 16:23:56 root] (main_tome.py 215): INFO Namespace(batch_size=300, epochs=300, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-20 16:24:00 root] (main_tome.py 285): INFO Creating model: vit_large_patch16_mae
[2024-01-20 16:24:07 root] (main_tome.py 369): INFO number of params: 304326632
[2024-01-20 16:24:09 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:20  flops: 39.7595 (39.7595)  loss: 0.7688 (0.7688)  acc1: 84.2466 (84.2466)  acc5: 95.5479 (95.5479)  time: 1.9201  data: 0.0008  max mem: 3396
[2024-01-20 16:24:15 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:01  flops: 39.7595 (39.7595)  loss: 0.6418 (0.6804)  acc1: 85.8108 (86.0451)  acc5: 97.6351 (97.4375)  time: 0.7745  data: 0.0002  max mem: 3450
[2024-01-20 16:24:21 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:40  flops: 39.7595 (39.7595)  loss: 0.6418 (0.6824)  acc1: 85.8108 (85.8576)  acc5: 97.6109 (97.6052)  time: 0.6247  data: 0.0001  max mem: 3450
[2024-01-20 16:24:27 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:29  flops: 39.7595 (39.7595)  loss: 0.6888 (0.6788)  acc1: 85.6164 (85.8959)  acc5: 97.6271 (97.6986)  time: 0.5907  data: 0.0001  max mem: 3450
[2024-01-20 16:24:33 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:21  flops: 39.7595 (39.7595)  loss: 0.6937 (0.6911)  acc1: 85.4730 (85.6398)  acc5: 97.2973 (97.5584)  time: 0.5938  data: 0.0001  max mem: 3450
[2024-01-20 16:24:39 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:13  flops: 39.7595 (39.7595)  loss: 0.6937 (0.6880)  acc1: 85.1351 (85.6268)  acc5: 97.2881 (97.5978)  time: 0.5876  data: 0.0001  max mem: 3450
[2024-01-20 16:24:44 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:06  flops: 39.7595 (39.7595)  loss: 0.6889 (0.6905)  acc1: 85.1351 (85.5083)  acc5: 97.3064 (97.5504)  time: 0.5788  data: 0.0001  max mem: 3450
[2024-01-20 16:24:50 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:59  flops: 39.7595 (39.7595)  loss: 0.6943 (0.6948)  acc1: 85.1724 (85.4978)  acc5: 97.2789 (97.4515)  time: 0.5800  data: 0.0001  max mem: 3450
[2024-01-20 16:24:56 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:53  flops: 39.7595 (39.7595)  loss: 0.7226 (0.6976)  acc1: 84.5118 (85.4084)  acc5: 97.2881 (97.4479)  time: 0.5815  data: 0.0001  max mem: 3450
[2024-01-20 16:25:02 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:46  flops: 39.7595 (39.7595)  loss: 0.7304 (0.7032)  acc1: 84.1379 (85.3034)  acc5: 97.3064 (97.4449)  time: 0.5881  data: 0.0001  max mem: 3450
[2024-01-20 16:25:08 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:40  flops: 39.7595 (39.7595)  loss: 0.7018 (0.7033)  acc1: 84.7973 (85.3188)  acc5: 97.3064 (97.4300)  time: 0.5894  data: 0.0001  max mem: 3450
[2024-01-20 16:25:14 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:34  flops: 39.7595 (39.7595)  loss: 0.7029 (0.7051)  acc1: 85.0847 (85.3228)  acc5: 97.6190 (97.3943)  time: 0.5816  data: 0.0001  max mem: 3450
[2024-01-20 16:25:19 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:28  flops: 39.7595 (39.7595)  loss: 0.6700 (0.7008)  acc1: 86.0068 (85.4112)  acc5: 97.6190 (97.4240)  time: 0.5805  data: 0.0001  max mem: 3450
[2024-01-20 16:25:25 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:22  flops: 39.7595 (39.7595)  loss: 0.6650 (0.6991)  acc1: 86.0544 (85.4500)  acc5: 97.9381 (97.4450)  time: 0.5823  data: 0.0001  max mem: 3450
[2024-01-20 16:25:31 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:16  flops: 39.7595 (39.7595)  loss: 0.6738 (0.6975)  acc1: 85.4237 (85.4350)  acc5: 97.6351 (97.4553)  time: 0.5830  data: 0.0001  max mem: 3450
[2024-01-20 16:25:37 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:10  flops: 39.7595 (39.7595)  loss: 0.6991 (0.6991)  acc1: 85.0340 (85.4265)  acc5: 97.2881 (97.4388)  time: 0.5813  data: 0.0002  max mem: 3450
[2024-01-20 16:25:43 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:04  flops: 39.7595 (39.7595)  loss: 0.7269 (0.7009)  acc1: 84.8485 (85.3733)  acc5: 97.2696 (97.4255)  time: 0.5817  data: 0.0001  max mem: 3450
[2024-01-20 16:25:46 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 39.7595 (39.7595)  loss: 0.6812 (0.6994)  acc1: 85.0847 (85.3934)  acc5: 97.2973 (97.4237)  time: 0.5786  data: 0.0001  max mem: 3450
[2024-01-20 16:25:46 root] (utils.py 307): INFO Test: Total time: 0:01:39 (0.5965 s / it)
[2024-01-20 16:25:46 root] (engine.py 118): INFO * Acc@1 85.393 Acc@5 97.424 loss 0.699 flops 39.760
[2024-01-20 16:25:46 root] (main_tome.py 377): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-01-21 08:29:28 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:29:32 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:29:39 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:29:41 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:32  flops: 21.8619 (21.8619)  loss: 2.0916 (2.0916)  acc1: 65.4110 (65.4110)  acc5: 83.5616 (83.5616)  time: 1.6337  data: 0.0008  max mem: 3396
[2024-01-21 08:29:45 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:26  flops: 21.8619 (21.8619)  loss: 1.8853 (1.8913)  acc1: 70.4467 (70.6391)  acc5: 86.8243 (86.1686)  time: 0.5495  data: 0.0002  max mem: 3450
[2024-01-21 08:29:49 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:08  flops: 21.8619 (21.8619)  loss: 1.8889 (1.8930)  acc1: 70.6081 (70.7605)  acc5: 86.0068 (86.1489)  time: 0.4061  data: 0.0002  max mem: 3450
[2024-01-21 08:29:53 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:59  flops: 21.8619 (21.8619)  loss: 1.8946 (1.9003)  acc1: 70.2703 (70.3671)  acc5: 85.7143 (86.0603)  time: 0.3720  data: 0.0002  max mem: 3450
[2024-01-21 08:29:57 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:53  flops: 21.8619 (21.8619)  loss: 1.9439 (1.9144)  acc1: 69.1781 (70.3360)  acc5: 84.9315 (85.7888)  time: 0.3746  data: 0.0002  max mem: 3450
[2024-01-21 08:30:00 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:47  flops: 21.8619 (21.8619)  loss: 1.9150 (1.9085)  acc1: 69.1525 (70.1956)  acc5: 85.2349 (85.8331)  time: 0.3683  data: 0.0002  max mem: 3450
[2024-01-21 08:30:04 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:42  flops: 21.8619 (21.8619)  loss: 1.8724 (1.9047)  acc1: 69.4915 (70.2984)  acc5: 86.2069 (86.0316)  time: 0.3587  data: 0.0002  max mem: 3450
[2024-01-21 08:30:07 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:38  flops: 21.8619 (21.8619)  loss: 1.8929 (1.9082)  acc1: 70.0680 (70.2066)  acc5: 86.0544 (85.9137)  time: 0.3587  data: 0.0004  max mem: 3450
[2024-01-21 08:30:11 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:33  flops: 21.8619 (21.8619)  loss: 1.9056 (1.9139)  acc1: 69.5946 (70.0624)  acc5: 85.0340 (85.7939)  time: 0.3603  data: 0.0004  max mem: 3450
[2024-01-21 08:30:15 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:29  flops: 21.8619 (21.8619)  loss: 1.9358 (1.9181)  acc1: 69.3603 (69.9653)  acc5: 85.8108 (85.8368)  time: 0.3674  data: 0.0002  max mem: 3450
[2024-01-21 08:30:18 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:25  flops: 21.8619 (21.8619)  loss: 1.9060 (1.9152)  acc1: 69.1525 (69.9859)  acc5: 86.3946 (85.8899)  time: 0.3678  data: 0.0002  max mem: 3450
[2024-01-21 08:30:22 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:21  flops: 21.8619 (21.8619)  loss: 1.9328 (1.9181)  acc1: 69.4631 (70.0859)  acc5: 85.3242 (85.8519)  time: 0.3597  data: 0.0002  max mem: 3450
[2024-01-21 08:30:26 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:17  flops: 21.8619 (21.8619)  loss: 1.9070 (1.9116)  acc1: 70.7904 (70.1518)  acc5: 85.4730 (85.9388)  time: 0.3594  data: 0.0002  max mem: 3450
[2024-01-21 08:30:29 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:14  flops: 21.8619 (21.8619)  loss: 1.8520 (1.9125)  acc1: 70.6081 (70.1277)  acc5: 85.5705 (85.9475)  time: 0.3616  data: 0.0002  max mem: 3450
[2024-01-21 08:30:33 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:10  flops: 21.8619 (21.8619)  loss: 1.8352 (1.9075)  acc1: 71.5753 (70.2706)  acc5: 85.8586 (86.0417)  time: 0.3623  data: 0.0002  max mem: 3450
[2024-01-21 08:30:36 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:06  flops: 21.8619 (21.8619)  loss: 1.9013 (1.9118)  acc1: 70.8475 (70.1716)  acc5: 85.8586 (85.9751)  time: 0.3607  data: 0.0002  max mem: 3450
[2024-01-21 08:30:40 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:02  flops: 21.8619 (21.8619)  loss: 1.9501 (1.9164)  acc1: 69.4915 (70.1035)  acc5: 84.8485 (85.8836)  time: 0.3614  data: 0.0002  max mem: 3450
[2024-01-21 08:30:42 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 21.8619 (21.8619)  loss: 1.8837 (1.9126)  acc1: 69.9659 (70.1696)  acc5: 85.4237 (85.9107)  time: 0.3615  data: 0.0002  max mem: 3450
[2024-01-21 08:30:42 root] (utils.py 307): INFO Test: Total time: 0:01:02 (0.3762 s / it)
[2024-01-21 08:30:42 root] (engine.py 118): INFO * Acc@1 70.170 Acc@5 85.911 loss 1.913 flops 21.862
[2024-01-21 08:30:42 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 70.2%
[2024-01-21 08:31:05 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:31:09 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:31:16 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:31:40 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:31:44 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:31:51 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:31:53 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:38  flops: 21.8619 (21.8619)  loss: 2.0987 (2.0987)  acc1: 65.4110 (65.4110)  acc5: 83.9041 (83.9041)  time: 1.6691  data: 0.0007  max mem: 3396
[2024-01-21 08:31:58 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:28  flops: 21.8619 (21.8619)  loss: 1.8675 (1.8909)  acc1: 71.4777 (71.0404)  acc5: 86.5979 (86.3229)  time: 0.5627  data: 0.0002  max mem: 3450
[2024-01-21 08:32:01 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:09  flops: 21.8619 (21.8619)  loss: 1.8928 (1.8949)  acc1: 71.2838 (70.8091)  acc5: 86.1487 (86.2136)  time: 0.4134  data: 0.0002  max mem: 3450
[2024-01-21 08:32:05 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:00  flops: 21.8619 (21.8619)  loss: 1.9051 (1.8983)  acc1: 70.2055 (70.5205)  acc5: 85.6655 (86.1589)  time: 0.3759  data: 0.0002  max mem: 3450
[2024-01-21 08:32:09 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:54  flops: 21.8619 (21.8619)  loss: 1.8957 (1.9052)  acc1: 70.0680 (70.4105)  acc5: 85.2740 (86.0454)  time: 0.3760  data: 0.0002  max mem: 3450
[2024-01-21 08:32:42 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:32:46 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:32:53 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:32:55 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:51  flops: 21.8619 (21.8619)  loss: 1.2114 (1.2114)  acc1: 78.4247 (78.4247)  acc5: 93.4931 (93.4931)  time: 1.7471  data: 0.0008  max mem: 3396
[2024-01-21 08:32:59 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:26  flops: 21.8619 (21.8619)  loss: 1.1180 (1.0995)  acc1: 81.4189 (80.9509)  acc5: 95.2218 (95.0602)  time: 0.5497  data: 0.0003  max mem: 3450
[2024-01-21 08:33:02 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:07  flops: 21.8619 (21.8619)  loss: 1.1024 (1.0999)  acc1: 80.7560 (80.9061)  acc5: 95.2862 (95.2265)  time: 0.3922  data: 0.0002  max mem: 3450
[2024-01-21 08:33:06 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:58  flops: 21.8619 (21.8619)  loss: 1.1266 (1.1114)  acc1: 79.8635 (80.3836)  acc5: 95.2703 (95.1781)  time: 0.3554  data: 0.0002  max mem: 3450
[2024-01-21 08:33:10 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:51  flops: 21.8619 (21.8619)  loss: 1.1321 (1.1225)  acc1: 80.0676 (80.1192)  acc5: 94.9324 (95.0753)  time: 0.3570  data: 0.0002  max mem: 3450
[2024-01-21 08:33:13 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:46  flops: 21.8619 (21.8619)  loss: 1.0943 (1.1185)  acc1: 80.4054 (80.2036)  acc5: 95.2542 (95.1823)  time: 0.3501  data: 0.0002  max mem: 3450
[2024-01-21 08:33:16 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:41  flops: 21.8619 (21.8619)  loss: 1.1168 (1.1218)  acc1: 80.0000 (80.0245)  acc5: 95.2542 (95.1676)  time: 0.3419  data: 0.0002  max mem: 3450
[2024-01-21 08:33:20 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:36  flops: 21.8619 (21.8619)  loss: 1.1215 (1.1225)  acc1: 78.7162 (80.0612)  acc5: 95.2703 (95.1085)  time: 0.3426  data: 0.0002  max mem: 3450
[2024-01-21 08:33:23 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:32  flops: 21.8619 (21.8619)  loss: 1.1451 (1.1273)  acc1: 79.0541 (79.8810)  acc5: 94.9495 (95.0551)  time: 0.3438  data: 0.0002  max mem: 3450
[2024-01-21 08:33:27 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:28  flops: 21.8619 (21.8619)  loss: 1.1591 (1.1347)  acc1: 78.9830 (79.7643)  acc5: 94.9153 (95.0203)  time: 0.3499  data: 0.0002  max mem: 3450
[2024-01-21 08:33:30 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:24  flops: 21.8619 (21.8619)  loss: 1.1420 (1.1363)  acc1: 79.5918 (79.8058)  acc5: 94.5578 (94.9708)  time: 0.3506  data: 0.0002  max mem: 3450
[2024-01-21 08:33:34 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:20  flops: 21.8619 (21.8619)  loss: 1.1420 (1.1386)  acc1: 80.3390 (79.7871)  acc5: 94.5578 (94.9017)  time: 0.3434  data: 0.0002  max mem: 3450
[2024-01-21 08:33:37 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:17  flops: 21.8619 (21.8619)  loss: 1.1057 (1.1357)  acc1: 80.2013 (79.8131)  acc5: 94.8980 (94.9435)  time: 0.3431  data: 0.0002  max mem: 3450
[2024-01-21 08:33:41 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:13  flops: 21.8619 (21.8619)  loss: 1.1005 (1.1342)  acc1: 80.0687 (79.8476)  acc5: 95.2703 (94.9781)  time: 0.3450  data: 0.0002  max mem: 3450
[2024-01-21 08:33:44 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:09  flops: 21.8619 (21.8619)  loss: 1.1278 (1.1343)  acc1: 79.1246 (79.8305)  acc5: 95.2703 (94.9733)  time: 0.3451  data: 0.0002  max mem: 3450
[2024-01-21 08:33:48 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:06  flops: 21.8619 (21.8619)  loss: 1.1278 (1.1358)  acc1: 78.9116 (79.7891)  acc5: 94.2177 (94.9608)  time: 0.3446  data: 0.0002  max mem: 3450
[2024-01-21 08:33:51 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:02  flops: 21.8619 (21.8619)  loss: 1.1517 (1.1365)  acc1: 79.3220 (79.7563)  acc5: 95.5631 (94.9944)  time: 0.3455  data: 0.0002  max mem: 3450
[2024-01-21 08:33:53 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 21.8619 (21.8619)  loss: 1.0906 (1.1334)  acc1: 80.0676 (79.8191)  acc5: 95.6229 (95.0144)  time: 0.3458  data: 0.0002  max mem: 3450
[2024-01-21 08:33:53 root] (utils.py 307): INFO Test: Total time: 0:01:00 (0.3606 s / it)
[2024-01-21 08:33:53 root] (engine.py 118): INFO * Acc@1 79.819 Acc@5 95.014 loss 1.133 flops 21.862
[2024-01-21 08:33:53 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 79.8%
[2024-01-21 08:34:00 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:34:04 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:34:11 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:34:13 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:46  flops: 21.8619 (21.8619)  loss: 2.2710 (2.2710)  acc1: 65.0685 (65.0685)  acc5: 79.4521 (79.4521)  time: 1.7159  data: 0.0007  max mem: 3396
[2024-01-21 08:34:17 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:25  flops: 21.8619 (21.8619)  loss: 2.1314 (2.1355)  acc1: 66.8919 (66.4094)  acc5: 83.1081 (82.7416)  time: 0.5446  data: 0.0002  max mem: 3450
[2024-01-21 08:34:27 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:34:31 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:34:38 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:34:40 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:39  flops: 21.8619 (21.8619)  loss: 3.5239 (3.5239)  acc1: 45.5479 (45.5479)  acc5: 62.3288 (62.3288)  time: 1.6737  data: 0.0010  max mem: 3396
[2024-01-21 08:34:44 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:24  flops: 21.8619 (21.8619)  loss: 3.5567 (3.5118)  acc1: 46.4164 (47.2368)  acc5: 62.3288 (62.1179)  time: 0.5374  data: 0.0002  max mem: 3450
[2024-01-21 08:34:48 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:06  flops: 21.8619 (21.8619)  loss: 3.5620 (3.5497)  acc1: 46.4164 (46.9417)  acc5: 61.2245 (61.4563)  time: 0.3893  data: 0.0002  max mem: 3450
[2024-01-21 08:34:51 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 21.8619 (21.8619)  loss: 3.6403 (3.5806)  acc1: 45.2381 (46.3890)  acc5: 59.8639 (60.9753)  time: 0.3573  data: 0.0002  max mem: 3450
[2024-01-21 08:34:55 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:51  flops: 21.8619 (21.8619)  loss: 3.5258 (3.5612)  acc1: 47.6190 (46.7721)  acc5: 62.1160 (61.3971)  time: 0.3587  data: 0.0002  max mem: 3450
[2024-01-21 08:34:58 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:45  flops: 21.8619 (21.8619)  loss: 3.4813 (3.5436)  acc1: 47.7816 (46.9590)  acc5: 62.2896 (61.5717)  time: 0.3496  data: 0.0002  max mem: 3450
[2024-01-21 08:35:06 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:35:10 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:35:17 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:35:19 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:48  flops: 21.8619 (21.8619)  loss: 1.2073 (1.2073)  acc1: 80.8219 (80.8219)  acc5: 94.1781 (94.1781)  time: 1.7249  data: 0.0008  max mem: 3396
[2024-01-21 08:35:28 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:35:32 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:35:39 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:35:41 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:35  flops: 21.8619 (21.8619)  loss: 1.1502 (1.1502)  acc1: 81.5069 (81.5069)  acc5: 95.2055 (95.2055)  time: 1.6508  data: 0.0008  max mem: 3396
[2024-01-21 08:35:45 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:24  flops: 21.8619 (21.8619)  loss: 1.0540 (1.0608)  acc1: 81.5069 (81.6919)  acc5: 95.9459 (95.6159)  time: 0.5386  data: 0.0002  max mem: 3450
[2024-01-21 08:35:48 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:06  flops: 21.8619 (21.8619)  loss: 1.0548 (1.0675)  acc1: 81.0997 (81.5858)  acc5: 95.5782 (95.4045)  time: 0.3910  data: 0.0002  max mem: 3450
[2024-01-21 08:35:52 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 21.8619 (21.8619)  loss: 1.0862 (1.0805)  acc1: 80.7432 (81.0849)  acc5: 95.5631 (95.3753)  time: 0.3546  data: 0.0002  max mem: 3450
[2024-01-21 08:35:56 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:51  flops: 21.8619 (21.8619)  loss: 1.1233 (1.0942)  acc1: 80.0676 (80.6820)  acc5: 94.9495 (95.2491)  time: 0.3566  data: 0.0002  max mem: 3450
[2024-01-21 08:35:59 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:45  flops: 21.8619 (21.8619)  loss: 1.1114 (1.0938)  acc1: 79.7251 (80.5297)  acc5: 95.2218 (95.2954)  time: 0.3506  data: 0.0002  max mem: 3450
[2024-01-21 08:36:02 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:41  flops: 21.8619 (21.8619)  loss: 1.1001 (1.1006)  acc1: 79.7251 (80.3864)  acc5: 95.2703 (95.2288)  time: 0.3414  data: 0.0002  max mem: 3450
[2024-01-21 08:36:06 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:36  flops: 21.8619 (21.8619)  loss: 1.1119 (1.1033)  acc1: 79.2517 (80.3433)  acc5: 95.1890 (95.1850)  time: 0.3430  data: 0.0002  max mem: 3450
[2024-01-21 08:36:09 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:32  flops: 21.8619 (21.8619)  loss: 1.1294 (1.1107)  acc1: 78.9116 (80.0821)  acc5: 94.5578 (95.0886)  time: 0.3444  data: 0.0002  max mem: 3450
[2024-01-21 08:36:13 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:28  flops: 21.8619 (21.8619)  loss: 1.1510 (1.1149)  acc1: 78.4512 (79.9582)  acc5: 94.4828 (95.0576)  time: 0.3511  data: 0.0002  max mem: 3450
[2024-01-21 08:36:16 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:24  flops: 21.8619 (21.8619)  loss: 1.1151 (1.1155)  acc1: 79.9320 (80.0443)  acc5: 94.6128 (95.0480)  time: 0.3521  data: 0.0002  max mem: 3450
[2024-01-21 08:36:20 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:20  flops: 21.8619 (21.8619)  loss: 1.1336 (1.1186)  acc1: 80.6122 (80.0532)  acc5: 94.6128 (95.0057)  time: 0.3436  data: 0.0002  max mem: 3450
[2024-01-21 08:36:23 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:17  flops: 21.8619 (21.8619)  loss: 1.1070 (1.1158)  acc1: 81.0345 (80.0881)  acc5: 95.2542 (95.0389)  time: 0.3428  data: 0.0002  max mem: 3450
[2024-01-21 08:36:27 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:13  flops: 21.8619 (21.8619)  loss: 1.0811 (1.1140)  acc1: 81.0345 (80.1275)  acc5: 95.2542 (95.0662)  time: 0.3449  data: 0.0002  max mem: 3450
[2024-01-21 08:36:30 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:09  flops: 21.8619 (21.8619)  loss: 1.1083 (1.1147)  acc1: 80.0000 (80.0640)  acc5: 95.2381 (95.0648)  time: 0.3453  data: 0.0002  max mem: 3450
[2024-01-21 08:36:34 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:06  flops: 21.8619 (21.8619)  loss: 1.1093 (1.1159)  acc1: 79.5918 (80.0544)  acc5: 94.5946 (95.0552)  time: 0.3442  data: 0.0002  max mem: 3450
[2024-01-21 08:36:44 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:36:48 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:36:55 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:37:19 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:37:23 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:37:30 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:38:06 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:38:10 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:38:17 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:39:32 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:39:36 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:39:43 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:40:41 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:40:44 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:40:52 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:41:27 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:41:31 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:41:38 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:41:51 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:41:55 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:42:02 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:42:27 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:42:31 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:42:38 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:43:16 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:43:21 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:43:28 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:44:25 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:44:29 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:44:36 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:44:38 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:03  flops: 21.8619 (21.8619)  loss: 1.1841 (1.1841)  acc1: 79.1096 (79.1096)  acc5: 93.8356 (93.8356)  time: 1.8146  data: 0.0008  max mem: 3396
[2024-01-21 08:44:42 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:26  flops: 21.8619 (21.8619)  loss: 1.1146 (1.1053)  acc1: 79.7251 (80.4878)  acc5: 94.8980 (94.9985)  time: 0.5521  data: 0.0002  max mem: 3450
[2024-01-21 08:44:46 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:07  flops: 21.8619 (21.8619)  loss: 1.1002 (1.1024)  acc1: 80.4054 (81.0194)  acc5: 94.9324 (95.0809)  time: 0.3911  data: 0.0002  max mem: 3450
[2024-01-21 08:44:49 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:58  flops: 21.8619 (21.8619)  loss: 1.1202 (1.1124)  acc1: 80.3390 (80.6027)  acc5: 95.2381 (95.0247)  time: 0.3583  data: 0.0002  max mem: 3450
[2024-01-21 08:44:53 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:52  flops: 21.8619 (21.8619)  loss: 1.1310 (1.1238)  acc1: 79.3919 (80.2682)  acc5: 94.9324 (94.9429)  time: 0.3596  data: 0.0002  max mem: 3450
[2024-01-21 08:44:56 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:46  flops: 21.8619 (21.8619)  loss: 1.1216 (1.1186)  acc1: 80.2721 (80.2569)  acc5: 95.2703 (95.0892)  time: 0.3497  data: 0.0002  max mem: 3450
[2024-01-21 08:45:00 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:41  flops: 21.8619 (21.8619)  loss: 1.1216 (1.1249)  acc1: 79.2517 (80.0857)  acc5: 95.2703 (95.0173)  time: 0.3399  data: 0.0002  max mem: 3450
[2024-01-21 08:45:03 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:36  flops: 21.8619 (21.8619)  loss: 1.1550 (1.1253)  acc1: 79.3220 (80.0899)  acc5: 94.6309 (95.0177)  time: 0.3410  data: 0.0002  max mem: 3450
[2024-01-21 08:45:07 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:32  flops: 21.8619 (21.8619)  loss: 1.1598 (1.1307)  acc1: 79.2517 (79.9061)  acc5: 94.9153 (94.9587)  time: 0.3422  data: 0.0002  max mem: 3450
[2024-01-21 08:45:10 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:28  flops: 21.8619 (21.8619)  loss: 1.1783 (1.1364)  acc1: 78.6441 (79.7978)  acc5: 94.6128 (94.9718)  time: 0.3516  data: 0.0002  max mem: 3450
[2024-01-21 08:45:14 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:24  flops: 21.8619 (21.8619)  loss: 1.1633 (1.1396)  acc1: 79.9320 (79.8260)  acc5: 94.5763 (94.8834)  time: 0.3535  data: 0.0002  max mem: 3450
[2024-01-21 08:45:17 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:21  flops: 21.8619 (21.8619)  loss: 1.1633 (1.1423)  acc1: 80.0000 (79.7749)  acc5: 94.2177 (94.8313)  time: 0.3442  data: 0.0002  max mem: 3450
[2024-01-21 08:45:21 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:17  flops: 21.8619 (21.8619)  loss: 1.0956 (1.1375)  acc1: 80.3448 (79.8748)  acc5: 94.5763 (94.8537)  time: 0.3436  data: 0.0002  max mem: 3450
[2024-01-21 08:45:24 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:13  flops: 21.8619 (21.8619)  loss: 1.0649 (1.1348)  acc1: 80.4124 (79.9072)  acc5: 95.2381 (94.9107)  time: 0.3447  data: 0.0002  max mem: 3450
[2024-01-21 08:45:28 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:09  flops: 21.8619 (21.8619)  loss: 1.1246 (1.1343)  acc1: 79.9320 (79.8763)  acc5: 95.2542 (94.9299)  time: 0.3440  data: 0.0002  max mem: 3450
[2024-01-21 08:45:31 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:06  flops: 21.8619 (21.8619)  loss: 1.1320 (1.1354)  acc1: 78.9116 (79.8610)  acc5: 94.5578 (94.9000)  time: 0.3424  data: 0.0002  max mem: 3450
[2024-01-21 08:45:34 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:02  flops: 21.8619 (21.8619)  loss: 1.1608 (1.1365)  acc1: 79.8658 (79.8279)  acc5: 94.8805 (94.9143)  time: 0.3438  data: 0.0002  max mem: 3450
[2024-01-21 08:45:36 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 21.8619 (21.8619)  loss: 1.0915 (1.1337)  acc1: 80.0000 (79.8619)  acc5: 95.5932 (94.9390)  time: 0.3449  data: 0.0002  max mem: 3450
[2024-01-21 08:45:36 root] (utils.py 307): INFO Test: Total time: 0:01:00 (0.3608 s / it)
[2024-01-21 08:45:36 root] (engine.py 118): INFO * Acc@1 79.862 Acc@5 94.939 loss 1.134 flops 21.862
[2024-01-21 08:45:36 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 79.9%
[2024-01-21 08:46:29 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:46:33 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:46:40 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:46:42 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:38  flops: 34.8324 (34.8324)  loss: 0.8256 (0.8256)  acc1: 83.9041 (83.9041)  acc5: 95.5479 (95.5479)  time: 2.0287  data: 0.0008  max mem: 3396
[2024-01-21 08:46:48 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:54  flops: 34.8324 (34.8324)  loss: 0.7209 (0.7369)  acc1: 84.8797 (85.3350)  acc5: 96.6216 (96.8509)  time: 0.7291  data: 0.0002  max mem: 3450
[2024-01-21 08:46:54 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:32  flops: 34.8324 (34.8324)  loss: 0.7209 (0.7353)  acc1: 84.8797 (85.3883)  acc5: 96.6216 (97.0065)  time: 0.5625  data: 0.0002  max mem: 3450
[2024-01-21 08:46:59 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:22  flops: 34.8324 (34.8324)  loss: 0.7238 (0.7353)  acc1: 85.3242 (85.3041)  acc5: 97.2973 (97.2712)  time: 0.5272  data: 0.0002  max mem: 3450
[2024-01-21 08:47:04 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:14  flops: 34.8324 (34.8324)  loss: 0.7548 (0.7466)  acc1: 84.8485 (85.1597)  acc5: 96.9595 (97.1528)  time: 0.5312  data: 0.0002  max mem: 3450
[2024-01-21 08:47:09 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:06  flops: 34.8324 (34.8324)  loss: 0.7498 (0.7444)  acc1: 85.2349 (85.1411)  acc5: 96.9595 (97.2252)  time: 0.5257  data: 0.0002  max mem: 3450
[2024-01-21 08:47:15 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:00  flops: 34.8324 (34.8324)  loss: 0.7482 (0.7492)  acc1: 85.0340 (85.0295)  acc5: 97.2881 (97.1885)  time: 0.5166  data: 0.0002  max mem: 3450
[2024-01-21 08:47:20 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:53  flops: 34.8324 (34.8324)  loss: 0.7560 (0.7527)  acc1: 84.4595 (85.0292)  acc5: 96.9697 (97.1263)  time: 0.5177  data: 0.0002  max mem: 3450
[2024-01-21 08:47:25 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:47  flops: 34.8324 (34.8324)  loss: 0.7844 (0.7572)  acc1: 83.9590 (84.9013)  acc5: 97.2973 (97.1420)  time: 0.5197  data: 0.0002  max mem: 3450
[2024-01-21 08:47:30 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:42  flops: 34.8324 (34.8324)  loss: 0.7844 (0.7622)  acc1: 83.4459 (84.7477)  acc5: 97.2973 (97.1241)  time: 0.5289  data: 0.0002  max mem: 3450
[2024-01-21 08:47:36 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:36  flops: 34.8324 (34.8324)  loss: 0.7795 (0.7633)  acc1: 84.1216 (84.7511)  acc5: 96.9697 (97.1142)  time: 0.5304  data: 0.0002  max mem: 3450
[2024-01-21 08:47:41 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:31  flops: 34.8324 (34.8324)  loss: 0.7822 (0.7650)  acc1: 84.6939 (84.7692)  acc5: 97.2414 (97.0731)  time: 0.5202  data: 0.0002  max mem: 3450
[2024-01-21 08:47:46 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:25  flops: 34.8324 (34.8324)  loss: 0.7294 (0.7610)  acc1: 85.1724 (84.8444)  acc5: 97.2881 (97.1069)  time: 0.5190  data: 0.0002  max mem: 3450
[2024-01-21 08:47:51 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:20  flops: 34.8324 (34.8324)  loss: 0.7172 (0.7593)  acc1: 85.4671 (84.9006)  acc5: 97.5779 (97.1289)  time: 0.5212  data: 0.0002  max mem: 3450
[2024-01-21 08:47:56 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:14  flops: 34.8324 (34.8324)  loss: 0.7356 (0.7578)  acc1: 84.7973 (84.9150)  acc5: 97.3064 (97.1424)  time: 0.5218  data: 0.0002  max mem: 3450
[2024-01-21 08:48:02 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:09  flops: 34.8324 (34.8324)  loss: 0.7476 (0.7588)  acc1: 84.7751 (84.9183)  acc5: 97.2696 (97.1285)  time: 0.5207  data: 0.0002  max mem: 3450
[2024-01-21 08:48:07 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 34.8324 (34.8324)  loss: 0.7710 (0.7610)  acc1: 84.7751 (84.8799)  acc5: 96.9697 (97.1345)  time: 0.5212  data: 0.0002  max mem: 3450
[2024-01-21 08:48:10 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 34.8324 (34.8324)  loss: 0.7405 (0.7592)  acc1: 85.1351 (84.9168)  acc5: 97.2696 (97.1447)  time: 0.5196  data: 0.0002  max mem: 3450
[2024-01-21 08:48:10 root] (utils.py 307): INFO Test: Total time: 0:01:29 (0.5364 s / it)
[2024-01-21 08:48:10 root] (engine.py 118): INFO * Acc@1 84.917 Acc@5 97.145 loss 0.759 flops 34.832
[2024-01-21 08:48:10 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-01-21 08:48:18 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9425, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:48:22 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:48:29 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:48:31 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:45  flops: 32.2755 (32.2755)  loss: 0.8428 (0.8428)  acc1: 83.2192 (83.2192)  acc5: 95.8904 (95.8904)  time: 1.7112  data: 0.0008  max mem: 3396
[2024-01-21 08:48:36 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:45  flops: 32.2755 (32.2755)  loss: 0.7646 (0.7638)  acc1: 85.5670 (85.0880)  acc5: 97.2509 (96.9126)  time: 0.6716  data: 0.0002  max mem: 3450
[2024-01-21 08:48:41 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:26  flops: 32.2755 (32.2755)  loss: 0.7588 (0.7650)  acc1: 84.4595 (84.9515)  acc5: 97.2509 (97.0227)  time: 0.5307  data: 0.0002  max mem: 3450
[2024-01-21 08:48:46 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:16  flops: 32.2755 (32.2755)  loss: 0.7588 (0.7661)  acc1: 84.1216 (84.9644)  acc5: 97.2696 (97.1507)  time: 0.4951  data: 0.0002  max mem: 3450
[2024-01-21 08:48:51 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:09  flops: 32.2755 (32.2755)  loss: 0.7736 (0.7738)  acc1: 84.8993 (84.8783)  acc5: 96.9697 (97.1445)  time: 0.4997  data: 0.0002  max mem: 3450
[2024-01-21 08:48:56 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:02  flops: 32.2755 (32.2755)  loss: 0.7729 (0.7714)  acc1: 85.0847 (84.8816)  acc5: 96.9697 (97.1919)  time: 0.4940  data: 0.0002  max mem: 3450
[2024-01-21 08:49:07 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:49:11 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:49:18 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:49:20 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:15  flops: 31.4818 (31.4818)  loss: 0.8821 (0.8821)  acc1: 83.9041 (83.9041)  acc5: 95.5479 (95.5479)  time: 1.8905  data: 0.0009  max mem: 3396
[2024-01-21 08:49:26 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:46  flops: 31.4818 (31.4818)  loss: 0.7805 (0.7863)  acc1: 85.0340 (84.6558)  acc5: 96.9595 (97.0052)  time: 0.6789  data: 0.0005  max mem: 3450
[2024-01-21 08:49:30 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:26  flops: 31.4818 (31.4818)  loss: 0.7778 (0.7823)  acc1: 85.0340 (84.7087)  acc5: 96.9595 (97.0388)  time: 0.5221  data: 0.0003  max mem: 3450
[2024-01-21 08:49:35 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:16  flops: 31.4818 (31.4818)  loss: 0.7778 (0.7858)  acc1: 84.7973 (84.6795)  acc5: 96.9595 (97.0740)  time: 0.4868  data: 0.0002  max mem: 3450
[2024-01-21 08:49:40 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:08  flops: 31.4818 (31.4818)  loss: 0.7865 (0.7948)  acc1: 84.3537 (84.5555)  acc5: 96.9595 (97.0121)  time: 0.4890  data: 0.0002  max mem: 3450
[2024-01-21 08:49:45 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:01  flops: 31.4818 (31.4818)  loss: 0.7865 (0.7924)  acc1: 84.3537 (84.5821)  acc5: 97.2696 (97.0655)  time: 0.4834  data: 0.0002  max mem: 3450
[2024-01-21 08:49:50 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:55  flops: 31.4818 (31.4818)  loss: 0.7869 (0.7950)  acc1: 84.1924 (84.4839)  acc5: 96.9595 (97.0772)  time: 0.4754  data: 0.0002  max mem: 3450
[2024-01-21 08:49:54 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:49  flops: 31.4818 (31.4818)  loss: 0.8006 (0.7978)  acc1: 84.1924 (84.4410)  acc5: 96.9388 (97.0355)  time: 0.4759  data: 0.0002  max mem: 3450
[2024-01-21 08:49:59 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:44  flops: 31.4818 (31.4818)  loss: 0.8361 (0.8009)  acc1: 82.7586 (84.3188)  acc5: 96.9697 (97.0373)  time: 0.4769  data: 0.0002  max mem: 3450
[2024-01-21 08:50:04 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:38  flops: 31.4818 (31.4818)  loss: 0.8361 (0.8056)  acc1: 82.4916 (84.1844)  acc5: 96.9697 (97.0308)  time: 0.4838  data: 0.0002  max mem: 3450
[2024-01-21 08:50:09 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:33  flops: 31.4818 (31.4818)  loss: 0.8204 (0.8068)  acc1: 84.1216 (84.2102)  acc5: 96.9388 (97.0234)  time: 0.4847  data: 0.0002  max mem: 3450
[2024-01-21 08:50:14 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:28  flops: 31.4818 (31.4818)  loss: 0.8169 (0.8086)  acc1: 84.3537 (84.2096)  acc5: 96.6330 (96.9600)  time: 0.4765  data: 0.0002  max mem: 3450
[2024-01-21 08:50:18 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:23  flops: 31.4818 (31.4818)  loss: 0.7793 (0.8039)  acc1: 85.1724 (84.3112)  acc5: 96.9492 (96.9807)  time: 0.4760  data: 0.0002  max mem: 3450
[2024-01-21 08:50:23 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:18  flops: 31.4818 (31.4818)  loss: 0.7752 (0.8022)  acc1: 85.3242 (84.3720)  acc5: 97.2318 (96.9993)  time: 0.4785  data: 0.0002  max mem: 3450
[2024-01-21 08:50:28 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:13  flops: 31.4818 (31.4818)  loss: 0.7770 (0.8006)  acc1: 84.4595 (84.3950)  acc5: 96.9595 (97.0027)  time: 0.4787  data: 0.0002  max mem: 3450
[2024-01-21 08:50:33 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:08  flops: 31.4818 (31.4818)  loss: 0.8032 (0.8026)  acc1: 83.7288 (84.3538)  acc5: 96.9492 (97.0025)  time: 0.4767  data: 0.0002  max mem: 3450
[2024-01-21 08:50:38 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 31.4818 (31.4818)  loss: 0.8251 (0.8049)  acc1: 83.6735 (84.3022)  acc5: 96.6102 (96.9701)  time: 0.4773  data: 0.0002  max mem: 3450
[2024-01-21 08:50:40 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 31.4818 (31.4818)  loss: 0.7932 (0.8036)  acc1: 84.2466 (84.3323)  acc5: 96.6216 (96.9634)  time: 0.4786  data: 0.0002  max mem: 3450
[2024-01-21 08:50:40 root] (utils.py 307): INFO Test: Total time: 0:01:22 (0.4933 s / it)
[2024-01-21 08:50:40 root] (engine.py 118): INFO * Acc@1 84.332 Acc@5 96.963 loss 0.804 flops 31.482
[2024-01-21 08:50:40 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-01-21 08:50:59 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:51:02 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:51:09 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:51:11 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:45  flops: 31.4818 (31.4818)  loss: 0.8764 (0.8764)  acc1: 84.2466 (84.2466)  acc5: 95.8904 (95.8904)  time: 1.7121  data: 0.0008  max mem: 3396
[2024-01-21 08:51:17 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:44  flops: 31.4818 (31.4818)  loss: 0.7637 (0.7891)  acc1: 85.1351 (84.7484)  acc5: 97.2789 (96.8818)  time: 0.6631  data: 0.0002  max mem: 3450
[2024-01-21 08:51:22 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:24  flops: 31.4818 (31.4818)  loss: 0.7637 (0.7859)  acc1: 85.1351 (84.8544)  acc5: 97.2414 (96.9579)  time: 0.5215  data: 0.0002  max mem: 3450
[2024-01-21 08:51:26 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:15  flops: 31.4818 (31.4818)  loss: 0.7886 (0.7872)  acc1: 84.9315 (84.7781)  acc5: 96.9492 (96.9973)  time: 0.4853  data: 0.0004  max mem: 3450
[2024-01-21 08:51:31 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:07  flops: 31.4818 (31.4818)  loss: 0.7886 (0.7962)  acc1: 84.7458 (84.6549)  acc5: 96.9492 (96.9790)  time: 0.4873  data: 0.0004  max mem: 3450
[2024-01-21 08:51:36 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:01  flops: 31.4818 (31.4818)  loss: 0.7846 (0.7933)  acc1: 84.7458 (84.6087)  acc5: 96.9388 (97.0122)  time: 0.4818  data: 0.0001  max mem: 3450
[2024-01-21 08:51:41 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:55  flops: 31.4818 (31.4818)  loss: 0.7867 (0.7969)  acc1: 83.5017 (84.4672)  acc5: 96.9388 (97.0104)  time: 0.4751  data: 0.0002  max mem: 3450
[2024-01-21 08:51:46 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:49  flops: 31.4818 (31.4818)  loss: 0.7965 (0.7990)  acc1: 84.0136 (84.4745)  acc5: 96.6330 (96.9638)  time: 0.4756  data: 0.0002  max mem: 3450
[2024-01-21 08:51:50 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:43  flops: 31.4818 (31.4818)  loss: 0.8293 (0.8028)  acc1: 82.3729 (84.2937)  acc5: 96.6216 (96.9534)  time: 0.4757  data: 0.0002  max mem: 3450
[2024-01-21 08:51:55 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:38  flops: 31.4818 (31.4818)  loss: 0.8446 (0.8074)  acc1: 82.0946 (84.1583)  acc5: 96.9283 (96.9562)  time: 0.4828  data: 0.0002  max mem: 3450
[2024-01-21 08:52:00 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:33  flops: 31.4818 (31.4818)  loss: 0.8200 (0.8078)  acc1: 83.6735 (84.1867)  acc5: 96.9697 (96.9529)  time: 0.4833  data: 0.0002  max mem: 3450
[2024-01-21 08:52:05 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:28  flops: 31.4818 (31.4818)  loss: 0.8025 (0.8094)  acc1: 84.4068 (84.1851)  acc5: 96.9388 (96.8896)  time: 0.4751  data: 0.0002  max mem: 3450
[2024-01-21 08:52:10 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:23  flops: 31.4818 (31.4818)  loss: 0.7751 (0.8041)  acc1: 85.0847 (84.2832)  acc5: 96.9388 (96.9245)  time: 0.4745  data: 0.0002  max mem: 3450
[2024-01-21 08:52:14 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:18  flops: 31.4818 (31.4818)  loss: 0.7699 (0.8020)  acc1: 85.1351 (84.3331)  acc5: 97.2789 (96.9630)  time: 0.4767  data: 0.0002  max mem: 3450
[2024-01-21 08:52:19 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:13  flops: 31.4818 (31.4818)  loss: 0.7817 (0.8006)  acc1: 84.7973 (84.3733)  acc5: 97.2881 (96.9714)  time: 0.4769  data: 0.0002  max mem: 3450
[2024-01-21 08:52:24 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:08  flops: 31.4818 (31.4818)  loss: 0.7925 (0.8023)  acc1: 84.4068 (84.3583)  acc5: 96.5986 (96.9666)  time: 0.4755  data: 0.0002  max mem: 3450
[2024-01-21 08:52:29 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 31.4818 (31.4818)  loss: 0.8064 (0.8045)  acc1: 83.6735 (84.3022)  acc5: 96.2963 (96.9448)  time: 0.4772  data: 0.0002  max mem: 3450
[2024-01-21 08:52:32 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 31.4818 (31.4818)  loss: 0.7919 (0.8031)  acc1: 84.0678 (84.3262)  acc5: 96.6216 (96.9430)  time: 0.4777  data: 0.0002  max mem: 3450
[2024-01-21 08:52:32 root] (utils.py 307): INFO Test: Total time: 0:01:22 (0.4911 s / it)
[2024-01-21 08:52:32 root] (engine.py 118): INFO * Acc@1 84.326 Acc@5 96.943 loss 0.803 flops 31.482
[2024-01-21 08:52:32 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-01-21 08:53:04 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:53:08 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:53:15 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 08:53:17 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:30  flops: 31.4818 (31.4818)  loss: 0.8869 (0.8869)  acc1: 82.8767 (82.8767)  acc5: 95.2055 (95.2055)  time: 1.9802  data: 0.0007  max mem: 3396
[2024-01-21 08:53:23 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:48  flops: 31.4818 (31.4818)  loss: 0.7755 (0.7865)  acc1: 85.2234 (84.7484)  acc5: 96.9388 (96.7891)  time: 0.6910  data: 0.0002  max mem: 3450
[2024-01-21 08:53:24 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:53:27 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:27  flops: 31.4818 (31.4818)  loss: 0.7755 (0.7833)  acc1: 85.1852 (84.8867)  acc5: 96.9388 (96.9094)  time: 0.5250  data: 0.0002  max mem: 3450
[2024-01-21 08:53:28 root] (main_tome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:53:33 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:18  flops: 31.4818 (31.4818)  loss: 0.7713 (0.7845)  acc1: 84.7973 (84.8219)  acc5: 96.9388 (96.9863)  time: 0.5054  data: 0.0002  max mem: 3450
[2024-01-21 08:53:38 root] (main_tome.py 370): INFO number of params: 304326632
[2024-01-21 08:53:38 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:10  flops: 31.4818 (31.4818)  loss: 0.7930 (0.7934)  acc1: 84.4595 (84.7128)  acc5: 96.6330 (96.8962)  time: 0.5102  data: 0.0002  max mem: 3450
[2024-01-21 08:53:43 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:15:56  flops: 31.4818 (31.4818)  loss: 0.8167 (0.8167)  acc1: 83.5616 (83.5616)  acc5: 95.8904 (95.8904)  time: 5.7274  data: 0.0008  max mem: 3396
[2024-01-21 08:53:44 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:06  flops: 31.4818 (31.4818)  loss: 0.7930 (0.7912)  acc1: 84.1216 (84.6553)  acc5: 96.6330 (96.9657)  time: 0.5549  data: 0.0002  max mem: 3450
[2024-01-21 08:53:51 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:02  flops: 31.4818 (31.4818)  loss: 0.7841 (0.7952)  acc1: 84.1216 (84.4895)  acc5: 96.9595 (96.9324)  time: 0.6448  data: 0.0002  max mem: 3450
[2024-01-21 08:53:55 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:55  flops: 31.4818 (31.4818)  loss: 0.8119 (0.7982)  acc1: 84.3537 (84.4554)  acc5: 96.9388 (96.9255)  time: 0.5774  data: 0.0002  max mem: 3450
[2024-01-21 08:53:59 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:54:00 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:48  flops: 31.4818 (31.4818)  loss: 0.8278 (0.8020)  acc1: 83.0508 (84.2602)  acc5: 96.9492 (96.9199)  time: 0.4783  data: 0.0002  max mem: 3450
[2024-01-21 08:54:04 root] (main_tome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:54:05 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:42  flops: 31.4818 (31.4818)  loss: 0.8295 (0.8064)  acc1: 82.4138 (84.1247)  acc5: 96.9492 (96.9264)  time: 0.4874  data: 0.0002  max mem: 3450
[2024-01-21 08:54:10 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:36  flops: 31.4818 (31.4818)  loss: 0.8295 (0.8072)  acc1: 83.6735 (84.1564)  acc5: 96.9697 (96.9428)  time: 0.4879  data: 0.0002  max mem: 3450
[2024-01-21 08:54:10 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=42.3, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 08:54:14 root] (main_tome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 08:54:15 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:30  flops: 31.4818 (31.4818)  loss: 0.8294 (0.8087)  acc1: 84.7973 (84.2065)  acc5: 96.9283 (96.8957)  time: 0.4780  data: 0.0002  max mem: 3450
[2024-01-21 08:54:20 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:25  flops: 31.4818 (31.4818)  loss: 0.7721 (0.8035)  acc1: 85.4237 (84.3197)  acc5: 96.9283 (96.9217)  time: 0.4891  data: 0.0002  max mem: 3450
[2024-01-21 08:54:23 root] (main_tome.py 370): INFO number of params: 304326632
[2024-01-21 08:54:25 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:19  flops: 31.4818 (31.4818)  loss: 0.7713 (0.8019)  acc1: 84.9829 (84.3642)  acc5: 97.2881 (96.9397)  time: 0.5032  data: 0.0002  max mem: 3450
[2024-01-21 08:54:29 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:32  flops: 31.4818 (31.4818)  loss: 0.8658 (0.8658)  acc1: 83.2192 (83.2192)  acc5: 95.5479 (95.5479)  time: 5.9406  data: 0.0007  max mem: 3396
[2024-01-21 08:54:32 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:14  flops: 31.4818 (31.4818)  loss: 0.7777 (0.8003)  acc1: 84.3537 (84.3902)  acc5: 97.2789 (96.9546)  time: 0.6356  data: 0.0002  max mem: 3450
[2024-01-21 08:54:40 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:04:10  flops: 31.4818 (31.4818)  loss: 0.7906 (0.7750)  acc1: 83.9590 (84.1000)  acc5: 96.9595 (96.9126)  time: 1.5935  data: 0.0002  max mem: 3450
[2024-01-21 08:54:43 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:09  flops: 31.4818 (31.4818)  loss: 0.7911 (0.8018)  acc1: 84.1216 (84.3606)  acc5: 96.9697 (96.9441)  time: 0.8956  data: 0.0002  max mem: 3450
[2024-01-21 08:54:51 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:03:13  flops: 31.4818 (31.4818)  loss: 0.7630 (0.7744)  acc1: 84.0136 (84.2880)  acc5: 96.9388 (96.9094)  time: 1.0867  data: 0.0002  max mem: 3450
[2024-01-21 08:54:53 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:04  flops: 31.4818 (31.4818)  loss: 0.8221 (0.8040)  acc1: 83.6177 (84.3043)  acc5: 96.6216 (96.9279)  time: 1.0319  data: 0.0002  max mem: 3450
[2024-01-21 08:54:59 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 31.4818 (31.4818)  loss: 0.7915 (0.8029)  acc1: 84.5638 (84.3282)  acc5: 96.9178 (96.9206)  time: 1.0299  data: 0.0003  max mem: 3450
[2024-01-21 08:54:59 root] (utils.py 307): INFO Test: Total time: 0:01:44 (0.6235 s / it)
[2024-01-21 08:54:59 root] (engine.py 118): INFO * Acc@1 84.328 Acc@5 96.921 loss 0.803 flops 31.482
[2024-01-21 08:54:59 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-01-21 08:55:00 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:02:43  flops: 31.4818 (31.4818)  loss: 0.7630 (0.7704)  acc1: 84.3537 (84.1863)  acc5: 96.9283 (97.0411)  time: 0.9722  data: 0.0002  max mem: 3450
[2024-01-21 08:55:05 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:09  flops: 31.4818 (31.4818)  loss: 0.7983 (0.7800)  acc1: 84.2466 (84.0507)  acc5: 96.9595 (97.0535)  time: 0.7094  data: 0.0002  max mem: 3450
[2024-01-21 08:55:09 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:46  flops: 31.4818 (31.4818)  loss: 0.7969 (0.7783)  acc1: 83.8384 (84.0697)  acc5: 96.9595 (97.1054)  time: 0.4790  data: 0.0002  max mem: 3450
[2024-01-21 08:55:14 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:29  flops: 31.4818 (31.4818)  loss: 0.7828 (0.7806)  acc1: 83.6735 (83.9884)  acc5: 96.9283 (97.0549)  time: 0.4682  data: 0.0002  max mem: 3450
[2024-01-21 08:55:19 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:16  flops: 31.4818 (31.4818)  loss: 0.7761 (0.7835)  acc1: 83.6735 (83.9581)  acc5: 96.6330 (97.0211)  time: 0.4686  data: 0.0002  max mem: 3450
[2024-01-21 08:55:23 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:05  flops: 31.4818 (31.4818)  loss: 0.8099 (0.7877)  acc1: 83.5570 (83.8495)  acc5: 96.9595 (97.0498)  time: 0.4696  data: 0.0002  max mem: 3450
[2024-01-21 08:55:28 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:55  flops: 31.4818 (31.4818)  loss: 0.8163 (0.7919)  acc1: 82.8283 (83.7592)  acc5: 97.2603 (97.0383)  time: 0.4780  data: 0.0002  max mem: 3450
[2024-01-21 08:55:33 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:46  flops: 31.4818 (31.4818)  loss: 0.8007 (0.7916)  acc1: 83.6735 (83.7802)  acc5: 96.9595 (97.0369)  time: 0.4786  data: 0.0002  max mem: 3450
[2024-01-21 08:55:38 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:38  flops: 31.4818 (31.4818)  loss: 0.8007 (0.7942)  acc1: 84.0678 (83.7875)  acc5: 96.6102 (96.9783)  time: 0.4686  data: 0.0002  max mem: 3450
[2024-01-21 08:55:42 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:30  flops: 31.4818 (31.4818)  loss: 0.7691 (0.7902)  acc1: 85.0847 (83.9072)  acc5: 96.9072 (96.9751)  time: 0.4672  data: 0.0002  max mem: 3450
[2024-01-21 08:55:47 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:23  flops: 31.4818 (31.4818)  loss: 0.7405 (0.7883)  acc1: 85.0847 (84.0170)  acc5: 96.9492 (96.9838)  time: 0.4692  data: 0.0002  max mem: 3450
[2024-01-21 08:55:52 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:17  flops: 31.4818 (31.4818)  loss: 0.7754 (0.7882)  acc1: 83.7838 (83.9641)  acc5: 96.9697 (96.9859)  time: 0.4698  data: 0.0002  max mem: 3450
[2024-01-21 08:55:56 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:10  flops: 31.4818 (31.4818)  loss: 0.8040 (0.7902)  acc1: 83.0508 (83.9333)  acc5: 96.9697 (96.9598)  time: 0.4680  data: 0.0002  max mem: 3450
[2024-01-21 08:56:01 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:04  flops: 31.4818 (31.4818)  loss: 0.8133 (0.7920)  acc1: 83.4459 (83.8952)  acc5: 96.9492 (96.9553)  time: 0.4686  data: 0.0002  max mem: 3450
[2024-01-21 08:56:04 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 31.4818 (31.4818)  loss: 0.7776 (0.7901)  acc1: 83.7288 (83.9290)  acc5: 96.9492 (96.9573)  time: 0.4675  data: 0.0002  max mem: 3450
[2024-01-21 08:56:04 root] (utils.py 307): INFO Test: Total time: 0:01:41 (0.6053 s / it)
[2024-01-21 08:56:04 root] (engine.py 118): INFO * Acc@1 83.929 Acc@5 96.957 loss 0.790 flops 31.482
[2024-01-21 08:56:04 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-01-21 09:00:36 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:00:40 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 09:00:48 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 09:00:49 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:04:51  flops: 34.8324 (34.8324)  loss: 0.8363 (0.8363)  acc1: 83.5616 (83.5616)  acc5: 95.8904 (95.8904)  time: 1.7429  data: 0.0008  max mem: 3396
[2024-01-21 09:00:55 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:50  flops: 34.8324 (34.8324)  loss: 0.7274 (0.7392)  acc1: 84.9498 (85.3350)  acc5: 96.9388 (96.9744)  time: 0.7037  data: 0.0003  max mem: 3450
[2024-01-21 09:01:01 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:31  flops: 34.8324 (34.8324)  loss: 0.7273 (0.7357)  acc1: 85.2740 (85.4531)  acc5: 96.9388 (97.0874)  time: 0.5631  data: 0.0002  max mem: 3450
[2024-01-21 09:01:06 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:20  flops: 34.8324 (34.8324)  loss: 0.7271 (0.7360)  acc1: 85.6164 (85.3479)  acc5: 97.2973 (97.2493)  time: 0.5289  data: 0.0002  max mem: 3450
[2024-01-21 09:01:11 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:13  flops: 34.8324 (34.8324)  loss: 0.7522 (0.7478)  acc1: 85.0340 (85.1432)  acc5: 97.2973 (97.1197)  time: 0.5321  data: 0.0002  max mem: 3450
[2024-01-21 09:01:17 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:06  flops: 34.8324 (34.8324)  loss: 0.7522 (0.7456)  acc1: 84.8993 (85.1344)  acc5: 97.2973 (97.2185)  time: 0.5251  data: 0.0002  max mem: 3450
[2024-01-21 09:01:22 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:59  flops: 34.8324 (34.8324)  loss: 0.7534 (0.7501)  acc1: 85.0340 (85.0184)  acc5: 97.3064 (97.1996)  time: 0.5169  data: 0.0002  max mem: 3450
[2024-01-21 09:01:27 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:53  flops: 34.8324 (34.8324)  loss: 0.7615 (0.7535)  acc1: 84.4595 (85.0387)  acc5: 96.9388 (97.1550)  time: 0.5170  data: 0.0002  max mem: 3450
[2024-01-21 09:01:32 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:47  flops: 34.8324 (34.8324)  loss: 0.7916 (0.7576)  acc1: 83.9590 (84.9013)  acc5: 97.2789 (97.1504)  time: 0.5177  data: 0.0002  max mem: 3450
[2024-01-21 09:01:37 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:42  flops: 34.8324 (34.8324)  loss: 0.7916 (0.7627)  acc1: 83.5017 (84.7850)  acc5: 97.2789 (97.1390)  time: 0.5243  data: 0.0002  max mem: 3450
[2024-01-21 09:01:43 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:36  flops: 34.8324 (34.8324)  loss: 0.7849 (0.7635)  acc1: 83.8926 (84.7914)  acc5: 96.9178 (97.1377)  time: 0.5261  data: 0.0005  max mem: 3450
[2024-01-21 09:01:48 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:30  flops: 34.8324 (34.8324)  loss: 0.7904 (0.7657)  acc1: 84.4068 (84.7692)  acc5: 97.2789 (97.1190)  time: 0.5190  data: 0.0005  max mem: 3450
[2024-01-21 09:01:53 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:25  flops: 34.8324 (34.8324)  loss: 0.7447 (0.7617)  acc1: 84.7973 (84.8304)  acc5: 97.2789 (97.1378)  time: 0.5179  data: 0.0002  max mem: 3450
[2024-01-21 09:01:58 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:19  flops: 34.8324 (34.8324)  loss: 0.7137 (0.7598)  acc1: 85.1351 (84.8928)  acc5: 97.5945 (97.1574)  time: 0.5207  data: 0.0002  max mem: 3450
[2024-01-21 09:02:03 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:14  flops: 34.8324 (34.8324)  loss: 0.7391 (0.7583)  acc1: 85.1351 (84.9198)  acc5: 97.6190 (97.1640)  time: 0.5221  data: 0.0002  max mem: 3450
[2024-01-21 09:02:09 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:09  flops: 34.8324 (34.8324)  loss: 0.7433 (0.7595)  acc1: 84.8485 (84.9318)  acc5: 97.2696 (97.1465)  time: 0.5214  data: 0.0002  max mem: 3450
[2024-01-21 09:02:14 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 34.8324 (34.8324)  loss: 0.7751 (0.7616)  acc1: 84.6939 (84.8631)  acc5: 96.9595 (97.1451)  time: 0.5219  data: 0.0002  max mem: 3450
[2024-01-21 09:02:17 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 34.8324 (34.8324)  loss: 0.7420 (0.7601)  acc1: 84.7458 (84.9005)  acc5: 96.9799 (97.1508)  time: 0.5193  data: 0.0002  max mem: 3450
[2024-01-21 09:02:17 root] (utils.py 307): INFO Test: Total time: 0:01:29 (0.5340 s / it)
[2024-01-21 09:02:17 root] (engine.py 118): INFO * Acc@1 84.901 Acc@5 97.151 loss 0.760 flops 34.832
[2024-01-21 09:02:17 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-01-21 09:02:24 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:02:28 root] (main_tome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 09:02:35 root] (main_tome.py 370): INFO number of params: 304326632
[2024-01-21 09:02:37 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:01  flops: 34.8324 (34.8324)  loss: 0.7990 (0.7990)  acc1: 84.5890 (84.5890)  acc5: 96.5753 (96.5753)  time: 1.8048  data: 0.0008  max mem: 3396
[2024-01-21 09:02:43 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:50  flops: 34.8324 (34.8324)  loss: 0.7269 (0.7187)  acc1: 85.7143 (85.4585)  acc5: 97.2789 (97.1905)  time: 0.7030  data: 0.0002  max mem: 3450
[2024-01-21 09:02:48 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:30  flops: 34.8324 (34.8324)  loss: 0.7201 (0.7245)  acc1: 85.3741 (85.2751)  acc5: 97.2789 (97.3463)  time: 0.5577  data: 0.0002  max mem: 3450
[2024-01-21 09:02:53 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:20  flops: 34.8324 (34.8324)  loss: 0.7198 (0.7243)  acc1: 84.7973 (85.0411)  acc5: 97.3064 (97.4027)  time: 0.5230  data: 0.0002  max mem: 3450
[2024-01-21 09:02:59 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:12  flops: 34.8324 (34.8324)  loss: 0.7423 (0.7365)  acc1: 84.7458 (84.9280)  acc5: 96.6443 (97.2356)  time: 0.5246  data: 0.0002  max mem: 3450
[2024-01-21 09:03:04 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:05  flops: 34.8324 (34.8324)  loss: 0.7526 (0.7341)  acc1: 84.6416 (84.9015)  acc5: 96.9492 (97.2851)  time: 0.5188  data: 0.0002  max mem: 3450
[2024-01-21 09:03:09 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:59  flops: 34.8324 (34.8324)  loss: 0.7475 (0.7373)  acc1: 83.6177 (84.7456)  acc5: 96.9697 (97.2330)  time: 0.5107  data: 0.0002  max mem: 3450
[2024-01-21 09:03:14 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:53  flops: 34.8324 (34.8324)  loss: 0.7550 (0.7418)  acc1: 83.6177 (84.6610)  acc5: 96.9388 (97.1598)  time: 0.5113  data: 0.0002  max mem: 3450
[2024-01-21 09:03:19 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:47  flops: 34.8324 (34.8324)  loss: 0.7550 (0.7464)  acc1: 83.6177 (84.5493)  acc5: 96.9595 (97.1546)  time: 0.5129  data: 0.0002  max mem: 3450
[2024-01-21 09:03:24 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:41  flops: 34.8324 (34.8324)  loss: 0.7530 (0.7501)  acc1: 83.6735 (84.5276)  acc5: 97.2881 (97.1689)  time: 0.5195  data: 0.0002  max mem: 3450
[2024-01-21 09:03:30 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:36  flops: 34.8324 (34.8324)  loss: 0.7530 (0.7498)  acc1: 83.8926 (84.5293)  acc5: 96.9697 (97.1478)  time: 0.5204  data: 0.0001  max mem: 3450
[2024-01-21 09:03:35 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:30  flops: 34.8324 (34.8324)  loss: 0.7665 (0.7518)  acc1: 84.6939 (84.5399)  acc5: 96.6443 (97.1098)  time: 0.5124  data: 0.0002  max mem: 3450
[2024-01-21 09:03:40 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:25  flops: 34.8324 (34.8324)  loss: 0.7193 (0.7478)  acc1: 85.5670 (84.6508)  acc5: 97.2414 (97.1490)  time: 0.5111  data: 0.0002  max mem: 3450
[2024-01-21 09:03:45 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:19  flops: 34.8324 (34.8324)  loss: 0.7083 (0.7461)  acc1: 85.5670 (84.7115)  acc5: 97.3244 (97.1703)  time: 0.5130  data: 0.0002  max mem: 3450
[2024-01-21 09:03:50 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:14  flops: 34.8324 (34.8324)  loss: 0.7234 (0.7451)  acc1: 84.9315 (84.7296)  acc5: 97.2881 (97.1905)  time: 0.5139  data: 0.0002  max mem: 3450
[2024-01-21 09:03:55 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:08  flops: 34.8324 (34.8324)  loss: 0.7407 (0.7465)  acc1: 84.4595 (84.6979)  acc5: 97.2318 (97.1847)  time: 0.5122  data: 0.0002  max mem: 3450
[2024-01-21 09:04:00 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 34.8324 (34.8324)  loss: 0.7564 (0.7486)  acc1: 84.1216 (84.6543)  acc5: 96.9283 (97.1577)  time: 0.5128  data: 0.0002  max mem: 3450
[2024-01-21 09:04:03 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 34.8324 (34.8324)  loss: 0.7278 (0.7469)  acc1: 84.5890 (84.6867)  acc5: 96.9492 (97.1528)  time: 0.5108  data: 0.0002  max mem: 3450
[2024-01-21 09:04:03 root] (utils.py 307): INFO Test: Total time: 0:01:28 (0.5277 s / it)
[2024-01-21 09:04:03 root] (engine.py 118): INFO * Acc@1 84.687 Acc@5 97.153 loss 0.747 flops 34.832
[2024-01-21 09:04:03 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-01-21 09:04:33 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:04:37 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 09:04:37 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:04:41 root] (main_tome.py 286): INFO Creating model: vit_deit_base_patch16_224
[2024-01-21 09:04:44 root] (main_pitome.py 370): INFO number of params: 304326632
[2024-01-21 09:04:46 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:06  flops: 34.8324 (34.8324)  loss: 0.8319 (0.8319)  acc1: 84.2466 (84.2466)  acc5: 95.8904 (95.8904)  time: 1.8347  data: 0.0007  max mem: 3396
[2024-01-21 09:04:52 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 34.8324 (34.8324)  loss: 0.7257 (0.7371)  acc1: 84.9498 (85.2424)  acc5: 96.9595 (97.0052)  time: 0.7149  data: 0.0002  max mem: 3450
[2024-01-21 09:04:57 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:32  flops: 34.8324 (34.8324)  loss: 0.7149 (0.7370)  acc1: 85.6164 (85.3560)  acc5: 96.9388 (97.1036)  time: 0.5666  data: 0.0002  max mem: 3450
[2024-01-21 09:05:15 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:05:19 root] (main_pitome.py 286): INFO Creating model: vit_deit_base_patch16_224
[2024-01-21 09:05:46 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:05:51 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:05:52 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:05:54 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 09:05:59 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:45  flops: 12.9405 (12.9405)  loss: 0.9013 (0.9013)  acc1: 81.1644 (81.1644)  acc5: 92.4658 (92.4658)  time: 5.3049  data: 1.2389  max mem: 2127
[2024-01-21 09:06:02 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:56  flops: 12.9405 (12.9405)  loss: 0.8238 (0.8131)  acc1: 82.0946 (82.1241)  acc5: 94.8980 (94.9058)  time: 0.7441  data: 0.1128  max mem: 2169
[2024-01-21 09:06:05 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:13  flops: 12.9405 (12.9405)  loss: 0.8318 (0.8394)  acc1: 81.4189 (81.7314)  acc5: 94.8980 (95.0324)  time: 0.2611  data: 0.0002  max mem: 2169
[2024-01-21 09:06:07 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:56  flops: 12.9405 (12.9405)  loss: 0.8342 (0.8349)  acc1: 81.3559 (81.8301)  acc5: 95.2542 (95.1890)  time: 0.2347  data: 0.0002  max mem: 2169
[2024-01-21 09:06:09 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8524 (0.8459)  acc1: 81.3559 (81.6669)  acc5: 94.9324 (95.1084)  time: 0.2363  data: 0.0002  max mem: 2169
[2024-01-21 09:06:12 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8566 (0.8388)  acc1: 80.2013 (81.6609)  acc5: 95.1890 (95.2954)  time: 0.2311  data: 0.0002  max mem: 2169
[2024-01-21 09:06:14 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8627 (0.8462)  acc1: 80.4714 (81.4664)  acc5: 95.1890 (95.2121)  time: 0.2246  data: 0.0002  max mem: 2169
[2024-01-21 09:06:16 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8665 (0.8472)  acc1: 80.7432 (81.4526)  acc5: 94.8276 (95.1468)  time: 0.2249  data: 0.0002  max mem: 2169
[2024-01-21 09:06:18 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8523 (0.8506)  acc1: 80.3390 (81.3058)  acc5: 95.2542 (95.1808)  time: 0.2250  data: 0.0002  max mem: 2169
[2024-01-21 09:06:21 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8437 (0.8572)  acc1: 80.0000 (81.1817)  acc5: 95.2381 (95.1248)  time: 0.2298  data: 0.0002  max mem: 2170
[2024-01-21 09:06:23 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8437 (0.8587)  acc1: 80.6780 (81.1597)  acc5: 94.6488 (95.1052)  time: 0.2301  data: 0.0002  max mem: 2170
[2024-01-21 09:06:25 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8697 (0.8604)  acc1: 80.7432 (81.1756)  acc5: 94.5763 (95.0821)  time: 0.2241  data: 0.0002  max mem: 2170
[2024-01-21 09:06:26 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:06:27 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8519 (0.8574)  acc1: 81.3793 (81.2302)  acc5: 94.9153 (95.1174)  time: 0.2237  data: 0.0002  max mem: 2170
[2024-01-21 09:06:30 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8369 (0.8558)  acc1: 81.2287 (81.2262)  acc5: 95.2542 (95.1517)  time: 0.2246  data: 0.0002  max mem: 2170
[2024-01-21 09:06:30 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:06:32 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:06:32 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8522 (0.8539)  acc1: 80.4714 (81.2316)  acc5: 95.2703 (95.1731)  time: 0.2250  data: 0.0002  max mem: 2170
[2024-01-21 09:06:34 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8522 (0.8559)  acc1: 81.0169 (81.2102)  acc5: 95.2381 (95.1519)  time: 0.2290  data: 0.0003  max mem: 2170
[2024-01-21 09:06:36 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8825 (0.8578)  acc1: 81.0811 (81.1837)  acc5: 94.9324 (95.1272)  time: 0.2293  data: 0.0002  max mem: 2170
[2024-01-21 09:06:38 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8518 (0.8560)  acc1: 81.3793 (81.2224)  acc5: 94.9324 (95.1142)  time: 0.2258  data: 0.0002  max mem: 2170
[2024-01-21 09:06:38 root] (utils.py 307): INFO Test: Total time: 0:00:43 (0.2622 s / it)
[2024-01-21 09:06:38 root] (engine.py 118): INFO * Acc@1 81.222 Acc@5 95.114 loss 0.856 flops 12.940
[2024-01-21 09:06:38 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-21 09:06:52 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:06:56 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:06:58 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:07:00 root] (main_pitome.py 370): INFO number of params: 86567656
[2024-01-21 09:07:38 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:07:42 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:07:43 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:07:45 root] (main_pitome.py 370): INFO number of params: 86567656
[2024-01-21 09:07:51 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:30  flops: 12.9405 (12.9405)  loss: 1.5937 (1.5937)  acc1: 76.0274 (76.0274)  acc5: 90.4110 (90.4110)  time: 5.2103  data: 1.7119  max mem: 2127
[2024-01-21 09:07:54 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:56  flops: 12.9405 (12.9405)  loss: 1.4639 (1.4753)  acc1: 76.4505 (76.3816)  acc5: 91.8367 (91.6950)  time: 0.7431  data: 0.1558  max mem: 2169
[2024-01-21 09:07:56 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:13  flops: 12.9405 (12.9405)  loss: 1.4710 (1.4855)  acc1: 75.9450 (76.0032)  acc5: 91.4089 (91.3754)  time: 0.2672  data: 0.0001  max mem: 2169
[2024-01-21 09:07:58 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 1.4727 (1.4868)  acc1: 74.8299 (75.9233)  acc5: 90.8784 (91.3425)  time: 0.2405  data: 0.0004  max mem: 2169
[2024-01-21 09:08:01 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 1.4880 (1.4957)  acc1: 75.8503 (75.9146)  acc5: 90.8784 (91.0694)  time: 0.2430  data: 0.0004  max mem: 2169
[2024-01-21 09:08:03 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 1.5419 (1.4880)  acc1: 75.4266 (76.0048)  acc5: 90.8475 (91.1898)  time: 0.2373  data: 0.0002  max mem: 2169
[2024-01-21 09:08:06 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 1.5149 (1.4960)  acc1: 74.4898 (75.8323)  acc5: 90.7850 (91.0589)  time: 0.2313  data: 0.0002  max mem: 2169
[2024-01-21 09:08:08 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 1.5149 (1.5001)  acc1: 74.4966 (75.8726)  acc5: 90.7216 (91.0538)  time: 0.2311  data: 0.0002  max mem: 2169
[2024-01-21 09:08:10 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 1.5556 (1.5109)  acc1: 74.4966 (75.7197)  acc5: 90.4437 (90.9358)  time: 0.2309  data: 0.0002  max mem: 2169
[2024-01-21 09:08:13 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 1.5892 (1.5187)  acc1: 73.8983 (75.5977)  acc5: 89.6321 (90.8911)  time: 0.2374  data: 0.0002  max mem: 2170
[2024-01-21 09:08:15 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 1.5521 (1.5210)  acc1: 75.4209 (75.6098)  acc5: 89.5973 (90.7982)  time: 0.2380  data: 0.0008  max mem: 2170
[2024-01-21 09:08:17 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 1.5542 (1.5230)  acc1: 75.5102 (75.5421)  acc5: 89.8305 (90.8004)  time: 0.2307  data: 0.0008  max mem: 2170
[2024-01-21 09:08:20 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 1.5243 (1.5200)  acc1: 75.2542 (75.5507)  acc5: 90.8475 (90.8298)  time: 0.2304  data: 0.0003  max mem: 2170
[2024-01-21 09:08:22 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 1.4950 (1.5191)  acc1: 75.8503 (75.5409)  acc5: 90.8475 (90.8502)  time: 0.2311  data: 0.0002  max mem: 2170
[2024-01-21 09:08:24 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 1.5068 (1.5165)  acc1: 74.9153 (75.5429)  acc5: 90.5724 (90.8782)  time: 0.2308  data: 0.0002  max mem: 2170
[2024-01-21 09:08:26 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 1.5068 (1.5172)  acc1: 75.1701 (75.5728)  acc5: 91.1864 (90.8637)  time: 0.2304  data: 0.0002  max mem: 2170
[2024-01-21 09:08:29 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 1.5629 (1.5200)  acc1: 75.1701 (75.5392)  acc5: 90.5085 (90.8259)  time: 0.2315  data: 0.0003  max mem: 2170
[2024-01-21 09:08:30 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 1.4965 (1.5172)  acc1: 76.4310 (75.6115)  acc5: 90.5085 (90.8291)  time: 0.2321  data: 0.0002  max mem: 2170
[2024-01-21 09:08:30 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.2676 s / it)
[2024-01-21 09:08:30 root] (engine.py 118): INFO * Acc@1 75.611 Acc@5 90.829 loss 1.517 flops 12.940
[2024-01-21 09:08:30 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 75.6%
[2024-01-21 09:09:05 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:09:09 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:09:11 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:09:13 root] (main_pitome.py 370): INFO number of params: 86567656
[2024-01-21 09:09:18 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:45  flops: 12.9405 (12.9405)  loss: 1.5681 (1.5681)  acc1: 76.0274 (76.0274)  acc5: 87.6712 (87.6712)  time: 5.2995  data: 0.8786  max mem: 2127
[2024-01-21 09:09:21 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:57  flops: 12.9405 (12.9405)  loss: 1.4719 (1.4753)  acc1: 76.0943 (76.8138)  acc5: 91.2162 (91.2319)  time: 0.7507  data: 0.0800  max mem: 2169
[2024-01-21 09:09:23 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:14  flops: 12.9405 (12.9405)  loss: 1.4974 (1.4867)  acc1: 76.0135 (76.2460)  acc5: 91.1565 (91.4078)  time: 0.2690  data: 0.0002  max mem: 2169
[2024-01-21 09:09:26 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 1.5027 (1.4900)  acc1: 75.7576 (75.9562)  acc5: 92.1502 (91.5507)  time: 0.2424  data: 0.0002  max mem: 2169
[2024-01-21 09:09:28 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 1.5217 (1.4984)  acc1: 75.0853 (75.8318)  acc5: 91.4676 (91.2928)  time: 0.2430  data: 0.0002  max mem: 2169
[2024-01-21 09:09:30 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 1.5217 (1.4927)  acc1: 75.0853 (75.8850)  acc5: 91.2752 (91.4160)  time: 0.2377  data: 0.0002  max mem: 2169
[2024-01-21 09:09:33 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 1.4805 (1.4988)  acc1: 76.0135 (75.8156)  acc5: 91.1864 (91.2872)  time: 0.2317  data: 0.0002  max mem: 2169
[2024-01-21 09:09:35 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 1.4851 (1.5002)  acc1: 76.1905 (75.9348)  acc5: 90.7534 (91.2308)  time: 0.2305  data: 0.0002  max mem: 2169
[2024-01-21 09:09:37 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 1.5188 (1.5091)  acc1: 75.1678 (75.7616)  acc5: 90.5085 (91.1495)  time: 0.2303  data: 0.0002  max mem: 2169
[2024-01-21 09:09:47 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:09:51 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:09:52 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:09:54 root] (main_pitome.py 370): INFO number of params: 86567656
[2024-01-21 09:09:59 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:56  flops: 12.9405 (12.9405)  loss: 1.5935 (1.5935)  acc1: 75.0000 (75.0000)  acc5: 88.0137 (88.0137)  time: 5.3711  data: 1.4606  max mem: 2127
[2024-01-21 09:10:02 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:59  flops: 12.9405 (12.9405)  loss: 1.4282 (1.4502)  acc1: 77.5920 (76.9682)  acc5: 91.7526 (91.6332)  time: 0.7629  data: 0.1329  max mem: 2169
[2024-01-21 09:10:05 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:15  flops: 12.9405 (12.9405)  loss: 1.4635 (1.4643)  acc1: 76.7677 (76.8123)  acc5: 90.8163 (91.3107)  time: 0.2724  data: 0.0002  max mem: 2169
[2024-01-21 09:10:07 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:58  flops: 12.9405 (12.9405)  loss: 1.4987 (1.4712)  acc1: 76.3699 (76.4055)  acc5: 91.2162 (91.5616)  time: 0.2427  data: 0.0002  max mem: 2169
[2024-01-21 09:10:10 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 1.4797 (1.4782)  acc1: 75.5034 (76.4195)  acc5: 91.2162 (91.3342)  time: 0.2430  data: 0.0002  max mem: 2169
[2024-01-21 09:10:12 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 1.4817 (1.4744)  acc1: 75.5034 (76.2510)  acc5: 91.1565 (91.4227)  time: 0.2374  data: 0.0002  max mem: 2169
[2024-01-21 09:10:14 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 1.4817 (1.4821)  acc1: 76.0135 (76.2109)  acc5: 91.4384 (91.3261)  time: 0.2309  data: 0.0002  max mem: 2169
[2024-01-21 09:10:17 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 1.5046 (1.4841)  acc1: 76.1905 (76.2025)  acc5: 90.8163 (91.2164)  time: 0.2315  data: 0.0002  max mem: 2169
[2024-01-21 09:10:19 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 1.5361 (1.4948)  acc1: 75.5932 (76.0634)  acc5: 90.5085 (91.1495)  time: 0.2328  data: 0.0002  max mem: 2169
[2024-01-21 09:10:21 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 1.5722 (1.5023)  acc1: 75.3378 (75.9558)  acc5: 90.6355 (91.1000)  time: 0.2385  data: 0.0002  max mem: 2170
[2024-01-21 09:10:24 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 1.5313 (1.5049)  acc1: 75.8389 (75.9390)  acc5: 90.8163 (91.0300)  time: 0.2385  data: 0.0002  max mem: 2170
[2024-01-21 09:10:26 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 1.5313 (1.5066)  acc1: 75.8389 (75.9060)  acc5: 90.5405 (90.9931)  time: 0.2311  data: 0.0002  max mem: 2170
[2024-01-21 09:10:28 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 1.5320 (1.5045)  acc1: 76.0135 (75.9211)  acc5: 90.5405 (91.0093)  time: 0.2300  data: 0.0002  max mem: 2170
[2024-01-21 09:10:31 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 1.4942 (1.5031)  acc1: 75.8389 (75.9322)  acc5: 90.5405 (91.0420)  time: 0.2318  data: 0.0002  max mem: 2170
[2024-01-21 09:10:33 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 1.4794 (1.5004)  acc1: 75.9322 (75.9353)  acc5: 90.8475 (91.0468)  time: 0.2335  data: 0.0002  max mem: 2170
[2024-01-21 09:10:35 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 1.4836 (1.5024)  acc1: 75.8503 (75.8742)  acc5: 90.8163 (91.0301)  time: 0.2331  data: 0.0002  max mem: 2170
[2024-01-21 09:10:38 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 1.5228 (1.5056)  acc1: 74.7440 (75.8176)  acc5: 90.5085 (90.9925)  time: 0.2327  data: 0.0002  max mem: 2170
[2024-01-21 09:10:39 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 1.5177 (1.5041)  acc1: 75.8503 (75.8416)  acc5: 90.6040 (90.9941)  time: 0.2335  data: 0.0002  max mem: 2170
[2024-01-21 09:10:39 root] (utils.py 307): INFO Test: Total time: 0:00:45 (0.2699 s / it)
[2024-01-21 09:10:39 root] (engine.py 118): INFO * Acc@1 75.842 Acc@5 90.994 loss 1.504 flops 12.940
[2024-01-21 09:10:39 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 75.8%
[2024-01-21 09:11:51 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:11:55 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:11:56 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:11:59 root] (main_pitome.py 370): INFO number of params: 86567656
[2024-01-21 09:12:04 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:51  flops: 12.9405 (12.9405)  loss: 1.5671 (1.5671)  acc1: 75.3425 (75.3425)  acc5: 87.6712 (87.6712)  time: 5.3358  data: 1.8519  max mem: 2127
[2024-01-21 09:12:07 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:58  flops: 12.9405 (12.9405)  loss: 1.4633 (1.4761)  acc1: 77.0270 (76.9373)  acc5: 91.4676 (91.0157)  time: 0.7538  data: 0.1685  max mem: 2169
[2024-01-21 09:12:09 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:14  flops: 12.9405 (12.9405)  loss: 1.4955 (1.4970)  acc1: 76.2542 (76.0841)  acc5: 90.8163 (90.8738)  time: 0.2678  data: 0.0002  max mem: 2169
[2024-01-21 09:12:12 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 1.5436 (1.5051)  acc1: 74.1497 (76.1205)  acc5: 89.8649 (90.8164)  time: 0.2408  data: 0.0002  max mem: 2169
[2024-01-21 09:12:14 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 1.5288 (1.5097)  acc1: 75.7576 (76.0636)  acc5: 90.2027 (90.7548)  time: 0.2458  data: 0.0002  max mem: 2169
[2024-01-21 09:12:15 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:12:17 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 1.5175 (1.4981)  acc1: 75.7576 (76.1179)  acc5: 90.5405 (90.9236)  time: 0.2411  data: 0.0002  max mem: 2169
[2024-01-21 09:12:19 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 1.4920 (1.5085)  acc1: 75.5172 (75.9604)  acc5: 90.5405 (90.7861)  time: 0.2336  data: 0.0002  max mem: 2169
[2024-01-21 09:12:19 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:12:21 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:12:21 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 1.5319 (1.5126)  acc1: 75.5102 (75.9061)  acc5: 90.4762 (90.7574)  time: 0.2368  data: 0.0002  max mem: 2169
[2024-01-21 09:12:24 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 1.5662 (1.5210)  acc1: 74.9153 (75.7784)  acc5: 90.5724 (90.6927)  time: 0.2464  data: 0.0003  max mem: 2169
[2024-01-21 09:12:25 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 09:12:26 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 1.6005 (1.5317)  acc1: 74.0741 (75.4970)  acc5: 90.4110 (90.6449)  time: 0.2504  data: 0.0002  max mem: 2170
[2024-01-21 09:12:29 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 1.5257 (1.5331)  acc1: 75.7576 (75.5224)  acc5: 90.4110 (90.6336)  time: 0.2451  data: 0.0002  max mem: 2170
[2024-01-21 09:12:31 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 1.5086 (1.5319)  acc1: 75.8389 (75.5299)  acc5: 90.1695 (90.6475)  time: 0.2503  data: 0.0002  max mem: 2170
[2024-01-21 09:12:33 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:21:41  flops: 12.9405 (12.9405)  loss: 0.9028 (0.9028)  acc1: 80.8219 (80.8219)  acc5: 92.4658 (92.4658)  time: 7.7964  data: 0.5092  max mem: 2127
[2024-01-21 09:12:35 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:14  flops: 12.9405 (12.9405)  loss: 1.5078 (1.5299)  acc1: 76.2069 (75.5788)  acc5: 90.6574 (90.6782)  time: 0.3383  data: 0.0002  max mem: 2170
[2024-01-21 09:12:38 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:11  flops: 12.9405 (12.9405)  loss: 1.5327 (1.5298)  acc1: 75.5102 (75.6213)  acc5: 90.6574 (90.6869)  time: 0.3490  data: 0.0002  max mem: 2170
[2024-01-21 09:12:57 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:13:01 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:13:02 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:13:05 root] (main_pitome.py 370): INFO number of params: 86567656
[2024-01-21 09:13:10 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:15:00  flops: 12.9405 (12.9405)  loss: 1.5173 (1.5173)  acc1: 75.0000 (75.0000)  acc5: 88.3562 (88.3562)  time: 5.3948  data: 1.6591  max mem: 2127
[2024-01-21 09:13:13 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:59  flops: 12.9405 (12.9405)  loss: 1.4321 (1.4413)  acc1: 77.3196 (77.1843)  acc5: 91.4089 (91.1392)  time: 0.7588  data: 0.1510  max mem: 2169
[2024-01-21 09:13:15 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:15  flops: 12.9405 (12.9405)  loss: 1.4865 (1.4752)  acc1: 76.3514 (76.7314)  acc5: 90.8784 (90.9061)  time: 0.2682  data: 0.0002  max mem: 2169
[2024-01-21 09:13:18 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:58  flops: 12.9405 (12.9405)  loss: 1.5088 (1.4752)  acc1: 75.7576 (76.7781)  acc5: 90.8784 (91.1562)  time: 0.2443  data: 0.0002  max mem: 2169
[2024-01-21 09:13:20 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 1.5088 (1.4833)  acc1: 75.9322 (76.6512)  acc5: 91.1263 (91.0776)  time: 0.2463  data: 0.0002  max mem: 2169
[2024-01-21 09:13:23 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 1.4629 (1.4730)  acc1: 75.6014 (76.7035)  acc5: 91.2752 (91.2829)  time: 0.2383  data: 0.0003  max mem: 2169
[2024-01-21 09:13:46 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:13:49 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:13:51 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:13:53 root] (main_pitome.py 370): INFO number of params: 86567656
[2024-01-21 09:13:58 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:57  flops: 12.9405 (12.9405)  loss: 1.5537 (1.5537)  acc1: 77.0548 (77.0548)  acc5: 88.6986 (88.6986)  time: 5.3772  data: 1.6649  max mem: 2126
[2024-01-21 09:14:01 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:59  flops: 12.9405 (12.9405)  loss: 1.4263 (1.4338)  acc1: 77.0270 (77.0299)  acc5: 92.2297 (91.9111)  time: 0.7616  data: 0.1515  max mem: 2169
[2024-01-21 09:14:04 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:15  flops: 12.9405 (12.9405)  loss: 1.4334 (1.4512)  acc1: 76.8966 (76.9579)  acc5: 91.4966 (91.5372)  time: 0.2726  data: 0.0002  max mem: 2169
[2024-01-21 09:14:06 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:58  flops: 12.9405 (12.9405)  loss: 1.4773 (1.4641)  acc1: 76.7677 (76.7562)  acc5: 91.0959 (91.4192)  time: 0.2458  data: 0.0002  max mem: 2169
[2024-01-21 09:14:14 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:14:18 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:14:19 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:14:21 root] (main_pitome.py 370): INFO number of params: 86567656
[2024-01-21 09:14:27 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:56  flops: 12.9405 (12.9405)  loss: 1.3626 (1.3626)  acc1: 75.6849 (75.6849)  acc5: 90.7534 (90.7534)  time: 5.3686  data: 1.4426  max mem: 2126
[2024-01-21 09:14:30 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:01  flops: 12.9405 (12.9405)  loss: 1.2819 (1.3000)  acc1: 77.5510 (77.9253)  acc5: 92.5170 (92.4051)  time: 0.7732  data: 0.1313  max mem: 2169
[2024-01-21 09:14:32 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:17  flops: 12.9405 (12.9405)  loss: 1.3472 (1.3215)  acc1: 76.7918 (77.6214)  acc5: 91.8919 (92.2330)  time: 0.2864  data: 0.0002  max mem: 2169
[2024-01-21 09:15:22 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:15:26 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 09:15:38 root] (main_pitome.py 370): INFO number of params: 632045800
[2024-01-21 09:15:41 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:06:49  flops: 80.6285 (80.6285)  loss: 0.8129 (0.8129)  acc1: 85.9589 (85.9589)  acc5: 95.8904 (95.8904)  time: 2.4549  data: 0.0008  max mem: 6079
[2024-01-21 09:15:53 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:23  flops: 80.6285 (80.6285)  loss: 0.6966 (0.7298)  acc1: 85.8586 (85.7672)  acc5: 97.2789 (97.2214)  time: 1.2987  data: 0.0004  max mem: 6165
[2024-01-21 09:16:04 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:02:56  flops: 80.6285 (80.6285)  loss: 0.6961 (0.7302)  acc1: 85.4730 (85.6149)  acc5: 97.2789 (97.3301)  time: 1.1397  data: 0.0003  max mem: 6165
[2024-01-21 09:16:15 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:02:40  flops: 80.6285 (80.6285)  loss: 0.7184 (0.7249)  acc1: 85.3242 (85.7205)  acc5: 97.6351 (97.4795)  time: 1.0974  data: 0.0002  max mem: 6165
[2024-01-21 09:16:26 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:26  flops: 80.6285 (80.6285)  loss: 0.7376 (0.7310)  acc1: 84.9829 (85.6563)  acc5: 97.3154 (97.4094)  time: 1.1022  data: 0.0004  max mem: 6165
[2024-01-21 09:16:36 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:13  flops: 80.6285 (80.6285)  loss: 0.7273 (0.7271)  acc1: 85.3741 (85.6734)  acc5: 97.2881 (97.4448)  time: 1.0956  data: 0.0004  max mem: 6165
[2024-01-21 09:16:47 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:00  flops: 80.6285 (80.6285)  loss: 0.7273 (0.7308)  acc1: 85.5670 (85.5974)  acc5: 97.2509 (97.3722)  time: 1.0833  data: 0.0002  max mem: 6165
[2024-01-21 09:16:58 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:49  flops: 80.6285 (80.6285)  loss: 0.7428 (0.7358)  acc1: 85.2234 (85.4117)  acc5: 96.9178 (97.3176)  time: 1.0854  data: 0.0002  max mem: 6165
[2024-01-21 09:17:09 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:37  flops: 80.6285 (80.6285)  loss: 0.7462 (0.7378)  acc1: 84.1216 (85.2743)  acc5: 96.9492 (97.3348)  time: 1.0898  data: 0.0002  max mem: 6165
[2024-01-21 09:17:20 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:26  flops: 80.6285 (80.6285)  loss: 0.7589 (0.7418)  acc1: 83.8384 (85.1356)  acc5: 97.2789 (97.3479)  time: 1.0978  data: 0.0002  max mem: 6165
[2024-01-21 09:17:31 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:14  flops: 80.6285 (80.6285)  loss: 0.7551 (0.7414)  acc1: 84.8993 (85.2012)  acc5: 97.2789 (97.3359)  time: 1.0993  data: 0.0002  max mem: 6165
[2024-01-21 09:17:42 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:03  flops: 80.6285 (80.6285)  loss: 0.7538 (0.7427)  acc1: 85.8108 (85.2494)  acc5: 97.2696 (97.3270)  time: 1.0884  data: 0.0002  max mem: 6165
[2024-01-21 09:17:53 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:52  flops: 80.6285 (80.6285)  loss: 0.7160 (0.7392)  acc1: 85.8131 (85.3355)  acc5: 97.2881 (97.3511)  time: 1.0848  data: 0.0002  max mem: 6165
[2024-01-21 09:18:04 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:41  flops: 80.6285 (80.6285)  loss: 0.6935 (0.7378)  acc1: 86.1487 (85.3981)  acc5: 97.6351 (97.3724)  time: 1.0888  data: 0.0002  max mem: 6165
[2024-01-21 09:18:15 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:29  flops: 80.6285 (80.6285)  loss: 0.7051 (0.7360)  acc1: 86.4865 (85.4471)  acc5: 97.6271 (97.3831)  time: 1.0902  data: 0.0002  max mem: 6165
[2024-01-21 09:18:24 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:18:25 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:18  flops: 80.6285 (80.6285)  loss: 0.7199 (0.7381)  acc1: 85.6655 (85.4107)  acc5: 97.6271 (97.3871)  time: 1.0866  data: 0.0002  max mem: 6165
[2024-01-21 09:18:28 root] (main_tome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 09:18:37 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:07  flops: 80.6285 (80.6285)  loss: 0.7683 (0.7395)  acc1: 84.7458 (85.3754)  acc5: 97.2881 (97.3644)  time: 1.1022  data: 0.0007  max mem: 6165
[2024-01-21 09:18:40 root] (main_tome.py 370): INFO number of params: 632045800
[2024-01-21 09:18:43 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 80.6285 (80.6285)  loss: 0.7159 (0.7382)  acc1: 85.3741 (85.3974)  acc5: 96.9595 (97.3565)  time: 1.1166  data: 0.0007  max mem: 6165
[2024-01-21 09:18:43 root] (utils.py 307): INFO Test: Total time: 0:03:05 (1.1083 s / it)
[2024-01-21 09:18:43 root] (engine.py 118): INFO * Acc@1 85.397 Acc@5 97.356 loss 0.738 flops 80.629
[2024-01-21 09:18:43 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-01-21 09:18:45 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:42  flops: 80.6285 (80.6285)  loss: 0.7506 (0.7506)  acc1: 85.6164 (85.6164)  acc5: 96.5753 (96.5753)  time: 4.9225  data: 0.0007  max mem: 6079
[2024-01-21 09:18:57 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:59  flops: 80.6285 (80.6285)  loss: 0.6568 (0.6745)  acc1: 85.4730 (85.5202)  acc5: 97.6190 (97.3140)  time: 1.5240  data: 0.0002  max mem: 6165
[2024-01-21 09:19:08 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:03:13  flops: 80.6285 (80.6285)  loss: 0.6481 (0.6731)  acc1: 85.4730 (85.3398)  acc5: 97.5862 (97.3786)  time: 1.1387  data: 0.0002  max mem: 6165
[2024-01-21 09:19:19 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:02:50  flops: 80.6285 (80.6285)  loss: 0.6507 (0.6689)  acc1: 85.5219 (85.2603)  acc5: 97.5862 (97.4356)  time: 1.0946  data: 0.0010  max mem: 6165
[2024-01-21 09:19:30 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:33  flops: 80.6285 (80.6285)  loss: 0.6730 (0.6738)  acc1: 85.4730 (85.2673)  acc5: 97.2973 (97.4176)  time: 1.0979  data: 0.0010  max mem: 6165
[2024-01-21 09:19:40 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:18  flops: 80.6285 (80.6285)  loss: 0.6745 (0.6681)  acc1: 85.4730 (85.4605)  acc5: 97.5945 (97.5180)  time: 1.0890  data: 0.0004  max mem: 6165
[2024-01-21 09:19:51 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:04  flops: 80.6285 (80.6285)  loss: 0.6721 (0.6700)  acc1: 85.5172 (85.3969)  acc5: 97.6190 (97.4780)  time: 1.0760  data: 0.0004  max mem: 6165
[2024-01-21 09:20:02 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:51  flops: 80.6285 (80.6285)  loss: 0.6721 (0.6738)  acc1: 85.1852 (85.3208)  acc5: 97.3154 (97.4037)  time: 1.0767  data: 0.0002  max mem: 6165
[2024-01-21 09:20:13 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:39  flops: 80.6285 (80.6285)  loss: 0.6793 (0.6775)  acc1: 84.3003 (85.2072)  acc5: 97.3154 (97.4186)  time: 1.0794  data: 0.0002  max mem: 6165
[2024-01-21 09:20:24 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:27  flops: 80.6285 (80.6285)  loss: 0.7007 (0.6809)  acc1: 83.9465 (85.1729)  acc5: 97.3064 (97.4412)  time: 1.0869  data: 0.0002  max mem: 6165
[2024-01-21 09:20:34 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:15  flops: 80.6285 (80.6285)  loss: 0.6947 (0.6814)  acc1: 84.8993 (85.2214)  acc5: 97.2973 (97.4367)  time: 1.0883  data: 0.0002  max mem: 6165
[2024-01-21 09:20:45 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:04  flops: 80.6285 (80.6285)  loss: 0.6916 (0.6823)  acc1: 85.4730 (85.2769)  acc5: 97.2973 (97.4401)  time: 1.0765  data: 0.0002  max mem: 6165
[2024-01-21 09:20:56 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:52  flops: 80.6285 (80.6285)  loss: 0.6562 (0.6791)  acc1: 85.8621 (85.3327)  acc5: 97.6351 (97.4633)  time: 1.0730  data: 0.0002  max mem: 6165
[2024-01-21 09:21:07 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:41  flops: 80.6285 (80.6285)  loss: 0.6370 (0.6774)  acc1: 85.5172 (85.4137)  acc5: 97.6351 (97.4709)  time: 1.0771  data: 0.0002  max mem: 6165
[2024-01-21 09:21:18 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:30  flops: 80.6285 (80.6285)  loss: 0.6375 (0.6767)  acc1: 85.4730 (85.4037)  acc5: 97.6271 (97.4939)  time: 1.0784  data: 0.0003  max mem: 6165
[2024-01-21 09:21:28 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:18  flops: 80.6285 (80.6285)  loss: 0.6955 (0.6797)  acc1: 84.9829 (85.3545)  acc5: 97.2789 (97.4703)  time: 1.0749  data: 0.0004  max mem: 6165
[2024-01-21 09:21:39 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:07  flops: 80.6285 (80.6285)  loss: 0.7071 (0.6806)  acc1: 84.8485 (85.3311)  acc5: 97.2881 (97.4677)  time: 1.0763  data: 0.0002  max mem: 6165
[2024-01-21 09:21:45 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 80.6285 (80.6285)  loss: 0.6732 (0.6793)  acc1: 85.0340 (85.3547)  acc5: 97.6271 (97.4705)  time: 1.0673  data: 0.0002  max mem: 6165
[2024-01-21 09:21:45 root] (utils.py 307): INFO Test: Total time: 0:03:05 (1.1098 s / it)
[2024-01-21 09:21:45 root] (engine.py 118): INFO * Acc@1 85.355 Acc@5 97.471 loss 0.679 flops 80.629
[2024-01-21 09:21:45 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-01-21 09:21:57 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.975, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:22:01 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 09:22:14 root] (main_pitome.py 370): INFO number of params: 632045800
[2024-01-21 09:22:17 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:07:59  flops: 113.2882 (113.2882)  loss: 0.6996 (0.6996)  acc1: 86.6438 (86.6438)  acc5: 96.9178 (96.9178)  time: 2.8734  data: 0.0009  max mem: 6079
[2024-01-21 09:22:50 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:22:54 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 09:23:07 root] (main_pitome.py 370): INFO number of params: 632045800
[2024-01-21 09:23:09 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:07:24  flops: 95.0005 (95.0005)  loss: 0.7492 (0.7492)  acc1: 85.9589 (85.9589)  acc5: 95.8904 (95.8904)  time: 2.6646  data: 0.0007  max mem: 6079
[2024-01-21 09:23:23 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:53  flops: 95.0005 (95.0005)  loss: 0.6580 (0.6671)  acc1: 85.9589 (86.1068)  acc5: 97.6190 (97.2831)  time: 1.4897  data: 0.0002  max mem: 6165
[2024-01-21 09:23:36 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:03:24  flops: 95.0005 (95.0005)  loss: 0.6403 (0.6631)  acc1: 86.5320 (86.3107)  acc5: 97.6351 (97.5566)  time: 1.3281  data: 0.0002  max mem: 6165
[2024-01-21 09:23:49 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:03:06  flops: 95.0005 (95.0005)  loss: 0.6403 (0.6562)  acc1: 86.4865 (86.2137)  acc5: 97.9522 (97.6877)  time: 1.2878  data: 0.0002  max mem: 6165
[2024-01-21 09:24:02 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:50  flops: 95.0005 (95.0005)  loss: 0.6692 (0.6624)  acc1: 86.1953 (86.2109)  acc5: 97.9522 (97.6577)  time: 1.2947  data: 0.0002  max mem: 6165
[2024-01-21 09:24:15 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:35  flops: 95.0005 (95.0005)  loss: 0.6675 (0.6570)  acc1: 86.4407 (86.3322)  acc5: 97.6431 (97.7242)  time: 1.2870  data: 0.0002  max mem: 6165
[2024-01-21 09:24:27 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:21  flops: 95.0005 (95.0005)  loss: 0.6666 (0.6615)  acc1: 86.0544 (86.1764)  acc5: 97.6431 (97.6896)  time: 1.2746  data: 0.0002  max mem: 6165
[2024-01-21 09:24:40 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:02:07  flops: 95.0005 (95.0005)  loss: 0.6694 (0.6648)  acc1: 85.6164 (86.1050)  acc5: 97.6190 (97.6953)  time: 1.2765  data: 0.0008  max mem: 6165
[2024-01-21 09:24:53 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:54  flops: 95.0005 (95.0005)  loss: 0.6877 (0.6686)  acc1: 85.0847 (85.9825)  acc5: 97.6190 (97.7036)  time: 1.2797  data: 0.0008  max mem: 6165
[2024-01-21 09:25:06 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:40  flops: 95.0005 (95.0005)  loss: 0.7003 (0.6724)  acc1: 85.0847 (85.9114)  acc5: 97.6431 (97.7023)  time: 1.2887  data: 0.0002  max mem: 6165
[2024-01-21 09:25:19 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:27  flops: 95.0005 (95.0005)  loss: 0.6691 (0.6720)  acc1: 86.2416 (86.0176)  acc5: 97.6351 (97.7122)  time: 1.2900  data: 0.0002  max mem: 6165
[2024-01-21 09:25:31 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:14  flops: 95.0005 (95.0005)  loss: 0.6661 (0.6721)  acc1: 86.2416 (86.0721)  acc5: 97.6351 (97.7093)  time: 1.2767  data: 0.0002  max mem: 6165
[2024-01-21 09:25:44 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:01:01  flops: 95.0005 (95.0005)  loss: 0.6471 (0.6694)  acc1: 86.2069 (86.1156)  acc5: 97.9522 (97.7327)  time: 1.2733  data: 0.0002  max mem: 6165
[2024-01-21 09:25:57 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:48  flops: 95.0005 (95.0005)  loss: 0.6231 (0.6682)  acc1: 86.5052 (86.1755)  acc5: 97.9798 (97.7404)  time: 1.2782  data: 0.0002  max mem: 6165
[2024-01-21 09:26:10 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:35  flops: 95.0005 (95.0005)  loss: 0.6345 (0.6672)  acc1: 86.8243 (86.1958)  acc5: 97.9730 (97.7611)  time: 1.2799  data: 0.0002  max mem: 6165
[2024-01-21 09:26:22 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:22  flops: 95.0005 (95.0005)  loss: 0.6511 (0.6694)  acc1: 85.7143 (86.1393)  acc5: 97.9661 (97.7513)  time: 1.2755  data: 0.0002  max mem: 6165
[2024-01-21 09:26:35 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:09  flops: 95.0005 (95.0005)  loss: 0.6918 (0.6707)  acc1: 85.8108 (86.0965)  acc5: 97.6271 (97.7460)  time: 1.2780  data: 0.0002  max mem: 6165
[2024-01-21 09:26:43 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 95.0005 (95.0005)  loss: 0.6535 (0.6697)  acc1: 86.3014 (86.1001)  acc5: 97.6271 (97.7434)  time: 1.2673  data: 0.0002  max mem: 6165
[2024-01-21 09:26:43 root] (utils.py 307): INFO Test: Total time: 0:03:36 (1.2937 s / it)
[2024-01-21 09:26:43 root] (engine.py 118): INFO * Acc@1 86.100 Acc@5 97.743 loss 0.670 flops 95.000
[2024-01-21 09:26:43 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 86.1%
[2024-01-21 09:27:47 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:27:54 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:27:58 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 09:28:11 root] (main_pitome.py 370): INFO number of params: 632045800
[2024-01-21 09:28:14 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:07:13  flops: 95.0005 (95.0005)  loss: 0.7350 (0.7350)  acc1: 86.6438 (86.6438)  acc5: 96.9178 (96.9178)  time: 2.5977  data: 0.0008  max mem: 6079
[2024-01-21 09:28:27 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:52  flops: 95.0005 (95.0005)  loss: 0.6430 (0.6595)  acc1: 86.5979 (86.5082)  acc5: 97.9592 (97.7153)  time: 1.4798  data: 0.0002  max mem: 6165
[2024-01-21 09:28:40 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:03:23  flops: 95.0005 (95.0005)  loss: 0.6377 (0.6552)  acc1: 86.4865 (86.3754)  acc5: 97.9381 (97.7023)  time: 1.3238  data: 0.0002  max mem: 6165
[2024-01-21 09:28:53 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:03:05  flops: 95.0005 (95.0005)  loss: 0.6209 (0.6499)  acc1: 85.8586 (86.4000)  acc5: 97.9522 (97.7863)  time: 1.2834  data: 0.0002  max mem: 6165
[2024-01-21 09:29:06 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:50  flops: 95.0005 (95.0005)  loss: 0.6744 (0.6561)  acc1: 86.1487 (86.3847)  acc5: 97.9522 (97.7239)  time: 1.2909  data: 0.0002  max mem: 6165
[2024-01-21 09:29:19 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:35  flops: 95.0005 (95.0005)  loss: 0.6503 (0.6486)  acc1: 86.6894 (86.5385)  acc5: 97.6351 (97.7908)  time: 1.2847  data: 0.0002  max mem: 6165
[2024-01-21 09:29:31 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:20  flops: 95.0005 (95.0005)  loss: 0.6450 (0.6534)  acc1: 86.7347 (86.4046)  acc5: 97.6351 (97.7063)  time: 1.2728  data: 0.0008  max mem: 6165
[2024-01-21 09:29:44 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:02:07  flops: 95.0005 (95.0005)  loss: 0.6584 (0.6570)  acc1: 85.9589 (86.3106)  acc5: 97.2789 (97.6666)  time: 1.2755  data: 0.0008  max mem: 6165
[2024-01-21 09:29:57 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:53  flops: 95.0005 (95.0005)  loss: 0.6766 (0.6599)  acc1: 85.4237 (86.1836)  acc5: 97.6190 (97.6700)  time: 1.2797  data: 0.0010  max mem: 6165
[2024-01-21 09:30:10 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:40  flops: 95.0005 (95.0005)  loss: 0.6917 (0.6639)  acc1: 84.9498 (86.0420)  acc5: 97.6351 (97.6873)  time: 1.2870  data: 0.0010  max mem: 6165
[2024-01-21 09:30:23 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:27  flops: 95.0005 (95.0005)  loss: 0.6798 (0.6640)  acc1: 86.2416 (86.1385)  acc5: 97.6431 (97.6853)  time: 1.2885  data: 0.0002  max mem: 6165
[2024-01-21 09:30:35 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:14  flops: 95.0005 (95.0005)  loss: 0.6798 (0.6655)  acc1: 86.4865 (86.1578)  acc5: 97.6027 (97.6634)  time: 1.2769  data: 0.0002  max mem: 6165
[2024-01-21 09:30:48 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:01:01  flops: 95.0005 (95.0005)  loss: 0.6435 (0.6627)  acc1: 86.5979 (86.2138)  acc5: 97.6271 (97.6850)  time: 1.2731  data: 0.0002  max mem: 6165
[2024-01-21 09:31:01 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:48  flops: 95.0005 (95.0005)  loss: 0.6157 (0.6612)  acc1: 87.1972 (86.2429)  acc5: 97.9730 (97.7145)  time: 1.2787  data: 0.0002  max mem: 6165
[2024-01-21 09:31:14 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:35  flops: 95.0005 (95.0005)  loss: 0.6202 (0.6595)  acc1: 85.4730 (86.2102)  acc5: 97.9798 (97.7466)  time: 1.2810  data: 0.0002  max mem: 6165
[2024-01-21 09:31:27 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:22  flops: 95.0005 (95.0005)  loss: 0.6535 (0.6618)  acc1: 85.4730 (86.1888)  acc5: 97.6271 (97.7423)  time: 1.2759  data: 0.0002  max mem: 6165
[2024-01-21 09:31:39 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:09  flops: 95.0005 (95.0005)  loss: 0.6783 (0.6632)  acc1: 86.2416 (86.1408)  acc5: 97.6271 (97.7376)  time: 1.2777  data: 0.0002  max mem: 6165
[2024-01-21 09:31:47 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 95.0005 (95.0005)  loss: 0.6480 (0.6618)  acc1: 86.3481 (86.1673)  acc5: 97.6351 (97.7332)  time: 1.2656  data: 0.0002  max mem: 6165
[2024-01-21 09:31:47 root] (utils.py 307): INFO Test: Total time: 0:03:35 (1.2919 s / it)
[2024-01-21 09:31:47 root] (engine.py 118): INFO * Acc@1 86.167 Acc@5 97.733 loss 0.662 flops 95.000
[2024-01-21 09:31:47 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 86.2%
[2024-01-21 09:31:48 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:31:52 root] (main_tome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 09:32:04 root] (main_tome.py 370): INFO number of params: 632045800
[2024-01-21 09:32:07 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:07:02  flops: 95.0005 (95.0005)  loss: 0.6940 (0.6940)  acc1: 85.9589 (85.9589)  acc5: 97.2603 (97.2603)  time: 2.5310  data: 0.0008  max mem: 6079
[2024-01-21 09:32:21 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:50  flops: 95.0005 (95.0005)  loss: 0.6321 (0.6320)  acc1: 86.4865 (86.5082)  acc5: 97.2789 (97.4684)  time: 1.4703  data: 0.0002  max mem: 6165
[2024-01-21 09:32:33 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:03:22  flops: 95.0005 (95.0005)  loss: 0.6151 (0.6307)  acc1: 86.3946 (86.3754)  acc5: 97.2789 (97.5890)  time: 1.3204  data: 0.0002  max mem: 6165
[2024-01-21 09:32:46 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:03:04  flops: 95.0005 (95.0005)  loss: 0.6053 (0.6249)  acc1: 86.0544 (86.3452)  acc5: 97.6351 (97.6767)  time: 1.2786  data: 0.0002  max mem: 6165
[2024-01-21 09:32:59 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:49  flops: 95.0005 (95.0005)  loss: 0.6315 (0.6324)  acc1: 86.3014 (86.3185)  acc5: 97.6351 (97.6246)  time: 1.2835  data: 0.0002  max mem: 6165
[2024-01-21 09:33:12 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:34  flops: 95.0005 (95.0005)  loss: 0.6334 (0.6280)  acc1: 86.4407 (86.4054)  acc5: 97.6351 (97.7176)  time: 1.2751  data: 0.0002  max mem: 6165
[2024-01-21 09:33:24 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:20  flops: 95.0005 (95.0005)  loss: 0.6304 (0.6308)  acc1: 86.0544 (86.3267)  acc5: 97.6431 (97.6951)  time: 1.2623  data: 0.0002  max mem: 6165
[2024-01-21 09:33:37 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:02:06  flops: 95.0005 (95.0005)  loss: 0.6304 (0.6342)  acc1: 85.4730 (86.2054)  acc5: 97.6431 (97.6858)  time: 1.2644  data: 0.0002  max mem: 6165
[2024-01-21 09:33:50 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:53  flops: 95.0005 (95.0005)  loss: 0.6473 (0.6375)  acc1: 85.1351 (86.0998)  acc5: 97.6351 (97.6952)  time: 1.2680  data: 0.0002  max mem: 6165
[2024-01-21 09:34:02 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:39  flops: 95.0005 (95.0005)  loss: 0.6568 (0.6408)  acc1: 84.5118 (85.9637)  acc5: 97.6351 (97.7060)  time: 1.2762  data: 0.0002  max mem: 6165
[2024-01-21 09:34:15 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:26  flops: 95.0005 (95.0005)  loss: 0.6524 (0.6419)  acc1: 85.7143 (85.9941)  acc5: 97.6431 (97.7054)  time: 1.2781  data: 0.0002  max mem: 6165
[2024-01-21 09:34:28 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:13  flops: 95.0005 (95.0005)  loss: 0.6614 (0.6423)  acc1: 86.4407 (86.0201)  acc5: 97.5862 (97.7093)  time: 1.2657  data: 0.0002  max mem: 6165
[2024-01-21 09:34:40 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:01:00  flops: 95.0005 (95.0005)  loss: 0.6165 (0.6399)  acc1: 86.4407 (86.0594)  acc5: 97.6589 (97.7215)  time: 1.2616  data: 0.0002  max mem: 6165
[2024-01-21 09:34:53 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:47  flops: 95.0005 (95.0005)  loss: 0.5919 (0.6377)  acc1: 86.2876 (86.1393)  acc5: 97.6589 (97.7378)  time: 1.2667  data: 0.0002  max mem: 6165
[2024-01-21 09:35:06 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:34  flops: 95.0005 (95.0005)  loss: 0.6074 (0.6367)  acc1: 85.8108 (86.1187)  acc5: 97.9661 (97.7515)  time: 1.2686  data: 0.0002  max mem: 6165
[2024-01-21 09:35:18 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:21  flops: 95.0005 (95.0005)  loss: 0.6424 (0.6400)  acc1: 85.4237 (86.0426)  acc5: 97.6190 (97.7379)  time: 1.2642  data: 0.0002  max mem: 6165
[2024-01-21 09:35:31 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:08  flops: 95.0005 (95.0005)  loss: 0.6737 (0.6414)  acc1: 85.0340 (85.9700)  acc5: 97.6190 (97.7334)  time: 1.2660  data: 0.0002  max mem: 6165
[2024-01-21 09:35:38 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 95.0005 (95.0005)  loss: 0.6226 (0.6399)  acc1: 85.8108 (85.9962)  acc5: 97.6431 (97.7292)  time: 1.2550  data: 0.0002  max mem: 6165
[2024-01-21 09:35:38 root] (utils.py 307): INFO Test: Total time: 0:03:34 (1.2818 s / it)
[2024-01-21 09:35:38 root] (engine.py 118): INFO * Acc@1 85.996 Acc@5 97.729 loss 0.640 flops 95.000
[2024-01-21 09:35:38 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 86.0%
[2024-01-21 09:41:20 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch14_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:41:23 root] (main_tome.py 286): INFO Creating model: vit_small_patch14_224
[2024-01-21 09:42:12 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:42:16 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:42:17 timm.models.hub] (hub.py 46): INFO Downloading: "https://storage.googleapis.com/vit_models/augreg/S_16-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz" to /media/caduser/MyBook/chau//.vision_ckts/checkpoints/S_16-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz

[2024-01-21 09:42:45 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:42:49 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:42:50 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:42:56 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:28  flops: 3.6357 (3.6357)  loss: 2.1847 (2.1847)  acc1: 52.7397 (52.7397)  acc5: 78.7671 (78.7671)  time: 5.9211  data: 1.4310  max mem: 1078
[2024-01-21 09:42:58 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:45  flops: 3.6357 (3.6357)  loss: 2.1775 (2.1450)  acc1: 55.0676 (54.3069)  acc5: 78.7671 (78.4810)  time: 0.6747  data: 0.1302  max mem: 1102
[2024-01-21 09:42:59 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:00  flops: 3.6357 (3.6357)  loss: 2.1152 (2.1328)  acc1: 55.0676 (54.5146)  acc5: 79.2517 (79.2718)  time: 0.1328  data: 0.0002  max mem: 1102
[2024-01-21 09:43:00 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.6357 (3.6357)  loss: 2.1308 (2.1412)  acc1: 53.4014 (54.4658)  acc5: 79.3919 (79.0575)  time: 0.1148  data: 0.0001  max mem: 1102
[2024-01-21 09:43:01 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.6357 (3.6357)  loss: 2.1247 (2.1280)  acc1: 54.5763 (54.5771)  acc5: 79.3919 (79.4074)  time: 0.1168  data: 0.0011  max mem: 1102
[2024-01-21 09:43:03 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.6357 (3.6357)  loss: 2.0993 (2.1237)  acc1: 54.6980 (54.8509)  acc5: 80.3448 (79.6047)  time: 0.1437  data: 0.0303  max mem: 1102
[2024-01-21 09:43:05 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.6357 (3.6357)  loss: 2.1056 (2.1247)  acc1: 55.1020 (54.8881)  acc5: 79.2517 (79.5624)  time: 0.1790  data: 0.0701  max mem: 1102
[2024-01-21 09:43:07 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.6357 (3.6357)  loss: 2.1648 (2.1307)  acc1: 54.1379 (54.6619)  acc5: 80.0676 (79.6452)  time: 0.1823  data: 0.0731  max mem: 1102
[2024-01-21 09:43:09 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.6357 (3.6357)  loss: 2.1753 (2.1342)  acc1: 53.7162 (54.5028)  acc5: 80.0000 (79.5499)  time: 0.1772  data: 0.0665  max mem: 1102
[2024-01-21 09:43:10 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.6357 (3.6357)  loss: 2.1528 (2.1405)  acc1: 52.7211 (54.3661)  acc5: 78.4983 (79.4659)  time: 0.1780  data: 0.0628  max mem: 1103
[2024-01-21 09:43:12 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.6357 (3.6357)  loss: 2.1528 (2.1401)  acc1: 53.7162 (54.3943)  acc5: 78.7671 (79.5035)  time: 0.1698  data: 0.0558  max mem: 1103
[2024-01-21 09:43:14 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.6357 (3.6357)  loss: 2.1611 (2.1413)  acc1: 54.1379 (54.3720)  acc5: 79.5222 (79.5088)  time: 0.1640  data: 0.0556  max mem: 1103
[2024-01-21 09:43:15 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.6357 (3.6357)  loss: 2.1615 (2.1419)  acc1: 54.2662 (54.3985)  acc5: 78.7162 (79.4988)  time: 0.1627  data: 0.0549  max mem: 1103
[2024-01-21 09:43:17 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.6357 (3.6357)  loss: 2.1291 (2.1382)  acc1: 54.2662 (54.4039)  acc5: 79.0541 (79.5755)  time: 0.1622  data: 0.0537  max mem: 1103
[2024-01-21 09:43:19 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.6357 (3.6357)  loss: 2.0673 (2.1368)  acc1: 54.2088 (54.4249)  acc5: 80.6122 (79.5994)  time: 0.1762  data: 0.0661  max mem: 1103
[2024-01-21 09:43:20 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.6357 (3.6357)  loss: 2.1019 (2.1377)  acc1: 53.8983 (54.3838)  acc5: 80.4795 (79.5979)  time: 0.1806  data: 0.0708  max mem: 1103
[2024-01-21 09:43:22 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.6357 (3.6357)  loss: 2.1668 (2.1411)  acc1: 53.4483 (54.2898)  acc5: 79.0541 (79.5412)  time: 0.1804  data: 0.0716  max mem: 1103
[2024-01-21 09:43:23 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.6357 (3.6357)  loss: 2.1488 (2.1389)  acc1: 54.8822 (54.3533)  acc5: 79.1246 (79.5646)  time: 0.1765  data: 0.0661  max mem: 1103
[2024-01-21 09:43:23 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1960 s / it)
[2024-01-21 09:43:23 root] (engine.py 118): INFO * Acc@1 54.353 Acc@5 79.565 loss 2.139 flops 3.636
[2024-01-21 09:43:23 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 54.4%
[2024-01-21 09:44:37 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:44:41 root] (main_tome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:44:43 root] (main_tome.py 370): INFO number of params: 22050664
[2024-01-21 09:44:49 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:15  flops: 3.6357 (3.6357)  loss: 0.8298 (0.8298)  acc1: 76.7123 (76.7123)  acc5: 94.1781 (94.1781)  time: 5.8411  data: 2.4260  max mem: 1078
[2024-01-21 09:44:50 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:44  flops: 3.6357 (3.6357)  loss: 0.9462 (0.9731)  acc1: 74.5704 (74.8070)  acc5: 92.9054 (92.5594)  time: 0.6645  data: 0.2207  max mem: 1102
[2024-01-21 09:44:51 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:58  flops: 3.6357 (3.6357)  loss: 0.9653 (0.9773)  acc1: 74.2475 (74.1748)  acc5: 92.8571 (92.5566)  time: 0.1292  data: 0.0001  max mem: 1102
[2024-01-21 09:44:53 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.6357 (3.6357)  loss: 1.0031 (0.9943)  acc1: 74.3243 (74.1808)  acc5: 92.4658 (92.2521)  time: 0.1114  data: 0.0002  max mem: 1102
[2024-01-21 09:44:54 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.6357 (3.6357)  loss: 1.0216 (0.9976)  acc1: 73.3108 (74.1682)  acc5: 91.2752 (92.2364)  time: 0.1160  data: 0.0050  max mem: 1102
[2024-01-21 09:44:55 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.6357 (3.6357)  loss: 0.9703 (0.9914)  acc1: 73.5395 (74.2813)  acc5: 92.2559 (92.4075)  time: 0.1420  data: 0.0344  max mem: 1102
[2024-01-21 09:44:57 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.6357 (3.6357)  loss: 0.9723 (1.0010)  acc1: 73.5395 (74.0062)  acc5: 91.9192 (92.1779)  time: 0.1755  data: 0.0716  max mem: 1102
[2024-01-21 09:44:59 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.6357 (3.6357)  loss: 1.0471 (1.0065)  acc1: 73.1292 (73.9792)  acc5: 91.2162 (92.1775)  time: 0.1833  data: 0.0794  max mem: 1102
[2024-01-21 09:45:01 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.6357 (3.6357)  loss: 1.0471 (1.0160)  acc1: 72.1477 (73.7460)  acc5: 91.2458 (92.1175)  time: 0.1734  data: 0.0692  max mem: 1102
[2024-01-21 09:45:03 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.6357 (3.6357)  loss: 1.0875 (1.0197)  acc1: 71.6216 (73.6469)  acc5: 91.5825 (92.1183)  time: 0.1705  data: 0.0623  max mem: 1103
[2024-01-21 09:45:04 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:13  flops: 3.6357 (3.6357)  loss: 1.0295 (1.0208)  acc1: 73.2203 (73.6243)  acc5: 91.8919 (92.1219)  time: 0.1672  data: 0.0588  max mem: 1103
[2024-01-21 09:45:06 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.6357 (3.6357)  loss: 1.0491 (1.0241)  acc1: 73.4483 (73.6214)  acc5: 91.4966 (92.0176)  time: 0.1714  data: 0.0672  max mem: 1103
[2024-01-21 09:45:08 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.6357 (3.6357)  loss: 0.9948 (1.0186)  acc1: 73.9726 (73.7436)  acc5: 92.3077 (92.1093)  time: 0.1750  data: 0.0711  max mem: 1103
[2024-01-21 09:45:09 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.6357 (3.6357)  loss: 0.9842 (1.0162)  acc1: 74.5763 (73.7322)  acc5: 92.7835 (92.1251)  time: 0.1753  data: 0.0709  max mem: 1103
[2024-01-21 09:45:11 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.6357 (3.6357)  loss: 0.9844 (1.0139)  acc1: 73.6487 (73.7517)  acc5: 92.5676 (92.1542)  time: 0.1849  data: 0.0803  max mem: 1103
[2024-01-21 09:45:13 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.6357 (3.6357)  loss: 1.0075 (1.0152)  acc1: 73.9865 (73.7469)  acc5: 92.5424 (92.1252)  time: 0.1825  data: 0.0783  max mem: 1103
[2024-01-21 09:45:15 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.6357 (3.6357)  loss: 1.0576 (1.0186)  acc1: 74.0614 (73.6669)  acc5: 91.8919 (92.0889)  time: 0.1728  data: 0.0685  max mem: 1103
[2024-01-21 09:45:16 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.6357 (3.6357)  loss: 1.0318 (1.0161)  acc1: 73.5593 (73.7297)  acc5: 91.9463 (92.1101)  time: 0.1698  data: 0.0639  max mem: 1103
[2024-01-21 09:45:16 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1950 s / it)
[2024-01-21 09:45:16 root] (engine.py 118): INFO * Acc@1 73.730 Acc@5 92.110 loss 1.016 flops 3.636
[2024-01-21 09:45:16 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 73.7%
[2024-01-21 09:45:48 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:45:52 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:45:54 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:45:59 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:06  flops: 3.6357 (3.6357)  loss: 2.1268 (2.1268)  acc1: 55.4795 (55.4795)  acc5: 78.4247 (78.4247)  time: 5.7888  data: 1.2272  max mem: 1078
[2024-01-21 09:46:01 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:44  flops: 3.6357 (3.6357)  loss: 2.2260 (2.1947)  acc1: 54.1806 (53.9981)  acc5: 78.4247 (78.0797)  time: 0.6668  data: 0.1117  max mem: 1102
[2024-01-21 09:46:02 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.6357 (3.6357)  loss: 2.1578 (2.1610)  acc1: 54.0816 (54.1909)  acc5: 78.4512 (78.8350)  time: 0.1354  data: 0.0002  max mem: 1102
[2024-01-21 09:46:03 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.6357 (3.6357)  loss: 2.1379 (2.1602)  acc1: 53.7415 (54.4438)  acc5: 79.1246 (79.0247)  time: 0.1164  data: 0.0002  max mem: 1102
[2024-01-21 09:46:05 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.6357 (3.6357)  loss: 2.1423 (2.1534)  acc1: 55.4054 (54.8171)  acc5: 79.5302 (79.2170)  time: 0.1170  data: 0.0002  max mem: 1102
[2024-01-21 09:46:06 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.6357 (3.6357)  loss: 2.1460 (2.1532)  acc1: 55.7432 (54.9374)  acc5: 78.7162 (79.0924)  time: 0.1349  data: 0.0218  max mem: 1102
[2024-01-21 09:46:08 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:24  flops: 3.6357 (3.6357)  loss: 2.1470 (2.1589)  acc1: 53.8721 (54.7433)  acc5: 78.3051 (78.9723)  time: 0.1697  data: 0.0606  max mem: 1102
[2024-01-21 09:46:10 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.6357 (3.6357)  loss: 2.1972 (2.1690)  acc1: 53.0405 (54.5042)  acc5: 78.9830 (78.9471)  time: 0.1798  data: 0.0707  max mem: 1102
[2024-01-21 09:46:11 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.6357 (3.6357)  loss: 2.1972 (2.1720)  acc1: 53.3784 (54.4106)  acc5: 78.7162 (78.9339)  time: 0.1754  data: 0.0658  max mem: 1102
[2024-01-21 09:46:13 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.6357 (3.6357)  loss: 2.1884 (2.1790)  acc1: 53.7671 (54.2579)  acc5: 78.2313 (78.8504)  time: 0.1763  data: 0.0629  max mem: 1103
[2024-01-21 09:46:15 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:13  flops: 3.6357 (3.6357)  loss: 2.1902 (2.1789)  acc1: 53.5593 (54.2129)  acc5: 78.4512 (78.8517)  time: 0.1681  data: 0.0551  max mem: 1103
[2024-01-21 09:46:17 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.6357 (3.6357)  loss: 2.1911 (2.1812)  acc1: 53.4483 (54.1854)  acc5: 78.8396 (78.8727)  time: 0.1692  data: 0.0602  max mem: 1103
[2024-01-21 09:46:18 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.6357 (3.6357)  loss: 2.1911 (2.1813)  acc1: 53.4483 (54.2358)  acc5: 78.4247 (78.8787)  time: 0.1772  data: 0.0685  max mem: 1103
[2024-01-21 09:46:20 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.6357 (3.6357)  loss: 2.1676 (2.1775)  acc1: 54.6075 (54.2588)  acc5: 77.9661 (78.9148)  time: 0.1760  data: 0.0671  max mem: 1103
[2024-01-21 09:46:22 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.6357 (3.6357)  loss: 2.1125 (2.1764)  acc1: 55.4054 (54.3334)  acc5: 78.0822 (78.8964)  time: 0.1830  data: 0.0735  max mem: 1103
[2024-01-21 09:46:24 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.6357 (3.6357)  loss: 2.1696 (2.1777)  acc1: 55.1370 (54.2848)  acc5: 78.6441 (78.9233)  time: 0.1798  data: 0.0706  max mem: 1103
[2024-01-21 09:46:25 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.6357 (3.6357)  loss: 2.2047 (2.1803)  acc1: 52.5952 (54.1864)  acc5: 78.6441 (78.8960)  time: 0.1725  data: 0.0640  max mem: 1103
[2024-01-21 09:46:26 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:46:26 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.6357 (3.6357)  loss: 2.1933 (2.1784)  acc1: 52.3649 (54.2209)  acc5: 78.6441 (78.9210)  time: 0.1753  data: 0.0648  max mem: 1103
[2024-01-21 09:46:26 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1963 s / it)
[2024-01-21 09:46:26 root] (engine.py 118): INFO * Acc@1 54.221 Acc@5 78.921 loss 2.178 flops 3.636
[2024-01-21 09:46:26 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 54.2%
[2024-01-21 09:46:29 root] (main_tome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:46:31 root] (main_tome.py 370): INFO number of params: 22050664
[2024-01-21 09:46:37 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:19  flops: 3.6357 (3.6357)  loss: 0.8298 (0.8298)  acc1: 76.7123 (76.7123)  acc5: 94.1781 (94.1781)  time: 5.8631  data: 1.5903  max mem: 1078
[2024-01-21 09:46:39 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:44  flops: 3.6357 (3.6357)  loss: 0.9459 (0.9729)  acc1: 74.5704 (74.8379)  acc5: 92.9054 (92.5594)  time: 0.6659  data: 0.1447  max mem: 1102
[2024-01-21 09:46:40 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.6357 (3.6357)  loss: 0.9651 (0.9771)  acc1: 74.3243 (74.1909)  acc5: 92.8571 (92.5566)  time: 0.1286  data: 0.0002  max mem: 1102
[2024-01-21 09:46:41 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.6357 (3.6357)  loss: 1.0031 (0.9943)  acc1: 74.3243 (74.1918)  acc5: 92.4658 (92.2521)  time: 0.1113  data: 0.0002  max mem: 1102
[2024-01-21 09:46:42 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.6357 (3.6357)  loss: 1.0215 (0.9976)  acc1: 73.3108 (74.1682)  acc5: 91.2752 (92.2364)  time: 0.1208  data: 0.0094  max mem: 1102
[2024-01-21 09:46:44 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.6357 (3.6357)  loss: 0.9704 (0.9914)  acc1: 73.5395 (74.2813)  acc5: 92.2559 (92.4075)  time: 0.1479  data: 0.0401  max mem: 1102
[2024-01-21 09:46:46 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.6357 (3.6357)  loss: 0.9723 (1.0010)  acc1: 73.5395 (74.0062)  acc5: 91.9192 (92.1779)  time: 0.1761  data: 0.0720  max mem: 1102
[2024-01-21 09:46:47 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.6357 (3.6357)  loss: 1.0471 (1.0065)  acc1: 73.1292 (73.9792)  acc5: 91.2162 (92.1775)  time: 0.1780  data: 0.0739  max mem: 1102
[2024-01-21 09:46:49 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.6357 (3.6357)  loss: 1.0471 (1.0160)  acc1: 72.1477 (73.7502)  acc5: 91.2458 (92.1175)  time: 0.1716  data: 0.0671  max mem: 1102
[2024-01-21 09:46:51 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.6357 (3.6357)  loss: 1.0871 (1.0197)  acc1: 71.6216 (73.6506)  acc5: 91.5825 (92.1183)  time: 0.1752  data: 0.0659  max mem: 1103
[2024-01-21 09:46:53 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.6357 (3.6357)  loss: 1.0294 (1.0208)  acc1: 73.2203 (73.6276)  acc5: 91.8919 (92.1219)  time: 0.1706  data: 0.0614  max mem: 1103
[2024-01-21 09:46:54 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.6357 (3.6357)  loss: 1.0487 (1.0241)  acc1: 73.4483 (73.6245)  acc5: 91.4966 (92.0176)  time: 0.1658  data: 0.0616  max mem: 1103
[2024-01-21 09:46:56 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.6357 (3.6357)  loss: 0.9948 (1.0186)  acc1: 73.9726 (73.7464)  acc5: 92.3077 (92.1093)  time: 0.1703  data: 0.0663  max mem: 1103
[2024-01-21 09:46:58 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.6357 (3.6357)  loss: 0.9840 (1.0161)  acc1: 74.5763 (73.7348)  acc5: 92.7835 (92.1251)  time: 0.1727  data: 0.0680  max mem: 1103
[2024-01-21 09:47:00 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.6357 (3.6357)  loss: 0.9845 (1.0138)  acc1: 73.6487 (73.7542)  acc5: 92.5676 (92.1542)  time: 0.1778  data: 0.0730  max mem: 1103
[2024-01-21 09:47:01 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.6357 (3.6357)  loss: 1.0077 (1.0151)  acc1: 73.9865 (73.7492)  acc5: 92.5424 (92.1252)  time: 0.1747  data: 0.0706  max mem: 1103
[2024-01-21 09:47:03 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.6357 (3.6357)  loss: 1.0575 (1.0186)  acc1: 74.0614 (73.6711)  acc5: 91.8919 (92.0868)  time: 0.1744  data: 0.0700  max mem: 1103
[2024-01-21 09:47:04 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.6357 (3.6357)  loss: 1.0317 (1.0160)  acc1: 73.5593 (73.7337)  acc5: 91.9463 (92.1081)  time: 0.1715  data: 0.0656  max mem: 1103
[2024-01-21 09:47:04 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1941 s / it)
[2024-01-21 09:47:04 root] (engine.py 118): INFO * Acc@1 73.734 Acc@5 92.108 loss 1.016 flops 3.636
[2024-01-21 09:47:04 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 73.7%
[2024-01-21 09:47:23 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:47:26 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:47:28 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:47:34 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:09  flops: 3.6357 (3.6357)  loss: 1.8184 (1.8184)  acc1: 63.0137 (63.0137)  acc5: 83.2192 (83.2192)  time: 5.8058  data: 1.2875  max mem: 1078
[2024-01-21 09:47:36 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:46  flops: 3.6357 (3.6357)  loss: 1.9106 (1.8897)  acc1: 59.7973 (60.3890)  acc5: 83.9590 (83.8530)  time: 0.6783  data: 0.1172  max mem: 1102
[2024-01-21 09:47:37 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:00  flops: 3.6357 (3.6357)  loss: 1.8516 (1.8679)  acc1: 59.7973 (60.6958)  acc5: 84.5118 (84.4175)  time: 0.1444  data: 0.0002  max mem: 1102
[2024-01-21 09:47:38 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:43  flops: 3.6357 (3.6357)  loss: 1.8536 (1.8711)  acc1: 60.5442 (60.6795)  acc5: 85.1724 (84.4822)  time: 0.1237  data: 0.0001  max mem: 1102
[2024-01-21 09:47:39 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:34  flops: 3.6357 (3.6357)  loss: 1.8756 (1.8637)  acc1: 60.4096 (61.0081)  acc5: 84.7973 (84.6714)  time: 0.1245  data: 0.0001  max mem: 1102
[2024-01-21 09:47:41 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.6357 (3.6357)  loss: 1.8495 (1.8567)  acc1: 60.4096 (61.0194)  acc5: 84.4068 (84.8283)  time: 0.1352  data: 0.0143  max mem: 1102
[2024-01-21 09:47:43 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.6357 (3.6357)  loss: 1.8495 (1.8632)  acc1: 60.1351 (60.8841)  acc5: 84.1216 (84.6231)  time: 0.1664  data: 0.0498  max mem: 1102
[2024-01-21 09:47:44 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.6357 (3.6357)  loss: 1.8775 (1.8670)  acc1: 59.6610 (60.7297)  acc5: 84.6939 (84.6897)  time: 0.1811  data: 0.0639  max mem: 1102
[2024-01-21 09:47:46 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.6357 (3.6357)  loss: 1.8964 (1.8699)  acc1: 59.6610 (60.6713)  acc5: 84.8993 (84.6750)  time: 0.1765  data: 0.0590  max mem: 1102
[2024-01-21 09:47:48 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.6357 (3.6357)  loss: 1.9118 (1.8789)  acc1: 57.9125 (60.3566)  acc5: 84.1751 (84.6059)  time: 0.1748  data: 0.0544  max mem: 1103
[2024-01-21 09:47:50 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.6357 (3.6357)  loss: 1.9202 (1.8811)  acc1: 58.2492 (60.3205)  acc5: 84.1751 (84.5562)  time: 0.1676  data: 0.0473  max mem: 1103
[2024-01-21 09:47:51 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.6357 (3.6357)  loss: 1.8830 (1.8832)  acc1: 60.0671 (60.4612)  acc5: 84.2466 (84.5552)  time: 0.1660  data: 0.0493  max mem: 1103
[2024-01-21 09:47:53 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.6357 (3.6357)  loss: 1.8622 (1.8793)  acc1: 62.1160 (60.5719)  acc5: 84.9498 (84.6031)  time: 0.1691  data: 0.0525  max mem: 1103
[2024-01-21 09:47:55 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.6357 (3.6357)  loss: 1.8078 (1.8756)  acc1: 61.0169 (60.5763)  acc5: 85.7143 (84.6519)  time: 0.1713  data: 0.0543  max mem: 1103
[2024-01-21 09:47:57 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.6357 (3.6357)  loss: 1.8114 (1.8725)  acc1: 60.6061 (60.6096)  acc5: 86.1017 (84.7200)  time: 0.1846  data: 0.0676  max mem: 1103
[2024-01-21 09:47:58 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.6357 (3.6357)  loss: 1.8393 (1.8718)  acc1: 61.1487 (60.6485)  acc5: 85.7627 (84.7788)  time: 0.1814  data: 0.0647  max mem: 1103
[2024-01-21 09:48:00 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.6357 (3.6357)  loss: 1.8913 (1.8747)  acc1: 59.7270 (60.5330)  acc5: 84.4828 (84.7239)  time: 0.1751  data: 0.0583  max mem: 1103
[2024-01-21 09:48:01 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.6357 (3.6357)  loss: 1.8913 (1.8722)  acc1: 59.7973 (60.6057)  acc5: 84.5890 (84.7518)  time: 0.1764  data: 0.0583  max mem: 1103
[2024-01-21 09:48:01 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1959 s / it)
[2024-01-21 09:48:01 root] (engine.py 118): INFO * Acc@1 60.606 Acc@5 84.752 loss 1.872 flops 3.636
[2024-01-21 09:48:01 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 60.6%
[2024-01-21 09:48:13 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:48:17 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:48:19 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:48:25 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:18  flops: 3.6357 (3.6357)  loss: 2.1276 (2.1276)  acc1: 55.1370 (55.1370)  acc5: 79.4521 (79.4521)  time: 5.8578  data: 1.9294  max mem: 1078
[2024-01-21 09:48:26 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:45  flops: 3.6357 (3.6357)  loss: 2.2079 (2.1917)  acc1: 54.0816 (54.2451)  acc5: 78.9116 (78.2958)  time: 0.6740  data: 0.1755  max mem: 1102
[2024-01-21 09:48:27 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.6357 (3.6357)  loss: 2.1332 (2.1602)  acc1: 53.9249 (54.2557)  acc5: 78.9116 (78.9968)  time: 0.1356  data: 0.0002  max mem: 1102
[2024-01-21 09:48:29 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.6357 (3.6357)  loss: 2.1162 (2.1613)  acc1: 53.7415 (54.5205)  acc5: 79.3220 (79.1342)  time: 0.1157  data: 0.0002  max mem: 1102
[2024-01-21 09:48:30 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.6357 (3.6357)  loss: 2.1335 (2.1557)  acc1: 55.6314 (54.8171)  acc5: 79.9320 (79.3412)  time: 0.1163  data: 0.0004  max mem: 1102
[2024-01-21 09:48:31 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.6357 (3.6357)  loss: 2.1490 (2.1552)  acc1: 55.6314 (54.8177)  acc5: 78.8396 (79.2321)  time: 0.1389  data: 0.0264  max mem: 1102
[2024-01-21 09:48:33 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.6357 (3.6357)  loss: 2.1406 (2.1596)  acc1: 53.5354 (54.6153)  acc5: 78.2313 (79.1059)  time: 0.1739  data: 0.0650  max mem: 1102
[2024-01-21 09:48:35 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.6357 (3.6357)  loss: 2.2021 (2.1693)  acc1: 53.4014 (54.3368)  acc5: 78.6441 (79.0475)  time: 0.1804  data: 0.0708  max mem: 1102
[2024-01-21 09:48:37 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.6357 (3.6357)  loss: 2.2021 (2.1737)  acc1: 53.5354 (54.2136)  acc5: 78.6441 (78.9968)  time: 0.1822  data: 0.0725  max mem: 1102
[2024-01-21 09:48:39 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.6357 (3.6357)  loss: 2.1941 (2.1817)  acc1: 53.5354 (54.0527)  acc5: 78.1145 (78.8728)  time: 0.1835  data: 0.0709  max mem: 1103
[2024-01-21 09:48:40 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.6357 (3.6357)  loss: 2.2053 (2.1823)  acc1: 53.4014 (53.9878)  acc5: 77.8912 (78.8954)  time: 0.1701  data: 0.0575  max mem: 1103
[2024-01-21 09:48:42 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.6357 (3.6357)  loss: 2.2040 (2.1851)  acc1: 53.3784 (53.9652)  acc5: 78.7671 (78.8941)  time: 0.1634  data: 0.0548  max mem: 1103
[2024-01-21 09:48:44 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.6357 (3.6357)  loss: 2.1962 (2.1847)  acc1: 53.3784 (54.0337)  acc5: 77.6271 (78.8562)  time: 0.1675  data: 0.0593  max mem: 1103
[2024-01-21 09:48:45 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.6357 (3.6357)  loss: 2.1636 (2.1816)  acc1: 54.9488 (54.0566)  acc5: 77.9661 (78.8733)  time: 0.1751  data: 0.0662  max mem: 1103
[2024-01-21 09:48:47 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.6357 (3.6357)  loss: 2.1364 (2.1806)  acc1: 55.1020 (54.1312)  acc5: 78.2313 (78.8555)  time: 0.1822  data: 0.0727  max mem: 1103
[2024-01-21 09:49:24 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:49:29 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:49:31 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:49:37 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:22  flops: 3.6357 (3.6357)  loss: 2.1105 (2.1105)  acc1: 55.8219 (55.8219)  acc5: 78.7671 (78.7671)  time: 5.8844  data: 1.1049  max mem: 1078
[2024-01-21 09:49:38 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:46  flops: 3.6357 (3.6357)  loss: 2.1569 (2.1946)  acc1: 53.5836 (53.7820)  acc5: 78.7671 (78.2649)  time: 0.6768  data: 0.1006  max mem: 1102
[2024-01-21 09:49:39 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:00  flops: 3.6357 (3.6357)  loss: 2.1392 (2.1625)  acc1: 53.5117 (53.9644)  acc5: 78.7879 (78.9159)  time: 0.1358  data: 0.0002  max mem: 1102
[2024-01-21 09:49:41 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:43  flops: 3.6357 (3.6357)  loss: 2.1311 (2.1633)  acc1: 53.4014 (54.2247)  acc5: 79.0541 (79.0247)  time: 0.1161  data: 0.0002  max mem: 1102
[2024-01-21 09:49:42 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.6357 (3.6357)  loss: 2.1287 (2.1574)  acc1: 54.3919 (54.6764)  acc5: 79.1809 (79.2253)  time: 0.1167  data: 0.0002  max mem: 1102
[2024-01-21 09:50:34 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:50:37 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:50:39 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:50:55 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:50:59 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:51:01 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:51:06 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:15:11  flops: 3.6357 (3.6357)  loss: 0.8168 (0.8168)  acc1: 76.3699 (76.3699)  acc5: 94.1781 (94.1781)  time: 5.4560  data: 0.2203  max mem: 1078
[2024-01-21 09:51:08 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:39  flops: 3.6357 (3.6357)  loss: 0.9867 (0.9794)  acc1: 74.5704 (74.3748)  acc5: 92.1502 (92.0037)  time: 0.6359  data: 0.0202  max mem: 1102
[2024-01-21 09:51:09 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:57  flops: 3.6357 (3.6357)  loss: 0.9896 (0.9857)  acc1: 73.8095 (74.1100)  acc5: 92.1502 (92.3948)  time: 0.1345  data: 0.0002  max mem: 1102
[2024-01-21 09:51:10 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:41  flops: 3.6357 (3.6357)  loss: 1.0065 (1.0021)  acc1: 73.7374 (73.9178)  acc5: 92.2034 (92.1205)  time: 0.1159  data: 0.0002  max mem: 1102
[2024-01-21 09:51:12 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:32  flops: 3.6357 (3.6357)  loss: 1.0296 (0.9978)  acc1: 73.9865 (74.1351)  acc5: 91.2752 (92.1784)  time: 0.1224  data: 0.0060  max mem: 1102
[2024-01-21 09:51:13 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:27  flops: 3.6357 (3.6357)  loss: 0.9654 (0.9918)  acc1: 74.0614 (74.2880)  acc5: 92.4399 (92.3143)  time: 0.1436  data: 0.0308  max mem: 1102
[2024-01-21 09:51:15 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:24  flops: 3.6357 (3.6357)  loss: 0.9685 (1.0015)  acc1: 72.8522 (74.0229)  acc5: 91.5825 (92.1445)  time: 0.1736  data: 0.0646  max mem: 1102
[2024-01-21 09:51:17 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.6357 (3.6357)  loss: 1.0486 (1.0074)  acc1: 71.7687 (73.7927)  acc5: 91.4089 (92.1488)  time: 0.1798  data: 0.0705  max mem: 1102
[2024-01-21 09:51:19 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:18  flops: 3.6357 (3.6357)  loss: 1.0550 (1.0162)  acc1: 71.8644 (73.5825)  acc5: 91.4384 (92.1007)  time: 0.1761  data: 0.0667  max mem: 1102
[2024-01-21 09:51:20 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.6357 (3.6357)  loss: 1.0830 (1.0195)  acc1: 72.2973 (73.5648)  acc5: 91.8644 (92.0997)  time: 0.1818  data: 0.0682  max mem: 1103
[2024-01-21 09:51:22 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:13  flops: 3.6357 (3.6357)  loss: 1.0292 (1.0204)  acc1: 73.0640 (73.5134)  acc5: 92.2559 (92.1152)  time: 0.1724  data: 0.0587  max mem: 1103
[2024-01-21 09:51:24 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.6357 (3.6357)  loss: 1.0405 (1.0236)  acc1: 72.8814 (73.5297)  acc5: 91.7808 (92.0390)  time: 0.1654  data: 0.0561  max mem: 1103
[2024-01-21 09:51:25 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.6357 (3.6357)  loss: 1.0094 (1.0187)  acc1: 73.6487 (73.6257)  acc5: 91.8919 (92.1065)  time: 0.1679  data: 0.0587  max mem: 1103
[2024-01-21 09:51:27 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.6357 (3.6357)  loss: 0.9632 (1.0157)  acc1: 74.4027 (73.6623)  acc5: 92.1769 (92.1277)  time: 0.1693  data: 0.0599  max mem: 1103
[2024-01-21 09:51:29 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.6357 (3.6357)  loss: 1.0018 (1.0140)  acc1: 73.3108 (73.6867)  acc5: 91.9192 (92.1132)  time: 0.1800  data: 0.0697  max mem: 1103
[2024-01-21 09:51:31 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.6357 (3.6357)  loss: 1.0153 (1.0152)  acc1: 73.7201 (73.6705)  acc5: 91.9192 (92.0960)  time: 0.1759  data: 0.0662  max mem: 1103
[2024-01-21 09:51:32 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.6357 (3.6357)  loss: 1.0312 (1.0183)  acc1: 73.4694 (73.5931)  acc5: 91.9192 (92.0488)  time: 0.1712  data: 0.0623  max mem: 1103
[2024-01-21 09:51:33 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.6357 (3.6357)  loss: 1.0200 (1.0158)  acc1: 73.7201 (73.6665)  acc5: 92.2297 (92.0613)  time: 0.1720  data: 0.0608  max mem: 1103
[2024-01-21 09:51:33 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1929 s / it)
[2024-01-21 09:51:33 root] (engine.py 118): INFO * Acc@1 73.667 Acc@5 92.061 loss 1.016 flops 3.636
[2024-01-21 09:51:33 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 73.7%
[2024-01-21 09:53:20 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:53:23 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:53:25 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:53:31 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:05  flops: 3.6357 (3.6357)  loss: 0.8115 (0.8115)  acc1: 77.0548 (77.0548)  acc5: 93.8356 (93.8356)  time: 5.7839  data: 2.0374  max mem: 1078
[2024-01-21 09:53:33 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:44  flops: 3.6357 (3.6357)  loss: 0.9930 (0.9943)  acc1: 74.5704 (74.0043)  acc5: 92.2297 (92.0346)  time: 0.6638  data: 0.1854  max mem: 1102
[2024-01-21 09:53:34 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.6357 (3.6357)  loss: 0.9930 (0.9951)  acc1: 73.6301 (74.0291)  acc5: 92.1502 (92.2492)  time: 0.1338  data: 0.0002  max mem: 1102
[2024-01-21 09:53:35 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.6357 (3.6357)  loss: 1.0201 (1.0089)  acc1: 73.6301 (73.9616)  acc5: 91.8919 (91.9452)  time: 0.1162  data: 0.0002  max mem: 1102
[2024-01-21 09:53:36 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.6357 (3.6357)  loss: 1.0397 (1.0032)  acc1: 73.6301 (74.1268)  acc5: 91.8644 (92.0957)  time: 0.1165  data: 0.0002  max mem: 1102
[2024-01-21 09:53:38 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.6357 (3.6357)  loss: 0.9790 (1.0002)  acc1: 74.6622 (74.2015)  acc5: 92.4399 (92.2079)  time: 0.1421  data: 0.0297  max mem: 1102
[2024-01-21 09:53:40 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.6357 (3.6357)  loss: 1.0112 (1.0088)  acc1: 72.8522 (73.9283)  acc5: 91.5541 (91.9998)  time: 0.1768  data: 0.0683  max mem: 1102
[2024-01-21 09:53:41 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.6357 (3.6357)  loss: 1.0409 (1.0137)  acc1: 72.4138 (73.7783)  acc5: 90.9091 (91.9480)  time: 0.1799  data: 0.0712  max mem: 1102
[2024-01-21 09:53:43 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.6357 (3.6357)  loss: 1.0488 (1.0229)  acc1: 71.9595 (73.5867)  acc5: 91.5541 (91.9247)  time: 0.1740  data: 0.0640  max mem: 1102
[2024-01-21 09:53:45 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.6357 (3.6357)  loss: 1.0628 (1.0256)  acc1: 72.4490 (73.5499)  acc5: 91.8644 (91.9355)  time: 0.1765  data: 0.0630  max mem: 1103
[2024-01-21 09:53:47 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.6357 (3.6357)  loss: 1.0189 (1.0265)  acc1: 73.4007 (73.5336)  acc5: 92.4658 (91.9808)  time: 0.1723  data: 0.0594  max mem: 1103
[2024-01-21 09:53:48 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.6357 (3.6357)  loss: 1.0567 (1.0288)  acc1: 73.1292 (73.5817)  acc5: 91.5825 (91.8739)  time: 0.1639  data: 0.0548  max mem: 1103
[2024-01-21 09:53:50 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.6357 (3.6357)  loss: 1.0116 (1.0240)  acc1: 73.6487 (73.6229)  acc5: 91.7526 (91.9410)  time: 0.1630  data: 0.0542  max mem: 1103
[2024-01-21 09:53:51 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.6357 (3.6357)  loss: 0.9684 (1.0219)  acc1: 73.8095 (73.6182)  acc5: 92.5424 (91.9619)  time: 0.1655  data: 0.0563  max mem: 1103
[2024-01-21 09:53:53 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.6357 (3.6357)  loss: 1.0240 (1.0204)  acc1: 73.0640 (73.6073)  acc5: 92.5170 (91.9592)  time: 0.1743  data: 0.0649  max mem: 1103
[2024-01-21 09:53:55 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.6357 (3.6357)  loss: 1.0240 (1.0213)  acc1: 72.9452 (73.5873)  acc5: 92.2034 (91.9656)  time: 0.1732  data: 0.0638  max mem: 1103
[2024-01-21 09:53:57 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.6357 (3.6357)  loss: 1.0403 (1.0241)  acc1: 72.7891 (73.5362)  acc5: 92.1502 (91.9371)  time: 0.1720  data: 0.0626  max mem: 1103
[2024-01-21 09:53:58 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.6357 (3.6357)  loss: 1.0063 (1.0214)  acc1: 73.4899 (73.5830)  acc5: 92.5424 (91.9615)  time: 0.1742  data: 0.0632  max mem: 1103
[2024-01-21 09:53:58 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1945 s / it)
[2024-01-21 09:53:58 root] (engine.py 118): INFO * Acc@1 73.583 Acc@5 91.961 loss 1.021 flops 3.636
[2024-01-21 09:53:58 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 73.6%
[2024-01-21 09:54:08 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:54:13 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:54:15 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:54:20 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:11  flops: 3.6357 (3.6357)  loss: 0.8095 (0.8095)  acc1: 78.4247 (78.4247)  acc5: 94.1781 (94.1781)  time: 5.8181  data: 2.1227  max mem: 1078
[2024-01-21 09:54:22 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:45  flops: 3.6357 (3.6357)  loss: 0.9721 (0.9705)  acc1: 74.3243 (74.7762)  acc5: 92.9293 (92.4051)  time: 0.6702  data: 0.1931  max mem: 1102
[2024-01-21 09:54:23 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.6357 (3.6357)  loss: 0.9721 (0.9719)  acc1: 74.0614 (74.4984)  acc5: 92.4138 (92.5728)  time: 0.1356  data: 0.0002  max mem: 1102
[2024-01-21 09:54:24 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.6357 (3.6357)  loss: 1.0215 (0.9893)  acc1: 73.8095 (74.1699)  acc5: 92.4138 (92.3507)  time: 0.1159  data: 0.0002  max mem: 1102
[2024-01-21 09:54:25 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.6357 (3.6357)  loss: 1.0283 (0.9855)  acc1: 73.8983 (74.4165)  acc5: 92.5926 (92.4681)  time: 0.1176  data: 0.0012  max mem: 1102
[2024-01-21 09:54:27 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.6357 (3.6357)  loss: 0.9710 (0.9820)  acc1: 74.6622 (74.4810)  acc5: 92.5926 (92.6271)  time: 0.1398  data: 0.0266  max mem: 1102
[2024-01-21 09:54:29 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.6357 (3.6357)  loss: 0.9746 (0.9907)  acc1: 73.4694 (74.2401)  acc5: 91.5541 (92.4340)  time: 0.1719  data: 0.0627  max mem: 1102
[2024-01-21 09:54:31 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.6357 (3.6357)  loss: 1.0393 (0.9975)  acc1: 73.1292 (74.0317)  acc5: 91.5541 (92.4118)  time: 0.1779  data: 0.0686  max mem: 1102
[2024-01-21 09:54:32 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.6357 (3.6357)  loss: 1.0458 (1.0066)  acc1: 71.9595 (73.7627)  acc5: 92.2297 (92.3480)  time: 0.1736  data: 0.0635  max mem: 1102
[2024-01-21 09:54:34 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.6357 (3.6357)  loss: 1.0547 (1.0098)  acc1: 71.9595 (73.6842)  acc5: 92.1769 (92.3272)  time: 0.1759  data: 0.0622  max mem: 1103
[2024-01-21 09:54:36 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.6357 (3.6357)  loss: 1.0118 (1.0103)  acc1: 72.7273 (73.6243)  acc5: 92.1233 (92.3268)  time: 0.1707  data: 0.0578  max mem: 1103
[2024-01-21 09:54:37 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.6357 (3.6357)  loss: 1.0396 (1.0134)  acc1: 72.9730 (73.6214)  acc5: 91.8089 (92.2164)  time: 0.1705  data: 0.0614  max mem: 1103
[2024-01-21 09:54:39 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.6357 (3.6357)  loss: 1.0172 (1.0091)  acc1: 73.2877 (73.6847)  acc5: 91.9463 (92.2861)  time: 0.1798  data: 0.0713  max mem: 1103
[2024-01-21 09:54:41 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.6357 (3.6357)  loss: 0.9629 (1.0071)  acc1: 74.1379 (73.6726)  acc5: 92.5926 (92.3117)  time: 0.1770  data: 0.0683  max mem: 1103
[2024-01-21 09:54:43 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.6357 (3.6357)  loss: 0.9765 (1.0054)  acc1: 73.8095 (73.6819)  acc5: 92.5676 (92.3082)  time: 0.1792  data: 0.0699  max mem: 1103
[2024-01-21 09:54:45 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.6357 (3.6357)  loss: 1.0135 (1.0066)  acc1: 74.1497 (73.6750)  acc5: 92.2034 (92.2984)  time: 0.1803  data: 0.0719  max mem: 1103
[2024-01-21 09:54:46 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.6357 (3.6357)  loss: 1.0314 (1.0100)  acc1: 73.8983 (73.6184)  acc5: 92.2034 (92.2386)  time: 0.1744  data: 0.0663  max mem: 1103
[2024-01-21 09:54:47 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.6357 (3.6357)  loss: 1.0236 (1.0072)  acc1: 74.4027 (73.7073)  acc5: 92.5170 (92.2608)  time: 0.1705  data: 0.0612  max mem: 1103
[2024-01-21 09:54:47 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1954 s / it)
[2024-01-21 09:54:47 root] (engine.py 118): INFO * Acc@1 73.707 Acc@5 92.261 loss 1.007 flops 3.636
[2024-01-21 09:54:47 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 73.7%
[2024-01-21 09:55:17 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:55:21 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:55:23 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:55:29 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:01  flops: 3.6357 (3.6357)  loss: 0.8551 (0.8551)  acc1: 76.0274 (76.0274)  acc5: 93.4931 (93.4931)  time: 5.7583  data: 1.8462  max mem: 1078
[2024-01-21 09:55:30 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:44  flops: 3.6357 (3.6357)  loss: 1.0072 (1.0070)  acc1: 74.2268 (73.6030)  acc5: 91.8089 (91.6641)  time: 0.6668  data: 0.1683  max mem: 1102
[2024-01-21 09:55:32 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.6357 (3.6357)  loss: 1.0212 (1.0142)  acc1: 73.5786 (73.4142)  acc5: 91.5825 (91.7152)  time: 0.1376  data: 0.0003  max mem: 1102
[2024-01-21 09:55:33 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.6357 (3.6357)  loss: 1.0379 (1.0260)  acc1: 72.7586 (73.3041)  acc5: 91.5541 (91.7479)  time: 0.1168  data: 0.0002  max mem: 1102
[2024-01-21 09:55:34 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.6357 (3.6357)  loss: 1.0427 (1.0240)  acc1: 72.7273 (73.4481)  acc5: 91.0959 (91.7646)  time: 0.1185  data: 0.0023  max mem: 1102
[2024-01-21 09:55:36 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.6357 (3.6357)  loss: 0.9873 (1.0215)  acc1: 73.9865 (73.5494)  acc5: 91.8919 (91.8286)  time: 0.1430  data: 0.0302  max mem: 1102
[2024-01-21 09:55:37 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.6357 (3.6357)  loss: 1.0205 (1.0318)  acc1: 72.8522 (73.3159)  acc5: 91.2162 (91.6323)  time: 0.1739  data: 0.0646  max mem: 1102
[2024-01-21 09:55:39 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.6357 (3.6357)  loss: 1.0595 (1.0382)  acc1: 72.5424 (73.1950)  acc5: 91.2162 (91.6420)  time: 0.1801  data: 0.0709  max mem: 1102
[2024-01-21 09:55:47 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:55:51 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:55:53 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:55:59 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:07  flops: 3.6357 (3.6357)  loss: 0.8129 (0.8129)  acc1: 78.0822 (78.0822)  acc5: 93.4931 (93.4931)  time: 5.7937  data: 1.8364  max mem: 1078
[2024-01-21 09:56:00 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:44  flops: 3.6357 (3.6357)  loss: 0.9493 (0.9697)  acc1: 74.4898 (74.9305)  acc5: 92.2559 (92.0963)  time: 0.6662  data: 0.1671  max mem: 1102
[2024-01-21 09:56:02 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.6357 (3.6357)  loss: 0.9612 (0.9716)  acc1: 74.0614 (74.4337)  acc5: 92.2559 (92.5728)  time: 0.1347  data: 0.0002  max mem: 1102
[2024-01-21 09:56:03 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.6357 (3.6357)  loss: 1.0098 (0.9891)  acc1: 73.6487 (74.0603)  acc5: 92.2559 (92.2849)  time: 0.1164  data: 0.0002  max mem: 1102
[2024-01-21 09:56:04 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.6357 (3.6357)  loss: 1.0160 (0.9856)  acc1: 73.7201 (74.3420)  acc5: 92.2034 (92.4102)  time: 0.1172  data: 0.0002  max mem: 1102
[2024-01-21 09:56:06 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.6357 (3.6357)  loss: 0.9640 (0.9816)  acc1: 74.3243 (74.4610)  acc5: 92.9054 (92.5872)  time: 0.1427  data: 0.0286  max mem: 1102
[2024-01-21 09:56:08 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.6357 (3.6357)  loss: 0.9900 (0.9905)  acc1: 73.8832 (74.2456)  acc5: 92.2559 (92.3895)  time: 0.1771  data: 0.0664  max mem: 1102
[2024-01-21 09:56:09 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.6357 (3.6357)  loss: 1.0322 (0.9962)  acc1: 73.4694 (74.0748)  acc5: 91.4966 (92.3592)  time: 0.1819  data: 0.0718  max mem: 1102
[2024-01-21 09:56:11 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.6357 (3.6357)  loss: 1.0322 (1.0046)  acc1: 72.0690 (73.8675)  acc5: 92.2297 (92.3564)  time: 0.1773  data: 0.0676  max mem: 1102
[2024-01-21 09:56:13 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.6357 (3.6357)  loss: 1.0493 (1.0077)  acc1: 71.3311 (73.7737)  acc5: 92.2297 (92.3533)  time: 0.1780  data: 0.0648  max mem: 1103
[2024-01-21 09:56:15 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.6357 (3.6357)  loss: 1.0041 (1.0079)  acc1: 73.5593 (73.7385)  acc5: 92.1233 (92.3537)  time: 0.1717  data: 0.0584  max mem: 1103
[2024-01-21 09:56:16 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.6357 (3.6357)  loss: 1.0389 (1.0105)  acc1: 73.8983 (73.7835)  acc5: 91.8919 (92.2562)  time: 0.1640  data: 0.0546  max mem: 1103
[2024-01-21 09:56:18 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.6357 (3.6357)  loss: 0.9681 (1.0048)  acc1: 74.4828 (73.9091)  acc5: 92.2819 (92.3506)  time: 0.1647  data: 0.0564  max mem: 1103
[2024-01-21 09:56:20 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.6357 (3.6357)  loss: 0.9646 (1.0030)  acc1: 74.7405 (73.9240)  acc5: 92.5424 (92.3454)  time: 0.1683  data: 0.0597  max mem: 1103
[2024-01-21 09:56:21 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.6357 (3.6357)  loss: 0.9853 (1.0014)  acc1: 73.5593 (73.9467)  acc5: 92.5424 (92.3588)  time: 0.1791  data: 0.0698  max mem: 1103
[2024-01-21 09:56:23 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.6357 (3.6357)  loss: 1.0083 (1.0028)  acc1: 74.1497 (73.9583)  acc5: 92.8814 (92.3456)  time: 0.1778  data: 0.0690  max mem: 1103
[2024-01-21 09:56:25 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.6357 (3.6357)  loss: 1.0190 (1.0057)  acc1: 74.0614 (73.9136)  acc5: 92.2034 (92.2913)  time: 0.1707  data: 0.0620  max mem: 1103
[2024-01-21 09:56:26 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.6357 (3.6357)  loss: 1.0083 (1.0033)  acc1: 73.5593 (73.9517)  acc5: 92.5676 (92.3057)  time: 0.1722  data: 0.0616  max mem: 1103
[2024-01-21 09:56:26 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1956 s / it)
[2024-01-21 09:56:26 root] (engine.py 118): INFO * Acc@1 73.952 Acc@5 92.306 loss 1.003 flops 3.636
[2024-01-21 09:56:26 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 74.0%
[2024-01-21 09:56:45 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='vit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:56:48 root] (main_pitome.py 286): INFO Creating model: vit_small_patch16_224
[2024-01-21 09:56:50 root] (main_pitome.py 370): INFO number of params: 22050664
[2024-01-21 09:56:56 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:07  flops: 3.6357 (3.6357)  loss: 0.8128 (0.8128)  acc1: 78.4247 (78.4247)  acc5: 93.4931 (93.4931)  time: 5.7947  data: 1.8424  max mem: 1078
[2024-01-21 09:56:58 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:44  flops: 3.6357 (3.6357)  loss: 0.9452 (0.9691)  acc1: 74.4898 (74.9923)  acc5: 92.2559 (92.1581)  time: 0.6648  data: 0.1676  max mem: 1102
[2024-01-21 09:56:59 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.6357 (3.6357)  loss: 0.9541 (0.9708)  acc1: 74.0614 (74.5146)  acc5: 92.2559 (92.6052)  time: 0.1342  data: 0.0002  max mem: 1102
[2024-01-21 09:57:00 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.6357 (3.6357)  loss: 1.0104 (0.9886)  acc1: 73.7931 (74.1370)  acc5: 92.2559 (92.3068)  time: 0.1173  data: 0.0003  max mem: 1102
[2024-01-21 09:57:01 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.6357 (3.6357)  loss: 1.0166 (0.9853)  acc1: 73.7374 (74.3917)  acc5: 92.2034 (92.4185)  time: 0.1182  data: 0.0003  max mem: 1102
[2024-01-21 09:57:09 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.9625, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:57:12 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:57:14 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:57:16 root] (main_pitome.py 370): INFO number of params: 86567656
[2024-01-21 09:57:21 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:16  flops: 13.9395 (13.9395)  loss: 0.8678 (0.8678)  acc1: 81.1644 (81.1644)  acc5: 94.8630 (94.8630)  time: 5.1308  data: 1.7580  max mem: 2149
[2024-01-21 09:57:24 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:57  flops: 13.9395 (13.9395)  loss: 0.8007 (0.8068)  acc1: 82.8179 (82.6490)  acc5: 95.5782 (95.5542)  time: 0.7488  data: 0.1600  max mem: 2193
[2024-01-21 09:57:27 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:15  flops: 13.9395 (13.9395)  loss: 0.8341 (0.8299)  acc1: 82.1549 (82.0388)  acc5: 95.2055 (95.4693)  time: 0.2832  data: 0.0002  max mem: 2193
[2024-01-21 09:57:29 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:59  flops: 13.9395 (13.9395)  loss: 0.8417 (0.8270)  acc1: 82.0339 (82.0493)  acc5: 95.2055 (95.5726)  time: 0.2566  data: 0.0002  max mem: 2193
[2024-01-21 09:57:32 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:49  flops: 13.9395 (13.9395)  loss: 0.8286 (0.8374)  acc1: 82.0339 (81.8987)  acc5: 95.5782 (95.5305)  time: 0.2572  data: 0.0002  max mem: 2193
[2024-01-21 09:57:34 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:42  flops: 13.9395 (13.9395)  loss: 0.8367 (0.8304)  acc1: 81.0811 (81.9870)  acc5: 95.6081 (95.6614)  time: 0.2516  data: 0.0002  max mem: 2193
[2024-01-21 09:57:45 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:57:49 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:57:51 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:57:53 root] (main_pitome.py 370): INFO number of params: 86567656
[2024-01-21 09:57:58 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:26  flops: 12.9405 (12.9405)  loss: 0.8805 (0.8805)  acc1: 80.8219 (80.8219)  acc5: 93.8356 (93.8356)  time: 5.1879  data: 1.2226  max mem: 2127
[2024-01-21 09:58:01 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:57  flops: 12.9405 (12.9405)  loss: 0.8168 (0.8283)  acc1: 82.8283 (82.4637)  acc5: 95.2703 (95.2763)  time: 0.7457  data: 0.1113  max mem: 2169
[2024-01-21 09:58:04 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:14  flops: 12.9405 (12.9405)  loss: 0.8507 (0.8508)  acc1: 81.9728 (81.7799)  acc5: 95.2862 (95.3398)  time: 0.2716  data: 0.0002  max mem: 2169
[2024-01-21 09:58:06 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8595 (0.8471)  acc1: 81.4189 (81.6658)  acc5: 95.2862 (95.4411)  time: 0.2417  data: 0.0002  max mem: 2169
[2024-01-21 09:58:08 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8596 (0.8579)  acc1: 80.7432 (81.4600)  acc5: 94.9324 (95.3485)  time: 0.2415  data: 0.0002  max mem: 2169
[2024-01-21 09:58:11 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8772 (0.8501)  acc1: 80.5461 (81.5544)  acc5: 95.6081 (95.5150)  time: 0.2356  data: 0.0002  max mem: 2169
[2024-01-21 09:58:13 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8753 (0.8566)  acc1: 80.6897 (81.3829)  acc5: 95.5326 (95.4014)  time: 0.2301  data: 0.0002  max mem: 2169
[2024-01-21 09:58:15 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8791 (0.8584)  acc1: 80.6897 (81.3283)  acc5: 94.8454 (95.3381)  time: 0.2305  data: 0.0002  max mem: 2169
[2024-01-21 09:58:18 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8626 (0.8611)  acc1: 80.9524 (81.2387)  acc5: 94.8980 (95.3401)  time: 0.2309  data: 0.0002  max mem: 2169
[2024-01-21 09:58:20 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8665 (0.8676)  acc1: 80.0000 (81.1257)  acc5: 94.8097 (95.2777)  time: 0.2371  data: 0.0002  max mem: 2170
[2024-01-21 09:58:22 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8822 (0.8691)  acc1: 80.5369 (81.1228)  acc5: 94.5578 (95.2463)  time: 0.2377  data: 0.0002  max mem: 2170
[2024-01-21 09:58:25 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8849 (0.8717)  acc1: 80.6780 (81.1084)  acc5: 94.2953 (95.1830)  time: 0.2318  data: 0.0002  max mem: 2170
[2024-01-21 09:58:27 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8748 (0.8692)  acc1: 81.0997 (81.1769)  acc5: 94.9324 (95.2325)  time: 0.2307  data: 0.0002  max mem: 2170
[2024-01-21 09:58:29 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8413 (0.8677)  acc1: 81.6609 (81.1692)  acc5: 95.5932 (95.2787)  time: 0.2312  data: 0.0001  max mem: 2170
[2024-01-21 09:58:31 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 09:58:32 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8639 (0.8660)  acc1: 80.7432 (81.1594)  acc5: 95.9184 (95.3296)  time: 0.2327  data: 0.0005  max mem: 2170
[2024-01-21 09:58:34 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8655 (0.8679)  acc1: 80.8081 (81.1450)  acc5: 95.9184 (95.3228)  time: 0.2325  data: 0.0005  max mem: 2170
[2024-01-21 09:58:35 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 09:58:36 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8852 (0.8694)  acc1: 81.0811 (81.1205)  acc5: 94.9324 (95.3023)  time: 0.2350  data: 0.0002  max mem: 2170
[2024-01-21 09:58:37 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 09:58:38 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8852 (0.8681)  acc1: 81.1448 (81.1531)  acc5: 94.9495 (95.2873)  time: 0.2399  data: 0.0002  max mem: 2170
[2024-01-21 09:58:38 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.2689 s / it)
[2024-01-21 09:58:38 root] (engine.py 118): INFO * Acc@1 81.153 Acc@5 95.287 loss 0.868 flops 12.940
[2024-01-21 09:58:38 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-21 09:58:40 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 09:58:45 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:14  flops: 12.9405 (12.9405)  loss: 0.9020 (0.9020)  acc1: 80.8219 (80.8219)  acc5: 92.4658 (92.4658)  time: 5.8355  data: 1.5882  max mem: 2127
[2024-01-21 09:58:48 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:04  flops: 12.9405 (12.9405)  loss: 0.8253 (0.8129)  acc1: 82.0946 (82.0932)  acc5: 94.8980 (94.9058)  time: 0.7939  data: 0.1445  max mem: 2169
[2024-01-21 09:58:51 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:17  flops: 12.9405 (12.9405)  loss: 0.8320 (0.8392)  acc1: 81.4189 (81.7152)  acc5: 94.8980 (95.0162)  time: 0.2628  data: 0.0002  max mem: 2169
[2024-01-21 09:58:53 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:59  flops: 12.9405 (12.9405)  loss: 0.8341 (0.8348)  acc1: 81.3559 (81.8192)  acc5: 95.2542 (95.1781)  time: 0.2369  data: 0.0002  max mem: 2169
[2024-01-21 09:58:55 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:49  flops: 12.9405 (12.9405)  loss: 0.8526 (0.8457)  acc1: 81.3559 (81.6669)  acc5: 94.9324 (95.1001)  time: 0.2374  data: 0.0002  max mem: 2169
[2024-01-21 09:58:58 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8564 (0.8386)  acc1: 80.5369 (81.6609)  acc5: 95.1890 (95.2888)  time: 0.2311  data: 0.0002  max mem: 2169
[2024-01-21 09:59:00 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8608 (0.8459)  acc1: 80.4714 (81.4609)  acc5: 95.1890 (95.2010)  time: 0.2248  data: 0.0002  max mem: 2169
[2024-01-21 09:59:02 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8668 (0.8470)  acc1: 80.7432 (81.4478)  acc5: 94.8276 (95.1277)  time: 0.2249  data: 0.0002  max mem: 2169
[2024-01-21 09:59:04 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8520 (0.8504)  acc1: 80.3390 (81.3058)  acc5: 95.2542 (95.1641)  time: 0.2256  data: 0.0002  max mem: 2169
[2024-01-21 09:59:07 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.8435 (0.8570)  acc1: 80.0000 (81.1854)  acc5: 95.2381 (95.1099)  time: 0.2308  data: 0.0002  max mem: 2170
[2024-01-21 09:59:09 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8440 (0.8586)  acc1: 80.6780 (81.1664)  acc5: 94.6488 (95.0917)  time: 0.2311  data: 0.0002  max mem: 2170
[2024-01-21 09:59:11 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8695 (0.8603)  acc1: 80.7432 (81.1787)  acc5: 94.5763 (95.0699)  time: 0.2253  data: 0.0002  max mem: 2170
[2024-01-21 09:59:14 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8522 (0.8574)  acc1: 81.3793 (81.2302)  acc5: 94.5946 (95.1034)  time: 0.2246  data: 0.0002  max mem: 2170
[2024-01-21 09:59:16 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8370 (0.8557)  acc1: 81.2287 (81.2262)  acc5: 95.2542 (95.1388)  time: 0.2255  data: 0.0002  max mem: 2170
[2024-01-21 09:59:18 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8522 (0.8539)  acc1: 80.4714 (81.2341)  acc5: 95.2703 (95.1611)  time: 0.2258  data: 0.0002  max mem: 2170
[2024-01-21 09:59:20 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8522 (0.8559)  acc1: 81.0169 (81.2125)  acc5: 95.2381 (95.1384)  time: 0.2255  data: 0.0002  max mem: 2170
[2024-01-21 09:59:23 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8830 (0.8578)  acc1: 81.0811 (81.1858)  acc5: 94.9324 (95.1167)  time: 0.2258  data: 0.0002  max mem: 2170
[2024-01-21 09:59:24 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8532 (0.8560)  acc1: 81.3793 (81.2244)  acc5: 94.9324 (95.1019)  time: 0.2270  data: 0.0002  max mem: 2170
[2024-01-21 09:59:24 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.2658 s / it)
[2024-01-21 09:59:24 root] (engine.py 118): INFO * Acc@1 81.224 Acc@5 95.102 loss 0.856 flops 12.940
[2024-01-21 09:59:24 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-21 10:00:13 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:00:17 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 10:00:18 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 10:01:12 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:01:16 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 10:01:17 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 10:01:19 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 10:01:24 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:38  flops: 12.9405 (12.9405)  loss: 0.9014 (0.9014)  acc1: 80.8219 (80.8219)  acc5: 92.4658 (92.4658)  time: 5.2588  data: 1.6335  max mem: 2127
[2024-01-21 10:01:27 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:56  flops: 12.9405 (12.9405)  loss: 0.8254 (0.8132)  acc1: 82.0946 (82.0932)  acc5: 94.8980 (94.9058)  time: 0.7389  data: 0.1486  max mem: 2169
[2024-01-21 10:01:29 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:13  flops: 12.9405 (12.9405)  loss: 0.8330 (0.8394)  acc1: 81.4189 (81.6990)  acc5: 94.8980 (95.0324)  time: 0.2624  data: 0.0002  max mem: 2169
[2024-01-21 10:01:32 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:56  flops: 12.9405 (12.9405)  loss: 0.8342 (0.8348)  acc1: 81.3793 (81.8301)  acc5: 95.2542 (95.1890)  time: 0.2362  data: 0.0002  max mem: 2169
[2024-01-21 10:01:34 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8524 (0.8459)  acc1: 81.6949 (81.6752)  acc5: 94.8980 (95.1001)  time: 0.2351  data: 0.0002  max mem: 2169
[2024-01-21 10:01:36 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8566 (0.8387)  acc1: 80.5369 (81.6609)  acc5: 95.1890 (95.2888)  time: 0.2302  data: 0.0002  max mem: 2169
[2024-01-21 10:01:39 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8629 (0.8461)  acc1: 80.4714 (81.4609)  acc5: 95.1890 (95.2065)  time: 0.2243  data: 0.0002  max mem: 2169
[2024-01-21 10:01:41 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8666 (0.8471)  acc1: 80.7432 (81.4574)  acc5: 94.8276 (95.1372)  time: 0.2245  data: 0.0002  max mem: 2169
[2024-01-21 10:01:43 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8520 (0.8504)  acc1: 80.6780 (81.3142)  acc5: 95.2542 (95.1724)  time: 0.2253  data: 0.0002  max mem: 2169
[2024-01-21 10:01:45 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8426 (0.8570)  acc1: 80.0000 (81.2003)  acc5: 95.2381 (95.1173)  time: 0.2299  data: 0.0002  max mem: 2170
[2024-01-21 10:01:48 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8426 (0.8585)  acc1: 80.7432 (81.1799)  acc5: 94.6488 (95.0951)  time: 0.2295  data: 0.0002  max mem: 2170
[2024-01-21 10:01:50 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8698 (0.8602)  acc1: 80.7432 (81.1909)  acc5: 94.5763 (95.0760)  time: 0.2237  data: 0.0002  max mem: 2170
[2024-01-21 10:01:52 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8521 (0.8572)  acc1: 81.3793 (81.2442)  acc5: 94.9153 (95.1090)  time: 0.2232  data: 0.0002  max mem: 2170
[2024-01-21 10:01:54 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8366 (0.8556)  acc1: 81.2287 (81.2391)  acc5: 95.2542 (95.1439)  time: 0.2241  data: 0.0002  max mem: 2170
[2024-01-21 10:01:57 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8521 (0.8538)  acc1: 80.4714 (81.2437)  acc5: 95.2703 (95.1659)  time: 0.2245  data: 0.0002  max mem: 2170
[2024-01-21 10:01:59 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8521 (0.8558)  acc1: 81.0169 (81.2215)  acc5: 95.2381 (95.1429)  time: 0.2239  data: 0.0002  max mem: 2170
[2024-01-21 10:02:01 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8797 (0.8577)  acc1: 81.0811 (81.1943)  acc5: 94.9324 (95.1188)  time: 0.2245  data: 0.0002  max mem: 2170
[2024-01-21 10:02:03 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8523 (0.8559)  acc1: 81.3793 (81.2326)  acc5: 94.9324 (95.1060)  time: 0.2256  data: 0.0002  max mem: 2170
[2024-01-21 10:02:03 root] (utils.py 307): INFO Test: Total time: 0:00:43 (0.2611 s / it)
[2024-01-21 10:02:03 root] (engine.py 118): INFO * Acc@1 81.233 Acc@5 95.106 loss 0.856 flops 12.940
[2024-01-21 10:02:03 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-21 10:02:19 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:02:23 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 10:02:25 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 10:02:27 root] (main_pitome.py 370): INFO number of params: 86567656
[2024-01-21 10:02:32 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:44  flops: 12.9405 (12.9405)  loss: 0.8797 (0.8797)  acc1: 80.4795 (80.4795)  acc5: 93.8356 (93.8356)  time: 5.2977  data: 1.8323  max mem: 2127
[2024-01-21 10:02:35 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:57  flops: 12.9405 (12.9405)  loss: 0.8154 (0.8284)  acc1: 82.5939 (82.3402)  acc5: 95.2703 (95.2454)  time: 0.7507  data: 0.1667  max mem: 2169
[2024-01-21 10:02:37 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:14  flops: 12.9405 (12.9405)  loss: 0.8399 (0.8500)  acc1: 82.1549 (81.8123)  acc5: 95.2862 (95.2913)  time: 0.2689  data: 0.0002  max mem: 2169
[2024-01-21 10:02:40 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8581 (0.8467)  acc1: 81.4189 (81.6877)  acc5: 95.2862 (95.4082)  time: 0.2412  data: 0.0002  max mem: 2169
[2024-01-21 10:02:42 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8581 (0.8577)  acc1: 80.7432 (81.4849)  acc5: 94.9324 (95.3319)  time: 0.2409  data: 0.0002  max mem: 2169
[2024-01-21 10:02:45 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8843 (0.8499)  acc1: 80.7432 (81.5611)  acc5: 95.2703 (95.4751)  time: 0.2358  data: 0.0002  max mem: 2169
[2024-01-21 10:02:47 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8746 (0.8565)  acc1: 80.7432 (81.3829)  acc5: 95.1890 (95.3736)  time: 0.2293  data: 0.0002  max mem: 2169
[2024-01-21 10:02:49 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8866 (0.8581)  acc1: 81.0345 (81.3426)  acc5: 94.8454 (95.3237)  time: 0.2295  data: 0.0002  max mem: 2169
[2024-01-21 10:02:51 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8659 (0.8608)  acc1: 80.9524 (81.2681)  acc5: 94.8980 (95.3359)  time: 0.2304  data: 0.0002  max mem: 2169
[2024-01-21 10:02:54 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8667 (0.8673)  acc1: 79.7980 (81.1519)  acc5: 94.8805 (95.2777)  time: 0.2358  data: 0.0002  max mem: 2170
[2024-01-21 10:02:56 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8825 (0.8688)  acc1: 80.5369 (81.1496)  acc5: 94.6488 (95.2295)  time: 0.2366  data: 0.0002  max mem: 2170
[2024-01-21 10:02:58 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8829 (0.8714)  acc1: 80.8219 (81.1481)  acc5: 94.2568 (95.1708)  time: 0.2308  data: 0.0002  max mem: 2170
[2024-01-21 10:03:01 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8723 (0.8689)  acc1: 81.4433 (81.2162)  acc5: 94.9324 (95.2128)  time: 0.2314  data: 0.0002  max mem: 2170
[2024-01-21 10:03:03 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8449 (0.8675)  acc1: 81.7568 (81.2210)  acc5: 95.2542 (95.2554)  time: 0.2325  data: 0.0002  max mem: 2170
[2024-01-21 10:03:05 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8609 (0.8658)  acc1: 80.7432 (81.2076)  acc5: 95.9459 (95.3079)  time: 0.2320  data: 0.0002  max mem: 2170
[2024-01-21 10:03:08 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8626 (0.8677)  acc1: 81.1448 (81.1855)  acc5: 95.9184 (95.3003)  time: 0.2316  data: 0.0002  max mem: 2170
[2024-01-21 10:03:10 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8886 (0.8692)  acc1: 81.4189 (81.1732)  acc5: 95.2703 (95.2854)  time: 0.2323  data: 0.0002  max mem: 2170
[2024-01-21 10:03:11 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8865 (0.8678)  acc1: 81.4189 (81.2000)  acc5: 95.2703 (95.2730)  time: 0.2327  data: 0.0002  max mem: 2170
[2024-01-21 10:03:11 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.2680 s / it)
[2024-01-21 10:03:11 root] (engine.py 118): INFO * Acc@1 81.200 Acc@5 95.273 loss 0.868 flops 12.940
[2024-01-21 10:03:11 root] (main_pitome.py 378): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-21 10:03:46 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:03:50 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 10:03:52 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 10:03:53 root] (main_pitome.py 373): INFO number of params: 86567656
[2024-01-21 10:03:59 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:15:14  flops: 12.9405 (12.9405)  loss: 0.8833 (0.8833)  acc1: 80.1370 (80.1370)  acc5: 93.8356 (93.8356)  time: 5.4758  data: 1.3793  max mem: 2127
[2024-01-21 10:04:02 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:00  flops: 12.9405 (12.9405)  loss: 0.8162 (0.8284)  acc1: 82.2526 (82.2476)  acc5: 95.2703 (95.2454)  time: 0.7667  data: 0.1255  max mem: 2169
[2024-01-21 10:04:04 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:15  flops: 12.9405 (12.9405)  loss: 0.8456 (0.8498)  acc1: 81.8182 (81.7476)  acc5: 95.2703 (95.2751)  time: 0.2681  data: 0.0002  max mem: 2169
[2024-01-21 10:04:07 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:58  flops: 12.9405 (12.9405)  loss: 0.8585 (0.8465)  acc1: 81.4189 (81.6219)  acc5: 95.2055 (95.3753)  time: 0.2401  data: 0.0002  max mem: 2169
[2024-01-21 10:04:09 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8599 (0.8573)  acc1: 81.0811 (81.4600)  acc5: 94.9153 (95.3236)  time: 0.2414  data: 0.0002  max mem: 2169
[2024-01-21 10:04:21 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:04:25 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 10:04:26 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 10:04:28 root] (main_pitome.py 373): INFO number of params: 86567656
[2024-01-21 10:04:34 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:55  flops: 12.9405 (12.9405)  loss: 0.8909 (0.8909)  acc1: 81.1644 (81.1644)  acc5: 92.8082 (92.8082)  time: 5.3618  data: 1.6844  max mem: 2127
[2024-01-21 10:04:37 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:58  flops: 12.9405 (12.9405)  loss: 0.8463 (0.8356)  acc1: 81.7568 (81.9080)  acc5: 95.2703 (95.1220)  time: 0.7565  data: 0.1533  max mem: 2169
[2024-01-21 10:04:39 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:15  flops: 12.9405 (12.9405)  loss: 0.8511 (0.8574)  acc1: 81.4433 (81.4725)  acc5: 95.1890 (95.1294)  time: 0.2689  data: 0.0002  max mem: 2169
[2024-01-21 10:04:41 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:58  flops: 12.9405 (12.9405)  loss: 0.8755 (0.8582)  acc1: 81.1448 (81.3151)  acc5: 94.8805 (95.2000)  time: 0.2419  data: 0.0002  max mem: 2169
[2024-01-21 10:04:44 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8828 (0.8658)  acc1: 80.5461 (81.2614)  acc5: 95.2218 (95.1498)  time: 0.2417  data: 0.0002  max mem: 2169
[2024-01-21 10:04:46 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8691 (0.8573)  acc1: 80.5461 (81.3881)  acc5: 95.5631 (95.3620)  time: 0.2359  data: 0.0002  max mem: 2169
[2024-01-21 10:04:48 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8691 (0.8641)  acc1: 80.9524 (81.2827)  acc5: 95.8763 (95.3068)  time: 0.2299  data: 0.0002  max mem: 2169
[2024-01-21 10:04:51 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8936 (0.8644)  acc1: 80.9524 (81.3379)  acc5: 94.5578 (95.2663)  time: 0.2298  data: 0.0002  max mem: 2169
[2024-01-21 10:04:53 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8642 (0.8684)  acc1: 80.6780 (81.2094)  acc5: 95.5782 (95.3149)  time: 0.2303  data: 0.0002  max mem: 2169
[2024-01-21 10:04:55 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.9035 (0.8746)  acc1: 80.2721 (81.0922)  acc5: 95.2703 (95.2628)  time: 0.2360  data: 0.0002  max mem: 2170
[2024-01-21 10:04:58 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.9024 (0.8754)  acc1: 80.7432 (81.0320)  acc5: 94.9495 (95.2563)  time: 0.2363  data: 0.0002  max mem: 2170
[2024-01-21 10:05:00 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.9024 (0.8779)  acc1: 80.4054 (81.0197)  acc5: 94.8980 (95.2167)  time: 0.2302  data: 0.0002  max mem: 2170
[2024-01-21 10:05:02 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8683 (0.8751)  acc1: 80.4795 (81.0646)  acc5: 94.8630 (95.2437)  time: 0.2298  data: 0.0002  max mem: 2170
[2024-01-21 10:05:05 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8569 (0.8731)  acc1: 81.4189 (81.0578)  acc5: 95.5932 (95.2865)  time: 0.2313  data: 0.0002  max mem: 2170
[2024-01-21 10:05:07 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8635 (0.8723)  acc1: 79.9320 (81.0270)  acc5: 95.5932 (95.3151)  time: 0.2324  data: 0.0005  max mem: 2170
[2024-01-21 10:05:09 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8638 (0.8734)  acc1: 80.8081 (80.9809)  acc5: 95.5782 (95.3093)  time: 0.2320  data: 0.0006  max mem: 2170
[2024-01-21 10:05:12 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8741 (0.8752)  acc1: 80.4054 (80.9391)  acc5: 95.2218 (95.2875)  time: 0.2316  data: 0.0002  max mem: 2170
[2024-01-21 10:05:13 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8741 (0.8737)  acc1: 81.2925 (80.9719)  acc5: 94.9324 (95.2669)  time: 0.2322  data: 0.0002  max mem: 2170
[2024-01-21 10:05:13 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.2682 s / it)
[2024-01-21 10:05:13 root] (engine.py 118): INFO * Acc@1 80.972 Acc@5 95.267 loss 0.874 flops 12.940
[2024-01-21 10:05:13 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 81.0%
[2024-01-21 10:05:46 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:05:50 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 10:05:52 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 10:05:58 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:06:02 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 10:06:03 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 10:06:05 root] (main_pitome.py 373): INFO number of params: 86567656
[2024-01-21 10:06:10 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:33  flops: 12.9405 (12.9405)  loss: 0.8868 (0.8868)  acc1: 80.8219 (80.8219)  acc5: 93.4931 (93.4931)  time: 5.2309  data: 1.1300  max mem: 2127
[2024-01-21 10:06:13 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:56  flops: 12.9405 (12.9405)  loss: 0.8469 (0.8345)  acc1: 81.9113 (82.0315)  acc5: 95.2862 (95.1220)  time: 0.7437  data: 0.1029  max mem: 2169
[2024-01-21 10:06:16 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:14  flops: 12.9405 (12.9405)  loss: 0.8476 (0.8561)  acc1: 81.4815 (81.5049)  acc5: 94.9324 (95.1133)  time: 0.2690  data: 0.0002  max mem: 2169
[2024-01-21 10:06:18 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8729 (0.8576)  acc1: 80.6897 (81.3151)  acc5: 95.2218 (95.2110)  time: 0.2422  data: 0.0002  max mem: 2169
[2024-01-21 10:06:21 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8857 (0.8654)  acc1: 81.0811 (81.2697)  acc5: 95.2218 (95.1746)  time: 0.2417  data: 0.0002  max mem: 2169
[2024-01-21 10:06:23 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8772 (0.8569)  acc1: 81.0811 (81.3947)  acc5: 95.6081 (95.3886)  time: 0.2363  data: 0.0002  max mem: 2169
[2024-01-21 10:06:25 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8772 (0.8636)  acc1: 80.6897 (81.2883)  acc5: 95.8763 (95.3290)  time: 0.2300  data: 0.0002  max mem: 2169
[2024-01-21 10:06:28 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8963 (0.8641)  acc1: 80.6897 (81.3379)  acc5: 94.5946 (95.2807)  time: 0.2297  data: 0.0002  max mem: 2169
[2024-01-21 10:06:30 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8688 (0.8681)  acc1: 80.6780 (81.2136)  acc5: 95.2542 (95.2982)  time: 0.2307  data: 0.0002  max mem: 2169
[2024-01-21 10:06:32 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.9070 (0.8745)  acc1: 80.2721 (81.1034)  acc5: 94.9495 (95.2404)  time: 0.2363  data: 0.0002  max mem: 2170
[2024-01-21 10:06:35 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8940 (0.8752)  acc1: 80.8725 (81.0690)  acc5: 94.9495 (95.2328)  time: 0.2368  data: 0.0002  max mem: 2170
[2024-01-21 10:06:37 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8999 (0.8776)  acc1: 80.7432 (81.0594)  acc5: 94.8980 (95.1983)  time: 0.2309  data: 0.0002  max mem: 2170
[2024-01-21 10:06:39 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8727 (0.8748)  acc1: 80.8219 (81.1179)  acc5: 94.8630 (95.2185)  time: 0.2299  data: 0.0002  max mem: 2170
[2024-01-21 10:06:42 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8500 (0.8727)  acc1: 81.4433 (81.1070)  acc5: 95.5932 (95.2683)  time: 0.2310  data: 0.0002  max mem: 2170
[2024-01-21 10:06:44 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8621 (0.8720)  acc1: 79.9320 (81.0800)  acc5: 95.5932 (95.2959)  time: 0.2314  data: 0.0002  max mem: 2170
[2024-01-21 10:06:46 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8621 (0.8730)  acc1: 81.0169 (81.0461)  acc5: 95.5782 (95.2913)  time: 0.2308  data: 0.0002  max mem: 2170
[2024-01-21 10:06:49 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8775 (0.8747)  acc1: 80.4054 (80.9982)  acc5: 95.2218 (95.2727)  time: 0.2322  data: 0.0002  max mem: 2170
[2024-01-21 10:06:50 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8775 (0.8733)  acc1: 81.2925 (81.0350)  acc5: 94.9324 (95.2547)  time: 0.2336  data: 0.0002  max mem: 2170
[2024-01-21 10:06:50 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.2676 s / it)
[2024-01-21 10:06:50 root] (engine.py 118): INFO * Acc@1 81.035 Acc@5 95.255 loss 0.873 flops 12.940
[2024-01-21 10:06:50 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 81.0%
[2024-01-21 10:07:33 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:07:37 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 10:07:38 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 10:07:41 root] (main_pitome.py 373): INFO number of params: 86567656
[2024-01-21 10:07:46 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:44  flops: 12.9405 (12.9405)  loss: 0.8868 (0.8868)  acc1: 80.4795 (80.4795)  acc5: 93.8356 (93.8356)  time: 5.2978  data: 1.2964  max mem: 2127
[2024-01-21 10:07:49 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:57  flops: 12.9405 (12.9405)  loss: 0.8244 (0.8365)  acc1: 82.2742 (82.2167)  acc5: 95.2703 (95.2763)  time: 0.7506  data: 0.1180  max mem: 2169
[2024-01-21 10:07:51 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:14  flops: 12.9405 (12.9405)  loss: 0.8543 (0.8553)  acc1: 81.7568 (81.6990)  acc5: 95.2218 (95.3236)  time: 0.2676  data: 0.0002  max mem: 2169
[2024-01-21 10:07:54 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8609 (0.8505)  acc1: 80.8081 (81.7425)  acc5: 95.2218 (95.4630)  time: 0.2407  data: 0.0002  max mem: 2169
[2024-01-21 10:07:56 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8706 (0.8593)  acc1: 80.6780 (81.6173)  acc5: 95.2218 (95.3485)  time: 0.2433  data: 0.0002  max mem: 2169
[2024-01-21 10:07:58 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8706 (0.8508)  acc1: 80.7560 (81.6409)  acc5: 95.8763 (95.5017)  time: 0.2376  data: 0.0002  max mem: 2169
[2024-01-21 10:08:01 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8549 (0.8573)  acc1: 80.9524 (81.5388)  acc5: 95.5326 (95.4125)  time: 0.2304  data: 0.0002  max mem: 2169
[2024-01-21 10:08:03 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8788 (0.8577)  acc1: 81.2081 (81.5339)  acc5: 94.8980 (95.3572)  time: 0.2302  data: 0.0002  max mem: 2169
[2024-01-21 10:08:05 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8788 (0.8618)  acc1: 80.6897 (81.3393)  acc5: 95.5932 (95.3736)  time: 0.2308  data: 0.0002  max mem: 2169
[2024-01-21 10:08:08 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8924 (0.8684)  acc1: 80.6020 (81.2712)  acc5: 94.9495 (95.3150)  time: 0.2359  data: 0.0002  max mem: 2170
[2024-01-21 10:08:10 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8846 (0.8700)  acc1: 80.8725 (81.2471)  acc5: 94.9324 (95.2933)  time: 0.2356  data: 0.0002  max mem: 2170
[2024-01-21 10:08:12 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8920 (0.8723)  acc1: 80.4714 (81.2001)  acc5: 94.8980 (95.2442)  time: 0.2305  data: 0.0002  max mem: 2170
[2024-01-21 10:08:15 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8715 (0.8695)  acc1: 80.6897 (81.2582)  acc5: 94.8454 (95.2690)  time: 0.2307  data: 0.0002  max mem: 2170
[2024-01-21 10:08:17 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8522 (0.8678)  acc1: 81.0169 (81.2599)  acc5: 95.5932 (95.3072)  time: 0.2311  data: 0.0002  max mem: 2170
[2024-01-21 10:08:19 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8705 (0.8666)  acc1: 80.8081 (81.2702)  acc5: 95.9184 (95.3440)  time: 0.2313  data: 0.0002  max mem: 2170
[2024-01-21 10:08:22 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8705 (0.8682)  acc1: 80.8081 (81.2305)  acc5: 95.8904 (95.3318)  time: 0.2308  data: 0.0002  max mem: 2170
[2024-01-21 10:08:24 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8814 (0.8697)  acc1: 81.0811 (81.2069)  acc5: 95.2703 (95.3170)  time: 0.2314  data: 0.0002  max mem: 2170
[2024-01-21 10:08:25 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8659 (0.8681)  acc1: 81.4189 (81.2305)  acc5: 94.9495 (95.2954)  time: 0.2336  data: 0.0002  max mem: 2170
[2024-01-21 10:08:25 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.2680 s / it)
[2024-01-21 10:08:25 root] (engine.py 118): INFO * Acc@1 81.231 Acc@5 95.295 loss 0.868 flops 12.940
[2024-01-21 10:08:25 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-21 10:08:48 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:08:52 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 10:08:53 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 10:08:56 root] (main_pitome.py 373): INFO number of params: 86567656
[2024-01-21 10:09:01 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:13:53  flops: 12.9405 (12.9405)  loss: 0.8987 (0.8987)  acc1: 81.1644 (81.1644)  acc5: 93.8356 (93.8356)  time: 4.9905  data: 0.5618  max mem: 2127
[2024-01-21 10:09:04 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:53  flops: 12.9405 (12.9405)  loss: 0.8306 (0.8348)  acc1: 82.8179 (82.6181)  acc5: 95.2862 (95.0911)  time: 0.7249  data: 0.0512  max mem: 2169
[2024-01-21 10:09:06 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 0.8501 (0.8524)  acc1: 81.9113 (81.9903)  acc5: 95.2055 (95.1133)  time: 0.2713  data: 0.0002  max mem: 2169
[2024-01-21 10:09:08 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:56  flops: 12.9405 (12.9405)  loss: 0.8473 (0.8489)  acc1: 81.1448 (81.8082)  acc5: 95.2381 (95.2986)  time: 0.2435  data: 0.0002  max mem: 2169
[2024-01-21 10:09:11 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:47  flops: 12.9405 (12.9405)  loss: 0.8513 (0.8566)  acc1: 81.5700 (81.5842)  acc5: 95.2703 (95.2905)  time: 0.2426  data: 0.0002  max mem: 2169
[2024-01-21 10:09:13 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8513 (0.8490)  acc1: 81.5700 (81.6742)  acc5: 95.6081 (95.4551)  time: 0.2359  data: 0.0002  max mem: 2169
[2024-01-21 10:09:15 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8627 (0.8557)  acc1: 81.4815 (81.5611)  acc5: 95.6081 (95.4237)  time: 0.2297  data: 0.0002  max mem: 2169
[2024-01-21 10:09:18 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8762 (0.8574)  acc1: 81.6327 (81.5626)  acc5: 95.1890 (95.3285)  time: 0.2303  data: 0.0002  max mem: 2169
[2024-01-21 10:09:20 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8559 (0.8611)  acc1: 81.6327 (81.4566)  acc5: 95.2862 (95.3484)  time: 0.2312  data: 0.0002  max mem: 2169
[2024-01-21 10:09:22 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8866 (0.8688)  acc1: 80.7432 (81.2675)  acc5: 94.9324 (95.2889)  time: 0.2367  data: 0.0002  max mem: 2170
[2024-01-21 10:09:25 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8781 (0.8699)  acc1: 80.3390 (81.1899)  acc5: 94.8630 (95.2765)  time: 0.2364  data: 0.0002  max mem: 2170
[2024-01-21 10:09:27 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8866 (0.8726)  acc1: 80.2013 (81.1512)  acc5: 94.9153 (95.2350)  time: 0.2312  data: 0.0002  max mem: 2170
[2024-01-21 10:09:29 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8775 (0.8696)  acc1: 81.3149 (81.2330)  acc5: 95.1890 (95.2858)  time: 0.2316  data: 0.0002  max mem: 2170
[2024-01-21 10:09:32 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8667 (0.8681)  acc1: 81.3559 (81.2521)  acc5: 95.6376 (95.3305)  time: 0.2322  data: 0.0002  max mem: 2170
[2024-01-21 10:09:34 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8714 (0.8664)  acc1: 80.7432 (81.2485)  acc5: 95.8904 (95.3681)  time: 0.2321  data: 0.0002  max mem: 2170
[2024-01-21 10:09:36 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.8657 (0.8679)  acc1: 81.1448 (81.2192)  acc5: 95.5782 (95.3520)  time: 0.2317  data: 0.0002  max mem: 2170
[2024-01-21 10:09:39 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8764 (0.8696)  acc1: 81.3559 (81.2153)  acc5: 94.6128 (95.3276)  time: 0.2317  data: 0.0002  max mem: 2170
[2024-01-21 10:09:40 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8655 (0.8677)  acc1: 81.5700 (81.2489)  acc5: 95.2862 (95.3178)  time: 0.2318  data: 0.0002  max mem: 2170
[2024-01-21 10:09:40 root] (utils.py 307): INFO Test: Total time: 0:00:44 (0.2667 s / it)
[2024-01-21 10:09:40 root] (engine.py 118): INFO * Acc@1 81.249 Acc@5 95.318 loss 0.868 flops 12.940
[2024-01-21 10:09:40 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-21 10:10:04 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:10:07 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:10:08 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:10:09 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:10:15 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:19  flops: 3.3726 (3.3726)  loss: 0.8885 (0.8885)  acc1: 80.8219 (80.8219)  acc5: 94.1781 (94.1781)  time: 5.8679  data: 1.1931  max mem: 1066
[2024-01-21 10:10:17 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:45  flops: 3.3726 (3.3726)  loss: 0.8885 (0.8912)  acc1: 80.8219 (80.6422)  acc5: 94.5392 (94.4736)  time: 0.6709  data: 0.1086  max mem: 1090
[2024-01-21 10:10:18 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.3726 (3.3726)  loss: 0.8940 (0.8926)  acc1: 80.4714 (80.3398)  acc5: 94.8980 (94.7087)  time: 0.1310  data: 0.0002  max mem: 1090
[2024-01-21 10:10:19 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.3726 (3.3726)  loss: 0.8961 (0.8911)  acc1: 80.0676 (80.1753)  acc5: 95.2703 (94.8603)  time: 0.1109  data: 0.0002  max mem: 1090
[2024-01-21 10:10:20 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 0.9043 (0.9021)  acc1: 78.4983 (79.8047)  acc5: 94.8805 (94.6946)  time: 0.1177  data: 0.0059  max mem: 1090
[2024-01-21 10:10:22 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9072 (0.8963)  acc1: 78.1570 (79.8776)  acc5: 94.8805 (94.8230)  time: 0.1447  data: 0.0365  max mem: 1090
[2024-01-21 10:10:24 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 0.9004 (0.9028)  acc1: 78.5714 (79.5568)  acc5: 95.2542 (94.8224)  time: 0.1771  data: 0.0738  max mem: 1090
[2024-01-21 10:10:26 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.3726 (3.3726)  loss: 0.9132 (0.9028)  acc1: 78.5714 (79.5400)  acc5: 94.8980 (94.8503)  time: 0.1797  data: 0.0769  max mem: 1090
[2024-01-21 10:10:27 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9339 (0.9100)  acc1: 77.9661 (79.2985)  acc5: 94.5763 (94.8456)  time: 0.1749  data: 0.0722  max mem: 1090
[2024-01-21 10:10:29 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9687 (0.9162)  acc1: 77.2881 (79.1936)  acc5: 94.1980 (94.7406)  time: 0.1780  data: 0.0721  max mem: 1091
[2024-01-21 10:10:31 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9539 (0.9203)  acc1: 78.4512 (79.1306)  acc5: 93.8356 (94.6819)  time: 0.1721  data: 0.0665  max mem: 1091
[2024-01-21 10:10:32 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9539 (0.9221)  acc1: 78.8591 (79.1082)  acc5: 93.7931 (94.6692)  time: 0.1670  data: 0.0647  max mem: 1091
[2024-01-21 10:10:34 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.8963 (0.9188)  acc1: 80.0676 (79.1874)  acc5: 95.5479 (94.7274)  time: 0.1680  data: 0.0650  max mem: 1091
[2024-01-21 10:10:36 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8814 (0.9177)  acc1: 80.2048 (79.2257)  acc5: 95.5932 (94.7475)  time: 0.1720  data: 0.0676  max mem: 1091
[2024-01-21 10:10:38 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.9070 (0.9169)  acc1: 78.7671 (79.2070)  acc5: 94.9324 (94.7855)  time: 0.1823  data: 0.0777  max mem: 1091
[2024-01-21 10:10:39 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9356 (0.9186)  acc1: 78.4983 (79.1887)  acc5: 94.8980 (94.7741)  time: 0.1777  data: 0.0741  max mem: 1091
[2024-01-21 10:10:41 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9302 (0.9206)  acc1: 78.8591 (79.1427)  acc5: 93.9394 (94.7435)  time: 0.1708  data: 0.0675  max mem: 1091
[2024-01-21 10:10:42 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9092 (0.9184)  acc1: 78.8591 (79.1735)  acc5: 94.9324 (94.7639)  time: 0.1728  data: 0.0675  max mem: 1091
[2024-01-21 10:10:42 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1942 s / it)
[2024-01-21 10:10:42 root] (engine.py 118): INFO * Acc@1 79.174 Acc@5 94.764 loss 0.918 flops 3.373
[2024-01-21 10:10:42 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.2%
[2024-01-21 10:11:01 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:11:06 root] (main_tome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:11:06 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:11:07 root] (main_tome.py 370): INFO number of params: 22050664
[2024-01-21 10:11:13 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:19  flops: 3.3726 (3.3726)  loss: 0.8864 (0.8864)  acc1: 81.1644 (81.1644)  acc5: 94.8630 (94.8630)  time: 5.8632  data: 1.6062  max mem: 1066
[2024-01-21 10:11:15 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:43  flops: 3.3726 (3.3726)  loss: 0.8956 (0.8967)  acc1: 80.8081 (80.7657)  acc5: 94.8805 (94.5353)  time: 0.6620  data: 0.1462  max mem: 1090
[2024-01-21 10:11:16 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:58  flops: 3.3726 (3.3726)  loss: 0.9031 (0.8980)  acc1: 80.1370 (80.2589)  acc5: 94.8805 (94.6602)  time: 0.1235  data: 0.0002  max mem: 1090
[2024-01-21 10:11:17 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:41  flops: 3.3726 (3.3726)  loss: 0.9031 (0.8981)  acc1: 79.7297 (80.0219)  acc5: 94.9324 (94.7726)  time: 0.1053  data: 0.0002  max mem: 1090
[2024-01-21 10:11:18 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 0.9202 (0.9075)  acc1: 79.2517 (79.8212)  acc5: 94.9324 (94.6863)  time: 0.1206  data: 0.0153  max mem: 1090
[2024-01-21 10:11:20 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9145 (0.8982)  acc1: 79.2517 (79.8975)  acc5: 94.9324 (94.8762)  time: 0.1491  data: 0.0473  max mem: 1090
[2024-01-21 10:11:22 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:24  flops: 3.3726 (3.3726)  loss: 0.9225 (0.9062)  acc1: 77.7778 (79.5290)  acc5: 94.9324 (94.7500)  time: 0.1739  data: 0.0758  max mem: 1090
[2024-01-21 10:11:23 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.3726 (3.3726)  loss: 0.9242 (0.9071)  acc1: 78.9655 (79.5066)  acc5: 93.8144 (94.7643)  time: 0.1792  data: 0.0810  max mem: 1090
[2024-01-21 10:11:25 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9466 (0.9134)  acc1: 78.3051 (79.2859)  acc5: 94.5946 (94.7827)  time: 0.1783  data: 0.0800  max mem: 1090
[2024-01-21 10:11:27 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9615 (0.9192)  acc1: 77.2881 (79.1898)  acc5: 94.5578 (94.6995)  time: 0.1818  data: 0.0798  max mem: 1091
[2024-01-21 10:11:29 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9410 (0.9218)  acc1: 79.3919 (79.1709)  acc5: 93.6455 (94.6483)  time: 0.1696  data: 0.0677  max mem: 1091
[2024-01-21 10:11:30 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9452 (0.9237)  acc1: 79.3919 (79.1693)  acc5: 94.2177 (94.6387)  time: 0.1625  data: 0.0648  max mem: 1091
[2024-01-21 10:11:32 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.9130 (0.9203)  acc1: 80.1370 (79.2800)  acc5: 94.5763 (94.6797)  time: 0.1681  data: 0.0707  max mem: 1091
[2024-01-21 10:11:34 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.9022 (0.9202)  acc1: 79.3220 (79.2516)  acc5: 94.9324 (94.7060)  time: 0.1702  data: 0.0725  max mem: 1091
[2024-01-21 10:11:36 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.9123 (0.9199)  acc1: 78.9116 (79.2551)  acc5: 94.9324 (94.7373)  time: 0.1793  data: 0.0814  max mem: 1091
[2024-01-21 10:11:37 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9358 (0.9217)  acc1: 78.7162 (79.2382)  acc5: 94.4637 (94.7247)  time: 0.1812  data: 0.0836  max mem: 1091
[2024-01-21 10:11:39 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9353 (0.9239)  acc1: 78.7162 (79.1954)  acc5: 94.2177 (94.6908)  time: 0.1766  data: 0.0788  max mem: 1091
[2024-01-21 10:11:40 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9307 (0.9218)  acc1: 79.0541 (79.2326)  acc5: 94.2568 (94.6987)  time: 0.1740  data: 0.0746  max mem: 1091
[2024-01-21 10:11:40 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1953 s / it)
[2024-01-21 10:11:40 root] (engine.py 118): INFO * Acc@1 79.233 Acc@5 94.699 loss 0.922 flops 3.373
[2024-01-21 10:11:40 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 79.2%
[2024-01-21 10:12:28 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:12:32 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:12:32 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:12:34 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:12:40 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:29  flops: 3.3726 (3.3726)  loss: 0.8893 (0.8893)  acc1: 80.1370 (80.1370)  acc5: 94.1781 (94.1781)  time: 5.9251  data: 2.0015  max mem: 1066
[2024-01-21 10:12:41 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:45  flops: 3.3726 (3.3726)  loss: 0.8885 (0.8910)  acc1: 80.4714 (80.6113)  acc5: 94.5392 (94.4736)  time: 0.6730  data: 0.1821  max mem: 1090
[2024-01-21 10:12:42 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.3726 (3.3726)  loss: 0.8937 (0.8926)  acc1: 80.4714 (80.3398)  acc5: 94.8980 (94.7087)  time: 0.1294  data: 0.0002  max mem: 1090
[2024-01-21 10:12:43 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.3726 (3.3726)  loss: 0.8954 (0.8909)  acc1: 80.0676 (80.1863)  acc5: 95.5172 (94.8603)  time: 0.1110  data: 0.0002  max mem: 1090
[2024-01-21 10:12:45 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 0.9042 (0.9018)  acc1: 78.4983 (79.7964)  acc5: 94.8805 (94.7029)  time: 0.1191  data: 0.0084  max mem: 1090
[2024-01-21 10:12:46 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9100 (0.8962)  acc1: 78.1570 (79.8576)  acc5: 94.8805 (94.8297)  time: 0.1477  data: 0.0407  max mem: 1090
[2024-01-21 10:12:48 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 0.9000 (0.9027)  acc1: 78.7162 (79.5457)  acc5: 95.5326 (94.8224)  time: 0.1762  data: 0.0727  max mem: 1090
[2024-01-21 10:12:50 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 0.9128 (0.9027)  acc1: 78.7162 (79.5400)  acc5: 94.8980 (94.8551)  time: 0.1792  data: 0.0757  max mem: 1090
[2024-01-21 10:12:52 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9343 (0.9099)  acc1: 77.9310 (79.2901)  acc5: 94.5763 (94.8498)  time: 0.1777  data: 0.0741  max mem: 1090
[2024-01-21 10:12:54 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9704 (0.9161)  acc1: 77.2881 (79.1861)  acc5: 94.2177 (94.7480)  time: 0.1770  data: 0.0701  max mem: 1091
[2024-01-21 10:12:55 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9538 (0.9202)  acc1: 78.4512 (79.1272)  acc5: 93.8356 (94.6886)  time: 0.1687  data: 0.0620  max mem: 1091
[2024-01-21 10:12:57 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9538 (0.9219)  acc1: 78.8591 (79.1021)  acc5: 93.8356 (94.6845)  time: 0.1642  data: 0.0612  max mem: 1091
[2024-01-21 10:12:58 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.8982 (0.9186)  acc1: 79.9320 (79.1789)  acc5: 95.5782 (94.7470)  time: 0.1616  data: 0.0588  max mem: 1091
[2024-01-21 10:13:00 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8798 (0.9175)  acc1: 80.0687 (79.2205)  acc5: 95.5932 (94.7656)  time: 0.1655  data: 0.0624  max mem: 1091
[2024-01-21 10:13:02 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.9095 (0.9168)  acc1: 78.7671 (79.2022)  acc5: 94.9324 (94.8023)  time: 0.1784  data: 0.0753  max mem: 1091
[2024-01-21 10:13:04 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9352 (0.9184)  acc1: 78.5714 (79.1819)  acc5: 94.8980 (94.7899)  time: 0.1766  data: 0.0740  max mem: 1091
[2024-01-21 10:13:05 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9310 (0.9205)  acc1: 78.8591 (79.1342)  acc5: 93.9394 (94.7583)  time: 0.1741  data: 0.0711  max mem: 1091
[2024-01-21 10:13:06 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9089 (0.9183)  acc1: 78.8591 (79.1654)  acc5: 94.9324 (94.7781)  time: 0.1728  data: 0.0677  max mem: 1091
[2024-01-21 10:13:06 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1939 s / it)
[2024-01-21 10:13:06 root] (engine.py 118): INFO * Acc@1 79.165 Acc@5 94.778 loss 0.918 flops 3.373
[2024-01-21 10:13:06 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.2%
[2024-01-21 10:13:25 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:13:29 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:13:29 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:13:31 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:13:37 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:26  flops: 3.3726 (3.3726)  loss: 0.8869 (0.8869)  acc1: 81.1644 (81.1644)  acc5: 94.1781 (94.1781)  time: 5.9081  data: 1.4675  max mem: 1066
[2024-01-21 10:13:38 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:45  flops: 3.3726 (3.3726)  loss: 0.8869 (0.8905)  acc1: 81.0811 (80.6422)  acc5: 94.5392 (94.4736)  time: 0.6692  data: 0.1335  max mem: 1090
[2024-01-21 10:13:39 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.3726 (3.3726)  loss: 0.8944 (0.8922)  acc1: 80.4714 (80.3560)  acc5: 94.8980 (94.7087)  time: 0.1270  data: 0.0001  max mem: 1090
[2024-01-21 10:13:40 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.3726 (3.3726)  loss: 0.8956 (0.8907)  acc1: 80.0676 (80.1863)  acc5: 95.2703 (94.8603)  time: 0.1111  data: 0.0001  max mem: 1090
[2024-01-21 10:13:42 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 0.9044 (0.9017)  acc1: 78.1570 (79.8047)  acc5: 94.8805 (94.6946)  time: 0.1177  data: 0.0052  max mem: 1090
[2024-01-21 10:13:43 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9069 (0.8960)  acc1: 78.1570 (79.8776)  acc5: 94.8805 (94.8163)  time: 0.1448  data: 0.0371  max mem: 1090
[2024-01-21 10:13:45 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 0.9015 (0.9026)  acc1: 78.7162 (79.5624)  acc5: 95.2703 (94.8168)  time: 0.1790  data: 0.0755  max mem: 1090
[2024-01-21 10:13:47 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 0.9124 (0.9026)  acc1: 78.7162 (79.5544)  acc5: 94.8980 (94.8408)  time: 0.1819  data: 0.0783  max mem: 1090
[2024-01-21 10:13:49 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9349 (0.9098)  acc1: 78.3051 (79.3153)  acc5: 94.5763 (94.8372)  time: 0.1749  data: 0.0714  max mem: 1090
[2024-01-21 10:13:50 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9704 (0.9161)  acc1: 77.2881 (79.2010)  acc5: 93.9799 (94.7294)  time: 0.1752  data: 0.0686  max mem: 1091
[2024-01-21 10:13:52 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9529 (0.9201)  acc1: 78.5235 (79.1440)  acc5: 93.8356 (94.6718)  time: 0.1682  data: 0.0617  max mem: 1091
[2024-01-21 10:13:54 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9529 (0.9219)  acc1: 78.8591 (79.1235)  acc5: 93.7931 (94.6662)  time: 0.1652  data: 0.0625  max mem: 1091
[2024-01-21 10:13:55 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.8981 (0.9186)  acc1: 80.0687 (79.2014)  acc5: 95.5782 (94.7302)  time: 0.1675  data: 0.0652  max mem: 1091
[2024-01-21 10:13:57 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8798 (0.9175)  acc1: 80.2721 (79.2387)  acc5: 95.5932 (94.7527)  time: 0.1693  data: 0.0668  max mem: 1091
[2024-01-21 10:13:59 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.9080 (0.9168)  acc1: 78.7671 (79.2166)  acc5: 94.9324 (94.7855)  time: 0.1795  data: 0.0765  max mem: 1091
[2024-01-21 10:14:01 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9334 (0.9184)  acc1: 78.4983 (79.1954)  acc5: 94.8980 (94.7741)  time: 0.1770  data: 0.0740  max mem: 1091
[2024-01-21 10:14:02 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9315 (0.9205)  acc1: 78.8591 (79.1511)  acc5: 93.9394 (94.7435)  time: 0.1708  data: 0.0676  max mem: 1091
[2024-01-21 10:14:03 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9108 (0.9182)  acc1: 78.8591 (79.1858)  acc5: 94.9324 (94.7639)  time: 0.1757  data: 0.0708  max mem: 1091
[2024-01-21 10:14:03 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1946 s / it)
[2024-01-21 10:14:03 root] (engine.py 118): INFO * Acc@1 79.186 Acc@5 94.764 loss 0.918 flops 3.373
[2024-01-21 10:14:03 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.2%
[2024-01-21 10:14:53 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:14:57 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:14:57 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:16:00 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:16:04 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:16:05 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:16:07 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:16:12 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:15:20  flops: 3.3726 (3.3726)  loss: 0.8887 (0.8887)  acc1: 80.4795 (80.4795)  acc5: 94.1781 (94.1781)  time: 5.5093  data: 0.5569  max mem: 1066
[2024-01-21 10:16:13 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:39  flops: 3.3726 (3.3726)  loss: 0.8887 (0.8908)  acc1: 80.4795 (80.6113)  acc5: 94.5392 (94.4736)  time: 0.6321  data: 0.0508  max mem: 1090
[2024-01-21 10:16:15 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:56  flops: 3.3726 (3.3726)  loss: 0.8933 (0.8926)  acc1: 80.4714 (80.3236)  acc5: 94.8980 (94.7087)  time: 0.1269  data: 0.0002  max mem: 1090
[2024-01-21 10:16:16 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:40  flops: 3.3726 (3.3726)  loss: 0.8968 (0.8911)  acc1: 79.7297 (80.1534)  acc5: 95.2703 (94.8603)  time: 0.1102  data: 0.0002  max mem: 1090
[2024-01-21 10:16:17 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:32  flops: 3.3726 (3.3726)  loss: 0.9052 (0.9020)  acc1: 78.1570 (79.7798)  acc5: 94.8805 (94.6863)  time: 0.1197  data: 0.0093  max mem: 1090
[2024-01-21 10:16:19 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:27  flops: 3.3726 (3.3726)  loss: 0.9074 (0.8963)  acc1: 78.1570 (79.8509)  acc5: 94.8805 (94.8297)  time: 0.1486  data: 0.0417  max mem: 1090
[2024-01-21 10:16:20 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:24  flops: 3.3726 (3.3726)  loss: 0.9001 (0.9027)  acc1: 78.7162 (79.5401)  acc5: 95.5326 (94.8224)  time: 0.1758  data: 0.0725  max mem: 1090
[2024-01-21 10:16:22 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.3726 (3.3726)  loss: 0.9127 (0.9028)  acc1: 78.7162 (79.5305)  acc5: 94.8980 (94.8456)  time: 0.1778  data: 0.0749  max mem: 1090
[2024-01-21 10:16:24 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:18  flops: 3.3726 (3.3726)  loss: 0.9347 (0.9100)  acc1: 78.3051 (79.2901)  acc5: 94.5763 (94.8372)  time: 0.1767  data: 0.0727  max mem: 1090
[2024-01-21 10:16:26 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9694 (0.9162)  acc1: 77.2881 (79.1824)  acc5: 94.2177 (94.7331)  time: 0.1805  data: 0.0734  max mem: 1091
[2024-01-21 10:16:28 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:13  flops: 3.3726 (3.3726)  loss: 0.9539 (0.9203)  acc1: 78.4512 (79.1272)  acc5: 93.8356 (94.6751)  time: 0.1751  data: 0.0689  max mem: 1091
[2024-01-21 10:16:29 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9539 (0.9220)  acc1: 78.8591 (79.1082)  acc5: 93.7931 (94.6692)  time: 0.1733  data: 0.0705  max mem: 1091
[2024-01-21 10:16:31 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.8973 (0.9187)  acc1: 79.9320 (79.1902)  acc5: 95.5782 (94.7302)  time: 0.1744  data: 0.0712  max mem: 1091
[2024-01-21 10:16:33 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8806 (0.9176)  acc1: 80.0687 (79.2309)  acc5: 95.5932 (94.7501)  time: 0.1738  data: 0.0697  max mem: 1091
[2024-01-21 10:16:35 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.9081 (0.9168)  acc1: 78.4247 (79.2022)  acc5: 94.9324 (94.7903)  time: 0.1794  data: 0.0758  max mem: 1091
[2024-01-21 10:16:36 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9328 (0.9185)  acc1: 78.4247 (79.1819)  acc5: 94.8980 (94.7786)  time: 0.1759  data: 0.0730  max mem: 1091
[2024-01-21 10:16:38 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9313 (0.9206)  acc1: 78.8591 (79.1385)  acc5: 93.9394 (94.7477)  time: 0.1742  data: 0.0709  max mem: 1091
[2024-01-21 10:16:39 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9100 (0.9184)  acc1: 78.8591 (79.1674)  acc5: 94.9324 (94.7679)  time: 0.1790  data: 0.0739  max mem: 1091
[2024-01-21 10:16:39 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1962 s / it)
[2024-01-21 10:16:39 root] (engine.py 118): INFO * Acc@1 79.167 Acc@5 94.768 loss 0.918 flops 3.373
[2024-01-21 10:16:39 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.2%
[2024-01-21 10:16:47 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:16:50 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:17:00 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:17:04 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:17:04 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:17:05 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:17:12 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:17:06  flops: 3.3726 (3.3726)  loss: 0.8885 (0.8885)  acc1: 80.4795 (80.4795)  acc5: 94.1781 (94.1781)  time: 6.1447  data: 2.6757  max mem: 1066
[2024-01-21 10:17:13 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:48  flops: 3.3726 (3.3726)  loss: 0.8885 (0.8909)  acc1: 80.4795 (80.6422)  acc5: 94.5392 (94.4736)  time: 0.6887  data: 0.2434  max mem: 1090
[2024-01-21 10:17:14 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:00  flops: 3.3726 (3.3726)  loss: 0.8953 (0.8925)  acc1: 80.4714 (80.3560)  acc5: 94.8980 (94.7087)  time: 0.1264  data: 0.0002  max mem: 1090
[2024-01-21 10:17:15 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:43  flops: 3.3726 (3.3726)  loss: 0.8957 (0.8910)  acc1: 80.0676 (80.1534)  acc5: 95.2703 (94.8493)  time: 0.1101  data: 0.0002  max mem: 1090
[2024-01-21 10:17:16 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:34  flops: 3.3726 (3.3726)  loss: 0.9051 (0.9020)  acc1: 78.1570 (79.7881)  acc5: 94.8805 (94.6946)  time: 0.1201  data: 0.0095  max mem: 1090
[2024-01-21 10:17:18 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:29  flops: 3.3726 (3.3726)  loss: 0.9056 (0.8962)  acc1: 78.1570 (79.8509)  acc5: 94.8805 (94.8297)  time: 0.1479  data: 0.0409  max mem: 1090
[2024-01-21 10:17:20 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 0.9004 (0.9028)  acc1: 78.7162 (79.5513)  acc5: 95.5326 (94.8280)  time: 0.1778  data: 0.0749  max mem: 1090
[2024-01-21 10:17:22 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 0.9126 (0.9028)  acc1: 78.7162 (79.5448)  acc5: 94.8980 (94.8551)  time: 0.1806  data: 0.0779  max mem: 1090
[2024-01-21 10:17:24 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9340 (0.9100)  acc1: 77.9661 (79.3069)  acc5: 94.5763 (94.8498)  time: 0.1769  data: 0.0735  max mem: 1090
[2024-01-21 10:17:25 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9688 (0.9162)  acc1: 77.2881 (79.1973)  acc5: 93.9799 (94.7443)  time: 0.1804  data: 0.0731  max mem: 1091
[2024-01-21 10:17:27 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9526 (0.9202)  acc1: 78.4512 (79.1373)  acc5: 93.8356 (94.6886)  time: 0.1752  data: 0.0680  max mem: 1091
[2024-01-21 10:17:29 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:12  flops: 3.3726 (3.3726)  loss: 0.9526 (0.9220)  acc1: 78.8591 (79.1143)  acc5: 93.7931 (94.6784)  time: 0.1720  data: 0.0690  max mem: 1091
[2024-01-21 10:17:30 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.8976 (0.9187)  acc1: 79.9320 (79.1958)  acc5: 95.5782 (94.7414)  time: 0.1657  data: 0.0631  max mem: 1091
[2024-01-21 10:17:32 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8809 (0.9176)  acc1: 80.4124 (79.2335)  acc5: 95.5932 (94.7630)  time: 0.1634  data: 0.0601  max mem: 1091
[2024-01-21 10:17:34 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.9091 (0.9169)  acc1: 78.4247 (79.2070)  acc5: 94.9324 (94.7975)  time: 0.1794  data: 0.0759  max mem: 1091
[2024-01-21 10:17:36 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9343 (0.9185)  acc1: 78.4247 (79.1864)  acc5: 94.8980 (94.7876)  time: 0.1844  data: 0.0812  max mem: 1091
[2024-01-21 10:17:38 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9309 (0.9206)  acc1: 78.8591 (79.1406)  acc5: 93.9394 (94.7562)  time: 0.1813  data: 0.0781  max mem: 1091
[2024-01-21 10:17:38 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9094 (0.9184)  acc1: 78.8591 (79.1735)  acc5: 94.9324 (94.7761)  time: 0.1736  data: 0.0686  max mem: 1091
[2024-01-21 10:17:38 root] (utils.py 307): INFO Test: Total time: 0:00:33 (0.1982 s / it)
[2024-01-21 10:17:38 root] (engine.py 118): INFO * Acc@1 79.174 Acc@5 94.776 loss 0.918 flops 3.373
[2024-01-21 10:17:38 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.2%
[2024-01-21 10:18:31 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:18:35 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:18:36 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:18:37 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:18:43 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:07  flops: 3.3726 (3.3726)  loss: 0.8884 (0.8884)  acc1: 81.1644 (81.1644)  acc5: 94.1781 (94.1781)  time: 5.7938  data: 1.6467  max mem: 1066
[2024-01-21 10:18:44 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:43  flops: 3.3726 (3.3726)  loss: 0.8884 (0.8910)  acc1: 81.0811 (80.6730)  acc5: 94.5392 (94.5045)  time: 0.6601  data: 0.1501  max mem: 1090
[2024-01-21 10:18:45 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:58  flops: 3.3726 (3.3726)  loss: 0.8949 (0.8928)  acc1: 80.4714 (80.3398)  acc5: 94.8980 (94.7087)  time: 0.1287  data: 0.0003  max mem: 1090
[2024-01-21 10:18:47 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:41  flops: 3.3726 (3.3726)  loss: 0.8963 (0.8911)  acc1: 80.0676 (80.1534)  acc5: 95.2703 (94.8493)  time: 0.1109  data: 0.0002  max mem: 1090
[2024-01-21 10:18:48 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 0.9047 (0.9020)  acc1: 78.1570 (79.7716)  acc5: 94.8805 (94.6780)  time: 0.1169  data: 0.0054  max mem: 1090
[2024-01-21 10:18:49 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9101 (0.8963)  acc1: 78.1570 (79.8443)  acc5: 94.8805 (94.8163)  time: 0.1447  data: 0.0370  max mem: 1090
[2024-01-21 10:18:51 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 0.9005 (0.9028)  acc1: 78.7162 (79.5346)  acc5: 95.5326 (94.8113)  time: 0.1777  data: 0.0743  max mem: 1090
[2024-01-21 10:18:53 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.3726 (3.3726)  loss: 0.9127 (0.9028)  acc1: 78.7162 (79.5257)  acc5: 94.8980 (94.8408)  time: 0.1802  data: 0.0773  max mem: 1090
[2024-01-21 10:18:55 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9344 (0.9100)  acc1: 77.9310 (79.2734)  acc5: 94.5763 (94.8372)  time: 0.1731  data: 0.0702  max mem: 1090
[2024-01-21 10:18:57 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9699 (0.9162)  acc1: 77.2881 (79.1674)  acc5: 94.1980 (94.7368)  time: 0.1760  data: 0.0692  max mem: 1091
[2024-01-21 10:18:58 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9532 (0.9202)  acc1: 78.4512 (79.1104)  acc5: 93.8356 (94.6819)  time: 0.1733  data: 0.0657  max mem: 1091
[2024-01-21 10:19:00 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9532 (0.9220)  acc1: 78.8591 (79.0868)  acc5: 93.7931 (94.6723)  time: 0.1696  data: 0.0658  max mem: 1091
[2024-01-21 10:19:02 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.8975 (0.9187)  acc1: 80.0687 (79.1705)  acc5: 95.5479 (94.7330)  time: 0.1702  data: 0.0671  max mem: 1091
[2024-01-21 10:19:03 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8806 (0.9176)  acc1: 80.2721 (79.2102)  acc5: 95.5932 (94.7527)  time: 0.1739  data: 0.0701  max mem: 1091
[2024-01-21 10:19:05 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.9077 (0.9168)  acc1: 78.3784 (79.1829)  acc5: 94.9324 (94.7879)  time: 0.1820  data: 0.0779  max mem: 1091
[2024-01-21 10:19:07 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9354 (0.9185)  acc1: 78.3784 (79.1684)  acc5: 94.8980 (94.7786)  time: 0.1761  data: 0.0726  max mem: 1091
[2024-01-21 10:19:09 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9313 (0.9206)  acc1: 78.8591 (79.1237)  acc5: 94.2568 (94.7498)  time: 0.1745  data: 0.0713  max mem: 1091
[2024-01-21 10:19:10 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9078 (0.9183)  acc1: 78.8591 (79.1532)  acc5: 94.9324 (94.7700)  time: 0.1748  data: 0.0680  max mem: 1091
[2024-01-21 10:19:10 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1954 s / it)
[2024-01-21 10:19:10 root] (engine.py 118): INFO * Acc@1 79.153 Acc@5 94.770 loss 0.918 flops 3.373
[2024-01-21 10:19:10 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.2%
[2024-01-21 10:21:12 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:21:16 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:21:16 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:21:18 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:21:24 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:13  flops: 3.3726 (3.3726)  loss: 0.8972 (0.8972)  acc1: 80.8219 (80.8219)  acc5: 94.5205 (94.5205)  time: 5.8264  data: 2.4449  max mem: 1066
[2024-01-21 10:21:25 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:44  flops: 3.3726 (3.3726)  loss: 0.8995 (0.9004)  acc1: 80.8081 (80.4878)  acc5: 94.8454 (94.5662)  time: 0.6635  data: 0.2224  max mem: 1090
[2024-01-21 10:21:26 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:58  flops: 3.3726 (3.3726)  loss: 0.9173 (0.9068)  acc1: 80.1347 (80.2427)  acc5: 94.8454 (94.6926)  time: 0.1285  data: 0.0002  max mem: 1090
[2024-01-21 10:21:27 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.3726 (3.3726)  loss: 0.9117 (0.9054)  acc1: 79.9320 (80.1534)  acc5: 94.5946 (94.6959)  time: 0.1111  data: 0.0002  max mem: 1090
[2024-01-21 10:21:29 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 0.9190 (0.9163)  acc1: 79.2517 (79.8295)  acc5: 94.5946 (94.6532)  time: 0.1168  data: 0.0056  max mem: 1090
[2024-01-21 10:21:30 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9233 (0.9085)  acc1: 79.0378 (79.7844)  acc5: 95.2218 (94.8297)  time: 0.1443  data: 0.0379  max mem: 1090
[2024-01-21 10:21:32 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:24  flops: 3.3726 (3.3726)  loss: 0.9274 (0.9158)  acc1: 77.7027 (79.4455)  acc5: 95.2218 (94.7612)  time: 0.1750  data: 0.0721  max mem: 1090
[2024-01-21 10:21:34 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.3726 (3.3726)  loss: 0.9274 (0.9155)  acc1: 78.7162 (79.4587)  acc5: 94.2568 (94.7691)  time: 0.1777  data: 0.0749  max mem: 1090
[2024-01-21 10:21:35 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:18  flops: 3.3726 (3.3726)  loss: 0.9624 (0.9227)  acc1: 78.4512 (79.2147)  acc5: 94.5946 (94.7618)  time: 0.1718  data: 0.0693  max mem: 1090
[2024-01-21 10:21:37 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9754 (0.9285)  acc1: 76.8966 (79.0705)  acc5: 93.8775 (94.6510)  time: 0.1744  data: 0.0673  max mem: 1091
[2024-01-21 10:21:39 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:13  flops: 3.3726 (3.3726)  loss: 0.9572 (0.9318)  acc1: 78.7879 (79.0533)  acc5: 93.4931 (94.5811)  time: 0.1716  data: 0.0645  max mem: 1091
[2024-01-21 10:21:41 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9604 (0.9342)  acc1: 78.9830 (78.9981)  acc5: 93.6242 (94.5438)  time: 0.1731  data: 0.0699  max mem: 1091
[2024-01-21 10:21:42 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.9121 (0.9309)  acc1: 79.2388 (79.0527)  acc5: 94.4828 (94.6039)  time: 0.1741  data: 0.0709  max mem: 1091
[2024-01-21 10:21:44 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.9085 (0.9302)  acc1: 80.3390 (79.0677)  acc5: 94.9153 (94.6205)  time: 0.1695  data: 0.0671  max mem: 1091
[2024-01-21 10:21:46 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.9239 (0.9301)  acc1: 79.5918 (79.0674)  acc5: 94.5763 (94.6266)  time: 0.1837  data: 0.0808  max mem: 1091
[2024-01-21 10:21:48 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9501 (0.9320)  acc1: 78.3784 (79.0155)  acc5: 94.2568 (94.6077)  time: 0.1807  data: 0.0777  max mem: 1091
[2024-01-21 10:21:50 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9510 (0.9340)  acc1: 78.3784 (78.9782)  acc5: 94.1980 (94.5854)  time: 0.1727  data: 0.0693  max mem: 1091
[2024-01-21 10:21:50 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9386 (0.9317)  acc1: 78.7671 (79.0269)  acc5: 94.2761 (94.5948)  time: 0.1728  data: 0.0675  max mem: 1091
[2024-01-21 10:21:50 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1949 s / it)
[2024-01-21 10:21:50 root] (engine.py 118): INFO * Acc@1 79.027 Acc@5 94.595 loss 0.932 flops 3.373
[2024-01-21 10:21:50 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.0%
[2024-01-21 10:21:58 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:22:01 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:22:01 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:22:03 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:22:09 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:19  flops: 3.3726 (3.3726)  loss: 0.8965 (0.8965)  acc1: 81.1644 (81.1644)  acc5: 94.5205 (94.5205)  time: 5.8643  data: 2.4365  max mem: 1066
[2024-01-21 10:22:10 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:45  flops: 3.3726 (3.3726)  loss: 0.9000 (0.8959)  acc1: 80.9524 (80.3334)  acc5: 95.2218 (94.6897)  time: 0.6690  data: 0.2217  max mem: 1090
[2024-01-21 10:22:11 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.3726 (3.3726)  loss: 0.9052 (0.8984)  acc1: 79.7297 (79.9838)  acc5: 94.8276 (94.7087)  time: 0.1294  data: 0.0002  max mem: 1090
[2024-01-21 10:22:13 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.3726 (3.3726)  loss: 0.9072 (0.8972)  acc1: 78.7671 (79.7479)  acc5: 94.9153 (94.7945)  time: 0.1116  data: 0.0002  max mem: 1090
[2024-01-21 10:22:14 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 0.9134 (0.9063)  acc1: 78.5714 (79.4405)  acc5: 94.9324 (94.7525)  time: 0.1221  data: 0.0089  max mem: 1090
[2024-01-21 10:22:15 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9015 (0.9012)  acc1: 78.2313 (79.4317)  acc5: 95.2218 (94.9095)  time: 0.1471  data: 0.0390  max mem: 1090
[2024-01-21 10:22:17 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 0.9015 (0.9077)  acc1: 78.3505 (79.2117)  acc5: 95.2381 (94.8836)  time: 0.1754  data: 0.0723  max mem: 1090
[2024-01-21 10:22:19 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 0.9138 (0.9077)  acc1: 78.3505 (79.2005)  acc5: 94.5946 (94.8312)  time: 0.1811  data: 0.0786  max mem: 1090
[2024-01-21 10:22:21 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9471 (0.9141)  acc1: 77.9310 (78.9926)  acc5: 94.2568 (94.7953)  time: 0.1753  data: 0.0729  max mem: 1090
[2024-01-21 10:22:23 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9679 (0.9198)  acc1: 77.6271 (78.9324)  acc5: 93.8775 (94.6846)  time: 0.1783  data: 0.0723  max mem: 1091
[2024-01-21 10:22:24 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9556 (0.9231)  acc1: 78.7162 (78.9088)  acc5: 93.6242 (94.6382)  time: 0.1732  data: 0.0667  max mem: 1091
[2024-01-21 10:22:26 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9518 (0.9251)  acc1: 78.7162 (78.8941)  acc5: 94.1379 (94.6111)  time: 0.1679  data: 0.0650  max mem: 1091
[2024-01-21 10:22:28 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.9102 (0.9209)  acc1: 79.3103 (78.9741)  acc5: 94.9153 (94.6769)  time: 0.1693  data: 0.0666  max mem: 1091
[2024-01-21 10:22:29 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8843 (0.9200)  acc1: 79.9308 (79.0055)  acc5: 94.9324 (94.6879)  time: 0.1691  data: 0.0661  max mem: 1091
[2024-01-21 10:22:31 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.9118 (0.9195)  acc1: 79.4521 (79.0096)  acc5: 94.5946 (94.7205)  time: 0.1790  data: 0.0754  max mem: 1091
[2024-01-21 10:22:39 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:22:43 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:22:44 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:22:45 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:22:51 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:35  flops: 3.3726 (3.3726)  loss: 0.8879 (0.8879)  acc1: 80.8219 (80.8219)  acc5: 94.1781 (94.1781)  time: 5.9640  data: 1.9740  max mem: 1066
[2024-01-21 10:22:53 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:45  flops: 3.3726 (3.3726)  loss: 0.8842 (0.8926)  acc1: 80.2048 (80.3952)  acc5: 94.5946 (94.7206)  time: 0.6739  data: 0.1796  max mem: 1090
[2024-01-21 10:22:54 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.3726 (3.3726)  loss: 0.8875 (0.8949)  acc1: 80.0676 (80.1618)  acc5: 94.8980 (94.7573)  time: 0.1273  data: 0.0002  max mem: 1090
[2024-01-21 10:22:55 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.3726 (3.3726)  loss: 0.8929 (0.8923)  acc1: 79.7297 (79.9562)  acc5: 95.2218 (94.9151)  time: 0.1101  data: 0.0002  max mem: 1090
[2024-01-21 10:22:56 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 0.9060 (0.9029)  acc1: 78.9116 (79.6143)  acc5: 94.9153 (94.8353)  time: 0.1220  data: 0.0115  max mem: 1090
[2024-01-21 10:22:58 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9078 (0.8974)  acc1: 78.3784 (79.6513)  acc5: 94.9495 (94.9561)  time: 0.1488  data: 0.0427  max mem: 1090
[2024-01-21 10:23:00 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 0.8943 (0.9034)  acc1: 78.3784 (79.3676)  acc5: 94.9153 (94.9059)  time: 0.1745  data: 0.0722  max mem: 1090
[2024-01-21 10:23:01 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 0.9185 (0.9039)  acc1: 78.7162 (79.3392)  acc5: 94.5578 (94.8695)  time: 0.1804  data: 0.0774  max mem: 1090
[2024-01-21 10:23:03 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9304 (0.9110)  acc1: 77.2881 (79.0973)  acc5: 94.5946 (94.8707)  time: 0.1769  data: 0.0737  max mem: 1090
[2024-01-21 10:23:05 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9765 (0.9180)  acc1: 77.2414 (78.9809)  acc5: 93.8983 (94.7518)  time: 0.1784  data: 0.0716  max mem: 1091
[2024-01-21 10:23:07 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9597 (0.9214)  acc1: 78.7879 (78.9626)  acc5: 94.1781 (94.7390)  time: 0.1717  data: 0.0646  max mem: 1091
[2024-01-21 10:23:08 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9597 (0.9238)  acc1: 78.8591 (78.9553)  acc5: 94.2177 (94.6754)  time: 0.1666  data: 0.0638  max mem: 1091
[2024-01-21 10:23:10 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.9113 (0.9200)  acc1: 79.5918 (79.0639)  acc5: 95.2055 (94.7386)  time: 0.1699  data: 0.0681  max mem: 1091
[2024-01-21 10:23:12 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8780 (0.9189)  acc1: 80.0000 (79.0988)  acc5: 95.2703 (94.7527)  time: 0.1689  data: 0.0669  max mem: 1091
[2024-01-21 10:23:14 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.9121 (0.9183)  acc1: 78.9116 (79.1107)  acc5: 94.9495 (94.7783)  time: 0.1737  data: 0.0710  max mem: 1091
[2024-01-21 10:23:15 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9384 (0.9202)  acc1: 78.5714 (79.0875)  acc5: 94.2177 (94.7561)  time: 0.1762  data: 0.0734  max mem: 1091
[2024-01-21 10:23:17 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9381 (0.9222)  acc1: 79.0541 (79.0520)  acc5: 94.2177 (94.7161)  time: 0.1779  data: 0.0746  max mem: 1091
[2024-01-21 10:23:18 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9085 (0.9202)  acc1: 79.0541 (79.0737)  acc5: 94.5946 (94.7231)  time: 0.1726  data: 0.0678  max mem: 1091
[2024-01-21 10:23:18 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1964 s / it)
[2024-01-21 10:23:18 root] (engine.py 118): INFO * Acc@1 79.074 Acc@5 94.723 loss 0.920 flops 3.373
[2024-01-21 10:23:18 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.1%
[2024-01-21 10:23:29 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:23:33 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:23:33 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:23:35 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:23:41 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:30  flops: 3.3726 (3.3726)  loss: 0.8777 (0.8777)  acc1: 78.7671 (78.7671)  acc5: 94.8630 (94.8630)  time: 5.9297  data: 1.7983  max mem: 1066
[2024-01-21 10:23:42 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:45  flops: 3.3726 (3.3726)  loss: 0.8824 (0.8914)  acc1: 81.0811 (80.4878)  acc5: 94.9324 (94.4119)  time: 0.6716  data: 0.1636  max mem: 1090
[2024-01-21 10:23:43 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:59  flops: 3.3726 (3.3726)  loss: 0.8976 (0.8931)  acc1: 80.6122 (80.1456)  acc5: 94.8980 (94.7735)  time: 0.1281  data: 0.0002  max mem: 1090
[2024-01-21 10:23:44 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.3726 (3.3726)  loss: 0.9023 (0.8920)  acc1: 79.7297 (80.1425)  acc5: 94.9153 (94.9041)  time: 0.1113  data: 0.0002  max mem: 1090
[2024-01-21 10:23:46 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 0.9069 (0.9021)  acc1: 79.1096 (79.7550)  acc5: 94.9153 (94.8353)  time: 0.1230  data: 0.0117  max mem: 1090
[2024-01-21 10:23:47 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9082 (0.8964)  acc1: 78.7879 (79.7511)  acc5: 94.9153 (94.9428)  time: 0.1490  data: 0.0423  max mem: 1090
[2024-01-21 10:23:49 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 0.9082 (0.9028)  acc1: 78.6942 (79.4232)  acc5: 94.5946 (94.8502)  time: 0.1735  data: 0.0712  max mem: 1090
[2024-01-21 10:23:51 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 0.9264 (0.9024)  acc1: 78.0405 (79.4205)  acc5: 94.2568 (94.8647)  time: 0.1771  data: 0.0744  max mem: 1090
[2024-01-21 10:23:53 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9278 (0.9087)  acc1: 77.8912 (79.1812)  acc5: 94.9153 (94.8917)  time: 0.1737  data: 0.0704  max mem: 1090
[2024-01-21 10:23:54 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9539 (0.9146)  acc1: 77.5920 (79.1190)  acc5: 93.9799 (94.7891)  time: 0.1738  data: 0.0651  max mem: 1091
[2024-01-21 10:23:56 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9501 (0.9179)  acc1: 79.1246 (79.1205)  acc5: 93.8356 (94.7356)  time: 0.1682  data: 0.0594  max mem: 1091
[2024-01-21 10:23:58 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9458 (0.9198)  acc1: 79.1246 (79.0959)  acc5: 93.8356 (94.7243)  time: 0.1778  data: 0.0748  max mem: 1091
[2024-01-21 10:24:00 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.8897 (0.9160)  acc1: 79.5848 (79.1846)  acc5: 94.9833 (94.7919)  time: 0.1801  data: 0.0766  max mem: 1091
[2024-01-21 10:24:01 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8825 (0.9151)  acc1: 79.9308 (79.2076)  acc5: 95.2703 (94.7915)  time: 0.1710  data: 0.0676  max mem: 1091
[2024-01-21 10:24:03 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.9135 (0.9145)  acc1: 79.3919 (79.2046)  acc5: 94.9324 (94.8168)  time: 0.1787  data: 0.0759  max mem: 1091
[2024-01-21 10:24:05 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9463 (0.9163)  acc1: 78.7162 (79.1887)  acc5: 94.5763 (94.8011)  time: 0.1793  data: 0.0772  max mem: 1091
[2024-01-21 10:24:07 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9225 (0.9180)  acc1: 78.9655 (79.1638)  acc5: 94.1177 (94.7667)  time: 0.1749  data: 0.0723  max mem: 1091
[2024-01-21 10:24:07 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9141 (0.9159)  acc1: 79.1946 (79.2082)  acc5: 94.9324 (94.7985)  time: 0.1729  data: 0.0684  max mem: 1091
[2024-01-21 10:24:07 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1955 s / it)
[2024-01-21 10:24:07 root] (engine.py 118): INFO * Acc@1 79.208 Acc@5 94.798 loss 0.916 flops 3.373
[2024-01-21 10:24:07 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.2%
[2024-01-21 10:24:22 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:24:27 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:24:27 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:24:28 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:24:34 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:49  flops: 3.3726 (3.3726)  loss: 0.8760 (0.8760)  acc1: 81.1644 (81.1644)  acc5: 94.8630 (94.8630)  time: 6.0468  data: 1.5989  max mem: 1066
[2024-01-21 10:24:36 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:48  flops: 3.3726 (3.3726)  loss: 0.8825 (0.8970)  acc1: 80.5461 (80.3026)  acc5: 94.8630 (94.5045)  time: 0.6902  data: 0.1455  max mem: 1090
[2024-01-21 10:24:37 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:01  flops: 3.3726 (3.3726)  loss: 0.8899 (0.8940)  acc1: 80.4714 (80.1780)  acc5: 94.8276 (94.6602)  time: 0.1345  data: 0.0002  max mem: 1090
[2024-01-21 10:24:38 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:43  flops: 3.3726 (3.3726)  loss: 0.8899 (0.8935)  acc1: 80.4054 (80.1205)  acc5: 94.9153 (94.7945)  time: 0.1131  data: 0.0002  max mem: 1090
[2024-01-21 10:24:39 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:34  flops: 3.3726 (3.3726)  loss: 0.9248 (0.9018)  acc1: 78.5714 (79.8709)  acc5: 94.6309 (94.6946)  time: 0.1171  data: 0.0060  max mem: 1090
[2024-01-21 10:24:41 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:29  flops: 3.3726 (3.3726)  loss: 0.9064 (0.8952)  acc1: 79.1946 (79.8776)  acc5: 94.8454 (94.8563)  time: 0.1433  data: 0.0372  max mem: 1090
[2024-01-21 10:24:43 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 0.9064 (0.9018)  acc1: 79.1246 (79.5513)  acc5: 94.9324 (94.7834)  time: 0.1744  data: 0.0724  max mem: 1090
[2024-01-21 10:24:44 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 0.9152 (0.9013)  acc1: 78.7162 (79.5974)  acc5: 94.2373 (94.8121)  time: 0.1766  data: 0.0741  max mem: 1090
[2024-01-21 10:24:46 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9293 (0.9075)  acc1: 78.4512 (79.3655)  acc5: 94.9153 (94.8623)  time: 0.1733  data: 0.0700  max mem: 1090
[2024-01-21 10:24:48 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9571 (0.9137)  acc1: 77.6271 (79.2793)  acc5: 94.3144 (94.7816)  time: 0.1753  data: 0.0681  max mem: 1091
[2024-01-21 10:24:50 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9445 (0.9172)  acc1: 79.5302 (79.2582)  acc5: 94.1980 (94.7289)  time: 0.1732  data: 0.0656  max mem: 1091
[2024-01-21 10:24:51 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9489 (0.9191)  acc1: 79.7297 (79.2947)  acc5: 94.2177 (94.7151)  time: 0.1730  data: 0.0695  max mem: 1091
[2024-01-21 10:24:53 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.8771 (0.9157)  acc1: 80.2721 (79.3754)  acc5: 94.6488 (94.7835)  time: 0.1712  data: 0.0686  max mem: 1091
[2024-01-21 10:24:55 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8771 (0.9146)  acc1: 80.4124 (79.4149)  acc5: 95.2542 (94.7889)  time: 0.1697  data: 0.0662  max mem: 1091
[2024-01-21 10:24:57 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.8952 (0.9143)  acc1: 79.2517 (79.3731)  acc5: 94.8980 (94.8120)  time: 0.1761  data: 0.0728  max mem: 1091
[2024-01-21 10:24:58 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9293 (0.9160)  acc1: 78.9655 (79.3618)  acc5: 94.8980 (94.8101)  time: 0.1755  data: 0.0727  max mem: 1091
[2024-01-21 10:25:00 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9296 (0.9182)  acc1: 78.9655 (79.2987)  acc5: 94.2761 (94.7730)  time: 0.1748  data: 0.0719  max mem: 1091
[2024-01-21 10:25:01 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9101 (0.9158)  acc1: 78.9655 (79.3242)  acc5: 94.8276 (94.7883)  time: 0.1722  data: 0.0677  max mem: 1091
[2024-01-21 10:25:01 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1973 s / it)
[2024-01-21 10:25:01 root] (engine.py 118): INFO * Acc@1 79.324 Acc@5 94.788 loss 0.916 flops 3.373
[2024-01-21 10:25:01 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.3%
[2024-01-21 10:25:22 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:25:25 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:25:26 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:25:27 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:25:33 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:51  flops: 3.3726 (3.3726)  loss: 0.8869 (0.8869)  acc1: 80.4795 (80.4795)  acc5: 94.1781 (94.1781)  time: 6.0556  data: 2.6649  max mem: 1066
[2024-01-21 10:25:35 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:47  flops: 3.3726 (3.3726)  loss: 0.8869 (0.9008)  acc1: 80.5461 (80.1482)  acc5: 94.9324 (94.4736)  time: 0.6830  data: 0.2424  max mem: 1090
[2024-01-21 10:25:36 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:00  flops: 3.3726 (3.3726)  loss: 0.8990 (0.8978)  acc1: 79.9320 (80.0000)  acc5: 94.9495 (94.7735)  time: 0.1280  data: 0.0002  max mem: 1090
[2024-01-21 10:25:37 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:43  flops: 3.3726 (3.3726)  loss: 0.9007 (0.8946)  acc1: 79.4613 (80.0219)  acc5: 95.2218 (94.8384)  time: 0.1110  data: 0.0002  max mem: 1090
[2024-01-21 10:25:38 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:34  flops: 3.3726 (3.3726)  loss: 0.9211 (0.9046)  acc1: 79.1096 (79.6888)  acc5: 94.9324 (94.7856)  time: 0.1214  data: 0.0102  max mem: 1090
[2024-01-21 10:25:40 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:29  flops: 3.3726 (3.3726)  loss: 0.9062 (0.8968)  acc1: 77.5168 (79.7378)  acc5: 94.9664 (94.9095)  time: 0.1461  data: 0.0390  max mem: 1090
[2024-01-21 10:25:42 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 0.9080 (0.9034)  acc1: 78.1145 (79.4566)  acc5: 95.2055 (94.8669)  time: 0.1729  data: 0.0698  max mem: 1090
[2024-01-21 10:25:44 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 3.3726 (3.3726)  loss: 0.9206 (0.9032)  acc1: 78.7671 (79.4396)  acc5: 94.8980 (94.9029)  time: 0.1810  data: 0.0778  max mem: 1090
[2024-01-21 10:25:45 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9352 (0.9102)  acc1: 77.6271 (79.1728)  acc5: 94.6309 (94.8917)  time: 0.1768  data: 0.0739  max mem: 1090
[2024-01-21 10:25:47 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9568 (0.9154)  acc1: 77.1044 (79.1115)  acc5: 93.8567 (94.7704)  time: 0.1771  data: 0.0700  max mem: 1091
[2024-01-21 10:25:49 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9432 (0.9190)  acc1: 78.7162 (79.0701)  acc5: 93.8567 (94.7457)  time: 0.1732  data: 0.0653  max mem: 1091
[2024-01-21 10:25:50 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9432 (0.9213)  acc1: 79.2517 (79.0898)  acc5: 94.2177 (94.6723)  time: 0.1701  data: 0.0666  max mem: 1091
[2024-01-21 10:25:52 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.8974 (0.9175)  acc1: 80.0676 (79.1846)  acc5: 94.6488 (94.7302)  time: 0.1698  data: 0.0663  max mem: 1091
[2024-01-21 10:25:54 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8846 (0.9161)  acc1: 80.0676 (79.2335)  acc5: 95.2542 (94.7449)  time: 0.1682  data: 0.0642  max mem: 1091
[2024-01-21 10:25:56 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.8935 (0.9159)  acc1: 78.5714 (79.2142)  acc5: 95.2381 (94.7807)  time: 0.1776  data: 0.0737  max mem: 1091
[2024-01-21 10:25:57 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9482 (0.9179)  acc1: 78.2313 (79.1662)  acc5: 94.9153 (94.7809)  time: 0.1784  data: 0.0748  max mem: 1091
[2024-01-21 10:25:59 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9501 (0.9202)  acc1: 78.4983 (79.1026)  acc5: 94.2568 (94.7435)  time: 0.1744  data: 0.0697  max mem: 1091
[2024-01-21 10:26:00 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9249 (0.9181)  acc1: 78.7879 (79.1328)  acc5: 94.6128 (94.7537)  time: 0.1783  data: 0.0687  max mem: 1091
[2024-01-21 10:26:00 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1965 s / it)
[2024-01-21 10:26:00 root] (engine.py 118): INFO * Acc@1 79.133 Acc@5 94.754 loss 0.918 flops 3.373
[2024-01-21 10:26:00 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.1%
[2024-01-21 10:26:34 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:26:37 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 10:26:38 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 10:26:39 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 10:26:45 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:17  flops: 3.3726 (3.3726)  loss: 0.8759 (0.8759)  acc1: 81.1644 (81.1644)  acc5: 94.8630 (94.8630)  time: 5.8530  data: 1.7265  max mem: 1066
[2024-01-21 10:26:46 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:44  flops: 3.3726 (3.3726)  loss: 0.8821 (0.8967)  acc1: 80.5461 (80.3026)  acc5: 94.8630 (94.5045)  time: 0.6640  data: 0.1571  max mem: 1090
[2024-01-21 10:26:48 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:58  flops: 3.3726 (3.3726)  loss: 0.8907 (0.8938)  acc1: 80.4714 (80.2265)  acc5: 94.8276 (94.6602)  time: 0.1278  data: 0.0002  max mem: 1090
[2024-01-21 10:26:49 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:42  flops: 3.3726 (3.3726)  loss: 0.8907 (0.8934)  acc1: 80.4054 (80.1425)  acc5: 94.8630 (94.7945)  time: 0.1107  data: 0.0002  max mem: 1090
[2024-01-21 10:26:50 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 0.9247 (0.9017)  acc1: 78.5714 (79.9040)  acc5: 94.6128 (94.6946)  time: 0.1196  data: 0.0089  max mem: 1090
[2024-01-21 10:26:52 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9060 (0.8950)  acc1: 79.3814 (79.9042)  acc5: 94.8454 (94.8563)  time: 0.1455  data: 0.0384  max mem: 1090
[2024-01-21 10:26:53 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:25  flops: 3.3726 (3.3726)  loss: 0.9060 (0.9017)  acc1: 79.1246 (79.5735)  acc5: 94.9324 (94.7834)  time: 0.1773  data: 0.0742  max mem: 1090
[2024-01-21 10:26:55 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:21  flops: 3.3726 (3.3726)  loss: 0.9150 (0.9013)  acc1: 78.7162 (79.6117)  acc5: 94.2373 (94.8121)  time: 0.1831  data: 0.0805  max mem: 1090
[2024-01-21 10:26:57 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 3.3726 (3.3726)  loss: 0.9291 (0.9073)  acc1: 78.4512 (79.3865)  acc5: 94.9153 (94.8581)  time: 0.1757  data: 0.0725  max mem: 1090
[2024-01-21 10:26:59 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:16  flops: 3.3726 (3.3726)  loss: 0.9568 (0.9136)  acc1: 77.6271 (79.2980)  acc5: 94.3144 (94.7741)  time: 0.1801  data: 0.0736  max mem: 1091
[2024-01-21 10:27:00 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9451 (0.9171)  acc1: 79.5302 (79.2784)  acc5: 94.1980 (94.7255)  time: 0.1732  data: 0.0666  max mem: 1091
[2024-01-21 10:27:02 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9493 (0.9190)  acc1: 79.7297 (79.3070)  acc5: 94.2177 (94.7090)  time: 0.1636  data: 0.0606  max mem: 1091
[2024-01-21 10:27:04 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.8769 (0.9156)  acc1: 80.0676 (79.3838)  acc5: 94.6488 (94.7723)  time: 0.1623  data: 0.0591  max mem: 1091
[2024-01-21 10:27:05 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 3.3726 (3.3726)  loss: 0.8769 (0.9146)  acc1: 80.0687 (79.4253)  acc5: 95.2542 (94.7786)  time: 0.1626  data: 0.0590  max mem: 1091
[2024-01-21 10:27:07 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 3.3726 (3.3726)  loss: 0.8966 (0.9143)  acc1: 79.2517 (79.3803)  acc5: 94.8980 (94.8023)  time: 0.1749  data: 0.0716  max mem: 1091
[2024-01-21 10:27:09 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9295 (0.9159)  acc1: 78.9655 (79.3663)  acc5: 94.8980 (94.7989)  time: 0.1811  data: 0.0775  max mem: 1091
[2024-01-21 10:27:11 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9300 (0.9181)  acc1: 78.9655 (79.3071)  acc5: 94.2761 (94.7625)  time: 0.1819  data: 0.0779  max mem: 1091
[2024-01-21 10:27:12 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9091 (0.9158)  acc1: 78.9655 (79.3304)  acc5: 94.8276 (94.7781)  time: 0.1734  data: 0.0678  max mem: 1091
[2024-01-21 10:27:12 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1950 s / it)
[2024-01-21 10:27:12 root] (engine.py 118): INFO * Acc@1 79.330 Acc@5 94.778 loss 0.916 flops 3.373
[2024-01-21 10:27:12 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.3%
[2024-01-21 10:27:33 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:27:37 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 10:27:39 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 10:27:41 root] (main_pitome.py 373): INFO number of params: 86567656
[2024-01-21 10:27:43 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:27:46 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:42  flops: 12.9405 (12.9405)  loss: 0.9020 (0.9020)  acc1: 80.4795 (80.4795)  acc5: 93.4931 (93.4931)  time: 5.2820  data: 1.2259  max mem: 2127
[2024-01-21 10:27:47 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 10:27:48 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 10:27:49 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:00  flops: 12.9405 (12.9405)  loss: 0.8147 (0.8327)  acc1: 82.2742 (82.1550)  acc5: 95.1890 (94.9985)  time: 0.7671  data: 0.1128  max mem: 2169
[2024-01-21 10:27:52 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:17  flops: 12.9405 (12.9405)  loss: 0.8557 (0.8518)  acc1: 81.9113 (81.6343)  acc5: 94.8980 (95.0000)  time: 0.2903  data: 0.0010  max mem: 2169
[2024-01-21 10:27:52 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 10:27:54 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:59  flops: 12.9405 (12.9405)  loss: 0.8599 (0.8456)  acc1: 80.3448 (81.7315)  acc5: 95.2542 (95.2329)  time: 0.2554  data: 0.0004  max mem: 2169
[2024-01-21 10:27:57 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:50  flops: 12.9405 (12.9405)  loss: 0.8620 (0.8548)  acc1: 81.5700 (81.6752)  acc5: 94.9664 (95.2160)  time: 0.2543  data: 0.0002  max mem: 2169
[2024-01-21 10:28:00 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:43  flops: 12.9405 (12.9405)  loss: 0.8620 (0.8475)  acc1: 81.4189 (81.7873)  acc5: 95.2862 (95.4152)  time: 0.2719  data: 0.0002  max mem: 2169
[2024-01-21 10:28:00 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:21:33  flops: 12.9405 (12.9405)  loss: 0.9016 (0.9016)  acc1: 80.8219 (80.8219)  acc5: 92.4658 (92.4658)  time: 7.7448  data: 1.0668  max mem: 2127
[2024-01-21 10:28:04 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8685 (0.8542)  acc1: 81.4189 (81.6279)  acc5: 95.2862 (95.3513)  time: 0.3764  data: 0.0002  max mem: 2169
[2024-01-21 10:28:06 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:15  flops: 12.9405 (12.9405)  loss: 0.8253 (0.8133)  acc1: 82.0946 (82.0932)  acc5: 94.8980 (94.9058)  time: 1.2465  data: 0.0971  max mem: 2169
[2024-01-21 10:28:09 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:39  flops: 12.9405 (12.9405)  loss: 0.8735 (0.8557)  acc1: 81.4189 (81.5865)  acc5: 94.9495 (95.3141)  time: 0.4794  data: 0.0002  max mem: 2169
[2024-01-21 10:28:11 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:02:09  flops: 12.9405 (12.9405)  loss: 0.8308 (0.8394)  acc1: 81.4189 (81.6990)  acc5: 94.8980 (95.0324)  time: 0.5410  data: 0.0002  max mem: 2169
[2024-01-21 10:28:14 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8596 (0.8594)  acc1: 81.4189 (81.4441)  acc5: 95.6081 (95.3401)  time: 0.4869  data: 0.0002  max mem: 2169
[2024-01-21 10:28:15 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:43  flops: 12.9405 (12.9405)  loss: 0.8342 (0.8348)  acc1: 81.0811 (81.8082)  acc5: 95.2542 (95.1890)  time: 0.4841  data: 0.0002  max mem: 2169
[2024-01-21 10:28:19 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:32  flops: 12.9405 (12.9405)  loss: 0.8790 (0.8662)  acc1: 80.8081 (81.3645)  acc5: 95.2542 (95.3113)  time: 0.4979  data: 0.0002  max mem: 2170
[2024-01-21 10:28:20 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:27  flops: 12.9405 (12.9405)  loss: 0.8527 (0.8458)  acc1: 81.3559 (81.6504)  acc5: 94.9324 (95.1084)  time: 0.4813  data: 0.0002  max mem: 2169
[2024-01-21 10:28:24 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:28  flops: 12.9405 (12.9405)  loss: 0.8802 (0.8682)  acc1: 80.6122 (81.2975)  acc5: 94.9324 (95.3000)  time: 0.5000  data: 0.0002  max mem: 2170
[2024-01-21 10:28:25 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:15  flops: 12.9405 (12.9405)  loss: 0.8566 (0.8387)  acc1: 80.2013 (81.6476)  acc5: 95.1890 (95.2954)  time: 0.4707  data: 0.0002  max mem: 2169
[2024-01-21 10:28:29 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:24  flops: 12.9405 (12.9405)  loss: 0.8953 (0.8712)  acc1: 80.6122 (81.2705)  acc5: 94.8276 (95.2534)  time: 0.4879  data: 0.0002  max mem: 2170
[2024-01-21 10:28:29 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:05  flops: 12.9405 (12.9405)  loss: 0.8632 (0.8461)  acc1: 80.3448 (81.4497)  acc5: 95.1890 (95.2065)  time: 0.4584  data: 0.0004  max mem: 2169
[2024-01-21 10:28:34 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.8753 (0.8687)  acc1: 81.1644 (81.3144)  acc5: 94.8630 (95.2970)  time: 0.4874  data: 0.0002  max mem: 2170
[2024-01-21 10:28:34 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8665 (0.8471)  acc1: 80.7432 (81.4383)  acc5: 94.8276 (95.1372)  time: 0.4598  data: 0.0004  max mem: 2169
[2024-01-21 10:28:39 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:50  flops: 12.9405 (12.9405)  loss: 0.8523 (0.8504)  acc1: 80.3390 (81.3016)  acc5: 95.2542 (95.1724)  time: 0.4634  data: 0.0002  max mem: 2169
[2024-01-21 10:28:39 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8584 (0.8668)  acc1: 81.3793 (81.3298)  acc5: 95.5782 (95.3409)  time: 0.4904  data: 0.0002  max mem: 2170
[2024-01-21 10:28:44 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:43  flops: 12.9405 (12.9405)  loss: 0.8449 (0.8571)  acc1: 80.0000 (81.1892)  acc5: 95.2381 (95.1173)  time: 0.4754  data: 0.0002  max mem: 2170
[2024-01-21 10:28:44 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8406 (0.8648)  acc1: 80.8081 (81.3376)  acc5: 95.9184 (95.3801)  time: 0.4903  data: 0.0002  max mem: 2170
[2024-01-21 10:28:48 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:37  flops: 12.9405 (12.9405)  loss: 0.8449 (0.8586)  acc1: 80.7432 (81.1698)  acc5: 94.6488 (95.0984)  time: 0.4745  data: 0.0002  max mem: 2170
[2024-01-21 10:28:48 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8527 (0.8668)  acc1: 80.8081 (81.3159)  acc5: 95.9184 (95.3700)  time: 0.4888  data: 0.0002  max mem: 2170
[2024-01-21 10:28:53 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8697 (0.8603)  acc1: 80.7432 (81.1818)  acc5: 94.5763 (95.0729)  time: 0.4617  data: 0.0002  max mem: 2170
[2024-01-21 10:28:53 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 12.9405 (12.9405)  loss: 0.8799 (0.8687)  acc1: 80.8081 (81.2955)  acc5: 95.1557 (95.3529)  time: 0.4898  data: 0.0002  max mem: 2170
[2024-01-21 10:28:56 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8691 (0.8671)  acc1: 81.6949 (81.3140)  acc5: 95.2703 (95.3341)  time: 0.4938  data: 0.0002  max mem: 2170
[2024-01-21 10:28:56 root] (utils.py 307): INFO Test: Total time: 0:01:15 (0.4540 s / it)
[2024-01-21 10:28:56 root] (engine.py 118): INFO * Acc@1 81.314 Acc@5 95.334 loss 0.867 flops 12.940
[2024-01-21 10:28:56 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 81.3%
[2024-01-21 10:28:57 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8521 (0.8574)  acc1: 81.3793 (81.2330)  acc5: 94.9153 (95.1062)  time: 0.4350  data: 0.0002  max mem: 2170
[2024-01-21 10:28:59 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:18  flops: 12.9405 (12.9405)  loss: 0.8364 (0.8557)  acc1: 81.2287 (81.2262)  acc5: 95.2542 (95.1414)  time: 0.3182  data: 0.0002  max mem: 2170
[2024-01-21 10:29:01 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8508 (0.8539)  acc1: 80.4714 (81.2316)  acc5: 95.2703 (95.1635)  time: 0.2284  data: 0.0003  max mem: 2170
[2024-01-21 10:29:04 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:08  flops: 12.9405 (12.9405)  loss: 0.8508 (0.8559)  acc1: 81.0169 (81.2102)  acc5: 95.2381 (95.1407)  time: 0.2268  data: 0.0003  max mem: 2170
[2024-01-21 10:29:06 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 12.9405 (12.9405)  loss: 0.8829 (0.8578)  acc1: 81.0811 (81.1858)  acc5: 94.9324 (95.1188)  time: 0.2271  data: 0.0002  max mem: 2170
[2024-01-21 10:29:07 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8518 (0.8560)  acc1: 81.3793 (81.2265)  acc5: 94.9324 (95.1060)  time: 0.2280  data: 0.0002  max mem: 2170
[2024-01-21 10:29:07 root] (utils.py 307): INFO Test: Total time: 0:01:15 (0.4510 s / it)
[2024-01-21 10:29:07 root] (engine.py 118): INFO * Acc@1 81.226 Acc@5 95.106 loss 0.856 flops 12.940
[2024-01-21 10:29:07 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-21 10:29:37 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:29:41 root] (main_pitome.py 286): INFO Creating model: vit_base_patch16_224
[2024-01-21 10:29:44 root] (main_pitome.py 373): INFO number of params: 86567656
[2024-01-21 10:29:45 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:29:49 root] (main_tome.py 286): INFO Creating model: vit_base_patch16_224
[2024-01-21 10:29:49 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:14:24  flops: 12.9405 (12.9405)  loss: 0.8639 (0.8639)  acc1: 76.3699 (76.3699)  acc5: 95.8904 (95.8904)  time: 5.1763  data: 0.0015  max mem: 2127
[2024-01-21 10:29:53 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:00  flops: 12.9405 (12.9405)  loss: 0.8873 (0.8792)  acc1: 76.9759 (77.0917)  acc5: 93.2432 (93.9487)  time: 0.7661  data: 0.0020  max mem: 2169
[2024-01-21 10:29:55 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 10:29:55 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:16  flops: 12.9405 (12.9405)  loss: 0.8659 (0.8629)  acc1: 77.7397 (77.4757)  acc5: 94.1980 (94.4013)  time: 0.2900  data: 0.0014  max mem: 2169
[2024-01-21 10:29:58 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:59  flops: 12.9405 (12.9405)  loss: 0.8234 (0.8593)  acc1: 78.0822 (77.7973)  acc5: 94.2568 (94.2466)  time: 0.2525  data: 0.0005  max mem: 2169
[2024-01-21 10:30:01 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:50  flops: 12.9405 (12.9405)  loss: 0.8355 (0.8552)  acc1: 77.6271 (77.7686)  acc5: 94.2373 (94.2145)  time: 0.2610  data: 0.0002  max mem: 2169
[2024-01-21 10:30:02 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:20:56  flops: 12.9405 (12.9405)  loss: 0.8595 (0.8595)  acc1: 76.3699 (76.3699)  acc5: 93.1507 (93.1507)  time: 7.5253  data: 0.1151  max mem: 2127
[2024-01-21 10:30:04 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:46  flops: 12.9405 (12.9405)  loss: 0.8357 (0.8494)  acc1: 77.3196 (77.9279)  acc5: 94.2373 (94.2707)  time: 0.3341  data: 0.0002  max mem: 2169
[2024-01-21 10:30:08 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:14  flops: 12.9405 (12.9405)  loss: 0.8804 (0.8744)  acc1: 77.0270 (77.0917)  acc5: 93.8144 (93.7944)  time: 1.2382  data: 0.0106  max mem: 2169
[2024-01-21 10:30:09 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:43  flops: 12.9405 (12.9405)  loss: 0.8393 (0.8525)  acc1: 77.1044 (77.6918)  acc5: 94.2568 (94.2490)  time: 0.4378  data: 0.0002  max mem: 2169
[2024-01-21 10:30:13 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:02:09  flops: 12.9405 (12.9405)  loss: 0.8501 (0.8633)  acc1: 77.7778 (77.1683)  acc5: 94.2177 (94.1909)  time: 0.5452  data: 0.0002  max mem: 2169
[2024-01-21 10:30:14 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8393 (0.8524)  acc1: 77.1331 (77.7374)  acc5: 94.1781 (94.2527)  time: 0.4839  data: 0.0002  max mem: 2169
[2024-01-21 10:30:18 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:42  flops: 12.9405 (12.9405)  loss: 0.8209 (0.8628)  acc1: 76.7918 (77.2932)  acc5: 94.5578 (94.1699)  time: 0.4819  data: 0.0002  max mem: 2169
[2024-01-21 10:30:19 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:37  flops: 12.9405 (12.9405)  loss: 0.8454 (0.8600)  acc1: 77.5168 (77.6139)  acc5: 93.8775 (94.1248)  time: 0.4864  data: 0.0002  max mem: 2169
[2024-01-21 10:30:23 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:27  flops: 12.9405 (12.9405)  loss: 0.8497 (0.8614)  acc1: 76.7918 (77.3547)  acc5: 93.9394 (94.0573)  time: 0.4833  data: 0.0002  max mem: 2169
[2024-01-21 10:30:24 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:33  flops: 12.9405 (12.9405)  loss: 0.8977 (0.8643)  acc1: 77.5510 (77.5859)  acc5: 93.6027 (94.1065)  time: 0.4994  data: 0.0002  max mem: 2170
[2024-01-21 10:30:27 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:15  flops: 12.9405 (12.9405)  loss: 0.8528 (0.8565)  acc1: 77.2109 (77.5619)  acc5: 94.2568 (94.1443)  time: 0.4742  data: 0.0002  max mem: 2169
[2024-01-21 10:30:29 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8977 (0.8652)  acc1: 77.7397 (77.6255)  acc5: 93.8983 (94.1141)  time: 0.5025  data: 0.0002  max mem: 2170
[2024-01-21 10:30:32 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:05  flops: 12.9405 (12.9405)  loss: 0.8528 (0.8610)  acc1: 76.9759 (77.3912)  acc5: 94.2568 (94.0931)  time: 0.4632  data: 0.0002  max mem: 2169
[2024-01-21 10:30:34 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8871 (0.8680)  acc1: 77.6271 (77.5729)  acc5: 94.2177 (94.0729)  time: 0.4891  data: 0.0002  max mem: 2170
[2024-01-21 10:30:37 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.8555 (0.8628)  acc1: 77.0548 (77.3788)  acc5: 93.9189 (94.0853)  time: 0.4591  data: 0.0002  max mem: 2169
[2024-01-21 10:30:39 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:21  flops: 12.9405 (12.9405)  loss: 0.8426 (0.8631)  acc1: 78.0405 (77.6412)  acc5: 94.2177 (94.0680)  time: 0.4887  data: 0.0008  max mem: 2170
[2024-01-21 10:30:41 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:50  flops: 12.9405 (12.9405)  loss: 0.8813 (0.8717)  acc1: 76.6102 (77.1571)  acc5: 93.6027 (93.9404)  time: 0.4597  data: 0.0002  max mem: 2169
[2024-01-21 10:30:44 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8386 (0.8631)  acc1: 77.7027 (77.5777)  acc5: 94.2953 (94.0997)  time: 0.4868  data: 0.0008  max mem: 2170
[2024-01-21 10:30:46 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:43  flops: 12.9405 (12.9405)  loss: 0.8974 (0.8761)  acc1: 76.6102 (77.1793)  acc5: 93.6027 (93.9311)  time: 0.4779  data: 0.0002  max mem: 2170
[2024-01-21 10:30:49 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8602 (0.8642)  acc1: 76.8708 (77.6012)  acc5: 94.2568 (94.0609)  time: 0.4873  data: 0.0002  max mem: 2170
[2024-01-21 10:30:51 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:37  flops: 12.9405 (12.9405)  loss: 0.8803 (0.8756)  acc1: 77.5510 (77.1921)  acc5: 93.6027 (93.9461)  time: 0.4768  data: 0.0002  max mem: 2170
[2024-01-21 10:30:53 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8698 (0.8654)  acc1: 76.6102 (77.5629)  acc5: 93.8356 (94.0456)  time: 0.4892  data: 0.0002  max mem: 2170
[2024-01-21 10:30:55 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8698 (0.8783)  acc1: 77.3973 (77.2120)  acc5: 93.8983 (93.9230)  time: 0.4617  data: 0.0002  max mem: 2170
[2024-01-21 10:30:58 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 12.9405 (12.9405)  loss: 0.8623 (0.8664)  acc1: 76.6102 (77.5212)  acc5: 93.8775 (94.0414)  time: 0.4900  data: 0.0002  max mem: 2170
[2024-01-21 10:31:00 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8450 (0.8729)  acc1: 77.2881 (77.2764)  acc5: 93.8983 (93.9473)  time: 0.4603  data: 0.0002  max mem: 2170
[2024-01-21 10:31:01 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8500 (0.8645)  acc1: 77.0270 (77.5280)  acc5: 93.9189 (94.0653)  time: 0.4948  data: 0.0002  max mem: 2170
[2024-01-21 10:31:01 root] (utils.py 307): INFO Test: Total time: 0:01:17 (0.4616 s / it)
[2024-01-21 10:31:01 root] (engine.py 118): INFO * Acc@1 77.528 Acc@5 94.065 loss 0.865 flops 12.940
[2024-01-21 10:31:01 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 77.5%
[2024-01-21 10:31:03 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8436 (0.8729)  acc1: 76.4706 (77.2149)  acc5: 94.2373 (93.9649)  time: 0.3784  data: 0.0002  max mem: 2170
[2024-01-21 10:31:05 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8691 (0.8740)  acc1: 76.5306 (77.2329)  acc5: 93.9189 (93.9140)  time: 0.2632  data: 0.0002  max mem: 2170
[2024-01-21 10:31:07 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:08  flops: 12.9405 (12.9405)  loss: 0.8670 (0.8752)  acc1: 77.1331 (77.2728)  acc5: 93.5154 (93.8949)  time: 0.2268  data: 0.0002  max mem: 2170
[2024-01-21 10:31:10 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 12.9405 (12.9405)  loss: 0.8642 (0.8759)  acc1: 77.3649 (77.2619)  acc5: 93.8775 (93.8874)  time: 0.2269  data: 0.0002  max mem: 2170
[2024-01-21 10:31:11 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8642 (0.8743)  acc1: 77.3649 (77.2917)  acc5: 93.8983 (93.8881)  time: 0.2278  data: 0.0002  max mem: 2170
[2024-01-21 10:31:11 root] (utils.py 307): INFO Test: Total time: 0:01:16 (0.4580 s / it)
[2024-01-21 10:31:11 root] (engine.py 118): INFO * Acc@1 77.292 Acc@5 93.888 loss 0.874 flops 12.940
[2024-01-21 10:31:11 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 77.3%
[2024-01-21 10:31:27 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_large_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:31:30 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_large_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:31:31 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_224
[2024-01-21 10:31:34 root] (main_tome.py 286): INFO Creating model: vit_large_patch16_224
[2024-01-21 10:31:38 timm.models.hub] (hub.py 46): INFO Downloading: "https://storage.googleapis.com/vit_models/augreg/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_224.npz" to /media/caduser/MyBook/chau//.vision_ckts/checkpoints/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_224.npz

[2024-01-21 10:31:40 timm.models.hub] (hub.py 46): INFO Downloading: "https://storage.googleapis.com/vit_models/augreg/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_224.npz" to /media/caduser/MyBook/chau//.vision_ckts/checkpoints/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_224.npz

[2024-01-21 10:31:58 root] (main_pitome.py 373): INFO number of params: 304326632
[2024-01-21 10:32:00 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:20  flops: 34.8324 (34.8324)  loss: 0.6309 (0.6309)  acc1: 83.9041 (83.9041)  acc5: 96.9178 (96.9178)  time: 1.9213  data: 0.0009  max mem: 3505
[2024-01-21 10:32:06 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:54  flops: 34.8324 (34.8324)  loss: 0.6309 (0.6404)  acc1: 82.7703 (83.1429)  acc5: 96.2585 (96.2334)  time: 0.7273  data: 0.0002  max mem: 3560
[2024-01-21 10:32:11 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:33  flops: 34.8324 (34.8324)  loss: 0.6385 (0.6448)  acc1: 82.7703 (82.9450)  acc5: 96.2585 (96.4239)  time: 0.5696  data: 0.0002  max mem: 3560
[2024-01-21 10:32:16 root] (main_tome.py 370): INFO number of params: 304326632
[2024-01-21 10:32:16 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:22  flops: 34.8324 (34.8324)  loss: 0.6508 (0.6423)  acc1: 82.6531 (82.7068)  acc5: 96.8966 (96.6356)  time: 0.5366  data: 0.0002  max mem: 3560
[2024-01-21 10:32:22 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:43  flops: 34.8324 (34.8324)  loss: 0.6355 (0.6355)  acc1: 83.2192 (83.2192)  acc5: 96.9178 (96.9178)  time: 6.0072  data: 0.0007  max mem: 3505
[2024-01-21 10:32:24 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:22  flops: 34.8324 (34.8324)  loss: 0.6705 (0.6445)  acc1: 82.5503 (82.6767)  acc5: 96.5753 (96.4658)  time: 0.6604  data: 0.0002  max mem: 3560
[2024-01-21 10:32:34 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:04:24  flops: 34.8324 (34.8324)  loss: 0.6430 (0.6362)  acc1: 83.2192 (83.0503)  acc5: 95.6081 (95.9555)  time: 1.6832  data: 0.0002  max mem: 3560
[2024-01-21 10:32:35 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:26  flops: 34.8324 (34.8324)  loss: 0.6321 (0.6376)  acc1: 82.4916 (82.6990)  acc5: 96.2457 (96.5331)  time: 0.9498  data: 0.0004  max mem: 3560
[2024-01-21 10:32:45 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:03:27  flops: 34.8324 (34.8324)  loss: 0.6360 (0.6267)  acc1: 83.1081 (83.2686)  acc5: 95.9459 (96.3107)  time: 1.1803  data: 0.0002  max mem: 3560
[2024-01-21 10:32:47 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:26  flops: 34.8324 (34.8324)  loss: 0.6156 (0.6420)  acc1: 81.5700 (82.4463)  acc5: 96.2838 (96.4648)  time: 1.1258  data: 0.0004  max mem: 3560
[2024-01-21 10:32:56 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:02:59  flops: 34.8324 (34.8324)  loss: 0.6286 (0.6307)  acc1: 82.9932 (83.1123)  acc5: 96.5986 (96.4493)  time: 1.1095  data: 0.0002  max mem: 3560
[2024-01-21 10:32:58 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:22  flops: 34.8324 (34.8324)  loss: 0.6427 (0.6453)  acc1: 81.5700 (82.4089)  acc5: 95.9732 (96.4043)  time: 1.1296  data: 0.0002  max mem: 3560
[2024-01-21 10:33:08 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:40  flops: 34.8324 (34.8324)  loss: 0.6542 (0.6356)  acc1: 82.5342 (82.9912)  acc5: 96.2585 (96.3582)  time: 1.1123  data: 0.0002  max mem: 3560
[2024-01-21 10:33:09 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:16  flops: 34.8324 (34.8324)  loss: 0.6427 (0.6534)  acc1: 81.5700 (82.1481)  acc5: 96.2712 (96.3458)  time: 1.1306  data: 0.0002  max mem: 3560
[2024-01-21 10:33:18 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:23  flops: 34.8324 (34.8324)  loss: 0.6212 (0.6291)  acc1: 82.2526 (82.8720)  acc5: 96.6443 (96.5065)  time: 1.0979  data: 0.0002  max mem: 3560
[2024-01-21 10:33:21 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:10  flops: 34.8324 (34.8324)  loss: 0.6871 (0.6567)  acc1: 80.9524 (82.0806)  acc5: 96.2712 (96.3259)  time: 1.1467  data: 0.0002  max mem: 3560
[2024-01-21 10:33:29 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:08  flops: 34.8324 (34.8324)  loss: 0.6156 (0.6341)  acc1: 82.1306 (82.7135)  acc5: 96.9178 (96.4648)  time: 1.0783  data: 0.0002  max mem: 3560
[2024-01-21 10:33:32 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:02  flops: 34.8324 (34.8324)  loss: 0.6576 (0.6575)  acc1: 81.7568 (82.1306)  acc5: 96.2457 (96.2776)  time: 1.1489  data: 0.0002  max mem: 3560
[2024-01-21 10:33:40 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:55  flops: 34.8324 (34.8324)  loss: 0.6654 (0.6393)  acc1: 82.0690 (82.5715)  acc5: 95.9732 (96.4378)  time: 1.0818  data: 0.0002  max mem: 3560
[2024-01-21 10:33:44 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:54  flops: 34.8324 (34.8324)  loss: 0.6631 (0.6606)  acc1: 81.7568 (82.0534)  acc5: 95.9322 (96.2137)  time: 1.1339  data: 0.0002  max mem: 3560
[2024-01-21 10:33:51 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:42  flops: 34.8324 (34.8324)  loss: 0.6666 (0.6473)  acc1: 81.8182 (82.3367)  acc5: 95.9732 (96.3835)  time: 1.0853  data: 0.0002  max mem: 3560
[2024-01-21 10:33:55 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:45  flops: 34.8324 (34.8324)  loss: 0.6630 (0.6568)  acc1: 81.9728 (82.0776)  acc5: 96.2199 (96.2567)  time: 1.1315  data: 0.0002  max mem: 3560
[2024-01-21 10:34:02 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:29  flops: 34.8324 (34.8324)  loss: 0.6640 (0.6497)  acc1: 81.6327 (82.3231)  acc5: 96.6102 (96.3482)  time: 1.0961  data: 0.0002  max mem: 3560
[2024-01-21 10:34:06 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:36  flops: 34.8324 (34.8324)  loss: 0.6245 (0.6563)  acc1: 82.2526 (82.0658)  acc5: 96.5398 (96.2556)  time: 1.1338  data: 0.0002  max mem: 3560
[2024-01-21 10:34:13 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:17  flops: 34.8324 (34.8324)  loss: 0.6640 (0.6498)  acc1: 82.7703 (82.3691)  acc5: 95.6229 (96.2978)  time: 1.0996  data: 0.0002  max mem: 3560
[2024-01-21 10:34:18 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:26  flops: 34.8324 (34.8324)  loss: 0.6411 (0.6549)  acc1: 81.9728 (82.0863)  acc5: 96.5986 (96.2637)  time: 1.1349  data: 0.0002  max mem: 3560
[2024-01-21 10:34:24 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:05  flops: 34.8324 (34.8324)  loss: 0.6678 (0.6537)  acc1: 82.6531 (82.3164)  acc5: 95.6229 (96.2260)  time: 1.0836  data: 0.0002  max mem: 3560
[2024-01-21 10:34:29 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:17  flops: 34.8324 (34.8324)  loss: 0.6444 (0.6553)  acc1: 81.9728 (82.0827)  acc5: 96.5986 (96.2807)  time: 1.1324  data: 0.0002  max mem: 3560
[2024-01-21 10:34:34 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:53  flops: 34.8324 (34.8324)  loss: 0.6199 (0.6496)  acc1: 82.7586 (82.3582)  acc5: 96.2457 (96.2791)  time: 1.0800  data: 0.0002  max mem: 3560
[2024-01-21 10:34:40 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:07  flops: 34.8324 (34.8324)  loss: 0.6444 (0.6558)  acc1: 81.5700 (82.0355)  acc5: 96.5870 (96.2827)  time: 1.1334  data: 0.0002  max mem: 3560
[2024-01-21 10:34:45 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:42  flops: 34.8324 (34.8324)  loss: 0.6199 (0.6490)  acc1: 82.9431 (82.3871)  acc5: 95.9866 (96.2712)  time: 1.0847  data: 0.0002  max mem: 3560
[2024-01-21 10:34:47 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 34.8324 (34.8324)  loss: 0.6403 (0.6547)  acc1: 81.4815 (82.0513)  acc5: 96.5986 (96.2852)  time: 1.1279  data: 0.0002  max mem: 3560
[2024-01-21 10:34:47 root] (utils.py 307): INFO Test: Total time: 0:02:49 (1.0138 s / it)
[2024-01-21 10:34:47 root] (engine.py 118): INFO * Acc@1 82.051 Acc@5 96.285 loss 0.655 flops 34.832
[2024-01-21 10:34:47 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 82.1%
[2024-01-21 10:34:51 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:29  flops: 34.8324 (34.8324)  loss: 0.6276 (0.6474)  acc1: 82.9932 (82.4113)  acc5: 96.2585 (96.2901)  time: 0.8419  data: 0.0002  max mem: 3560
[2024-01-21 10:34:56 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:18  flops: 34.8324 (34.8324)  loss: 0.6276 (0.6482)  acc1: 83.3898 (82.4425)  acc5: 96.5753 (96.2785)  time: 0.5540  data: 0.0002  max mem: 3560
[2024-01-21 10:35:02 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:07  flops: 34.8324 (34.8324)  loss: 0.6305 (0.6481)  acc1: 82.6990 (82.4003)  acc5: 96.2712 (96.2785)  time: 0.5125  data: 0.0002  max mem: 3560
[2024-01-21 10:35:05 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 34.8324 (34.8324)  loss: 0.6190 (0.6468)  acc1: 81.6949 (82.4057)  acc5: 96.2712 (96.2730)  time: 0.5104  data: 0.0002  max mem: 3560
[2024-01-21 10:35:05 root] (utils.py 307): INFO Test: Total time: 0:02:48 (1.0110 s / it)
[2024-01-21 10:35:05 root] (engine.py 118): INFO * Acc@1 82.406 Acc@5 96.273 loss 0.647 flops 34.832
[2024-01-21 10:35:05 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 82.4%
[2024-01-21 10:36:11 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_large_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:36:15 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_224
[2024-01-21 10:36:23 root] (main_pitome.py 373): INFO number of params: 304326632
[2024-01-21 10:36:38 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:36:42 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:36:54 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 10:36:57 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:06:48  flops: 80.6285 (80.6285)  loss: 0.7765 (0.7765)  acc1: 86.3014 (86.3014)  acc5: 96.2329 (96.2329)  time: 2.4470  data: 0.0008  max mem: 6079
[2024-01-21 10:37:09 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:23  flops: 80.6285 (80.6285)  loss: 0.7045 (0.7053)  acc1: 85.3741 (85.8290)  acc5: 96.9388 (96.9744)  time: 1.2978  data: 0.0002  max mem: 6165
[2024-01-21 10:37:19 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:02:56  flops: 80.6285 (80.6285)  loss: 0.6894 (0.7031)  acc1: 85.3741 (85.7120)  acc5: 97.2414 (97.2330)  time: 1.1388  data: 0.0002  max mem: 6165
[2024-01-21 10:37:30 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:02:39  flops: 80.6285 (80.6285)  loss: 0.6764 (0.6956)  acc1: 85.3741 (85.8411)  acc5: 97.9452 (97.4904)  time: 1.0961  data: 0.0009  max mem: 6165
[2024-01-21 10:37:42 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:26  flops: 80.6285 (80.6285)  loss: 0.6941 (0.7007)  acc1: 85.0340 (85.7226)  acc5: 97.9452 (97.4342)  time: 1.1014  data: 0.0009  max mem: 6165
[2024-01-21 10:37:52 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:13  flops: 80.6285 (80.6285)  loss: 0.6844 (0.6956)  acc1: 86.1017 (85.8464)  acc5: 97.2881 (97.5047)  time: 1.0962  data: 0.0002  max mem: 6165
[2024-01-21 10:38:03 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:00  flops: 80.6285 (80.6285)  loss: 0.7072 (0.7015)  acc1: 85.8621 (85.6976)  acc5: 97.2881 (97.3722)  time: 1.0854  data: 0.0002  max mem: 6165
[2024-01-21 10:38:14 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:49  flops: 80.6285 (80.6285)  loss: 0.7157 (0.7062)  acc1: 85.2234 (85.5408)  acc5: 96.9072 (97.3415)  time: 1.0873  data: 0.0002  max mem: 6165
[2024-01-21 10:38:25 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:37  flops: 80.6285 (80.6285)  loss: 0.7231 (0.7080)  acc1: 84.7973 (85.4000)  acc5: 97.6190 (97.3851)  time: 1.0908  data: 0.0002  max mem: 6165
[2024-01-21 10:38:36 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:26  flops: 80.6285 (80.6285)  loss: 0.7258 (0.7115)  acc1: 84.7973 (85.3072)  acc5: 97.6271 (97.4076)  time: 1.0989  data: 0.0002  max mem: 6165
[2024-01-21 10:38:47 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:14  flops: 80.6285 (80.6285)  loss: 0.7151 (0.7108)  acc1: 85.8586 (85.3894)  acc5: 97.3154 (97.4199)  time: 1.1003  data: 0.0002  max mem: 6165
[2024-01-21 10:38:58 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:03  flops: 80.6285 (80.6285)  loss: 0.7045 (0.7122)  acc1: 85.8586 (85.4237)  acc5: 97.2973 (97.4034)  time: 1.0886  data: 0.0002  max mem: 6165
[2024-01-21 10:39:09 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:52  flops: 80.6285 (80.6285)  loss: 0.6848 (0.7093)  acc1: 85.8131 (85.4645)  acc5: 97.5779 (97.4324)  time: 1.0854  data: 0.0002  max mem: 6165
[2024-01-21 10:39:20 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:41  flops: 80.6285 (80.6285)  loss: 0.6562 (0.7081)  acc1: 86.3481 (85.4940)  acc5: 97.9592 (97.4605)  time: 1.0897  data: 0.0002  max mem: 6165
[2024-01-21 10:39:31 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:29  flops: 80.6285 (80.6285)  loss: 0.6816 (0.7064)  acc1: 85.8108 (85.4928)  acc5: 97.6351 (97.4770)  time: 1.0916  data: 0.0002  max mem: 6165
[2024-01-21 10:39:41 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:18  flops: 80.6285 (80.6285)  loss: 0.6936 (0.7085)  acc1: 85.4237 (85.4759)  acc5: 97.2881 (97.4523)  time: 1.0881  data: 0.0002  max mem: 6165
[2024-01-21 10:39:49 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:39:52 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:07  flops: 80.6285 (80.6285)  loss: 0.7167 (0.7095)  acc1: 85.4237 (85.4576)  acc5: 97.2414 (97.4508)  time: 1.0895  data: 0.0002  max mem: 6165
[2024-01-21 10:39:53 root] (main_tome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:39:59 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 80.6285 (80.6285)  loss: 0.6851 (0.7083)  acc1: 85.6164 (85.4606)  acc5: 97.6271 (97.4583)  time: 1.0930  data: 0.0002  max mem: 6165
[2024-01-21 10:39:59 root] (utils.py 307): INFO Test: Total time: 0:03:04 (1.1060 s / it)
[2024-01-21 10:39:59 root] (engine.py 118): INFO * Acc@1 85.461 Acc@5 97.458 loss 0.708 flops 80.629
[2024-01-21 10:39:59 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-01-21 10:40:05 root] (main_tome.py 370): INFO number of params: 632045800
[2024-01-21 10:40:07 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:06:40  flops: 80.6285 (80.6285)  loss: 0.7490 (0.7490)  acc1: 86.3014 (86.3014)  acc5: 96.5753 (96.5753)  time: 2.3997  data: 0.0010  max mem: 6079
[2024-01-21 10:40:19 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:22  flops: 80.6285 (80.6285)  loss: 0.6744 (0.6762)  acc1: 84.7973 (85.6128)  acc5: 97.6190 (97.2214)  time: 1.2910  data: 0.0003  max mem: 6165
[2024-01-21 10:40:30 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:02:55  flops: 80.6285 (80.6285)  loss: 0.6519 (0.6745)  acc1: 84.7973 (85.3236)  acc5: 97.6190 (97.4110)  time: 1.1358  data: 0.0002  max mem: 6165
[2024-01-21 10:40:41 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:02:39  flops: 80.6285 (80.6285)  loss: 0.6622 (0.6700)  acc1: 85.0847 (85.2164)  acc5: 97.6351 (97.4904)  time: 1.0923  data: 0.0002  max mem: 6165
[2024-01-21 10:40:52 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:25  flops: 80.6285 (80.6285)  loss: 0.6724 (0.6744)  acc1: 85.1351 (85.2508)  acc5: 97.3064 (97.4508)  time: 1.0956  data: 0.0002  max mem: 6165
[2024-01-21 10:41:02 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:12  flops: 80.6285 (80.6285)  loss: 0.6724 (0.6688)  acc1: 85.7627 (85.4072)  acc5: 97.3064 (97.5246)  time: 1.0869  data: 0.0002  max mem: 6165
[2024-01-21 10:41:13 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:00  flops: 80.6285 (80.6285)  loss: 0.6666 (0.6704)  acc1: 85.7627 (85.3580)  acc5: 97.6351 (97.5114)  time: 1.0740  data: 0.0002  max mem: 6165
[2024-01-21 10:41:24 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:48  flops: 80.6285 (80.6285)  loss: 0.6681 (0.6745)  acc1: 85.3741 (85.3113)  acc5: 97.3154 (97.4371)  time: 1.0754  data: 0.0002  max mem: 6165
[2024-01-21 10:41:35 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:36  flops: 80.6285 (80.6285)  loss: 0.6788 (0.6785)  acc1: 84.4068 (85.1947)  acc5: 97.3064 (97.4437)  time: 1.0784  data: 0.0002  max mem: 6165
[2024-01-21 10:41:46 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:25  flops: 80.6285 (80.6285)  loss: 0.6950 (0.6814)  acc1: 84.3537 (85.1393)  acc5: 97.3064 (97.4561)  time: 1.0861  data: 0.0002  max mem: 6165
[2024-01-21 10:41:56 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:14  flops: 80.6285 (80.6285)  loss: 0.6903 (0.6818)  acc1: 85.1351 (85.2080)  acc5: 97.2973 (97.4501)  time: 1.0876  data: 0.0002  max mem: 6165
[2024-01-21 10:42:07 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:02  flops: 80.6285 (80.6285)  loss: 0.6901 (0.6824)  acc1: 85.4237 (85.2647)  acc5: 97.2789 (97.4524)  time: 1.0762  data: 0.0002  max mem: 6165
[2024-01-21 10:42:18 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:51  flops: 80.6285 (80.6285)  loss: 0.6505 (0.6793)  acc1: 85.4237 (85.3130)  acc5: 97.5862 (97.4661)  time: 1.0731  data: 0.0002  max mem: 6165
[2024-01-21 10:42:29 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:40  flops: 80.6285 (80.6285)  loss: 0.6302 (0.6774)  acc1: 85.4730 (85.3981)  acc5: 97.5862 (97.4735)  time: 1.0772  data: 0.0002  max mem: 6165
[2024-01-21 10:42:40 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:29  flops: 80.6285 (80.6285)  loss: 0.6402 (0.6766)  acc1: 85.4730 (85.3821)  acc5: 97.6271 (97.4963)  time: 1.0785  data: 0.0002  max mem: 6165
[2024-01-21 10:42:50 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:18  flops: 80.6285 (80.6285)  loss: 0.7072 (0.6800)  acc1: 84.7458 (85.3275)  acc5: 97.3064 (97.4770)  time: 1.0752  data: 0.0002  max mem: 6165
[2024-01-21 10:43:01 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:07  flops: 80.6285 (80.6285)  loss: 0.7079 (0.6809)  acc1: 84.7458 (85.2848)  acc5: 97.6109 (97.4782)  time: 1.0779  data: 0.0002  max mem: 6165
[2024-01-21 10:43:07 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 80.6285 (80.6285)  loss: 0.6775 (0.6796)  acc1: 84.7973 (85.2997)  acc5: 97.6271 (97.4827)  time: 1.0686  data: 0.0002  max mem: 6165
[2024-01-21 10:43:07 root] (utils.py 307): INFO Test: Total time: 0:03:02 (1.0939 s / it)
[2024-01-21 10:43:07 root] (engine.py 118): INFO * Acc@1 85.300 Acc@5 97.483 loss 0.680 flops 80.629
[2024-01-21 10:43:07 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-01-21 10:48:35 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:48:39 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:48:51 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 10:48:54 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:06:53  flops: 80.6285 (80.6285)  loss: 0.7588 (0.7588)  acc1: 85.6164 (85.6164)  acc5: 96.5753 (96.5753)  time: 2.4752  data: 0.0009  max mem: 6079
[2024-01-21 10:49:05 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:23  flops: 80.6285 (80.6285)  loss: 0.6860 (0.7043)  acc1: 85.7143 (85.6746)  acc5: 97.2509 (97.1905)  time: 1.2991  data: 0.0003  max mem: 6165
[2024-01-21 10:49:16 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:02:56  flops: 80.6285 (80.6285)  loss: 0.6855 (0.7003)  acc1: 85.8586 (85.7282)  acc5: 97.2789 (97.2816)  time: 1.1378  data: 0.0002  max mem: 6165
[2024-01-21 10:49:27 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:02:40  flops: 80.6285 (80.6285)  loss: 0.6685 (0.6951)  acc1: 85.8586 (85.7534)  acc5: 97.9798 (97.5233)  time: 1.0959  data: 0.0002  max mem: 6165
[2024-01-21 10:49:38 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:26  flops: 80.6285 (80.6285)  loss: 0.7159 (0.7020)  acc1: 85.0340 (85.6150)  acc5: 97.6027 (97.4425)  time: 1.0990  data: 0.0002  max mem: 6165
[2024-01-21 10:49:49 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:13  flops: 80.6285 (80.6285)  loss: 0.7021 (0.6983)  acc1: 85.1852 (85.7000)  acc5: 97.2881 (97.4647)  time: 1.0910  data: 0.0002  max mem: 6165
[2024-01-21 10:50:00 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:00  flops: 80.6285 (80.6285)  loss: 0.6979 (0.7037)  acc1: 85.0340 (85.5862)  acc5: 96.9178 (97.3722)  time: 1.0807  data: 0.0002  max mem: 6165
[2024-01-21 10:50:11 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:48  flops: 80.6285 (80.6285)  loss: 0.7145 (0.7082)  acc1: 85.0340 (85.4882)  acc5: 96.9178 (97.3415)  time: 1.0841  data: 0.0002  max mem: 6165
[2024-01-21 10:50:22 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:37  flops: 80.6285 (80.6285)  loss: 0.7145 (0.7104)  acc1: 84.5118 (85.3204)  acc5: 97.6190 (97.3474)  time: 1.0890  data: 0.0002  max mem: 6165
[2024-01-21 10:50:33 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:26  flops: 80.6285 (80.6285)  loss: 0.7289 (0.7133)  acc1: 83.7288 (85.2512)  acc5: 97.6271 (97.3815)  time: 1.0968  data: 0.0002  max mem: 6165
[2024-01-21 10:50:44 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:14  flops: 80.6285 (80.6285)  loss: 0.7212 (0.7123)  acc1: 85.8108 (85.3625)  acc5: 97.3064 (97.3796)  time: 1.0979  data: 0.0002  max mem: 6165
[2024-01-21 10:50:55 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:03  flops: 80.6285 (80.6285)  loss: 0.6992 (0.7131)  acc1: 85.8108 (85.3809)  acc5: 96.9799 (97.3759)  time: 1.0875  data: 0.0002  max mem: 6165
[2024-01-21 10:51:05 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:52  flops: 80.6285 (80.6285)  loss: 0.6809 (0.7106)  acc1: 85.8108 (85.4225)  acc5: 97.2881 (97.3988)  time: 1.0847  data: 0.0002  max mem: 6165
[2024-01-21 10:51:16 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:41  flops: 80.6285 (80.6285)  loss: 0.6735 (0.7094)  acc1: 85.8108 (85.4422)  acc5: 97.6431 (97.4243)  time: 1.0889  data: 0.0002  max mem: 6165
[2024-01-21 10:51:25 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:51:29 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:51:41 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 10:52:02 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:52:06 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:52:18 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 10:52:46 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:52:50 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:53:02 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 10:54:23 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:54:27 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:54:40 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 10:55:13 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:55:17 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:55:29 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 10:55:54 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:55:57 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:56:10 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 10:56:27 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:56:31 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:56:44 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 10:57:30 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:57:34 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:57:46 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 10:57:49 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:06:49  flops: 80.6285 (80.6285)  loss: 0.8250 (0.8250)  acc1: 84.2466 (84.2466)  acc5: 95.8904 (95.8904)  time: 2.4548  data: 0.0009  max mem: 6079
[2024-01-21 10:57:59 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:58:03 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:58:30 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:58:34 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:58:46 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 10:58:49 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:06:53  flops: 80.6285 (80.6285)  loss: 0.8394 (0.8394)  acc1: 83.2192 (83.2192)  acc5: 96.2329 (96.2329)  time: 2.4769  data: 0.0007  max mem: 6079
[2024-01-21 10:59:31 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 10:59:35 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 10:59:47 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 11:00:07 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:00:11 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 11:00:23 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 11:00:26 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:06:58  flops: 80.6285 (80.6285)  loss: 0.7745 (0.7745)  acc1: 86.9863 (86.9863)  acc5: 95.8904 (95.8904)  time: 2.5035  data: 0.0008  max mem: 6079
[2024-01-21 11:00:38 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:24  flops: 80.6285 (80.6285)  loss: 0.7050 (0.7095)  acc1: 85.8108 (85.5511)  acc5: 97.2973 (97.1287)  time: 1.3038  data: 0.0002  max mem: 6165
[2024-01-21 11:00:49 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:02:56  flops: 80.6285 (80.6285)  loss: 0.6858 (0.7024)  acc1: 85.8108 (85.6472)  acc5: 97.2973 (97.2654)  time: 1.1386  data: 0.0002  max mem: 6165
[2024-01-21 11:01:00 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:02:40  flops: 80.6285 (80.6285)  loss: 0.6831 (0.6989)  acc1: 85.7143 (85.6219)  acc5: 97.6109 (97.3479)  time: 1.0971  data: 0.0002  max mem: 6165
[2024-01-21 11:01:11 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:26  flops: 80.6285 (80.6285)  loss: 0.7043 (0.7026)  acc1: 85.7143 (85.7143)  acc5: 97.6109 (97.3597)  time: 1.1038  data: 0.0002  max mem: 6165
[2024-01-21 11:01:22 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:13  flops: 80.6285 (80.6285)  loss: 0.6885 (0.6977)  acc1: 86.1017 (85.7932)  acc5: 97.6109 (97.4581)  time: 1.0967  data: 0.0002  max mem: 6165
[2024-01-21 11:01:32 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:01  flops: 80.6285 (80.6285)  loss: 0.6961 (0.7021)  acc1: 85.0340 (85.5918)  acc5: 97.5945 (97.4279)  time: 1.0852  data: 0.0002  max mem: 6165
[2024-01-21 11:01:43 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:49  flops: 80.6285 (80.6285)  loss: 0.6982 (0.7066)  acc1: 84.8797 (85.4691)  acc5: 97.3064 (97.3797)  time: 1.0872  data: 0.0002  max mem: 6165
[2024-01-21 11:01:54 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:37  flops: 80.6285 (80.6285)  loss: 0.7222 (0.7093)  acc1: 84.0678 (85.3288)  acc5: 96.6330 (97.3390)  time: 1.0905  data: 0.0002  max mem: 6165
[2024-01-21 11:02:05 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:26  flops: 80.6285 (80.6285)  loss: 0.7328 (0.7123)  acc1: 84.0678 (85.2512)  acc5: 96.9697 (97.3591)  time: 1.0993  data: 0.0002  max mem: 6165
[2024-01-21 11:02:16 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:14  flops: 80.6285 (80.6285)  loss: 0.7238 (0.7128)  acc1: 85.4237 (85.2583)  acc5: 97.2789 (97.3560)  time: 1.1015  data: 0.0002  max mem: 6165
[2024-01-21 11:02:27 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:03  flops: 80.6285 (80.6285)  loss: 0.7121 (0.7125)  acc1: 85.5705 (85.3534)  acc5: 97.2789 (97.3514)  time: 1.0903  data: 0.0002  max mem: 6165
[2024-01-21 11:02:38 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:52  flops: 80.6285 (80.6285)  loss: 0.6890 (0.7093)  acc1: 85.8131 (85.3972)  acc5: 97.3244 (97.3847)  time: 1.0872  data: 0.0002  max mem: 6165
[2024-01-21 11:02:49 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:41  flops: 80.6285 (80.6285)  loss: 0.6728 (0.7086)  acc1: 85.8131 (85.4111)  acc5: 97.3244 (97.3906)  time: 1.0916  data: 0.0002  max mem: 6165
[2024-01-21 11:03:00 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:29  flops: 80.6285 (80.6285)  loss: 0.6819 (0.7070)  acc1: 85.8586 (85.4134)  acc5: 97.2973 (97.4048)  time: 1.0931  data: 0.0002  max mem: 6165
[2024-01-21 11:03:11 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:18  flops: 80.6285 (80.6285)  loss: 0.7124 (0.7097)  acc1: 85.0847 (85.3478)  acc5: 97.2789 (97.3848)  time: 1.0897  data: 0.0002  max mem: 6165
[2024-01-21 11:03:22 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:07  flops: 80.6285 (80.6285)  loss: 0.7124 (0.7110)  acc1: 84.9829 (85.3290)  acc5: 96.9697 (97.3728)  time: 1.0916  data: 0.0002  max mem: 6165
[2024-01-21 11:03:28 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 80.6285 (80.6285)  loss: 0.7002 (0.7098)  acc1: 85.4237 (85.3587)  acc5: 97.2973 (97.3748)  time: 1.0843  data: 0.0002  max mem: 6165
[2024-01-21 11:03:28 root] (utils.py 307): INFO Test: Total time: 0:03:04 (1.1061 s / it)
[2024-01-21 11:03:28 root] (engine.py 118): INFO * Acc@1 85.359 Acc@5 97.375 loss 0.710 flops 80.629
[2024-01-21 11:03:28 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-01-21 11:03:36 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:03:40 root] (main_pitome.py 286): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 11:03:52 root] (main_pitome.py 373): INFO number of params: 632045800
[2024-01-21 11:03:54 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:06:51  flops: 80.6285 (80.6285)  loss: 0.7873 (0.7873)  acc1: 85.2740 (85.2740)  acc5: 95.8904 (95.8904)  time: 2.4623  data: 0.0009  max mem: 6079
[2024-01-21 11:04:06 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:24  flops: 80.6285 (80.6285)  loss: 0.6902 (0.7052)  acc1: 85.1351 (85.4276)  acc5: 97.3064 (97.1905)  time: 1.3036  data: 0.0002  max mem: 6165
[2024-01-21 11:04:17 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:02:57  flops: 80.6285 (80.6285)  loss: 0.6849 (0.6980)  acc1: 85.1351 (85.6958)  acc5: 97.3064 (97.3139)  time: 1.1446  data: 0.0002  max mem: 6165
[2024-01-21 11:04:28 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:02:41  flops: 80.6285 (80.6285)  loss: 0.6849 (0.6962)  acc1: 85.8586 (85.6219)  acc5: 97.2973 (97.3808)  time: 1.1048  data: 0.0002  max mem: 6165
[2024-01-21 11:04:39 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:27  flops: 80.6285 (80.6285)  loss: 0.7104 (0.7011)  acc1: 85.8108 (85.6481)  acc5: 97.2973 (97.3763)  time: 1.1111  data: 0.0002  max mem: 6165
[2024-01-21 11:04:50 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:14  flops: 80.6285 (80.6285)  loss: 0.7066 (0.6974)  acc1: 86.1017 (85.7400)  acc5: 97.5945 (97.4647)  time: 1.1032  data: 0.0002  max mem: 6165
[2024-01-21 11:05:01 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:01  flops: 80.6285 (80.6285)  loss: 0.7048 (0.7017)  acc1: 85.5219 (85.5862)  acc5: 97.5945 (97.4168)  time: 1.0914  data: 0.0003  max mem: 6165
[2024-01-21 11:05:12 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:49  flops: 80.6285 (80.6285)  loss: 0.7064 (0.7052)  acc1: 85.1351 (85.4643)  acc5: 97.2414 (97.3797)  time: 1.0933  data: 0.0003  max mem: 6165
[2024-01-21 11:05:23 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:38  flops: 80.6285 (80.6285)  loss: 0.7109 (0.7079)  acc1: 84.0136 (85.3162)  acc5: 96.9697 (97.3390)  time: 1.0958  data: 0.0002  max mem: 6165
[2024-01-21 11:05:34 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:26  flops: 80.6285 (80.6285)  loss: 0.7260 (0.7112)  acc1: 84.1216 (85.2400)  acc5: 96.9388 (97.3255)  time: 1.1048  data: 0.0002  max mem: 6165
[2024-01-21 11:05:45 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:15  flops: 80.6285 (80.6285)  loss: 0.7213 (0.7110)  acc1: 85.7143 (85.3054)  acc5: 96.9388 (97.3191)  time: 1.1063  data: 0.0002  max mem: 6165
[2024-01-21 11:05:56 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:03  flops: 80.6285 (80.6285)  loss: 0.7178 (0.7115)  acc1: 85.8108 (85.3565)  acc5: 96.9388 (97.3239)  time: 1.0937  data: 0.0002  max mem: 6165
[2024-01-21 11:06:07 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:52  flops: 80.6285 (80.6285)  loss: 0.6869 (0.7084)  acc1: 85.9107 (85.4056)  acc5: 97.3244 (97.3567)  time: 1.0906  data: 0.0002  max mem: 6165
[2024-01-21 11:06:18 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:41  flops: 80.6285 (80.6285)  loss: 0.6850 (0.7076)  acc1: 85.9107 (85.4085)  acc5: 97.3244 (97.3699)  time: 1.0950  data: 0.0002  max mem: 6165
[2024-01-21 11:06:29 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:30  flops: 80.6285 (80.6285)  loss: 0.6931 (0.7063)  acc1: 85.7627 (85.4206)  acc5: 97.6271 (97.3759)  time: 1.0964  data: 0.0002  max mem: 6165
[2024-01-21 11:06:40 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:18  flops: 80.6285 (80.6285)  loss: 0.7104 (0.7090)  acc1: 85.4730 (85.3815)  acc5: 97.2881 (97.3691)  time: 1.0924  data: 0.0002  max mem: 6165
[2024-01-21 11:06:51 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:07  flops: 80.6285 (80.6285)  loss: 0.7223 (0.7104)  acc1: 84.8485 (85.3543)  acc5: 97.2414 (97.3496)  time: 1.0937  data: 0.0002  max mem: 6165
[2024-01-21 11:06:57 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 80.6285 (80.6285)  loss: 0.6895 (0.7091)  acc1: 85.7143 (85.3812)  acc5: 97.2881 (97.3544)  time: 1.0843  data: 0.0002  max mem: 6165
[2024-01-21 11:06:57 root] (utils.py 307): INFO Test: Total time: 0:03:05 (1.1103 s / it)
[2024-01-21 11:06:57 root] (engine.py 118): INFO * Acc@1 85.381 Acc@5 97.354 loss 0.709 flops 80.629
[2024-01-21 11:06:57 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-01-21 11:07:18 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:07:20 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:07:22 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 11:07:25 root] (main_tome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 11:07:30 root] (main_pitome.py 373): INFO number of params: 304326632
[2024-01-21 11:07:32 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:31  flops: 34.8324 (34.8324)  loss: 0.8138 (0.8138)  acc1: 84.5890 (84.5890)  acc5: 96.2329 (96.2329)  time: 1.9860  data: 0.0010  max mem: 3396
[2024-01-21 11:07:33 root] (main_tome.py 370): INFO number of params: 304326632
[2024-01-21 11:07:39 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:07  flops: 34.8324 (34.8324)  loss: 0.7976 (0.7976)  acc1: 84.2466 (84.2466)  acc5: 96.2329 (96.2329)  time: 5.7912  data: 0.0007  max mem: 3396
[2024-01-21 11:07:41 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:32  flops: 34.8324 (34.8324)  loss: 0.6974 (0.7223)  acc1: 85.1351 (85.3967)  acc5: 97.2789 (97.1905)  time: 0.9702  data: 0.0002  max mem: 3450
[2024-01-21 11:07:51 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:04:14  flops: 34.8324 (34.8324)  loss: 0.7219 (0.7164)  acc1: 85.6655 (85.3659)  acc5: 97.5945 (97.2522)  time: 1.6221  data: 0.0002  max mem: 3449
[2024-01-21 11:07:53 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:02:38  flops: 34.8324 (34.8324)  loss: 0.7045 (0.7254)  acc1: 85.2843 (85.2589)  acc5: 96.9697 (97.2330)  time: 1.0361  data: 0.0002  max mem: 3450
[2024-01-21 11:08:01 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:03:19  flops: 34.8324 (34.8324)  loss: 0.7177 (0.7223)  acc1: 85.6655 (85.3236)  acc5: 97.2789 (97.3625)  time: 1.1380  data: 0.0002  max mem: 3449
[2024-01-21 11:08:05 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:02:34  flops: 34.8324 (34.8324)  loss: 0.7048 (0.7233)  acc1: 85.3741 (85.2603)  acc5: 96.9697 (97.3151)  time: 1.2112  data: 0.0002  max mem: 3450
[2024-01-21 11:08:12 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:02:53  flops: 34.8324 (34.8324)  loss: 0.7113 (0.7215)  acc1: 85.1351 (85.1507)  acc5: 96.9697 (97.3918)  time: 1.0720  data: 0.0002  max mem: 3449
[2024-01-21 11:08:17 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:25  flops: 34.8324 (34.8324)  loss: 0.7320 (0.7335)  acc1: 84.9315 (85.0770)  acc5: 96.9595 (97.2024)  time: 1.2182  data: 0.0002  max mem: 3450
[2024-01-21 11:08:23 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:02:35  flops: 34.8324 (34.8324)  loss: 0.7443 (0.7343)  acc1: 84.7458 (85.0108)  acc5: 96.6443 (97.2273)  time: 1.0753  data: 0.0002  max mem: 3449
[2024-01-21 11:08:29 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:15  flops: 34.8324 (34.8324)  loss: 0.7282 (0.7287)  acc1: 84.6416 (85.1145)  acc5: 97.2696 (97.2718)  time: 1.2051  data: 0.0002  max mem: 3450
[2024-01-21 11:08:33 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:02:18  flops: 34.8324 (34.8324)  loss: 0.7565 (0.7324)  acc1: 84.5638 (84.9614)  acc5: 96.9492 (97.2784)  time: 1.0619  data: 0.0002  max mem: 3449
[2024-01-21 11:08:41 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:04  flops: 34.8324 (34.8324)  loss: 0.7282 (0.7331)  acc1: 84.8485 (85.0518)  acc5: 97.2789 (97.2275)  time: 1.1891  data: 0.0002  max mem: 3450
[2024-01-21 11:08:44 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:02:04  flops: 34.8324 (34.8324)  loss: 0.7501 (0.7360)  acc1: 83.6735 (84.7845)  acc5: 96.9595 (97.2163)  time: 1.0434  data: 0.0002  max mem: 3449
[2024-01-21 11:08:53 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:53  flops: 34.8324 (34.8324)  loss: 0.7497 (0.7368)  acc1: 85.0340 (85.0674)  acc5: 96.9388 (97.1933)  time: 1.1896  data: 0.0002  max mem: 3450
[2024-01-21 11:08:54 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:51  flops: 34.8324 (34.8324)  loss: 0.7501 (0.7408)  acc1: 83.6735 (84.7327)  acc5: 96.9388 (97.1359)  time: 1.0440  data: 0.0002  max mem: 3449
[2024-01-21 11:09:05 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:38  flops: 34.8324 (34.8324)  loss: 0.7649 (0.7455)  acc1: 83.6177 (84.5954)  acc5: 96.9697 (97.1336)  time: 1.0497  data: 0.0002  max mem: 3449
[2024-01-21 11:09:05 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:01:41  flops: 34.8324 (34.8324)  loss: 0.7720 (0.7407)  acc1: 84.8993 (84.9390)  acc5: 96.9492 (97.1672)  time: 1.1927  data: 0.0002  max mem: 3450
[2024-01-21 11:09:16 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:26  flops: 34.8324 (34.8324)  loss: 0.7649 (0.7494)  acc1: 83.3898 (84.5239)  acc5: 96.9900 (97.1502)  time: 1.0637  data: 0.0002  max mem: 3449
[2024-01-21 11:09:17 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:01:30  flops: 34.8324 (34.8324)  loss: 0.7720 (0.7452)  acc1: 83.3898 (84.8185)  acc5: 96.9492 (97.1539)  time: 1.2071  data: 0.0002  max mem: 3450
[2024-01-21 11:09:26 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:15  flops: 34.8324 (34.8324)  loss: 0.7495 (0.7493)  acc1: 83.6735 (84.5327)  acc5: 96.9697 (97.1377)  time: 1.0633  data: 0.0002  max mem: 3449
[2024-01-21 11:09:29 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:01:18  flops: 34.8324 (34.8324)  loss: 0.7449 (0.7462)  acc1: 83.5017 (84.7679)  acc5: 97.2789 (97.1343)  time: 1.2073  data: 0.0002  max mem: 3450
[2024-01-21 11:09:36 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:03  flops: 34.8324 (34.8324)  loss: 0.7601 (0.7512)  acc1: 85.0847 (84.5460)  acc5: 96.9388 (97.0915)  time: 1.0466  data: 0.0002  max mem: 3449
[2024-01-21 11:09:41 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:01:07  flops: 34.8324 (34.8324)  loss: 0.7449 (0.7474)  acc1: 84.0678 (84.7845)  acc5: 97.2789 (97.1098)  time: 1.1915  data: 0.0002  max mem: 3450
[2024-01-21 11:09:47 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:52  flops: 34.8324 (34.8324)  loss: 0.7176 (0.7473)  acc1: 85.4730 (84.6592)  acc5: 96.9900 (97.1350)  time: 1.0449  data: 0.0002  max mem: 3449
[2024-01-21 11:09:53 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:55  flops: 34.8324 (34.8324)  loss: 0.7127 (0.7433)  acc1: 85.1211 (84.8697)  acc5: 97.2881 (97.1406)  time: 1.1905  data: 0.0002  max mem: 3450
[2024-01-21 11:09:57 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:40  flops: 34.8324 (34.8324)  loss: 0.7045 (0.7454)  acc1: 85.6655 (84.7296)  acc5: 97.6190 (97.1626)  time: 1.0483  data: 0.0002  max mem: 3449
[2024-01-21 11:10:05 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:43  flops: 34.8324 (34.8324)  loss: 0.6870 (0.7412)  acc1: 85.5172 (84.9162)  acc5: 97.6190 (97.1600)  time: 1.1914  data: 0.0002  max mem: 3450
[2024-01-21 11:10:08 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:29  flops: 34.8324 (34.8324)  loss: 0.7197 (0.7442)  acc1: 85.1852 (84.7513)  acc5: 97.2973 (97.1857)  time: 1.0486  data: 0.0003  max mem: 3449
[2024-01-21 11:10:17 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:31  flops: 34.8324 (34.8324)  loss: 0.7165 (0.7394)  acc1: 85.0340 (84.9319)  acc5: 97.6190 (97.1737)  time: 1.1933  data: 0.0002  max mem: 3450
[2024-01-21 11:10:18 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:18  flops: 34.8324 (34.8324)  loss: 0.7317 (0.7457)  acc1: 84.6939 (84.7069)  acc5: 97.2696 (97.1779)  time: 1.0457  data: 0.0004  max mem: 3449
[2024-01-21 11:10:29 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:20  flops: 34.8324 (34.8324)  loss: 0.7251 (0.7407)  acc1: 84.7458 (84.9183)  acc5: 97.2318 (97.1510)  time: 1.1918  data: 0.0002  max mem: 3450
[2024-01-21 11:10:29 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:07  flops: 34.8324 (34.8324)  loss: 0.7568 (0.7478)  acc1: 84.1216 (84.6606)  acc5: 96.9492 (97.1472)  time: 1.0468  data: 0.0002  max mem: 3449
[2024-01-21 11:10:35 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 34.8324 (34.8324)  loss: 0.7225 (0.7462)  acc1: 84.5638 (84.6989)  acc5: 96.9595 (97.1467)  time: 1.0408  data: 0.0002  max mem: 3449
[2024-01-21 11:10:35 root] (utils.py 307): INFO Test: Total time: 0:03:02 (1.0908 s / it)
[2024-01-21 11:10:35 root] (engine.py 118): INFO * Acc@1 84.699 Acc@5 97.147 loss 0.746 flops 34.832
[2024-01-21 11:10:35 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-01-21 11:10:38 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:08  flops: 34.8324 (34.8324)  loss: 0.7350 (0.7425)  acc1: 84.7458 (84.8694)  acc5: 96.9697 (97.1367)  time: 1.0322  data: 0.0002  max mem: 3450
[2024-01-21 11:10:41 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:01  flops: 34.8324 (34.8324)  loss: 0.7052 (0.7405)  acc1: 84.8485 (84.8964)  acc5: 97.2696 (97.1508)  time: 0.8308  data: 0.0002  max mem: 3450
[2024-01-21 11:10:41 root] (utils.py 307): INFO Test: Total time: 0:03:10 (1.1395 s / it)
[2024-01-21 11:10:41 root] (engine.py 118): INFO * Acc@1 84.896 Acc@5 97.151 loss 0.740 flops 34.832
[2024-01-21 11:10:41 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-01-21 11:10:49 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:10:53 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 11:11:01 root] (main_pitome.py 373): INFO number of params: 304326632
[2024-01-21 11:11:03 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:38  flops: 34.8324 (34.8324)  loss: 0.8238 (0.8238)  acc1: 83.5616 (83.5616)  acc5: 96.2329 (96.2329)  time: 2.0297  data: 0.0008  max mem: 3396
[2024-01-21 11:11:09 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:55  flops: 34.8324 (34.8324)  loss: 0.7137 (0.7210)  acc1: 85.3242 (85.3967)  acc5: 97.2789 (97.1287)  time: 0.7338  data: 0.0002  max mem: 3450
[2024-01-21 11:11:14 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:33  flops: 34.8324 (34.8324)  loss: 0.7121 (0.7248)  acc1: 85.3242 (85.3074)  acc5: 97.2789 (97.2168)  time: 0.5688  data: 0.0002  max mem: 3450
[2024-01-21 11:11:19 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:22  flops: 34.8324 (34.8324)  loss: 0.7146 (0.7230)  acc1: 85.4730 (85.3479)  acc5: 97.2973 (97.2493)  time: 0.5350  data: 0.0002  max mem: 3450
[2024-01-21 11:11:25 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:14  flops: 34.8324 (34.8324)  loss: 0.7329 (0.7326)  acc1: 84.8993 (85.1680)  acc5: 96.9388 (97.1280)  time: 0.5375  data: 0.0002  max mem: 3450
[2024-01-21 11:11:30 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:07  flops: 34.8324 (34.8324)  loss: 0.7295 (0.7280)  acc1: 84.7973 (85.2076)  acc5: 96.9388 (97.1986)  time: 0.5306  data: 0.0002  max mem: 3450
[2024-01-21 11:11:35 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:00  flops: 34.8324 (34.8324)  loss: 0.7295 (0.7323)  acc1: 84.7973 (85.1409)  acc5: 97.2973 (97.1774)  time: 0.5223  data: 0.0002  max mem: 3450
[2024-01-21 11:11:41 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:54  flops: 34.8324 (34.8324)  loss: 0.7493 (0.7364)  acc1: 84.9829 (85.1248)  acc5: 96.9388 (97.1168)  time: 0.5242  data: 0.0002  max mem: 3450
[2024-01-21 11:11:46 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:48  flops: 34.8324 (34.8324)  loss: 0.7572 (0.7399)  acc1: 84.8993 (84.9935)  acc5: 97.2881 (97.1169)  time: 0.5255  data: 0.0002  max mem: 3450
[2024-01-21 11:11:51 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:42  flops: 34.8324 (34.8324)  loss: 0.7699 (0.7447)  acc1: 83.4459 (84.8819)  acc5: 97.2881 (97.1204)  time: 0.5313  data: 0.0002  max mem: 3450
[2024-01-21 11:11:56 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:36  flops: 34.8324 (34.8324)  loss: 0.7648 (0.7456)  acc1: 84.0136 (84.8350)  acc5: 97.2789 (97.1175)  time: 0.5319  data: 0.0002  max mem: 3450
[2024-01-21 11:12:02 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:31  flops: 34.8324 (34.8324)  loss: 0.7648 (0.7472)  acc1: 84.2282 (84.8396)  acc5: 96.9492 (97.0884)  time: 0.5236  data: 0.0002  max mem: 3450
[2024-01-21 11:12:07 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:25  flops: 34.8324 (34.8324)  loss: 0.7056 (0.7434)  acc1: 85.2234 (84.9202)  acc5: 96.9492 (97.1069)  time: 0.5230  data: 0.0002  max mem: 3450
[2024-01-21 11:12:12 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:20  flops: 34.8324 (34.8324)  loss: 0.6917 (0.7416)  acc1: 85.4237 (84.9654)  acc5: 97.5945 (97.1289)  time: 0.5249  data: 0.0002  max mem: 3450
[2024-01-21 11:12:17 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:14  flops: 34.8324 (34.8324)  loss: 0.7132 (0.7398)  acc1: 84.7973 (84.9608)  acc5: 97.6190 (97.1496)  time: 0.5251  data: 0.0002  max mem: 3450
[2024-01-21 11:12:23 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:09  flops: 34.8324 (34.8324)  loss: 0.7200 (0.7413)  acc1: 84.4291 (84.9250)  acc5: 96.9697 (97.1240)  time: 0.5233  data: 0.0002  max mem: 3450
[2024-01-21 11:12:28 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 34.8324 (34.8324)  loss: 0.7428 (0.7431)  acc1: 84.4291 (84.8799)  acc5: 96.9283 (97.1071)  time: 0.5248  data: 0.0002  max mem: 3450
[2024-01-21 11:12:31 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 34.8324 (34.8324)  loss: 0.7265 (0.7412)  acc1: 84.4595 (84.8985)  acc5: 96.9492 (97.1202)  time: 0.5234  data: 0.0002  max mem: 3450
[2024-01-21 11:12:31 root] (utils.py 307): INFO Test: Total time: 0:01:30 (0.5408 s / it)
[2024-01-21 11:12:31 root] (engine.py 118): INFO * Acc@1 84.898 Acc@5 97.120 loss 0.741 flops 34.832
[2024-01-21 11:12:31 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-01-21 11:12:41 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:12:46 root] (main_pitome.py 286): INFO Creating model: vit_large_patch16_mae
[2024-01-21 11:12:53 root] (main_pitome.py 373): INFO number of params: 304326632
[2024-01-21 11:12:55 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:05:04  flops: 34.8324 (34.8324)  loss: 0.8211 (0.8211)  acc1: 83.5616 (83.5616)  acc5: 96.2329 (96.2329)  time: 1.8210  data: 0.0009  max mem: 3396
[2024-01-21 11:13:01 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:52  flops: 34.8324 (34.8324)  loss: 0.6951 (0.7220)  acc1: 85.2843 (85.4585)  acc5: 97.2696 (97.2522)  time: 0.7136  data: 0.0002  max mem: 3450
[2024-01-21 11:13:07 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:32  flops: 34.8324 (34.8324)  loss: 0.6965 (0.7252)  acc1: 85.2843 (85.3398)  acc5: 97.2414 (97.2492)  time: 0.5688  data: 0.0002  max mem: 3450
[2024-01-21 11:13:12 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:21  flops: 34.8324 (34.8324)  loss: 0.7048 (0.7226)  acc1: 85.4730 (85.3370)  acc5: 97.2414 (97.2822)  time: 0.5350  data: 0.0002  max mem: 3450
[2024-01-21 11:13:17 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:14  flops: 34.8324 (34.8324)  loss: 0.7396 (0.7326)  acc1: 84.7458 (85.1184)  acc5: 96.9595 (97.1611)  time: 0.5373  data: 0.0005  max mem: 3450
[2024-01-21 11:13:23 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:06  flops: 34.8324 (34.8324)  loss: 0.7207 (0.7277)  acc1: 84.6939 (85.2010)  acc5: 97.2696 (97.2318)  time: 0.5315  data: 0.0005  max mem: 3450
[2024-01-21 11:13:28 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:00  flops: 34.8324 (34.8324)  loss: 0.7292 (0.7323)  acc1: 84.7973 (85.1186)  acc5: 97.2789 (97.1829)  time: 0.5223  data: 0.0002  max mem: 3450
[2024-01-21 11:13:33 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:54  flops: 34.8324 (34.8324)  loss: 0.7437 (0.7360)  acc1: 84.7973 (85.1105)  acc5: 97.2414 (97.1455)  time: 0.5228  data: 0.0002  max mem: 3450
[2024-01-21 11:13:38 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:48  flops: 34.8324 (34.8324)  loss: 0.7738 (0.7398)  acc1: 83.8926 (84.9809)  acc5: 96.9595 (97.1462)  time: 0.5247  data: 0.0002  max mem: 3450
[2024-01-21 11:13:44 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:42  flops: 34.8324 (34.8324)  loss: 0.7766 (0.7453)  acc1: 83.3898 (84.8260)  acc5: 96.9900 (97.1390)  time: 0.5316  data: 0.0002  max mem: 3450
[2024-01-21 11:13:49 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:36  flops: 34.8324 (34.8324)  loss: 0.7525 (0.7463)  acc1: 84.2282 (84.7779)  acc5: 96.9697 (97.1209)  time: 0.5324  data: 0.0002  max mem: 3450
[2024-01-21 11:13:54 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:31  flops: 34.8324 (34.8324)  loss: 0.7525 (0.7479)  acc1: 84.7458 (84.7998)  acc5: 96.9492 (97.0915)  time: 0.5244  data: 0.0002  max mem: 3450
[2024-01-21 11:13:59 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:25  flops: 34.8324 (34.8324)  loss: 0.7279 (0.7440)  acc1: 85.5670 (84.8893)  acc5: 96.9799 (97.1013)  time: 0.5232  data: 0.0002  max mem: 3450
[2024-01-21 11:14:05 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:20  flops: 34.8324 (34.8324)  loss: 0.6928 (0.7417)  acc1: 85.6655 (84.9395)  acc5: 97.6190 (97.1263)  time: 0.5251  data: 0.0002  max mem: 3450
[2024-01-21 11:14:10 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:14  flops: 34.8324 (34.8324)  loss: 0.7143 (0.7396)  acc1: 85.0847 (84.9511)  acc5: 97.6271 (97.1496)  time: 0.5258  data: 0.0002  max mem: 3450
[2024-01-21 11:14:15 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:09  flops: 34.8324 (34.8324)  loss: 0.7169 (0.7410)  acc1: 84.7458 (84.9385)  acc5: 96.9388 (97.1262)  time: 0.5235  data: 0.0002  max mem: 3450
[2024-01-21 11:14:20 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 34.8324 (34.8324)  loss: 0.7370 (0.7427)  acc1: 84.6939 (84.8968)  acc5: 96.9388 (97.1198)  time: 0.5247  data: 0.0008  max mem: 3450
[2024-01-21 11:14:24 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 34.8324 (34.8324)  loss: 0.7136 (0.7409)  acc1: 85.1351 (84.9249)  acc5: 96.9595 (97.1324)  time: 0.5228  data: 0.0008  max mem: 3450
[2024-01-21 11:14:24 root] (utils.py 307): INFO Test: Total time: 0:01:30 (0.5396 s / it)
[2024-01-21 11:14:24 root] (engine.py 118): INFO * Acc@1 84.925 Acc@5 97.132 loss 0.741 flops 34.832
[2024-01-21 11:14:24 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-01-21 11:14:56 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_base_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:14:59 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_base_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:15:01 root] (main_tome.py 286): INFO Creating model: vit_base_patch16_mae
[2024-01-21 11:15:03 root] (main_pitome.py 286): INFO Creating model: vit_base_patch16_mae
[2024-01-21 11:15:04 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 11:15:08 root] (main_pitome.py 373): INFO number of params: 86567656
[2024-01-21 11:15:11 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:18:09  flops: 12.9405 (12.9405)  loss: 0.8003 (0.8003)  acc1: 81.1644 (81.1644)  acc5: 95.8904 (95.8904)  time: 6.5267  data: 2.6826  max mem: 2049
[2024-01-21 11:15:14 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:18  flops: 12.9405 (12.9405)  loss: 0.7306 (0.7425)  acc1: 83.1615 (83.3899)  acc5: 95.9459 (96.0482)  time: 0.8844  data: 0.2440  max mem: 2091
[2024-01-21 11:15:16 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:22:40  flops: 12.9405 (12.9405)  loss: 0.8121 (0.8121)  acc1: 82.8767 (82.8767)  acc5: 95.2055 (95.2055)  time: 8.1492  data: 0.6913  max mem: 2049
[2024-01-21 11:15:18 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:35  flops: 12.9405 (12.9405)  loss: 0.7408 (0.7433)  acc1: 83.2192 (83.4790)  acc5: 96.2585 (96.3269)  time: 0.3578  data: 0.0002  max mem: 2091
[2024-01-21 11:15:22 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:28  flops: 12.9405 (12.9405)  loss: 0.7227 (0.7392)  acc1: 84.1924 (83.6987)  acc5: 95.9596 (95.8938)  time: 1.3311  data: 0.0630  max mem: 2091
[2024-01-21 11:15:23 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:20  flops: 12.9405 (12.9405)  loss: 0.7427 (0.7383)  acc1: 83.2192 (83.5836)  acc5: 96.5870 (96.4164)  time: 0.4283  data: 0.0007  max mem: 2091
[2024-01-21 11:15:27 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:11  flops: 12.9405 (12.9405)  loss: 0.7735 (0.7513)  acc1: 83.2192 (83.2975)  acc5: 96.5753 (96.3003)  time: 0.4622  data: 0.0007  max mem: 2091
[2024-01-21 11:15:28 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:02:19  flops: 12.9405 (12.9405)  loss: 0.7213 (0.7349)  acc1: 83.1650 (83.5761)  acc5: 96.2585 (96.2621)  time: 0.5923  data: 0.0002  max mem: 2091
[2024-01-21 11:15:32 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:02  flops: 12.9405 (12.9405)  loss: 0.7543 (0.7438)  acc1: 82.4742 (83.3977)  acc5: 96.6330 (96.4466)  time: 0.4521  data: 0.0002  max mem: 2091
[2024-01-21 11:15:33 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:52  flops: 12.9405 (12.9405)  loss: 0.7213 (0.7304)  acc1: 83.1650 (83.6493)  acc5: 96.9595 (96.4932)  time: 0.5379  data: 0.0002  max mem: 2091
[2024-01-21 11:15:36 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.7492 (0.7492)  acc1: 82.4742 (83.2368)  acc5: 96.6216 (96.3757)  time: 0.4396  data: 0.0002  max mem: 2091
[2024-01-21 11:15:38 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:35  flops: 12.9405 (12.9405)  loss: 0.7556 (0.7407)  acc1: 83.2765 (83.4382)  acc5: 96.2838 (96.4244)  time: 0.5390  data: 0.0002  max mem: 2091
[2024-01-21 11:15:41 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:49  flops: 12.9405 (12.9405)  loss: 0.7686 (0.7517)  acc1: 82.3129 (83.2313)  acc5: 96.2585 (96.3517)  time: 0.4399  data: 0.0002  max mem: 2091
[2024-01-21 11:15:44 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:22  flops: 12.9405 (12.9405)  loss: 0.7410 (0.7330)  acc1: 83.1081 (83.5574)  acc5: 96.2838 (96.5065)  time: 0.5277  data: 0.0002  max mem: 2091
[2024-01-21 11:15:45 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:43  flops: 12.9405 (12.9405)  loss: 0.7522 (0.7551)  acc1: 82.4324 (83.1957)  acc5: 96.2712 (96.3374)  time: 0.4429  data: 0.0002  max mem: 2091
[2024-01-21 11:15:49 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:11  flops: 12.9405 (12.9405)  loss: 0.7088 (0.7364)  acc1: 82.6531 (83.4094)  acc5: 96.6330 (96.4926)  time: 0.5125  data: 0.0002  max mem: 2091
[2024-01-21 11:15:50 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:38  flops: 12.9405 (12.9405)  loss: 0.7934 (0.7611)  acc1: 82.4324 (82.9908)  acc5: 95.9184 (96.3259)  time: 0.4545  data: 0.0002  max mem: 2091
[2024-01-21 11:15:54 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:01:03  flops: 12.9405 (12.9405)  loss: 0.7495 (0.7383)  acc1: 82.4324 (83.3604)  acc5: 96.2963 (96.4426)  time: 0.5112  data: 0.0002  max mem: 2091
[2024-01-21 11:15:54 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:32  flops: 12.9405 (12.9405)  loss: 0.7749 (0.7642)  acc1: 81.4815 (82.9134)  acc5: 95.6522 (96.2642)  time: 0.4554  data: 0.0002  max mem: 2091
[2024-01-21 11:15:59 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8116 (0.7679)  acc1: 83.0508 (82.9067)  acc5: 95.6081 (96.2045)  time: 0.4440  data: 0.0002  max mem: 2091
[2024-01-21 11:15:59 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.7504 (0.7419)  acc1: 82.7119 (83.2796)  acc5: 96.2585 (96.3961)  time: 0.5160  data: 0.0002  max mem: 2091
[2024-01-21 11:16:03 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.7390 (0.7649)  acc1: 83.0508 (82.9587)  acc5: 96.2585 (96.2314)  time: 0.4423  data: 0.0002  max mem: 2091
[2024-01-21 11:16:04 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.7802 (0.7478)  acc1: 82.4324 (83.1027)  acc5: 96.2585 (96.3855)  time: 0.5290  data: 0.0002  max mem: 2091
[2024-01-21 11:16:07 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:17  flops: 12.9405 (12.9405)  loss: 0.7292 (0.7637)  acc1: 83.3333 (82.9701)  acc5: 96.6102 (96.2608)  time: 0.4458  data: 0.0007  max mem: 2091
[2024-01-21 11:16:10 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.7802 (0.7508)  acc1: 81.6949 (82.9974)  acc5: 95.9459 (96.3280)  time: 0.5292  data: 0.0002  max mem: 2091
[2024-01-21 11:16:12 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.7294 (0.7626)  acc1: 82.8283 (82.9746)  acc5: 96.9178 (96.2853)  time: 0.4460  data: 0.0007  max mem: 2091
[2024-01-21 11:16:15 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.7799 (0.7536)  acc1: 82.7119 (82.9893)  acc5: 95.9732 (96.2627)  time: 0.5150  data: 0.0002  max mem: 2091
[2024-01-21 11:16:16 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:08  flops: 12.9405 (12.9405)  loss: 0.7570 (0.7648)  acc1: 82.6531 (82.9372)  acc5: 95.9184 (96.2582)  time: 0.4420  data: 0.0002  max mem: 2091
[2024-01-21 11:16:20 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:28  flops: 12.9405 (12.9405)  loss: 0.7211 (0.7508)  acc1: 83.3898 (83.0345)  acc5: 96.2069 (96.2651)  time: 0.5146  data: 0.0004  max mem: 2091
[2024-01-21 11:16:21 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 12.9405 (12.9405)  loss: 0.7723 (0.7669)  acc1: 82.6531 (82.8958)  acc5: 95.6081 (96.2279)  time: 0.4449  data: 0.0002  max mem: 2091
[2024-01-21 11:16:23 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.7354 (0.7641)  acc1: 82.8859 (82.9433)  acc5: 96.2838 (96.2343)  time: 0.4463  data: 0.0002  max mem: 2091
[2024-01-21 11:16:23 root] (utils.py 307): INFO Test: Total time: 0:01:19 (0.4734 s / it)
[2024-01-21 11:16:23 root] (engine.py 118): INFO * Acc@1 82.943 Acc@5 96.234 loss 0.764 flops 12.940
[2024-01-21 11:16:23 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 82.9%
[2024-01-21 11:16:24 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:21  flops: 12.9405 (12.9405)  loss: 0.7104 (0.7496)  acc1: 83.5570 (83.0893)  acc5: 96.5398 (96.3048)  time: 0.4736  data: 0.0004  max mem: 2091
[2024-01-21 11:16:27 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.7301 (0.7485)  acc1: 82.8767 (83.1022)  acc5: 96.9697 (96.3624)  time: 0.3325  data: 0.0002  max mem: 2091
[2024-01-21 11:16:29 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:09  flops: 12.9405 (12.9405)  loss: 0.7412 (0.7506)  acc1: 82.7119 (83.0766)  acc5: 96.5986 (96.3527)  time: 0.2334  data: 0.0002  max mem: 2091
[2024-01-21 11:16:31 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 12.9405 (12.9405)  loss: 0.7567 (0.7525)  acc1: 82.7119 (83.0708)  acc5: 95.9322 (96.3186)  time: 0.2337  data: 0.0002  max mem: 2091
[2024-01-21 11:16:33 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.7298 (0.7503)  acc1: 83.2192 (83.1144)  acc5: 96.2457 (96.3198)  time: 0.2351  data: 0.0002  max mem: 2091
[2024-01-21 11:16:33 root] (utils.py 307): INFO Test: Total time: 0:01:24 (0.5089 s / it)
[2024-01-21 11:16:33 root] (engine.py 118): INFO * Acc@1 83.114 Acc@5 96.320 loss 0.750 flops 12.940
[2024-01-21 11:16:33 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 83.1%
[2024-01-21 11:17:39 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_tiny_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:17:42 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='vit_base_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:17:43 root] (main_pitome.py 286): INFO Creating model: deit_tiny_patch16_224
[2024-01-21 11:17:43 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth)
[2024-01-21 11:17:46 root] (main_tome.py 286): INFO Creating model: vit_base_patch16_mae
[2024-01-21 11:17:46 root] (main_pitome.py 373): INFO number of params: 5717416
[2024-01-21 11:17:50 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 11:17:53 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:18:15  flops: 0.9119 (0.9119)  loss: 1.1949 (1.1949)  acc1: 75.6849 (75.6849)  acc5: 90.4110 (90.4110)  time: 6.5599  data: 2.6360  max mem: 600
[2024-01-21 11:17:54 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:46  flops: 0.9119 (0.9119)  loss: 1.2406 (1.2549)  acc1: 71.9595 (72.0284)  acc5: 90.8784 (90.4909)  time: 0.6804  data: 0.2398  max mem: 615
[2024-01-21 11:17:55 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:57  flops: 0.9119 (0.9119)  loss: 1.2406 (1.2546)  acc1: 72.3906 (72.0388)  acc5: 90.8784 (90.5178)  time: 0.0816  data: 0.0002  max mem: 615
[2024-01-21 11:17:56 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:41  flops: 0.9119 (0.9119)  loss: 1.2545 (1.2600)  acc1: 72.1088 (71.7589)  acc5: 90.6897 (90.5973)  time: 0.0942  data: 0.0232  max mem: 615
[2024-01-21 11:17:56 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:16:18  flops: 12.9405 (12.9405)  loss: 0.7992 (0.7992)  acc1: 81.1644 (81.1644)  acc5: 95.8904 (95.8904)  time: 5.8618  data: 1.3605  max mem: 2049
[2024-01-21 11:17:58 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:35  flops: 0.9119 (0.9119)  loss: 1.2692 (1.2642)  acc1: 69.9324 (71.7679)  acc5: 89.8649 (90.4817)  time: 0.1687  data: 0.0569  max mem: 615
[2024-01-21 11:18:00 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:30  flops: 0.9119 (0.9119)  loss: 1.2057 (1.2566)  acc1: 71.3805 (71.7128)  acc5: 91.5254 (90.8105)  time: 0.1960  data: 0.0478  max mem: 615
[2024-01-21 11:18:00 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:22  flops: 12.9405 (12.9405)  loss: 0.7293 (0.7432)  acc1: 83.1615 (83.3591)  acc5: 95.9184 (96.0173)  time: 0.9082  data: 0.1239  max mem: 2091
[2024-01-21 11:18:01 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:26  flops: 0.9119 (0.9119)  loss: 1.2918 (1.2664)  acc1: 70.7071 (71.3506)  acc5: 90.5405 (90.5968)  time: 0.1727  data: 0.0277  max mem: 615
[2024-01-21 11:18:03 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:22  flops: 0.9119 (0.9119)  loss: 1.3058 (1.2687)  acc1: 70.1342 (71.3589)  acc5: 90.2685 (90.6139)  time: 0.1740  data: 0.0316  max mem: 615
[2024-01-21 11:18:04 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:33  flops: 12.9405 (12.9405)  loss: 0.7413 (0.7437)  acc1: 83.1615 (83.4628)  acc5: 96.2199 (96.3269)  time: 0.3754  data: 0.0003  max mem: 2091
[2024-01-21 11:18:05 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:19  flops: 0.9119 (0.9119)  loss: 1.3072 (1.2764)  acc1: 69.9324 (71.1394)  acc5: 90.2685 (90.5377)  time: 0.1783  data: 0.0368  max mem: 615
[2024-01-21 11:18:07 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:17  flops: 0.9119 (0.9119)  loss: 1.3382 (1.2827)  acc1: 69.8305 (71.0396)  acc5: 89.7260 (90.5368)  time: 0.1704  data: 0.0605  max mem: 615
[2024-01-21 11:18:08 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:14  flops: 0.9119 (0.9119)  loss: 1.3283 (1.2881)  acc1: 70.2422 (70.9702)  acc5: 89.5623 (90.4488)  time: 0.1624  data: 0.0936  max mem: 615
[2024-01-21 11:18:10 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:12  flops: 0.9119 (0.9119)  loss: 1.3191 (1.2897)  acc1: 70.6081 (71.0035)  acc5: 89.5270 (90.3753)  time: 0.1703  data: 0.1096  max mem: 615
[2024-01-21 11:18:12 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 0.9119 (0.9119)  loss: 1.2443 (1.2840)  acc1: 72.1649 (71.1648)  acc5: 90.8475 (90.4706)  time: 0.1713  data: 0.1111  max mem: 615
[2024-01-21 11:18:13 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 0.9119 (0.9119)  loss: 1.2288 (1.2832)  acc1: 72.4490 (71.2109)  acc5: 91.5541 (90.4952)  time: 0.1700  data: 0.1096  max mem: 615
[2024-01-21 11:18:15 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 0.9119 (0.9119)  loss: 1.2484 (1.2805)  acc1: 71.2838 (71.1662)  acc5: 91.0959 (90.5484)  time: 0.1810  data: 0.1201  max mem: 615
[2024-01-21 11:18:17 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 0.9119 (0.9119)  loss: 1.2929 (1.2841)  acc1: 69.5205 (71.1070)  acc5: 90.5085 (90.5219)  time: 0.1862  data: 0.1248  max mem: 615
[2024-01-21 11:18:18 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_tiny_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:18:19 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 0.9119 (0.9119)  loss: 1.3247 (1.2865)  acc1: 69.1525 (71.0587)  acc5: 90.1024 (90.4970)  time: 0.1841  data: 0.1207  max mem: 615
[2024-01-21 11:18:20 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 0.9119 (0.9119)  loss: 1.2774 (1.2846)  acc1: 70.8475 (71.0882)  acc5: 90.5724 (90.5236)  time: 0.1824  data: 0.1171  max mem: 615
[2024-01-21 11:18:20 root] (utils.py 307): INFO Test: Total time: 0:00:33 (0.2021 s / it)
[2024-01-21 11:18:20 root] (engine.py 118): INFO * Acc@1 71.088 Acc@5 90.524 loss 1.285 flops 0.912
[2024-01-21 11:18:20 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 71.1%
[2024-01-21 11:18:22 root] (main_tome.py 286): INFO Creating model: deit_tiny_patch16_224
[2024-01-21 11:18:22 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth)
[2024-01-21 11:18:24 root] (main_tome.py 370): INFO number of params: 5717416
[2024-01-21 11:18:30 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:15:42  flops: 0.9119 (0.9119)  loss: 1.1813 (1.1813)  acc1: 75.0000 (75.0000)  acc5: 91.0959 (91.0959)  time: 5.6452  data: 1.5433  max mem: 600
[2024-01-21 11:18:31 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:01:32  flops: 0.9119 (0.9119)  loss: 1.2501 (1.2595)  acc1: 72.1649 (72.0284)  acc5: 90.5724 (90.1513)  time: 0.5893  data: 0.1404  max mem: 615
[2024-01-21 11:18:32 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:00:49  flops: 0.9119 (0.9119)  loss: 1.2571 (1.2628)  acc1: 71.7172 (72.0065)  acc5: 90.3780 (90.3722)  time: 0.0719  data: 0.0002  max mem: 615
[2024-01-21 11:18:33 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:37  flops: 0.9119 (0.9119)  loss: 1.2632 (1.2734)  acc1: 70.6081 (71.3205)  acc5: 90.8163 (90.5205)  time: 0.0954  data: 0.0363  max mem: 615
[2024-01-21 11:18:35 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:31  flops: 0.9119 (0.9119)  loss: 1.2966 (1.2765)  acc1: 69.8305 (71.3541)  acc5: 90.1695 (90.4072)  time: 0.1476  data: 0.0887  max mem: 615
[2024-01-21 11:18:36 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:26  flops: 0.9119 (0.9119)  loss: 1.2217 (1.2691)  acc1: 71.4286 (71.3867)  acc5: 90.5085 (90.6109)  time: 0.1669  data: 0.1103  max mem: 615
[2024-01-21 11:18:38 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:23  flops: 0.9119 (0.9119)  loss: 1.2892 (1.2767)  acc1: 70.7904 (71.1391)  acc5: 90.2357 (90.4688)  time: 0.1745  data: 0.1206  max mem: 615
[2024-01-21 11:18:40 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:20  flops: 0.9119 (0.9119)  loss: 1.3036 (1.2775)  acc1: 70.6897 (71.1150)  acc5: 89.9329 (90.4896)  time: 0.1791  data: 0.1251  max mem: 615
[2024-01-21 11:18:42 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:18  flops: 0.9119 (0.9119)  loss: 1.3062 (1.2854)  acc1: 69.6552 (70.8503)  acc5: 90.1695 (90.4161)  time: 0.1781  data: 0.1243  max mem: 615
[2024-01-21 11:18:43 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:15  flops: 0.9119 (0.9119)  loss: 1.3247 (1.2915)  acc1: 69.1525 (70.7673)  acc5: 90.1695 (90.4099)  time: 0.1783  data: 0.1218  max mem: 615
[2024-01-21 11:18:45 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:13  flops: 0.9119 (0.9119)  loss: 1.3247 (1.2959)  acc1: 69.7279 (70.7250)  acc5: 90.0685 (90.3245)  time: 0.1733  data: 0.1164  max mem: 615
[2024-01-21 11:18:47 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:11  flops: 0.9119 (0.9119)  loss: 1.3097 (1.2977)  acc1: 70.6485 (70.8047)  acc5: 89.4915 (90.2682)  time: 0.1697  data: 0.1160  max mem: 615
[2024-01-21 11:18:48 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:09  flops: 0.9119 (0.9119)  loss: 1.2586 (1.2925)  acc1: 71.8213 (70.9375)  acc5: 90.9699 (90.3499)  time: 0.1707  data: 0.1173  max mem: 615
[2024-01-21 11:18:50 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:07  flops: 0.9119 (0.9119)  loss: 1.2400 (1.2923)  acc1: 71.8213 (70.9388)  acc5: 91.4676 (90.3708)  time: 0.1715  data: 0.1177  max mem: 615
[2024-01-21 11:18:52 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:05  flops: 0.9119 (0.9119)  loss: 1.2605 (1.2896)  acc1: 70.5085 (70.9038)  acc5: 90.5724 (90.4040)  time: 0.1802  data: 0.1263  max mem: 615
[2024-01-21 11:18:54 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 0.9119 (0.9119)  loss: 1.2919 (1.2922)  acc1: 68.4931 (70.8147)  acc5: 90.2357 (90.3668)  time: 0.1782  data: 0.1246  max mem: 615
[2024-01-21 11:18:56 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 0.9119 (0.9119)  loss: 1.3317 (1.2952)  acc1: 69.5946 (70.7551)  acc5: 89.7611 (90.3178)  time: 0.1728  data: 0.1192  max mem: 615
[2024-01-21 11:18:57 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 0.9119 (0.9119)  loss: 1.3012 (1.2933)  acc1: 69.9659 (70.7847)  acc5: 90.3448 (90.3281)  time: 0.1724  data: 0.1175  max mem: 615
[2024-01-21 11:18:57 root] (utils.py 307): INFO Test: Total time: 0:00:32 (0.1930 s / it)
[2024-01-21 11:18:57 root] (engine.py 118): INFO * Acc@1 70.785 Acc@5 90.328 loss 1.293 flops 0.912
[2024-01-21 11:18:57 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 70.8%
[2024-01-21 11:19:12 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:19:14 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:19:15 root] (main_pitome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 11:19:16 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 11:19:17 root] (main_pitome.py 373): INFO number of params: 22050664
[2024-01-21 11:19:18 root] (main_tome.py 286): INFO Creating model: deit_small_patch16_224
[2024-01-21 11:19:19 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth)
[2024-01-21 11:19:21 root] (main_tome.py 370): INFO number of params: 22050664
[2024-01-21 11:19:25 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:20:54  flops: 3.3726 (3.3726)  loss: 0.8838 (0.8838)  acc1: 80.1370 (80.1370)  acc5: 94.8630 (94.8630)  time: 7.5137  data: 2.7153  max mem: 1066
[2024-01-21 11:19:26 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:09  flops: 3.3726 (3.3726)  loss: 0.8838 (0.8963)  acc1: 80.4124 (80.5187)  acc5: 94.8630 (94.5045)  time: 0.8244  data: 0.2470  max mem: 1090
[2024-01-21 11:19:28 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:12  flops: 3.3726 (3.3726)  loss: 0.8894 (0.8911)  acc1: 80.4124 (80.5663)  acc5: 94.5578 (94.6764)  time: 0.1404  data: 0.0002  max mem: 1090
[2024-01-21 11:19:29 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:00:51  flops: 3.3726 (3.3726)  loss: 0.8900 (0.8918)  acc1: 80.2721 (80.3726)  acc5: 94.9324 (94.7397)  time: 0.1316  data: 0.0002  max mem: 1090
[2024-01-21 11:19:29 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:21:21  flops: 3.3726 (3.3726)  loss: 0.8862 (0.8862)  acc1: 81.1644 (81.1644)  acc5: 94.8630 (94.8630)  time: 7.6717  data: 0.6422  max mem: 1066
[2024-01-21 11:19:31 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:43  flops: 3.3726 (3.3726)  loss: 0.9191 (0.9020)  acc1: 78.5235 (80.0944)  acc5: 94.9153 (94.7029)  time: 0.1827  data: 0.0002  max mem: 1090
[2024-01-21 11:19:32 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:24  flops: 3.3726 (3.3726)  loss: 0.8958 (0.8968)  acc1: 80.8081 (80.7657)  acc5: 94.8805 (94.5353)  time: 0.9204  data: 0.0588  max mem: 1090
[2024-01-21 11:19:33 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:23  flops: 3.3726 (3.3726)  loss: 0.9031 (0.8980)  acc1: 80.0687 (80.2427)  acc5: 94.8805 (94.6602)  time: 0.2154  data: 0.0003  max mem: 1090
[2024-01-21 11:19:34 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:37  flops: 3.3726 (3.3726)  loss: 0.9117 (0.8947)  acc1: 78.5235 (80.0705)  acc5: 94.6309 (94.8363)  time: 0.2278  data: 0.0002  max mem: 1090
[2024-01-21 11:19:35 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:01  flops: 3.3726 (3.3726)  loss: 0.9031 (0.8982)  acc1: 79.7297 (80.0000)  acc5: 94.9324 (94.7726)  time: 0.1857  data: 0.0002  max mem: 1090
[2024-01-21 11:19:36 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:32  flops: 3.3726 (3.3726)  loss: 0.9039 (0.9012)  acc1: 78.1145 (79.7461)  acc5: 94.8980 (94.8057)  time: 0.2273  data: 0.0002  max mem: 1090
[2024-01-21 11:19:37 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:00:48  flops: 3.3726 (3.3726)  loss: 0.9207 (0.9075)  acc1: 79.3220 (79.8129)  acc5: 94.9324 (94.6863)  time: 0.1867  data: 0.0002  max mem: 1090
[2024-01-21 11:19:38 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9249 (0.9008)  acc1: 79.1809 (79.7743)  acc5: 94.8630 (94.8551)  time: 0.2269  data: 0.0003  max mem: 1090
[2024-01-21 11:19:39 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:00:39  flops: 3.3726 (3.3726)  loss: 0.9146 (0.8983)  acc1: 79.5302 (79.8909)  acc5: 94.9324 (94.8829)  time: 0.1784  data: 0.0002  max mem: 1090
[2024-01-21 11:19:40 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:24  flops: 3.3726 (3.3726)  loss: 0.9311 (0.9072)  acc1: 78.6441 (79.4996)  acc5: 94.9495 (94.9126)  time: 0.2269  data: 0.0003  max mem: 1090
[2024-01-21 11:19:41 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:00:33  flops: 3.3726 (3.3726)  loss: 0.9225 (0.9062)  acc1: 77.7778 (79.5234)  acc5: 94.9324 (94.7556)  time: 0.1709  data: 0.0002  max mem: 1090
[2024-01-21 11:19:42 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:28  flops: 3.3726 (3.3726)  loss: 0.9242 (0.9071)  acc1: 78.9655 (79.5018)  acc5: 93.8144 (94.7691)  time: 0.1722  data: 0.0002  max mem: 1090
[2024-01-21 11:19:43 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:21  flops: 3.3726 (3.3726)  loss: 0.9625 (0.9132)  acc1: 77.0270 (79.3763)  acc5: 94.4828 (94.8226)  time: 0.2333  data: 0.0003  max mem: 1091
[2024-01-21 11:19:44 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:24  flops: 3.3726 (3.3726)  loss: 0.9467 (0.9134)  acc1: 78.3051 (79.2817)  acc5: 94.5946 (94.7869)  time: 0.1716  data: 0.0003  max mem: 1090
[2024-01-21 11:19:45 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:18  flops: 3.3726 (3.3726)  loss: 0.9439 (0.9167)  acc1: 78.8591 (79.3422)  acc5: 93.8775 (94.7658)  time: 0.2352  data: 0.0003  max mem: 1091
[2024-01-21 11:19:46 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:20  flops: 3.3726 (3.3726)  loss: 0.9614 (0.9192)  acc1: 77.2881 (79.1861)  acc5: 94.5578 (94.7033)  time: 0.1795  data: 0.0002  max mem: 1091
[2024-01-21 11:19:47 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:15  flops: 3.3726 (3.3726)  loss: 0.9508 (0.9188)  acc1: 79.3919 (79.3314)  acc5: 93.7931 (94.7273)  time: 0.2289  data: 0.0003  max mem: 1091
[2024-01-21 11:19:48 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:17  flops: 3.3726 (3.3726)  loss: 0.9421 (0.9218)  acc1: 79.3919 (79.1675)  acc5: 93.6455 (94.6516)  time: 0.1789  data: 0.0005  max mem: 1091
[2024-01-21 11:19:49 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:14  flops: 3.3726 (3.3726)  loss: 0.9452 (0.9237)  acc1: 79.3919 (79.1663)  acc5: 94.2177 (94.6417)  time: 0.1701  data: 0.0005  max mem: 1091
[2024-01-21 11:19:50 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:12  flops: 3.3726 (3.3726)  loss: 0.8803 (0.9153)  acc1: 80.3448 (79.4147)  acc5: 94.8980 (94.7695)  time: 0.2268  data: 0.0006  max mem: 1091
[2024-01-21 11:19:51 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:11  flops: 3.3726 (3.3726)  loss: 0.9131 (0.9203)  acc1: 80.1370 (79.2772)  acc5: 94.5763 (94.6825)  time: 0.1746  data: 0.0029  max mem: 1091
[2024-01-21 11:19:52 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:09  flops: 3.3726 (3.3726)  loss: 0.8765 (0.9139)  acc1: 80.4714 (79.4460)  acc5: 95.5326 (94.7863)  time: 0.2136  data: 0.0005  max mem: 1091
[2024-01-21 11:19:53 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:08  flops: 3.3726 (3.3726)  loss: 0.9024 (0.9202)  acc1: 79.3220 (79.2490)  acc5: 94.9324 (94.7086)  time: 0.1887  data: 0.0149  max mem: 1091
[2024-01-21 11:19:54 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:06  flops: 3.3726 (3.3726)  loss: 0.9083 (0.9138)  acc1: 79.3919 (79.4068)  acc5: 94.8980 (94.8192)  time: 0.2082  data: 0.0002  max mem: 1091
[2024-01-21 11:19:55 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:06  flops: 3.3726 (3.3726)  loss: 0.9123 (0.9199)  acc1: 78.9116 (79.2527)  acc5: 94.9324 (94.7398)  time: 0.1932  data: 0.0196  max mem: 1091
[2024-01-21 11:19:56 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:04  flops: 3.3726 (3.3726)  loss: 0.9318 (0.9153)  acc1: 78.9655 (79.3798)  acc5: 94.5946 (94.8213)  time: 0.2195  data: 0.0003  max mem: 1091
[2024-01-21 11:19:57 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:03  flops: 3.3726 (3.3726)  loss: 0.9358 (0.9216)  acc1: 78.7162 (79.2382)  acc5: 94.4637 (94.7269)  time: 0.1839  data: 0.0099  max mem: 1091
[2024-01-21 11:19:58 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9318 (0.9173)  acc1: 78.8396 (79.3261)  acc5: 94.4828 (94.7920)  time: 0.2193  data: 0.0003  max mem: 1091
[2024-01-21 11:19:59 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:01  flops: 3.3726 (3.3726)  loss: 0.9341 (0.9239)  acc1: 78.7162 (79.1954)  acc5: 94.2177 (94.6929)  time: 0.1859  data: 0.0108  max mem: 1091
[2024-01-21 11:20:00 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9030 (0.9151)  acc1: 78.8591 (79.3548)  acc5: 94.5946 (94.8087)  time: 0.2228  data: 0.0003  max mem: 1091
[2024-01-21 11:20:00 root] (utils.py 307): INFO Test: Total time: 0:00:42 (0.2532 s / it)
[2024-01-21 11:20:00 root] (engine.py 118): INFO * Acc@1 79.355 Acc@5 94.809 loss 0.915 flops 3.373
[2024-01-21 11:20:00 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 79.4%
[2024-01-21 11:20:00 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 3.3726 (3.3726)  loss: 0.9305 (0.9218)  acc1: 79.0541 (79.2306)  acc5: 94.2568 (94.7007)  time: 0.1829  data: 0.0084  max mem: 1091
[2024-01-21 11:20:00 root] (utils.py 307): INFO Test: Total time: 0:00:38 (0.2292 s / it)
[2024-01-21 11:20:00 root] (engine.py 118): INFO * Acc@1 79.231 Acc@5 94.701 loss 0.922 flops 3.373
[2024-01-21 11:20:00 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 79.2%
[2024-01-21 11:20:17 root] (main_pitome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:20:19 root] (main_tome.py 216): INFO Namespace(batch_size=300, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 11:20:20 root] (main_pitome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 11:20:22 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 11:20:23 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 11:20:25 root] (main_pitome.py 373): INFO number of params: 86567656
[2024-01-21 11:20:25 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 11:20:27 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 11:20:31 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:17:54  flops: 12.9405 (12.9405)  loss: 0.9078 (0.9078)  acc1: 80.4795 (80.4795)  acc5: 94.1781 (94.1781)  time: 6.4362  data: 1.5919  max mem: 2127
[2024-01-21 11:20:34 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:02:20  flops: 12.9405 (12.9405)  loss: 0.8264 (0.8352)  acc1: 82.6087 (82.1241)  acc5: 95.1890 (95.2454)  time: 0.8936  data: 0.1448  max mem: 2169
[2024-01-21 11:20:35 root] (utils.py 293): INFO Test:  [  0/167]  eta: 0:20:55  flops: 12.9405 (12.9405)  loss: 0.9017 (0.9017)  acc1: 80.8219 (80.8219)  acc5: 92.4658 (92.4658)  time: 7.5179  data: 0.5740  max mem: 2127
[2024-01-21 11:20:40 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:01:45  flops: 12.9405 (12.9405)  loss: 0.8613 (0.8535)  acc1: 81.4815 (81.6019)  acc5: 95.1890 (95.2104)  time: 0.4307  data: 0.0001  max mem: 2169
[2024-01-21 11:20:41 root] (utils.py 293): INFO Test:  [ 10/167]  eta: 0:03:08  flops: 12.9405 (12.9405)  loss: 0.8254 (0.8125)  acc1: 82.0946 (82.0932)  acc5: 94.8980 (94.9676)  time: 1.2004  data: 0.0524  max mem: 2169
[2024-01-21 11:20:45 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:30  flops: 12.9405 (12.9405)  loss: 0.8613 (0.8500)  acc1: 80.4795 (81.6438)  acc5: 95.2862 (95.4192)  time: 0.5268  data: 0.0002  max mem: 2169
[2024-01-21 11:20:45 root] (utils.py 293): INFO Test:  [ 20/167]  eta: 0:02:04  flops: 12.9405 (12.9405)  loss: 0.8307 (0.8394)  acc1: 81.7568 (81.7314)  acc5: 94.8980 (95.0647)  time: 0.5132  data: 0.0002  max mem: 2169
[2024-01-21 11:20:50 root] (utils.py 293): INFO Test:  [ 30/167]  eta: 0:01:39  flops: 12.9405 (12.9405)  loss: 0.8307 (0.8346)  acc1: 81.0811 (81.8301)  acc5: 95.2542 (95.2110)  time: 0.4624  data: 0.0002  max mem: 2169
[2024-01-21 11:20:50 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:19  flops: 12.9405 (12.9405)  loss: 0.8487 (0.8555)  acc1: 82.0946 (81.5925)  acc5: 95.5479 (95.4147)  time: 0.5327  data: 0.0002  max mem: 2169
[2024-01-21 11:20:55 root] (utils.py 293): INFO Test:  [ 40/167]  eta: 0:01:23  flops: 12.9405 (12.9405)  loss: 0.8526 (0.8456)  acc1: 81.0811 (81.6669)  acc5: 94.8980 (95.1084)  time: 0.4661  data: 0.0002  max mem: 2169
[2024-01-21 11:20:55 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:10  flops: 12.9405 (12.9405)  loss: 0.8446 (0.8471)  acc1: 81.7568 (81.6742)  acc5: 95.6229 (95.6015)  time: 0.5234  data: 0.0002  max mem: 2169
[2024-01-21 11:20:59 root] (utils.py 293): INFO Test:  [ 50/167]  eta: 0:01:12  flops: 12.9405 (12.9405)  loss: 0.8565 (0.8387)  acc1: 80.2013 (81.6409)  acc5: 95.1890 (95.2954)  time: 0.4548  data: 0.0002  max mem: 2169
[2024-01-21 11:21:01 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:03  flops: 12.9405 (12.9405)  loss: 0.8621 (0.8537)  acc1: 81.0811 (81.5332)  acc5: 95.6229 (95.5684)  time: 0.5125  data: 0.0002  max mem: 2169
[2024-01-21 11:21:03 root] (utils.py 293): INFO Test:  [ 60/167]  eta: 0:01:03  flops: 12.9405 (12.9405)  loss: 0.8625 (0.8461)  acc1: 80.3448 (81.4442)  acc5: 95.1890 (95.2121)  time: 0.4432  data: 0.0002  max mem: 2169
[2024-01-21 11:21:06 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:56  flops: 12.9405 (12.9405)  loss: 0.8684 (0.8559)  acc1: 81.2081 (81.5578)  acc5: 95.5326 (95.5245)  time: 0.5143  data: 0.0002  max mem: 2169
[2024-01-21 11:21:08 root] (utils.py 293): INFO Test:  [ 70/167]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8666 (0.8470)  acc1: 80.7432 (81.4335)  acc5: 94.8276 (95.1420)  time: 0.4437  data: 0.0002  max mem: 2169
[2024-01-21 11:21:11 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:49  flops: 12.9405 (12.9405)  loss: 0.8551 (0.8594)  acc1: 81.5700 (81.4692)  acc5: 95.2862 (95.5035)  time: 0.5163  data: 0.0002  max mem: 2169
[2024-01-21 11:21:12 root] (utils.py 293): INFO Test:  [ 80/167]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8522 (0.8502)  acc1: 80.3390 (81.2974)  acc5: 95.2542 (95.1766)  time: 0.4460  data: 0.0002  max mem: 2169
[2024-01-21 11:21:16 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:43  flops: 12.9405 (12.9405)  loss: 0.8649 (0.8664)  acc1: 81.4189 (81.3607)  acc5: 95.2703 (95.4679)  time: 0.5256  data: 0.0002  max mem: 2170
[2024-01-21 11:21:17 root] (utils.py 293): INFO Test:  [ 90/167]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8426 (0.8569)  acc1: 80.0000 (81.1854)  acc5: 95.2381 (95.1210)  time: 0.4534  data: 0.0002  max mem: 2170
[2024-01-21 11:21:21 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:37  flops: 12.9405 (12.9405)  loss: 0.8706 (0.8677)  acc1: 80.6122 (81.3176)  acc5: 94.8805 (95.4310)  time: 0.5259  data: 0.0002  max mem: 2170
[2024-01-21 11:21:21 root] (utils.py 293): INFO Test:  [100/167]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8426 (0.8584)  acc1: 80.6780 (81.1664)  acc5: 94.6488 (95.1018)  time: 0.4534  data: 0.0002  max mem: 2170
[2024-01-21 11:21:26 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.8695 (0.8601)  acc1: 80.6780 (81.1787)  acc5: 94.5763 (95.0791)  time: 0.4450  data: 0.0002  max mem: 2170
[2024-01-21 11:21:27 root] (utils.py 293): INFO Test:  [110/167]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.8784 (0.8705)  acc1: 80.6122 (81.2888)  acc5: 94.6309 (95.3727)  time: 0.5155  data: 0.0002  max mem: 2170
[2024-01-21 11:21:30 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:24  flops: 12.9405 (12.9405)  loss: 0.8574 (0.8572)  acc1: 81.2287 (81.2274)  acc5: 94.9153 (95.1146)  time: 0.4429  data: 0.0002  max mem: 2170
[2024-01-21 11:21:32 root] (utils.py 293): INFO Test:  [120/167]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8684 (0.8677)  acc1: 81.4433 (81.3677)  acc5: 94.9664 (95.4093)  time: 0.5145  data: 0.0002  max mem: 2170
[2024-01-21 11:21:35 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8369 (0.8556)  acc1: 81.0345 (81.2262)  acc5: 95.2542 (95.1465)  time: 0.4448  data: 0.0002  max mem: 2170
[2024-01-21 11:21:37 root] (utils.py 293): INFO Test:  [130/167]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.8546 (0.8666)  acc1: 81.4433 (81.3609)  acc5: 95.5932 (95.4238)  time: 0.5165  data: 0.0002  max mem: 2170
[2024-01-21 11:21:39 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8519 (0.8538)  acc1: 80.4714 (81.2292)  acc5: 95.2703 (95.1659)  time: 0.4461  data: 0.0002  max mem: 2170
[2024-01-21 11:21:42 root] (utils.py 293): INFO Test:  [140/167]  eta: 0:00:14  flops: 12.9405 (12.9405)  loss: 0.8576 (0.8645)  acc1: 81.0169 (81.3544)  acc5: 95.6081 (95.4548)  time: 0.5187  data: 0.0002  max mem: 2170
[2024-01-21 11:21:44 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:08  flops: 12.9405 (12.9405)  loss: 0.8519 (0.8558)  acc1: 81.0169 (81.2080)  acc5: 95.2381 (95.1429)  time: 0.4440  data: 0.0002  max mem: 2170
[2024-01-21 11:21:47 root] (utils.py 293): INFO Test:  [150/167]  eta: 0:00:09  flops: 12.9405 (12.9405)  loss: 0.8586 (0.8661)  acc1: 81.2925 (81.3406)  acc5: 95.5782 (95.4240)  time: 0.5164  data: 0.0002  max mem: 2170
[2024-01-21 11:21:48 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 12.9405 (12.9405)  loss: 0.8797 (0.8577)  acc1: 80.7432 (81.1753)  acc5: 94.5946 (95.1167)  time: 0.4462  data: 0.0002  max mem: 2170
[2024-01-21 11:21:51 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8523 (0.8560)  acc1: 81.3559 (81.2142)  acc5: 94.9153 (95.1040)  time: 0.4496  data: 0.0002  max mem: 2170
[2024-01-21 11:21:51 root] (utils.py 307): INFO Test: Total time: 0:01:23 (0.4995 s / it)
[2024-01-21 11:21:51 root] (engine.py 118): INFO * Acc@1 81.214 Acc@5 95.104 loss 0.856 flops 12.940
[2024-01-21 11:21:51 root] (main_tome.py 378): INFO Accuracy of the network on the 50000 test images: 81.2%
[2024-01-21 11:21:52 root] (utils.py 293): INFO Test:  [160/167]  eta: 0:00:03  flops: 12.9405 (12.9405)  loss: 0.8756 (0.8681)  acc1: 80.8725 (81.3018)  acc5: 95.1557 (95.4056)  time: 0.4719  data: 0.0002  max mem: 2170
[2024-01-21 11:21:53 root] (utils.py 293): INFO Test:  [166/167]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8718 (0.8664)  acc1: 81.0169 (81.3324)  acc5: 95.2862 (95.3871)  time: 0.3887  data: 0.0002  max mem: 2170
[2024-01-21 11:21:53 root] (utils.py 307): INFO Test: Total time: 0:01:28 (0.5289 s / it)
[2024-01-21 11:21:53 root] (engine.py 118): INFO * Acc@1 81.332 Acc@5 95.387 loss 0.866 flops 12.940
[2024-01-21 11:21:53 root] (main_pitome.py 381): INFO Accuracy of the network on the 50000 test images: 81.3%
[2024-01-21 14:05:51 root] (main_tome.py 216): INFO Namespace(batch_size=256, epochs=3, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:05:56 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:05:58 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:05:59 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 14:15:13 root] (main_tome.py 216): INFO Namespace(batch_size=256, epochs=3, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:15:17 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:15:20 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:15:21 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 14:15:21 root] (main_tome.py 416): INFO Start training for 3 epochs
[2024-01-21 14:16:41 root] (main_tome.py 216): INFO Namespace(batch_size=256, epochs=3, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:16:46 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:16:48 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:16:50 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 14:16:50 root] (main_tome.py 416): INFO Start training for 3 epochs
[2024-01-21 14:17:53 root] (main_tome.py 216): INFO Namespace(batch_size=100, epochs=3, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:17:58 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:18:01 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:18:01 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 14:18:01 root] (main_tome.py 416): INFO Start training for 3 epochs
[2024-01-21 14:18:32 root] (main_tome.py 216): INFO Namespace(batch_size=100, epochs=3, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:18:36 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:18:39 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:18:40 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 14:18:40 root] (main_tome.py 416): INFO Start training for 3 epochs
[2024-01-21 14:19:04 root] (main_tome.py 216): INFO Namespace(batch_size=103, epochs=3, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:19:09 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:19:12 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:19:13 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 14:19:13 root] (main_tome.py 416): INFO Start training for 3 epochs
[2024-01-21 14:19:35 root] (main_tome.py 216): INFO Namespace(batch_size=259, epochs=3, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:19:40 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:19:43 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:19:47 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 14:19:47 root] (main_tome.py 416): INFO Start training for 3 epochs
[2024-01-21 14:22:09 root] (main_tome.py 216): INFO Namespace(batch_size=259, epochs=2, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:22:14 root] (main_tome.py 286): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:22:18 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:22:22 root] (main_tome.py 370): INFO number of params: 86567656
[2024-01-21 14:22:22 root] (main_tome.py 416): INFO Start training for 2 epochs
[2024-01-21 14:23:48 root] (main_tome.py 213): INFO Namespace(batch_size=100, epochs=2, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:23:53 root] (main_tome.py 283): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:23:54 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:23:55 root] (main_tome.py 367): INFO number of params: 86567656
[2024-01-21 14:23:55 root] (main_tome.py 413): INFO Start training for 2 epochs
[2024-01-21 14:35:29 root] (main_tome.py 213): INFO Namespace(batch_size=100, epochs=2, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:35:34 root] (main_tome.py 283): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:35:35 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:35:36 root] (main_tome.py 367): INFO number of params: 86567656
[2024-01-21 14:35:36 root] (main_tome.py 413): INFO Start training for 2 epochs
[2024-01-21 14:40:00 root] (main_tome.py 213): INFO Namespace(batch_size=100, epochs=2, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:40:04 root] (main_tome.py 283): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:40:06 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:40:07 root] (main_tome.py 367): INFO number of params: 86567656
[2024-01-21 14:40:07 root] (main_tome.py 413): INFO Start training for 2 epochs
[2024-01-21 14:43:13 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=2, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 14:44:03 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 14:45:27 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 14:47:55 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 14:48:48 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 14:52:55 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 14:53:55 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 14:55:12 root] (main_tome.py 301): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:55:14 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:55:14 root] (main_tome.py 385): INFO number of params: 86567656
[2024-01-21 14:55:17 root] (utils.py 293): INFO Test:  [  0/492]  eta: 0:17:36  flops: 12.9405 (12.9405)  loss: 0.8542 (0.8542)  acc1: 83.0000 (83.0000)  acc5: 94.0000 (94.0000)  time: 2.1483  data: 0.2402  max mem: 964
[2024-01-21 14:55:17 root] (utils.py 293): INFO Test:  [ 10/492]  eta: 0:02:08  flops: 12.9405 (12.9405)  loss: 0.8860 (0.8653)  acc1: 82.0000 (81.4545)  acc5: 94.0000 (93.9091)  time: 0.2676  data: 0.0219  max mem: 964
[2024-01-21 14:55:18 root] (utils.py 293): INFO Test:  [ 20/492]  eta: 0:01:23  flops: 12.9405 (12.9405)  loss: 0.7820 (0.8201)  acc1: 83.0000 (81.9524)  acc5: 95.0000 (94.8095)  time: 0.0792  data: 0.0001  max mem: 964
[2024-01-21 14:55:19 root] (utils.py 293): INFO Test:  [ 30/492]  eta: 0:01:07  flops: 12.9405 (12.9405)  loss: 0.7201 (0.8124)  acc1: 83.0000 (82.0323)  acc5: 95.0000 (94.9355)  time: 0.0790  data: 0.0001  max mem: 964
[2024-01-21 14:55:20 root] (utils.py 293): INFO Test:  [ 40/492]  eta: 0:00:58  flops: 12.9405 (12.9405)  loss: 0.7751 (0.8128)  acc1: 83.0000 (82.1220)  acc5: 95.0000 (95.0000)  time: 0.0792  data: 0.0001  max mem: 964
[2024-01-21 14:55:21 root] (utils.py 293): INFO Test:  [ 50/492]  eta: 0:00:52  flops: 12.9405 (12.9405)  loss: 0.8820 (0.8330)  acc1: 81.0000 (81.7255)  acc5: 94.0000 (94.9804)  time: 0.0794  data: 0.0001  max mem: 964
[2024-01-21 14:55:21 root] (utils.py 293): INFO Test:  [ 60/492]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8814 (0.8349)  acc1: 81.0000 (81.8197)  acc5: 95.0000 (95.0656)  time: 0.0795  data: 0.0001  max mem: 964
[2024-01-21 14:55:22 root] (utils.py 293): INFO Test:  [ 70/492]  eta: 0:00:45  flops: 12.9405 (12.9405)  loss: 0.7908 (0.8343)  acc1: 83.0000 (81.9577)  acc5: 95.0000 (95.0704)  time: 0.0796  data: 0.0001  max mem: 964
[2024-01-21 14:55:23 root] (utils.py 293): INFO Test:  [ 80/492]  eta: 0:00:43  flops: 12.9405 (12.9405)  loss: 0.8315 (0.8389)  acc1: 80.0000 (81.7284)  acc5: 95.0000 (95.1358)  time: 0.0796  data: 0.0001  max mem: 964
[2024-01-21 14:55:24 root] (utils.py 293): INFO Test:  [ 90/492]  eta: 0:00:41  flops: 12.9405 (12.9405)  loss: 0.8251 (0.8364)  acc1: 80.0000 (81.7692)  acc5: 96.0000 (95.1758)  time: 0.0795  data: 0.0001  max mem: 964
[2024-01-21 14:55:24 root] (utils.py 293): INFO Test:  [100/492]  eta: 0:00:39  flops: 12.9405 (12.9405)  loss: 0.8251 (0.8405)  acc1: 80.0000 (81.7327)  acc5: 95.0000 (95.1584)  time: 0.0794  data: 0.0001  max mem: 964
[2024-01-21 14:55:25 root] (utils.py 293): INFO Test:  [110/492]  eta: 0:00:37  flops: 12.9405 (12.9405)  loss: 0.8116 (0.8363)  acc1: 83.0000 (81.9189)  acc5: 95.0000 (95.1532)  time: 0.0794  data: 0.0001  max mem: 964
[2024-01-21 14:55:26 root] (utils.py 293): INFO Test:  [120/492]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8174 (0.8458)  acc1: 82.0000 (81.6529)  acc5: 95.0000 (95.1074)  time: 0.0796  data: 0.0001  max mem: 964
[2024-01-21 14:55:27 root] (utils.py 293): INFO Test:  [130/492]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8562 (0.8433)  acc1: 81.0000 (81.6489)  acc5: 96.0000 (95.1832)  time: 0.0797  data: 0.0001  max mem: 964
[2024-01-21 14:55:28 root] (utils.py 293): INFO Test:  [140/492]  eta: 0:00:33  flops: 12.9405 (12.9405)  loss: 0.8329 (0.8403)  acc1: 82.0000 (81.6241)  acc5: 96.0000 (95.2624)  time: 0.0796  data: 0.0001  max mem: 964
[2024-01-21 14:55:28 root] (utils.py 293): INFO Test:  [150/492]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.7984 (0.8382)  acc1: 82.0000 (81.6225)  acc5: 97.0000 (95.3179)  time: 0.0797  data: 0.0001  max mem: 964
[2024-01-21 14:55:29 root] (utils.py 293): INFO Test:  [160/492]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8208 (0.8419)  acc1: 80.0000 (81.5528)  acc5: 96.0000 (95.3043)  time: 0.0797  data: 0.0001  max mem: 964
[2024-01-21 14:55:30 root] (utils.py 293): INFO Test:  [170/492]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.9154 (0.8429)  acc1: 80.0000 (81.5439)  acc5: 95.0000 (95.2632)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:55:31 root] (utils.py 293): INFO Test:  [180/492]  eta: 0:00:28  flops: 12.9405 (12.9405)  loss: 0.9154 (0.8464)  acc1: 80.0000 (81.4475)  acc5: 95.0000 (95.1934)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:55:32 root] (utils.py 293): INFO Test:  [190/492]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8582 (0.8457)  acc1: 80.0000 (81.4764)  acc5: 94.0000 (95.1832)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:55:32 root] (utils.py 293): INFO Test:  [200/492]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8363 (0.8460)  acc1: 81.0000 (81.4975)  acc5: 95.0000 (95.1493)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:55:33 root] (utils.py 293): INFO Test:  [210/492]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8293 (0.8458)  acc1: 81.0000 (81.4739)  acc5: 95.0000 (95.1469)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:55:34 root] (utils.py 293): INFO Test:  [220/492]  eta: 0:00:24  flops: 12.9405 (12.9405)  loss: 0.8131 (0.8459)  acc1: 81.0000 (81.4434)  acc5: 96.0000 (95.1810)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:55:35 root] (utils.py 293): INFO Test:  [230/492]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.8964 (0.8494)  acc1: 80.0000 (81.3463)  acc5: 95.0000 (95.1732)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:55:36 root] (utils.py 293): INFO Test:  [240/492]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8964 (0.8511)  acc1: 80.0000 (81.3320)  acc5: 95.0000 (95.1369)  time: 0.0797  data: 0.0001  max mem: 964
[2024-01-21 14:55:36 root] (utils.py 293): INFO Test:  [250/492]  eta: 0:00:21  flops: 12.9405 (12.9405)  loss: 0.9372 (0.8558)  acc1: 80.0000 (81.2390)  acc5: 95.0000 (95.0916)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:55:37 root] (utils.py 293): INFO Test:  [260/492]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.9876 (0.8577)  acc1: 79.0000 (81.1839)  acc5: 95.0000 (95.0805)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:55:38 root] (utils.py 293): INFO Test:  [270/492]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8563 (0.8568)  acc1: 81.0000 (81.2214)  acc5: 95.0000 (95.1033)  time: 0.0800  data: 0.0001  max mem: 964
[2024-01-21 14:55:39 root] (utils.py 293): INFO Test:  [280/492]  eta: 0:00:18  flops: 12.9405 (12.9405)  loss: 0.8563 (0.8587)  acc1: 81.0000 (81.1851)  acc5: 94.0000 (95.0712)  time: 0.0802  data: 0.0001  max mem: 964
[2024-01-21 14:55:40 root] (utils.py 293): INFO Test:  [290/492]  eta: 0:00:17  flops: 12.9405 (12.9405)  loss: 0.8839 (0.8595)  acc1: 80.0000 (81.1478)  acc5: 94.0000 (95.0928)  time: 0.0802  data: 0.0001  max mem: 964
[2024-01-21 14:55:40 root] (utils.py 293): INFO Test:  [300/492]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8733 (0.8589)  acc1: 81.0000 (81.1761)  acc5: 95.0000 (95.0864)  time: 0.0801  data: 0.0001  max mem: 964
[2024-01-21 14:55:41 root] (utils.py 293): INFO Test:  [310/492]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8261 (0.8587)  acc1: 82.0000 (81.2283)  acc5: 94.0000 (95.0740)  time: 0.0802  data: 0.0001  max mem: 964
[2024-01-21 14:55:42 root] (utils.py 293): INFO Test:  [320/492]  eta: 0:00:14  flops: 12.9405 (12.9405)  loss: 0.8261 (0.8599)  acc1: 82.0000 (81.1963)  acc5: 95.0000 (95.0654)  time: 0.0803  data: 0.0001  max mem: 964
[2024-01-21 14:55:43 root] (utils.py 293): INFO Test:  [330/492]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8906 (0.8606)  acc1: 79.0000 (81.1782)  acc5: 95.0000 (95.0665)  time: 0.0805  data: 0.0001  max mem: 964
[2024-01-21 14:55:44 root] (utils.py 293): INFO Test:  [340/492]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8329 (0.8579)  acc1: 79.0000 (81.1935)  acc5: 96.0000 (95.1114)  time: 0.0803  data: 0.0001  max mem: 964
[2024-01-21 14:55:44 root] (utils.py 293): INFO Test:  [350/492]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.7987 (0.8576)  acc1: 82.0000 (81.2336)  acc5: 96.0000 (95.1083)  time: 0.0802  data: 0.0001  max mem: 964
[2024-01-21 14:55:45 root] (utils.py 293): INFO Test:  [360/492]  eta: 0:00:11  flops: 12.9405 (12.9405)  loss: 0.8417 (0.8560)  acc1: 82.0000 (81.2742)  acc5: 96.0000 (95.1247)  time: 0.0802  data: 0.0001  max mem: 964
[2024-01-21 14:55:46 root] (utils.py 293): INFO Test:  [370/492]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8504 (0.8554)  acc1: 82.0000 (81.2776)  acc5: 96.0000 (95.1509)  time: 0.0802  data: 0.0001  max mem: 964
[2024-01-21 14:55:47 root] (utils.py 293): INFO Test:  [380/492]  eta: 0:00:09  flops: 12.9405 (12.9405)  loss: 0.8648 (0.8562)  acc1: 82.0000 (81.2362)  acc5: 95.0000 (95.1339)  time: 0.0803  data: 0.0001  max mem: 964
[2024-01-21 14:55:48 root] (utils.py 293): INFO Test:  [390/492]  eta: 0:00:08  flops: 12.9405 (12.9405)  loss: 0.8399 (0.8551)  acc1: 82.0000 (81.2327)  acc5: 96.0000 (95.1586)  time: 0.0803  data: 0.0001  max mem: 964
[2024-01-21 14:55:49 root] (utils.py 293): INFO Test:  [400/492]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8399 (0.8551)  acc1: 81.0000 (81.2319)  acc5: 96.0000 (95.1521)  time: 0.0803  data: 0.0001  max mem: 964
[2024-01-21 14:55:49 root] (utils.py 293): INFO Test:  [410/492]  eta: 0:00:06  flops: 12.9405 (12.9405)  loss: 0.8506 (0.8554)  acc1: 79.0000 (81.2044)  acc5: 94.0000 (95.1533)  time: 0.0805  data: 0.0001  max mem: 964
[2024-01-21 14:55:50 root] (utils.py 293): INFO Test:  [420/492]  eta: 0:00:06  flops: 12.9405 (12.9405)  loss: 0.8128 (0.8549)  acc1: 81.0000 (81.2257)  acc5: 95.0000 (95.1591)  time: 0.0802  data: 0.0001  max mem: 964
[2024-01-21 14:55:51 root] (utils.py 293): INFO Test:  [430/492]  eta: 0:00:05  flops: 12.9405 (12.9405)  loss: 0.9055 (0.8552)  acc1: 82.0000 (81.2251)  acc5: 95.0000 (95.1531)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:55:52 root] (utils.py 293): INFO Test:  [440/492]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.9022 (0.8556)  acc1: 82.0000 (81.2268)  acc5: 95.0000 (95.1429)  time: 0.0797  data: 0.0001  max mem: 964
[2024-01-21 14:55:53 root] (utils.py 293): INFO Test:  [450/492]  eta: 0:00:03  flops: 12.9405 (12.9405)  loss: 0.8330 (0.8557)  acc1: 81.0000 (81.2217)  acc5: 96.0000 (95.1552)  time: 0.0797  data: 0.0001  max mem: 964
[2024-01-21 14:55:53 root] (utils.py 293): INFO Test:  [460/492]  eta: 0:00:02  flops: 12.9405 (12.9405)  loss: 0.8548 (0.8564)  acc1: 81.0000 (81.2169)  acc5: 95.0000 (95.1410)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:55:54 root] (utils.py 293): INFO Test:  [470/492]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8528 (0.8570)  acc1: 81.0000 (81.2059)  acc5: 94.0000 (95.1359)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:55:55 root] (utils.py 293): INFO Test:  [480/492]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8468 (0.8580)  acc1: 80.0000 (81.1684)  acc5: 95.0000 (95.1268)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:55:56 root] (utils.py 293): INFO Test:  [490/492]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8140 (0.8565)  acc1: 82.0000 (81.2301)  acc5: 95.0000 (95.1141)  time: 0.0800  data: 0.0002  max mem: 964
[2024-01-21 14:55:56 root] (utils.py 293): INFO Test:  [491/492]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8140 (0.8558)  acc1: 82.0000 (81.2305)  acc5: 95.0000 (95.1142)  time: 0.0848  data: 0.0001  max mem: 964
[2024-01-21 14:55:56 root] (utils.py 307): INFO Test: Total time: 0:00:41 (0.0843 s / it)
[2024-01-21 14:55:56 root] (engine.py 120): INFO * Acc@1 81.231 Acc@5 95.114 loss 0.856 flops 12.940
[2024-01-21 14:55:56 root] (main_tome.py 393): INFO Accuracy of the network on the 49101 test images: 81.2%
[2024-01-21 14:57:39 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 14:57:43 root] (main_tome.py 301): INFO Creating model: deit_base_patch16_224
[2024-01-21 14:57:44 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 14:57:45 root] (main_tome.py 385): INFO number of params: 86567656
[2024-01-21 14:57:47 root] (utils.py 293): INFO Test:  [  0/492]  eta: 0:17:00  flops: 12.9405 (12.9405)  loss: 0.8543 (0.8543)  acc1: 83.0000 (83.0000)  acc5: 94.0000 (94.0000)  time: 2.0751  data: 0.3531  max mem: 964
[2024-01-21 14:57:48 root] (utils.py 293): INFO Test:  [ 10/492]  eta: 0:02:05  flops: 12.9405 (12.9405)  loss: 0.8831 (0.8661)  acc1: 82.0000 (81.4545)  acc5: 94.0000 (93.9091)  time: 0.2613  data: 0.0322  max mem: 964
[2024-01-21 14:57:49 root] (utils.py 293): INFO Test:  [ 20/492]  eta: 0:01:22  flops: 12.9405 (12.9405)  loss: 0.7824 (0.8205)  acc1: 83.0000 (81.9524)  acc5: 95.0000 (94.8095)  time: 0.0796  data: 0.0001  max mem: 964
[2024-01-21 14:57:49 root] (utils.py 293): INFO Test:  [ 30/492]  eta: 0:01:06  flops: 12.9405 (12.9405)  loss: 0.7138 (0.8123)  acc1: 83.0000 (82.0645)  acc5: 95.0000 (94.9355)  time: 0.0794  data: 0.0001  max mem: 964
[2024-01-21 14:57:50 root] (utils.py 293): INFO Test:  [ 40/492]  eta: 0:00:57  flops: 12.9405 (12.9405)  loss: 0.7751 (0.8128)  acc1: 83.0000 (82.1463)  acc5: 95.0000 (95.0000)  time: 0.0794  data: 0.0001  max mem: 964
[2024-01-21 14:57:51 root] (utils.py 293): INFO Test:  [ 50/492]  eta: 0:00:52  flops: 12.9405 (12.9405)  loss: 0.8821 (0.8329)  acc1: 81.0000 (81.7255)  acc5: 94.0000 (94.9804)  time: 0.0794  data: 0.0001  max mem: 964
[2024-01-21 14:57:52 root] (utils.py 293): INFO Test:  [ 60/492]  eta: 0:00:48  flops: 12.9405 (12.9405)  loss: 0.8798 (0.8350)  acc1: 81.0000 (81.8197)  acc5: 95.0000 (95.0656)  time: 0.0794  data: 0.0001  max mem: 964
[2024-01-21 14:57:53 root] (utils.py 293): INFO Test:  [ 70/492]  eta: 0:00:45  flops: 12.9405 (12.9405)  loss: 0.7908 (0.8345)  acc1: 83.0000 (81.9577)  acc5: 95.0000 (95.0704)  time: 0.0793  data: 0.0001  max mem: 964
[2024-01-21 14:57:53 root] (utils.py 293): INFO Test:  [ 80/492]  eta: 0:00:42  flops: 12.9405 (12.9405)  loss: 0.8313 (0.8390)  acc1: 81.0000 (81.7407)  acc5: 95.0000 (95.1358)  time: 0.0793  data: 0.0001  max mem: 964
[2024-01-21 14:57:54 root] (utils.py 293): INFO Test:  [ 90/492]  eta: 0:00:40  flops: 12.9405 (12.9405)  loss: 0.8249 (0.8364)  acc1: 80.0000 (81.7802)  acc5: 96.0000 (95.1758)  time: 0.0795  data: 0.0001  max mem: 964
[2024-01-21 14:57:55 root] (utils.py 293): INFO Test:  [100/492]  eta: 0:00:38  flops: 12.9405 (12.9405)  loss: 0.8249 (0.8406)  acc1: 80.0000 (81.7426)  acc5: 95.0000 (95.1584)  time: 0.0797  data: 0.0001  max mem: 964
[2024-01-21 14:57:56 root] (utils.py 293): INFO Test:  [110/492]  eta: 0:00:37  flops: 12.9405 (12.9405)  loss: 0.8122 (0.8364)  acc1: 83.0000 (81.9279)  acc5: 95.0000 (95.1532)  time: 0.0796  data: 0.0001  max mem: 964
[2024-01-21 14:57:56 root] (utils.py 293): INFO Test:  [120/492]  eta: 0:00:35  flops: 12.9405 (12.9405)  loss: 0.8169 (0.8459)  acc1: 82.0000 (81.6529)  acc5: 95.0000 (95.1074)  time: 0.0795  data: 0.0001  max mem: 964
[2024-01-21 14:57:57 root] (utils.py 293): INFO Test:  [130/492]  eta: 0:00:34  flops: 12.9405 (12.9405)  loss: 0.8558 (0.8434)  acc1: 81.0000 (81.6489)  acc5: 96.0000 (95.1832)  time: 0.0797  data: 0.0001  max mem: 964
[2024-01-21 14:57:58 root] (utils.py 293): INFO Test:  [140/492]  eta: 0:00:32  flops: 12.9405 (12.9405)  loss: 0.8330 (0.8404)  acc1: 82.0000 (81.6312)  acc5: 96.0000 (95.2624)  time: 0.0797  data: 0.0001  max mem: 964
[2024-01-21 14:57:59 root] (utils.py 293): INFO Test:  [150/492]  eta: 0:00:31  flops: 12.9405 (12.9405)  loss: 0.7985 (0.8384)  acc1: 82.0000 (81.6291)  acc5: 97.0000 (95.3179)  time: 0.0797  data: 0.0001  max mem: 964
[2024-01-21 14:58:00 root] (utils.py 293): INFO Test:  [160/492]  eta: 0:00:30  flops: 12.9405 (12.9405)  loss: 0.8211 (0.8420)  acc1: 80.0000 (81.5590)  acc5: 96.0000 (95.3043)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:58:00 root] (utils.py 293): INFO Test:  [170/492]  eta: 0:00:29  flops: 12.9405 (12.9405)  loss: 0.9154 (0.8430)  acc1: 80.0000 (81.5497)  acc5: 95.0000 (95.2632)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:58:01 root] (utils.py 293): INFO Test:  [180/492]  eta: 0:00:28  flops: 12.9405 (12.9405)  loss: 0.9154 (0.8465)  acc1: 80.0000 (81.4530)  acc5: 95.0000 (95.1878)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:58:02 root] (utils.py 293): INFO Test:  [190/492]  eta: 0:00:27  flops: 12.9405 (12.9405)  loss: 0.8582 (0.8458)  acc1: 80.0000 (81.4817)  acc5: 94.0000 (95.1780)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:58:03 root] (utils.py 293): INFO Test:  [200/492]  eta: 0:00:26  flops: 12.9405 (12.9405)  loss: 0.8365 (0.8461)  acc1: 81.0000 (81.5025)  acc5: 95.0000 (95.1443)  time: 0.0800  data: 0.0001  max mem: 964
[2024-01-21 14:58:04 root] (utils.py 293): INFO Test:  [210/492]  eta: 0:00:25  flops: 12.9405 (12.9405)  loss: 0.8301 (0.8459)  acc1: 81.0000 (81.4787)  acc5: 95.0000 (95.1422)  time: 0.0800  data: 0.0001  max mem: 964
[2024-01-21 14:58:04 root] (utils.py 293): INFO Test:  [220/492]  eta: 0:00:24  flops: 12.9405 (12.9405)  loss: 0.8142 (0.8460)  acc1: 81.0000 (81.4480)  acc5: 96.0000 (95.1765)  time: 0.0801  data: 0.0001  max mem: 964
[2024-01-21 14:58:05 root] (utils.py 293): INFO Test:  [230/492]  eta: 0:00:23  flops: 12.9405 (12.9405)  loss: 0.8966 (0.8495)  acc1: 80.0000 (81.3506)  acc5: 95.0000 (95.1688)  time: 0.0802  data: 0.0001  max mem: 964
[2024-01-21 14:58:06 root] (utils.py 293): INFO Test:  [240/492]  eta: 0:00:22  flops: 12.9405 (12.9405)  loss: 0.8966 (0.8512)  acc1: 80.0000 (81.3361)  acc5: 95.0000 (95.1328)  time: 0.0801  data: 0.0001  max mem: 964
[2024-01-21 14:58:07 root] (utils.py 293): INFO Test:  [250/492]  eta: 0:00:21  flops: 12.9405 (12.9405)  loss: 0.9373 (0.8558)  acc1: 80.0000 (81.2430)  acc5: 95.0000 (95.0876)  time: 0.0800  data: 0.0001  max mem: 964
[2024-01-21 14:58:08 root] (utils.py 293): INFO Test:  [260/492]  eta: 0:00:20  flops: 12.9405 (12.9405)  loss: 0.9884 (0.8577)  acc1: 79.0000 (81.1916)  acc5: 95.0000 (95.0766)  time: 0.0800  data: 0.0001  max mem: 964
[2024-01-21 14:58:09 root] (utils.py 293): INFO Test:  [270/492]  eta: 0:00:19  flops: 12.9405 (12.9405)  loss: 0.8562 (0.8568)  acc1: 81.0000 (81.2288)  acc5: 95.0000 (95.0996)  time: 0.0801  data: 0.0001  max mem: 964
[2024-01-21 14:58:09 root] (utils.py 293): INFO Test:  [280/492]  eta: 0:00:18  flops: 12.9405 (12.9405)  loss: 0.8562 (0.8586)  acc1: 81.0000 (81.1922)  acc5: 94.0000 (95.0676)  time: 0.0801  data: 0.0001  max mem: 964
[2024-01-21 14:58:10 root] (utils.py 293): INFO Test:  [290/492]  eta: 0:00:17  flops: 12.9405 (12.9405)  loss: 0.8832 (0.8594)  acc1: 80.0000 (81.1546)  acc5: 94.0000 (95.0893)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:58:11 root] (utils.py 293): INFO Test:  [300/492]  eta: 0:00:16  flops: 12.9405 (12.9405)  loss: 0.8733 (0.8589)  acc1: 81.0000 (81.1794)  acc5: 95.0000 (95.0831)  time: 0.0796  data: 0.0001  max mem: 964
[2024-01-21 14:58:12 root] (utils.py 293): INFO Test:  [310/492]  eta: 0:00:15  flops: 12.9405 (12.9405)  loss: 0.8262 (0.8586)  acc1: 82.0000 (81.2283)  acc5: 94.0000 (95.0707)  time: 0.0796  data: 0.0001  max mem: 964
[2024-01-21 14:58:12 root] (utils.py 293): INFO Test:  [320/492]  eta: 0:00:14  flops: 12.9405 (12.9405)  loss: 0.8262 (0.8599)  acc1: 82.0000 (81.1931)  acc5: 95.0000 (95.0623)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:58:13 root] (utils.py 293): INFO Test:  [330/492]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8910 (0.8605)  acc1: 79.0000 (81.1752)  acc5: 95.0000 (95.0634)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:58:14 root] (utils.py 293): INFO Test:  [340/492]  eta: 0:00:13  flops: 12.9405 (12.9405)  loss: 0.8327 (0.8579)  acc1: 79.0000 (81.1906)  acc5: 96.0000 (95.1085)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:58:15 root] (utils.py 293): INFO Test:  [350/492]  eta: 0:00:12  flops: 12.9405 (12.9405)  loss: 0.8022 (0.8576)  acc1: 82.0000 (81.2308)  acc5: 96.0000 (95.1054)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:58:16 root] (utils.py 293): INFO Test:  [360/492]  eta: 0:00:11  flops: 12.9405 (12.9405)  loss: 0.8435 (0.8560)  acc1: 82.0000 (81.2715)  acc5: 96.0000 (95.1219)  time: 0.0801  data: 0.0001  max mem: 964
[2024-01-21 14:58:16 root] (utils.py 293): INFO Test:  [370/492]  eta: 0:00:10  flops: 12.9405 (12.9405)  loss: 0.8497 (0.8554)  acc1: 82.0000 (81.2749)  acc5: 96.0000 (95.1482)  time: 0.0801  data: 0.0001  max mem: 964
[2024-01-21 14:58:17 root] (utils.py 293): INFO Test:  [380/492]  eta: 0:00:09  flops: 12.9405 (12.9405)  loss: 0.8648 (0.8562)  acc1: 82.0000 (81.2336)  acc5: 95.0000 (95.1312)  time: 0.0800  data: 0.0001  max mem: 964
[2024-01-21 14:58:18 root] (utils.py 293): INFO Test:  [390/492]  eta: 0:00:08  flops: 12.9405 (12.9405)  loss: 0.8397 (0.8551)  acc1: 82.0000 (81.2302)  acc5: 96.0000 (95.1535)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:58:19 root] (utils.py 293): INFO Test:  [400/492]  eta: 0:00:07  flops: 12.9405 (12.9405)  loss: 0.8397 (0.8551)  acc1: 81.0000 (81.2294)  acc5: 96.0000 (95.1471)  time: 0.0800  data: 0.0001  max mem: 964
[2024-01-21 14:58:20 root] (utils.py 293): INFO Test:  [410/492]  eta: 0:00:06  flops: 12.9405 (12.9405)  loss: 0.8501 (0.8554)  acc1: 79.0000 (81.2044)  acc5: 94.0000 (95.1484)  time: 0.0800  data: 0.0001  max mem: 964
[2024-01-21 14:58:20 root] (utils.py 293): INFO Test:  [420/492]  eta: 0:00:06  flops: 12.9405 (12.9405)  loss: 0.8050 (0.8548)  acc1: 81.0000 (81.2280)  acc5: 95.0000 (95.1544)  time: 0.0800  data: 0.0001  max mem: 964
[2024-01-21 14:58:21 root] (utils.py 293): INFO Test:  [430/492]  eta: 0:00:05  flops: 12.9405 (12.9405)  loss: 0.9030 (0.8552)  acc1: 82.0000 (81.2274)  acc5: 95.0000 (95.1485)  time: 0.0800  data: 0.0001  max mem: 964
[2024-01-21 14:58:22 root] (utils.py 293): INFO Test:  [440/492]  eta: 0:00:04  flops: 12.9405 (12.9405)  loss: 0.9025 (0.8556)  acc1: 82.0000 (81.2290)  acc5: 95.0000 (95.1383)  time: 0.0801  data: 0.0001  max mem: 964
[2024-01-21 14:58:23 root] (utils.py 293): INFO Test:  [450/492]  eta: 0:00:03  flops: 12.9405 (12.9405)  loss: 0.8331 (0.8557)  acc1: 81.0000 (81.2217)  acc5: 96.0000 (95.1508)  time: 0.0800  data: 0.0001  max mem: 964
[2024-01-21 14:58:24 root] (utils.py 293): INFO Test:  [460/492]  eta: 0:00:02  flops: 12.9405 (12.9405)  loss: 0.8546 (0.8563)  acc1: 81.0000 (81.2169)  acc5: 95.0000 (95.1367)  time: 0.0799  data: 0.0001  max mem: 964
[2024-01-21 14:58:24 root] (utils.py 293): INFO Test:  [470/492]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8521 (0.8570)  acc1: 81.0000 (81.2038)  acc5: 94.0000 (95.1316)  time: 0.0797  data: 0.0001  max mem: 964
[2024-01-21 14:58:25 root] (utils.py 293): INFO Test:  [480/492]  eta: 0:00:01  flops: 12.9405 (12.9405)  loss: 0.8471 (0.8580)  acc1: 80.0000 (81.1663)  acc5: 95.0000 (95.1227)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:58:26 root] (utils.py 293): INFO Test:  [490/492]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8141 (0.8565)  acc1: 82.0000 (81.2281)  acc5: 95.0000 (95.1100)  time: 0.0798  data: 0.0001  max mem: 964
[2024-01-21 14:58:26 root] (utils.py 293): INFO Test:  [491/492]  eta: 0:00:00  flops: 12.9405 (12.9405)  loss: 0.8141 (0.8558)  acc1: 82.0000 (81.2285)  acc5: 95.0000 (95.1101)  time: 0.0777  data: 0.0001  max mem: 964
[2024-01-21 14:58:26 root] (utils.py 307): INFO Test: Total time: 0:00:41 (0.0839 s / it)
[2024-01-21 14:58:26 root] (engine.py 120): INFO * Acc@1 81.228 Acc@5 95.110 loss 0.856 flops 12.940
[2024-01-21 14:58:26 root] (main_tome.py 393): INFO Accuracy of the network on the 49101 test images: 81.2%
[2024-01-21 14:58:57 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 15:48:18 root] (main_tome.py 302): INFO Creating model: deit_base_patch16_224
[2024-01-21 15:48:19 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 15:48:20 root] (main_tome.py 386): INFO number of params: 86567656
[2024-01-21 15:48:22 root] (utils.py 293): INFO Test:  [  0/492]  eta: 0:19:54  flops: 12.9405 (12.9405)  loss: 0.8543 (0.8543)  acc1: 83.0000 (83.0000)  acc5: 94.0000 (94.0000)  time: 2.4274  data: 0.3627  max mem: 964
[2024-01-21 15:48:23 root] (utils.py 293): INFO Test:  [ 10/492]  eta: 0:02:21  flops: 12.9405 (12.9405)  loss: 0.8834 (0.8660)  acc1: 82.0000 (81.4545)  acc5: 94.0000 (93.9091)  time: 0.2929  data: 0.0331  max mem: 964
[2024-01-21 15:48:24 root] (utils.py 293): INFO Test:  [ 20/492]  eta: 0:01:30  flops: 12.9405 (12.9405)  loss: 0.7830 (0.8207)  acc1: 83.0000 (81.9524)  acc5: 95.0000 (94.8095)  time: 0.0792  data: 0.0001  max mem: 964
[2024-01-21 15:48:25 root] (utils.py 293): INFO Test:  [ 30/492]  eta: 0:01:11  flops: 12.9405 (12.9405)  loss: 0.7149 (0.8125)  acc1: 83.0000 (82.0323)  acc5: 95.0000 (94.9355)  time: 0.0791  data: 0.0001  max mem: 964
[2024-01-21 15:48:26 root] (utils.py 293): INFO Test:  [ 40/492]  eta: 0:01:01  flops: 12.9405 (12.9405)  loss: 0.7750 (0.8128)  acc1: 83.0000 (82.1220)  acc5: 95.0000 (95.0000)  time: 0.0792  data: 0.0001  max mem: 964
[2024-01-21 15:48:26 root] (utils.py 293): INFO Test:  [ 50/492]  eta: 0:00:55  flops: 12.9405 (12.9405)  loss: 0.8820 (0.8329)  acc1: 81.0000 (81.7255)  acc5: 94.0000 (94.9804)  time: 0.0793  data: 0.0001  max mem: 964
[2024-01-21 15:48:46 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=2, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 15:48:53 root] (main_tome.py 262): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 15:48:54 root] (main_tome.py 302): INFO Creating model: deit_base_patch16_224
[2024-01-21 15:49:00 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 15:49:01 root] (main_tome.py 386): INFO number of params: 86567656
[2024-01-21 15:49:01 root] (main_tome.py 432): INFO Start training for 2 epochs
[2024-01-21 15:49:25 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=2, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 15:49:40 root] (main_tome.py 262): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 15:49:41 root] (main_tome.py 302): INFO Creating model: deit_base_patch16_224
[2024-01-21 15:49:44 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 15:49:45 root] (main_tome.py 386): INFO number of params: 86567656
[2024-01-21 15:49:45 root] (main_tome.py 432): INFO Start training for 2 epochs
[2024-01-21 15:50:55 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=2, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 15:50:58 root] (main_tome.py 262): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 15:50:59 root] (main_tome.py 302): INFO Creating model: deit_base_patch16_224
[2024-01-21 15:51:02 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 15:51:03 root] (main_tome.py 386): INFO number of params: 86567656
[2024-01-21 15:51:03 root] (main_tome.py 432): INFO Start training for 2 epochs
[2024-01-21 15:51:06 root] (utils.py 293): INFO Epoch: [0]  [   0/3152]  eta: 2:14:08  lr_architecture: 0.010000  loss_cls: 3.3684 (3.3684)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 4.2487 (4.2487)  time: 2.5536  data: 0.0008  max mem: 8707
[2024-01-21 15:51:09 root] (utils.py 293): INFO Epoch: [0]  [  10/3152]  eta: 0:26:55  lr_architecture: 0.010000  loss_cls: 8.2120 (8.3942)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 3.0166 (inf)  time: 0.5141  data: 0.0002  max mem: 9646
[2024-01-21 15:51:12 root] (utils.py 293): INFO Epoch: [0]  [  20/3152]  eta: 0:21:19  lr_architecture: 0.010000  loss_cls: 7.9428 (8.1488)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 1.9231 (inf)  time: 0.3011  data: 0.0001  max mem: 9646
[2024-01-21 15:51:15 root] (utils.py 293): INFO Epoch: [0]  [  30/3152]  eta: 0:19:19  lr_architecture: 0.010000  loss_cls: 7.5520 (7.8941)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 1.0680 (inf)  time: 0.2929  data: 0.0001  max mem: 9646
[2024-01-21 15:51:35 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=2, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 15:51:39 root] (main_tome.py 262): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 15:51:40 root] (main_tome.py 302): INFO Creating model: deit_base_patch16_224
[2024-01-21 15:51:43 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 15:51:44 root] (main_tome.py 386): INFO number of params: 86567656
[2024-01-21 15:51:44 root] (main_tome.py 432): INFO Start training for 2 epochs
[2024-01-21 15:51:46 root] (utils.py 293): INFO Epoch: [0]  [   0/3152]  eta: 2:16:48  lr_architecture: 0.010000  loss_cls: 3.3685 (3.3685)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 4.2495 (4.2495)  time: 2.6041  data: 0.0009  max mem: 8707
[2024-01-21 15:51:49 root] (utils.py 293): INFO Epoch: [0]  [  10/3152]  eta: 0:26:50  lr_architecture: 0.010000  loss_cls: 8.2605 (8.4146)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 2.9235 (inf)  time: 0.5127  data: 0.0002  max mem: 9646
[2024-01-21 15:51:52 root] (utils.py 293): INFO Epoch: [0]  [  20/3152]  eta: 0:21:19  lr_architecture: 0.010000  loss_cls: 7.9577 (8.1477)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 1.9709 (inf)  time: 0.2986  data: 0.0001  max mem: 9646
[2024-01-21 15:51:55 root] (utils.py 293): INFO Epoch: [0]  [  30/3152]  eta: 0:19:18  lr_architecture: 0.010000  loss_cls: 7.5954 (7.9267)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 1.0921 (inf)  time: 0.2930  data: 0.0001  max mem: 9646
[2024-01-21 15:51:58 root] (utils.py 293): INFO Epoch: [0]  [  40/3152]  eta: 0:18:14  lr_architecture: 0.010000  loss_cls: 7.3225 (7.7565)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.7031 (inf)  time: 0.2920  data: 0.0001  max mem: 9646
[2024-01-21 15:52:01 root] (utils.py 293): INFO Epoch: [0]  [  50/3152]  eta: 0:17:34  lr_architecture: 0.010000  loss_cls: 7.1984 (7.6376)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.5822 (inf)  time: 0.2919  data: 0.0001  max mem: 9646
[2024-01-21 15:52:04 root] (utils.py 293): INFO Epoch: [0]  [  60/3152]  eta: 0:17:07  lr_architecture: 0.010000  loss_cls: 7.1168 (7.5489)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.5522 (inf)  time: 0.2923  data: 0.0001  max mem: 9646
[2024-01-21 15:52:07 root] (utils.py 293): INFO Epoch: [0]  [  70/3152]  eta: 0:16:46  lr_architecture: 0.010000  loss_cls: 7.0726 (7.4821)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.4694 (inf)  time: 0.2929  data: 0.0001  max mem: 9646
[2024-01-21 15:52:11 root] (utils.py 293): INFO Epoch: [0]  [  80/3152]  eta: 0:17:26  lr_architecture: 0.010000  loss_cls: 7.0627 (7.4281)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.4471 (inf)  time: 0.3671  data: 0.0325  max mem: 9647
[2024-01-21 15:52:14 root] (utils.py 293): INFO Epoch: [0]  [  90/3152]  eta: 0:17:07  lr_architecture: 0.010000  loss_cls: 7.0516 (7.3860)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.4074 (inf)  time: 0.3668  data: 0.0325  max mem: 9647
[2024-01-21 15:52:17 root] (utils.py 293): INFO Epoch: [0]  [ 100/3152]  eta: 0:16:50  lr_architecture: 0.010000  loss_cls: 7.0298 (7.3519)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3984 (inf)  time: 0.2924  data: 0.0001  max mem: 9647
[2024-01-21 15:52:20 root] (utils.py 293): INFO Epoch: [0]  [ 110/3152]  eta: 0:16:36  lr_architecture: 0.010000  loss_cls: 7.0330 (7.3238)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3984 (inf)  time: 0.2923  data: 0.0001  max mem: 9647
[2024-01-21 15:52:25 root] (utils.py 293): INFO Epoch: [0]  [ 120/3152]  eta: 0:17:13  lr_architecture: 0.010000  loss_cls: 7.0473 (7.3023)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.4177 (inf)  time: 0.3902  data: 0.0781  max mem: 9647
[2024-01-21 15:52:28 root] (utils.py 293): INFO Epoch: [0]  [ 130/3152]  eta: 0:17:11  lr_architecture: 0.010000  loss_cls: 7.0473 (7.2810)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.4432 (inf)  time: 0.4177  data: 0.0781  max mem: 9647
[2024-01-21 15:52:31 root] (utils.py 293): INFO Epoch: [0]  [ 140/3152]  eta: 0:17:00  lr_architecture: 0.010000  loss_cls: 7.0018 (7.2615)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.4064 (inf)  time: 0.3247  data: 0.0001  max mem: 9647
[2024-01-21 15:52:34 root] (utils.py 293): INFO Epoch: [0]  [ 150/3152]  eta: 0:16:47  lr_architecture: 0.010000  loss_cls: 7.0018 (7.2449)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3963 (inf)  time: 0.2976  data: 0.0001  max mem: 9647
[2024-01-21 15:52:37 root] (utils.py 293): INFO Epoch: [0]  [ 160/3152]  eta: 0:16:36  lr_architecture: 0.010000  loss_cls: 7.0190 (7.2317)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.4188 (inf)  time: 0.2932  data: 0.0001  max mem: 9647
[2024-01-21 15:52:40 root] (utils.py 293): INFO Epoch: [0]  [ 170/3152]  eta: 0:16:26  lr_architecture: 0.010000  loss_cls: 7.0177 (7.2183)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.4107 (inf)  time: 0.2931  data: 0.0001  max mem: 9647
[2024-01-21 15:52:44 root] (utils.py 293): INFO Epoch: [0]  [ 180/3152]  eta: 0:16:24  lr_architecture: 0.010000  loss_cls: 6.9989 (7.2073)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3855 (inf)  time: 0.3180  data: 0.0130  max mem: 9647
[2024-01-21 15:52:48 root] (utils.py 293): INFO Epoch: [0]  [ 190/3152]  eta: 0:16:42  lr_architecture: 0.010000  loss_cls: 6.9927 (7.1967)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3616 (inf)  time: 0.4044  data: 0.0130  max mem: 9647
[2024-01-21 15:52:51 root] (utils.py 293): INFO Epoch: [0]  [ 200/3152]  eta: 0:16:32  lr_architecture: 0.010000  loss_cls: 6.9826 (7.1863)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3629 (inf)  time: 0.3793  data: 0.0001  max mem: 9647
[2024-01-21 15:52:54 root] (utils.py 293): INFO Epoch: [0]  [ 210/3152]  eta: 0:16:22  lr_architecture: 0.010000  loss_cls: 6.9807 (7.1771)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3629 (inf)  time: 0.2930  data: 0.0001  max mem: 9647
[2024-01-21 15:52:59 root] (utils.py 293): INFO Epoch: [0]  [ 220/3152]  eta: 0:16:33  lr_architecture: 0.010000  loss_cls: 6.9818 (7.1685)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3753 (inf)  time: 0.3677  data: 0.0001  max mem: 9647
[2024-01-21 15:53:02 root] (utils.py 293): INFO Epoch: [0]  [ 230/3152]  eta: 0:16:24  lr_architecture: 0.010000  loss_cls: 6.9736 (7.1600)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3753 (inf)  time: 0.3678  data: 0.0001  max mem: 9647
[2024-01-21 15:53:05 root] (utils.py 293): INFO Epoch: [0]  [ 240/3152]  eta: 0:16:16  lr_architecture: 0.010000  loss_cls: 6.9580 (7.1520)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3439 (inf)  time: 0.2934  data: 0.0001  max mem: 9647
[2024-01-21 15:53:08 root] (utils.py 293): INFO Epoch: [0]  [ 250/3152]  eta: 0:16:07  lr_architecture: 0.010000  loss_cls: 6.9685 (7.1451)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3414 (inf)  time: 0.2936  data: 0.0001  max mem: 9647
[2024-01-21 15:53:13 root] (utils.py 293): INFO Epoch: [0]  [ 260/3152]  eta: 0:16:29  lr_architecture: 0.010000  loss_cls: 6.9804 (7.1399)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3664 (inf)  time: 0.4256  data: 0.1288  max mem: 9647
[2024-01-21 15:53:16 root] (utils.py 293): INFO Epoch: [0]  [ 270/3152]  eta: 0:16:20  lr_architecture: 0.010000  loss_cls: 6.9856 (7.1341)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3944 (inf)  time: 0.4257  data: 0.1288  max mem: 9647
[2024-01-21 15:53:19 root] (utils.py 293): INFO Epoch: [0]  [ 280/3152]  eta: 0:16:12  lr_architecture: 0.010000  loss_cls: 6.9888 (7.1295)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3886 (inf)  time: 0.2938  data: 0.0001  max mem: 9647
[2024-01-21 15:53:22 root] (utils.py 293): INFO Epoch: [0]  [ 290/3152]  eta: 0:16:04  lr_architecture: 0.010000  loss_cls: 6.9943 (7.1244)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3795 (inf)  time: 0.2932  data: 0.0001  max mem: 9647
[2024-01-21 15:53:25 root] (utils.py 293): INFO Epoch: [0]  [ 300/3152]  eta: 0:16:02  lr_architecture: 0.010000  loss_cls: 6.9794 (7.1195)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3717 (inf)  time: 0.3189  data: 0.0260  max mem: 9647
[2024-01-21 15:53:29 root] (utils.py 293): INFO Epoch: [0]  [ 310/3152]  eta: 0:16:00  lr_architecture: 0.010000  loss_cls: 6.9680 (7.1147)  loss_flops: 98.8134 (98.8134)  flops: 12.9405 (12.9405)  grad_norm: 0.3426 (inf)  time: 0.3498  data: 0.0560  max mem: 9647
[2024-01-21 15:53:52 root] (main_tome.py 217): INFO Namespace(batch_size=100, epochs=2, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 15:55:36 root] (main_tome.py 262): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 15:55:37 root] (main_tome.py 302): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 15:55:48 root] (main_tome.py 386): INFO number of params: 632045800
[2024-01-21 15:55:48 root] (main_tome.py 432): INFO Start training for 2 epochs
[2024-01-21 15:56:06 root] (main_tome.py 217): INFO Namespace(batch_size=64, epochs=2, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 15:56:15 root] (main_tome.py 262): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 15:56:17 root] (main_tome.py 302): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 15:56:29 root] (main_tome.py 386): INFO number of params: 632045800
[2024-01-21 15:56:29 root] (main_tome.py 432): INFO Start training for 2 epochs
[2024-01-21 15:56:49 root] (main_tome.py 217): INFO Namespace(batch_size=32, epochs=2, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 15:56:52 root] (main_tome.py 262): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 15:56:54 root] (main_tome.py 302): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 15:57:05 root] (main_tome.py 386): INFO number of params: 632045800
[2024-01-21 15:57:05 root] (main_tome.py 432): INFO Start training for 2 epochs
[2024-01-21 15:57:10 root] (utils.py 293): INFO Epoch: [0]  [   0/9852]  eta: 13:27:30  lr_architecture: 0.010000  loss_cls: 3.2811 (3.2811)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 11.2909 (11.2909)  time: 4.9178  data: 0.0007  max mem: 15215
[2024-01-21 15:57:26 root] (main_tome.py 217): INFO Namespace(batch_size=24, epochs=2, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 15:57:29 root] (main_tome.py 262): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 15:57:31 root] (main_tome.py 302): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 15:57:41 root] (main_tome.py 386): INFO number of params: 632045800
[2024-01-21 15:57:41 root] (main_tome.py 432): INFO Start training for 2 epochs
[2024-01-21 15:57:46 root] (utils.py 293): INFO Epoch: [0]  [    0/13136]  eta: 17:16:57  lr_architecture: 0.010000  loss_cls: 3.7433 (3.7433)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 15.4189 (15.4189)  time: 4.7364  data: 0.0007  max mem: 14771
[2024-01-21 15:57:56 root] (utils.py 293): INFO Epoch: [0]  [   10/13136]  eta: 4:58:13  lr_architecture: 0.010000  loss_cls: 7.9200 (7.6676)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 2.2490 (3.4921)  time: 1.3632  data: 0.0001  max mem: 20364
[2024-01-21 15:58:06 root] (utils.py 293): INFO Epoch: [0]  [   20/13136]  eta: 4:19:47  lr_architecture: 0.010000  loss_cls: 8.0515 (7.8370)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.7437 (2.6253)  time: 1.0111  data: 0.0001  max mem: 20364
[2024-01-21 15:58:16 root] (utils.py 293): INFO Epoch: [0]  [   30/13136]  eta: 4:06:04  lr_architecture: 0.010000  loss_cls: 7.7965 (7.7791)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.5196 (2.2081)  time: 0.9964  data: 0.0001  max mem: 20364
[2024-01-21 15:58:26 root] (utils.py 293): INFO Epoch: [0]  [   40/13136]  eta: 3:58:55  lr_architecture: 0.010000  loss_cls: 7.4937 (7.7036)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.2482 (1.9753)  time: 0.9962  data: 0.0001  max mem: 20364
[2024-01-21 15:58:36 root] (utils.py 293): INFO Epoch: [0]  [   50/13136]  eta: 3:54:26  lr_architecture: 0.010000  loss_cls: 7.2238 (7.5934)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.1611 (1.8107)  time: 0.9950  data: 0.0001  max mem: 20364
[2024-01-21 15:58:46 root] (utils.py 293): INFO Epoch: [0]  [   60/13136]  eta: 3:51:21  lr_architecture: 0.010000  loss_cls: 7.1443 (7.5246)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.1580 (1.7199)  time: 0.9939  data: 0.0001  max mem: 20364
[2024-01-21 15:58:56 root] (utils.py 293): INFO Epoch: [0]  [   70/13136]  eta: 3:49:06  lr_architecture: 0.010000  loss_cls: 7.1366 (7.4671)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.1705 (1.6395)  time: 0.9938  data: 0.0001  max mem: 20364
[2024-01-21 15:59:06 root] (utils.py 293): INFO Epoch: [0]  [   80/13136]  eta: 3:47:23  lr_architecture: 0.010000  loss_cls: 7.1132 (7.4250)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.1332 (1.5799)  time: 0.9941  data: 0.0001  max mem: 20364
[2024-01-21 15:59:16 root] (utils.py 293): INFO Epoch: [0]  [   90/13136]  eta: 3:46:01  lr_architecture: 0.010000  loss_cls: 7.1307 (7.3928)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.1230 (1.5309)  time: 0.9948  data: 0.0001  max mem: 20364
[2024-01-21 15:59:26 root] (utils.py 293): INFO Epoch: [0]  [  100/13136]  eta: 3:44:51  lr_architecture: 0.010000  loss_cls: 7.1307 (7.3657)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.1081 (1.4941)  time: 0.9944  data: 0.0001  max mem: 20364
[2024-01-21 15:59:36 root] (utils.py 293): INFO Epoch: [0]  [  110/13136]  eta: 3:43:54  lr_architecture: 0.010000  loss_cls: 7.0885 (7.3369)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.1869 (1.4695)  time: 0.9942  data: 0.0001  max mem: 20364
[2024-01-21 16:00:00 root] (main_pitome.py 217): INFO Namespace(batch_size=24, epochs=2, ratio=0.95, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:14:27 root] (main_pitome.py 262): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:14:28 root] (main_pitome.py 302): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 16:14:38 root] (main_pitome.py 389): INFO number of params: 632045800
[2024-01-21 16:14:38 root] (main_pitome.py 435): INFO Start training for 2 epochs
[2024-01-21 16:14:43 root] (utils.py 293): INFO Epoch: [0]  [    0/13136]  eta: 16:52:46  lr_architecture: 0.010000  loss_cls: 3.9312 (3.9312)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 15.5667 (15.5667)  time: 4.6259  data: 0.0007  max mem: 14768
[2024-01-21 16:14:53 root] (utils.py 293): INFO Epoch: [0]  [   10/13136]  eta: 5:01:07  lr_architecture: 0.010000  loss_cls: 8.1666 (7.6756)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 2.0428 (5.1708)  time: 1.3764  data: 0.0001  max mem: 19643
[2024-01-21 16:15:03 root] (utils.py 293): INFO Epoch: [0]  [   20/13136]  eta: 4:24:51  lr_architecture: 0.010000  loss_cls: 7.8139 (7.6853)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.6930 (3.4404)  time: 1.0409  data: 0.0001  max mem: 19643
[2024-01-21 16:15:14 root] (utils.py 293): INFO Epoch: [0]  [   30/13136]  eta: 4:11:48  lr_architecture: 0.010000  loss_cls: 7.6226 (7.6562)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.3881 (2.7646)  time: 1.0298  data: 0.0001  max mem: 19643
[2024-01-21 16:15:24 root] (utils.py 293): INFO Epoch: [0]  [   40/13136]  eta: 4:04:53  lr_architecture: 0.010000  loss_cls: 7.4460 (7.5746)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.2956 (2.3996)  time: 1.0279  data: 0.0001  max mem: 19643
[2024-01-21 16:15:34 root] (utils.py 293): INFO Epoch: [0]  [   50/13136]  eta: 4:00:34  lr_architecture: 0.010000  loss_cls: 7.2123 (7.4929)  loss_flops: 6026.1841 (6026.1841)  flops: 80.6285 (80.6285)  grad_norm: 1.0988 (2.1438)  time: 1.0260  data: 0.0001  max mem: 19643
[2024-01-21 16:16:03 root] (main_pitome.py 218): INFO Namespace(batch_size=20, epochs=2, ratio=0.9625, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:16:07 root] (main_pitome.py 263): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:16:08 root] (main_pitome.py 303): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 16:16:19 root] (main_pitome.py 390): INFO number of params: 632045800
[2024-01-21 16:16:29 root] (main_pitome.py 444): INFO Start training for 2 epochs
[2024-01-21 16:16:32 root] (utils.py 293): INFO Epoch: [0]  [    0/15763]  eta: 16:34:03  lr_architecture: 0.010000  loss_cls: 3.4797 (3.4797)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 14.2260 (14.2260)  time: 3.7837  data: 0.0007  max mem: 14771
[2024-01-21 16:16:43 root] (utils.py 293): INFO Epoch: [0]  [   10/15763]  eta: 5:40:26  lr_architecture: 0.010000  loss_cls: 7.7113 (7.5392)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 2.0620 (4.1439)  time: 1.2967  data: 0.0001  max mem: 19644
[2024-01-21 16:16:53 root] (utils.py 293): INFO Epoch: [0]  [   20/15763]  eta: 5:06:08  lr_architecture: 0.010000  loss_cls: 7.9833 (7.8633)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.9112 (3.1351)  time: 1.0359  data: 0.0001  max mem: 19644
[2024-01-21 16:17:03 root] (utils.py 293): INFO Epoch: [0]  [   30/15763]  eta: 4:53:47  lr_architecture: 0.010000  loss_cls: 7.7790 (7.7642)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.7437 (2.6213)  time: 1.0235  data: 0.0001  max mem: 19644
[2024-01-21 16:17:14 root] (utils.py 293): INFO Epoch: [0]  [   40/15763]  eta: 4:47:13  lr_architecture: 0.010000  loss_cls: 7.3575 (7.6511)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.3810 (2.2934)  time: 1.0219  data: 0.0001  max mem: 19644
[2024-01-21 16:17:24 root] (utils.py 293): INFO Epoch: [0]  [   50/15763]  eta: 4:43:12  lr_architecture: 0.010000  loss_cls: 7.2385 (7.5647)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.1941 (2.0709)  time: 1.0209  data: 0.0001  max mem: 19644
[2024-01-21 16:17:34 root] (utils.py 293): INFO Epoch: [0]  [   60/15763]  eta: 4:40:27  lr_architecture: 0.010000  loss_cls: 7.2247 (7.4972)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.1506 (1.9253)  time: 1.0215  data: 0.0001  max mem: 19644
[2024-01-21 16:17:44 root] (utils.py 293): INFO Epoch: [0]  [   70/15763]  eta: 4:38:29  lr_architecture: 0.010000  loss_cls: 7.1699 (7.4434)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.1889 (1.8310)  time: 1.0225  data: 0.0001  max mem: 19644
[2024-01-21 16:17:54 root] (utils.py 293): INFO Epoch: [0]  [   80/15763]  eta: 4:36:55  lr_architecture: 0.010000  loss_cls: 7.1006 (7.4000)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.2203 (1.7634)  time: 1.0222  data: 0.0001  max mem: 19644
[2024-01-21 16:18:05 root] (utils.py 293): INFO Epoch: [0]  [   90/15763]  eta: 4:35:38  lr_architecture: 0.010000  loss_cls: 7.1325 (7.3723)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.2299 (1.7114)  time: 1.0211  data: 0.0001  max mem: 19644
[2024-01-21 16:18:15 root] (utils.py 293): INFO Epoch: [0]  [  100/15763]  eta: 4:34:35  lr_architecture: 0.010000  loss_cls: 7.1318 (7.3460)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.2299 (1.6690)  time: 1.0211  data: 0.0001  max mem: 19644
[2024-01-21 16:18:25 root] (utils.py 293): INFO Epoch: [0]  [  110/15763]  eta: 4:33:41  lr_architecture: 0.010000  loss_cls: 7.0956 (7.3272)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.2668 (1.6363)  time: 1.0215  data: 0.0001  max mem: 19644
[2024-01-21 16:18:59 root] (main_pitome.py 218): INFO Namespace(batch_size=20, epochs=2, ratio=0.9625, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:19:03 root] (main_pitome.py 263): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:19:04 root] (main_pitome.py 303): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 16:19:15 root] (main_pitome.py 390): INFO number of params: 632045800
[2024-01-21 16:19:21 root] (main_pitome.py 445): INFO Start training for 2 epochs
[2024-01-21 16:19:25 root] (utils.py 293): INFO Epoch: [0]  [    0/15763]  eta: 14:17:53  lr_architecture: 0.010000  loss_cls: 3.5691 (3.5691)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 14.0616 (14.0616)  time: 3.2654  data: 0.0005  max mem: 14771
[2024-01-21 16:19:35 root] (utils.py 293): INFO Epoch: [0]  [   10/15763]  eta: 5:29:25  lr_architecture: 0.010000  loss_cls: 7.7670 (7.6118)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 2.0485 (3.9325)  time: 1.2547  data: 0.0001  max mem: 19644
[2024-01-21 16:19:46 root] (utils.py 293): INFO Epoch: [0]  [   20/15763]  eta: 5:01:29  lr_architecture: 0.010000  loss_cls: 7.7494 (7.6661)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.8645 (2.8990)  time: 1.0433  data: 0.0001  max mem: 19644
[2024-01-21 16:19:56 root] (utils.py 293): INFO Epoch: [0]  [   30/15763]  eta: 4:51:29  lr_architecture: 0.010000  loss_cls: 7.5483 (7.6304)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.5786 (2.4501)  time: 1.0330  data: 0.0001  max mem: 19644
[2024-01-21 16:20:06 root] (utils.py 293): INFO Epoch: [0]  [   40/15763]  eta: 4:46:05  lr_architecture: 0.010000  loss_cls: 7.4813 (7.5882)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.4175 (2.1774)  time: 1.0315  data: 0.0001  max mem: 19644
[2024-01-21 16:20:17 root] (utils.py 293): INFO Epoch: [0]  [   50/15763]  eta: 4:42:41  lr_architecture: 0.010000  loss_cls: 7.3331 (7.5221)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.2673 (1.9831)  time: 1.0295  data: 0.0001  max mem: 19644
[2024-01-21 16:20:27 root] (utils.py 293): INFO Epoch: [0]  [   60/15763]  eta: 4:40:19  lr_architecture: 0.010000  loss_cls: 7.1448 (7.4567)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.1838 (1.8522)  time: 1.0287  data: 0.0001  max mem: 19644
[2024-01-21 16:20:37 root] (utils.py 293): INFO Epoch: [0]  [   70/15763]  eta: 4:38:36  lr_architecture: 0.010000  loss_cls: 7.1359 (7.4155)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.2471 (1.7765)  time: 1.0289  data: 0.0001  max mem: 19644
[2024-01-21 16:20:47 root] (utils.py 293): INFO Epoch: [0]  [   80/15763]  eta: 4:37:10  lr_architecture: 0.010000  loss_cls: 7.1029 (7.3759)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.3396 (1.7197)  time: 1.0279  data: 0.0001  max mem: 19644
[2024-01-21 16:20:55 root] (engine.py 57): INFO Loss is nan, stopping training
[2024-01-21 16:22:23 root] (main_pitome.py 218): INFO Namespace(batch_size=16, epochs=2, ratio=0.9625, model='vit_huge_patch14_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.0001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:22:26 root] (main_pitome.py 263): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:22:28 root] (main_pitome.py 303): INFO Creating model: vit_huge_patch14_mae
[2024-01-21 16:22:38 root] (main_pitome.py 390): INFO number of params: 632045800
[2024-01-21 16:22:45 root] (main_pitome.py 445): INFO Start training for 2 epochs
[2024-01-21 16:22:48 root] (utils.py 293): INFO Epoch: [0]  [    0/19704]  eta: 17:30:45  lr_architecture: 0.001000  loss_cls: 3.5409 (3.5409)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 14.7789 (14.7789)  time: 3.1996  data: 0.0005  max mem: 14761
[2024-01-21 16:22:58 root] (utils.py 293): INFO Epoch: [0]  [   10/19704]  eta: 6:40:33  lr_architecture: 0.001000  loss_cls: 7.2436 (6.9965)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 2.3027 (4.6950)  time: 1.2204  data: 0.0001  max mem: 18416
[2024-01-21 16:23:08 root] (utils.py 293): INFO Epoch: [0]  [   20/19704]  eta: 6:06:41  lr_architecture: 0.001000  loss_cls: 7.1523 (7.0518)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.6159 (3.1720)  time: 1.0137  data: 0.0001  max mem: 18416
[2024-01-21 16:23:19 root] (utils.py 293): INFO Epoch: [0]  [   30/19704]  eta: 5:54:30  lr_architecture: 0.001000  loss_cls: 7.0960 (7.0610)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.3119 (2.5580)  time: 1.0045  data: 0.0001  max mem: 18416
[2024-01-21 16:23:29 root] (utils.py 293): INFO Epoch: [0]  [   40/19704]  eta: 5:48:12  lr_architecture: 0.001000  loss_cls: 7.1313 (7.0873)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.2424 (2.2288)  time: 1.0044  data: 0.0001  max mem: 18416
[2024-01-21 16:23:39 root] (utils.py 293): INFO Epoch: [0]  [   50/19704]  eta: 5:44:14  lr_architecture: 0.001000  loss_cls: 7.1322 (7.0830)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.1594 (2.0134)  time: 1.0041  data: 0.0001  max mem: 18416
[2024-01-21 16:23:49 root] (utils.py 293): INFO Epoch: [0]  [   60/19704]  eta: 5:41:35  lr_architecture: 0.001000  loss_cls: 7.0477 (7.0791)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.0767 (1.8573)  time: 1.0042  data: 0.0001  max mem: 18416
[2024-01-21 16:23:59 root] (utils.py 293): INFO Epoch: [0]  [   70/19704]  eta: 5:39:40  lr_architecture: 0.001000  loss_cls: 7.0390 (7.0800)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.0410 (1.7443)  time: 1.0052  data: 0.0001  max mem: 18416
[2024-01-21 16:24:09 root] (utils.py 293): INFO Epoch: [0]  [   80/19704]  eta: 5:38:09  lr_architecture: 0.001000  loss_cls: 7.0058 (7.0661)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.0112 (1.6537)  time: 1.0052  data: 0.0001  max mem: 18416
[2024-01-21 16:24:19 root] (utils.py 293): INFO Epoch: [0]  [   90/19704]  eta: 5:36:56  lr_architecture: 0.001000  loss_cls: 7.0412 (7.0686)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.0026 (1.5835)  time: 1.0047  data: 0.0001  max mem: 18416
[2024-01-21 16:24:29 root] (utils.py 293): INFO Epoch: [0]  [  100/19704]  eta: 5:35:55  lr_architecture: 0.001000  loss_cls: 7.0412 (7.0600)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9914 (1.5245)  time: 1.0047  data: 0.0001  max mem: 18416
[2024-01-21 16:24:39 root] (utils.py 293): INFO Epoch: [0]  [  110/19704]  eta: 5:35:03  lr_architecture: 0.001000  loss_cls: 7.0012 (7.0580)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9908 (1.4786)  time: 1.0046  data: 0.0001  max mem: 18416
[2024-01-21 16:24:49 root] (utils.py 293): INFO Epoch: [0]  [  120/19704]  eta: 5:34:19  lr_architecture: 0.001000  loss_cls: 7.0011 (7.0538)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9929 (1.4415)  time: 1.0047  data: 0.0001  max mem: 18416
[2024-01-21 16:24:59 root] (utils.py 293): INFO Epoch: [0]  [  130/19704]  eta: 5:33:38  lr_architecture: 0.001000  loss_cls: 6.9862 (7.0504)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 1.0061 (1.4093)  time: 1.0045  data: 0.0001  max mem: 18416
[2024-01-21 16:25:09 root] (utils.py 293): INFO Epoch: [0]  [  140/19704]  eta: 5:33:04  lr_architecture: 0.001000  loss_cls: 6.9838 (7.0460)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9721 (1.3761)  time: 1.0047  data: 0.0001  max mem: 18416
[2024-01-21 16:25:19 root] (utils.py 293): INFO Epoch: [0]  [  150/19704]  eta: 5:32:33  lr_architecture: 0.001000  loss_cls: 6.9838 (7.0430)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9455 (1.3494)  time: 1.0053  data: 0.0001  max mem: 18416
[2024-01-21 16:25:29 root] (utils.py 293): INFO Epoch: [0]  [  160/19704]  eta: 5:32:05  lr_architecture: 0.001000  loss_cls: 6.9520 (7.0389)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9480 (1.3244)  time: 1.0055  data: 0.0001  max mem: 18416
[2024-01-21 16:25:39 root] (utils.py 293): INFO Epoch: [0]  [  170/19704]  eta: 5:31:40  lr_architecture: 0.001000  loss_cls: 6.9945 (7.0362)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9368 (1.3022)  time: 1.0061  data: 0.0001  max mem: 18416
[2024-01-21 16:25:49 root] (utils.py 293): INFO Epoch: [0]  [  180/19704]  eta: 5:31:15  lr_architecture: 0.001000  loss_cls: 7.0087 (7.0338)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9154 (1.2807)  time: 1.0061  data: 0.0001  max mem: 18416
[2024-01-21 16:25:59 root] (utils.py 293): INFO Epoch: [0]  [  190/19704]  eta: 5:30:53  lr_architecture: 0.001000  loss_cls: 7.0042 (7.0320)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9069 (1.2611)  time: 1.0061  data: 0.0001  max mem: 18416
[2024-01-21 16:26:09 root] (utils.py 293): INFO Epoch: [0]  [  200/19704]  eta: 5:30:33  lr_architecture: 0.001000  loss_cls: 6.9817 (7.0288)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9136 (1.2445)  time: 1.0064  data: 0.0001  max mem: 18416
[2024-01-21 16:26:19 root] (utils.py 293): INFO Epoch: [0]  [  210/19704]  eta: 5:30:12  lr_architecture: 0.001000  loss_cls: 6.9555 (7.0251)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9213 (1.2297)  time: 1.0063  data: 0.0001  max mem: 18416
[2024-01-21 16:26:30 root] (utils.py 293): INFO Epoch: [0]  [  220/19704]  eta: 5:29:53  lr_architecture: 0.001000  loss_cls: 6.9679 (7.0235)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9386 (1.2189)  time: 1.0062  data: 0.0001  max mem: 18416
[2024-01-21 16:26:40 root] (utils.py 293): INFO Epoch: [0]  [  230/19704]  eta: 5:29:35  lr_architecture: 0.001000  loss_cls: 6.9911 (7.0218)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9483 (1.2068)  time: 1.0059  data: 0.0001  max mem: 18416
[2024-01-21 16:26:50 root] (utils.py 293): INFO Epoch: [0]  [  240/19704]  eta: 5:29:16  lr_architecture: 0.001000  loss_cls: 6.9585 (7.0184)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9445 (1.1969)  time: 1.0055  data: 0.0001  max mem: 18416
[2024-01-21 16:27:00 root] (utils.py 293): INFO Epoch: [0]  [  250/19704]  eta: 5:28:59  lr_architecture: 0.001000  loss_cls: 6.9628 (7.0182)  loss_flops: 8464.0889 (8464.0889)  flops: 95.0005 (95.0005)  grad_norm: 0.9109 (1.1859)  time: 1.0057  data: 0.0001  max mem: 18416
[2024-01-21 16:28:14 root] (main_pitome.py 218): INFO Namespace(batch_size=16, epochs=2, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.0001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:28:46 root] (main_pitome.py 218): INFO Namespace(batch_size=16, epochs=2, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.0001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:29:49 root] (main_pitome.py 218): INFO Namespace(batch_size=16, epochs=2, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.0001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:30:45 root] (main_pitome.py 219): INFO Namespace(batch_size=16, epochs=2, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.0001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:30:48 root] (main_pitome.py 264): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:30:50 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 16:30:55 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 16:37:11 root] (main_pitome.py 219): INFO Namespace(batch_size=16, epochs=2, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.0001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:37:15 root] (main_pitome.py 264): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:37:16 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 16:37:21 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 16:39:33 root] (main_pitome.py 219): INFO Namespace(batch_size=16, epochs=2, ratio=0.95, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.0001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:39:37 root] (main_pitome.py 264): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:39:38 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 16:39:43 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 16:39:51 root] (main_pitome.py 446): INFO Start training for 2 epochs
[2024-01-21 16:39:53 root] (utils.py 302): INFO Epoch: [0]  [    0/19704]  eta: 12:38:00  lr_architecture: 0.001000  loss_cls: 3.4336 (3.4336)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 14.5901 (14.5901)  time: 2.3082  data: 0.0005  max mem: 6994
[2024-01-21 16:39:58 root] (utils.py 302): INFO Epoch: [0]  [   10/19704]  eta: 3:38:36  lr_architecture: 0.001000  loss_cls: 7.1585 (6.8700)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 2.4817 (5.9157)  time: 0.6660  data: 0.0001  max mem: 8650
[2024-01-21 16:40:03 root] (utils.py 302): INFO Epoch: [0]  [   20/19704]  eta: 3:10:54  lr_architecture: 0.001000  loss_cls: 7.1617 (6.9996)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 1.6502 (3.8500)  time: 0.4956  data: 0.0001  max mem: 8650
[2024-01-21 16:40:08 root] (utils.py 302): INFO Epoch: [0]  [   30/19704]  eta: 3:01:07  lr_architecture: 0.001000  loss_cls: 7.1558 (7.0309)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 1.4636 (3.0519)  time: 0.4899  data: 0.0001  max mem: 8650
[2024-01-21 16:40:13 root] (utils.py 302): INFO Epoch: [0]  [   40/19704]  eta: 2:56:07  lr_architecture: 0.001000  loss_cls: 7.1413 (7.0590)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 1.3467 (2.6464)  time: 0.4907  data: 0.0001  max mem: 8650
[2024-01-21 16:40:18 root] (utils.py 302): INFO Epoch: [0]  [   50/19704]  eta: 2:53:00  lr_architecture: 0.001000  loss_cls: 7.1379 (7.0687)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 1.1890 (2.3518)  time: 0.4906  data: 0.0001  max mem: 8650
[2024-01-21 16:40:23 root] (utils.py 302): INFO Epoch: [0]  [   60/19704]  eta: 2:50:54  lr_architecture: 0.001000  loss_cls: 7.0546 (7.0585)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 1.0877 (2.1393)  time: 0.4905  data: 0.0001  max mem: 8650
[2024-01-21 16:40:28 root] (utils.py 302): INFO Epoch: [0]  [   70/19704]  eta: 2:49:20  lr_architecture: 0.001000  loss_cls: 7.0417 (7.0657)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 1.0673 (1.9903)  time: 0.4903  data: 0.0001  max mem: 8650
[2024-01-21 16:40:33 root] (utils.py 302): INFO Epoch: [0]  [   80/19704]  eta: 2:48:11  lr_architecture: 0.001000  loss_cls: 7.0065 (7.0552)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 1.0308 (1.8719)  time: 0.4905  data: 0.0001  max mem: 8650
[2024-01-21 16:40:37 root] (utils.py 302): INFO Epoch: [0]  [   90/19704]  eta: 2:47:14  lr_architecture: 0.001000  loss_cls: 6.9984 (7.0558)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 1.0060 (1.7741)  time: 0.4907  data: 0.0001  max mem: 8650
[2024-01-21 16:40:42 root] (utils.py 302): INFO Epoch: [0]  [  100/19704]  eta: 2:46:28  lr_architecture: 0.001000  loss_cls: 7.0061 (7.0501)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 0.9568 (1.6908)  time: 0.4904  data: 0.0001  max mem: 8650
[2024-01-21 16:40:47 root] (utils.py 302): INFO Epoch: [0]  [  110/19704]  eta: 2:45:50  lr_architecture: 0.001000  loss_cls: 7.0061 (7.0455)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 0.9513 (1.6245)  time: 0.4907  data: 0.0001  max mem: 8650
[2024-01-21 16:40:52 root] (utils.py 302): INFO Epoch: [0]  [  120/19704]  eta: 2:45:17  lr_architecture: 0.001000  loss_cls: 7.0085 (7.0424)  loss_flops: 1013.3037 (1013.3037)  flops: 34.8324 (34.8324)  grad_norm: 0.9818 (1.5726)  time: 0.4906  data: 0.0001  max mem: 8650
[2024-01-21 16:41:33 root] (main_pitome.py 219): INFO Namespace(batch_size=32, epochs=2, ratio=0.9425, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:41:36 root] (main_pitome.py 264): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:41:37 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 16:41:43 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 16:41:50 root] (main_pitome.py 446): INFO Start training for 2 epochs
[2024-01-21 16:41:53 root] (utils.py 302): INFO Epoch: [0]  [   0/9852]  eta: 6:38:32  lr_architecture: 0.010000  loss_cls: 3.2319 (3.2319)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 12.0292 (12.0292)  time: 2.4272  data: 0.0006  max mem: 7082
[2024-01-21 16:41:58 root] (utils.py 302): INFO Epoch: [0]  [  10/9852]  eta: 1:56:57  lr_architecture: 0.010000  loss_cls: 7.8829 (7.4943)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 1.8356 (3.0640)  time: 0.7130  data: 0.0001  max mem: 10523
[2024-01-21 16:42:03 root] (utils.py 302): INFO Epoch: [0]  [  20/9852]  eta: 1:42:22  lr_architecture: 0.010000  loss_cls: 7.8241 (7.6480)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 1.5667 (2.2947)  time: 0.5346  data: 0.0001  max mem: 10523
[2024-01-21 16:42:09 root] (utils.py 302): INFO Epoch: [0]  [  30/9852]  eta: 1:37:06  lr_architecture: 0.010000  loss_cls: 7.5843 (7.5872)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 1.1799 (1.8932)  time: 0.5273  data: 0.0001  max mem: 10523
[2024-01-21 16:42:14 root] (utils.py 302): INFO Epoch: [0]  [  40/9852]  eta: 1:34:21  lr_architecture: 0.010000  loss_cls: 7.1882 (7.4732)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.9142 (1.6448)  time: 0.5269  data: 0.0001  max mem: 10523
[2024-01-21 16:42:19 root] (utils.py 302): INFO Epoch: [0]  [  50/9852]  eta: 1:32:37  lr_architecture: 0.010000  loss_cls: 7.1328 (7.4058)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.8550 (1.4894)  time: 0.5265  data: 0.0001  max mem: 10523
[2024-01-21 16:42:24 root] (utils.py 302): INFO Epoch: [0]  [  60/9852]  eta: 1:31:27  lr_architecture: 0.010000  loss_cls: 7.1124 (7.3578)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.8443 (1.3881)  time: 0.5264  data: 0.0001  max mem: 10523
[2024-01-21 16:42:30 root] (utils.py 302): INFO Epoch: [0]  [  70/9852]  eta: 1:30:34  lr_architecture: 0.010000  loss_cls: 7.0906 (7.3157)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.8859 (1.3188)  time: 0.5263  data: 0.0001  max mem: 10523
[2024-01-21 16:42:35 root] (utils.py 302): INFO Epoch: [0]  [  80/9852]  eta: 1:29:52  lr_architecture: 0.010000  loss_cls: 7.0480 (7.2874)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.8728 (1.2655)  time: 0.5258  data: 0.0001  max mem: 10523
[2024-01-21 16:42:40 root] (utils.py 302): INFO Epoch: [0]  [  90/9852]  eta: 1:29:18  lr_architecture: 0.010000  loss_cls: 7.0442 (7.2564)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.8262 (1.2171)  time: 0.5256  data: 0.0001  max mem: 10523
[2024-01-21 16:42:45 root] (utils.py 302): INFO Epoch: [0]  [ 100/9852]  eta: 1:28:50  lr_architecture: 0.010000  loss_cls: 7.0274 (7.2372)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.8447 (1.1850)  time: 0.5256  data: 0.0001  max mem: 10523
[2024-01-21 16:43:23 root] (main_pitome.py 219): INFO Namespace(batch_size=64, epochs=3, ratio=0.9425, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:43:27 root] (main_pitome.py 264): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:43:28 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 16:43:35 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 16:43:41 root] (main_pitome.py 446): INFO Start training for 3 epochs
[2024-01-21 16:43:44 root] (utils.py 302): INFO Epoch: [0]  [   0/4926]  eta: 3:46:29  lr_architecture: 0.010000  loss_cls: 3.4240 (3.4240)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 9.5476 (9.5476)  time: 2.7586  data: 0.0006  max mem: 11144
[2024-01-21 16:43:50 root] (utils.py 302): INFO Epoch: [0]  [  10/4926]  eta: 1:07:38  lr_architecture: 0.010000  loss_cls: 7.7290 (7.3365)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 1.2086 (2.0786)  time: 0.8256  data: 0.0001  max mem: 14587
[2024-01-21 16:43:57 root] (utils.py 302): INFO Epoch: [0]  [  20/4926]  eta: 0:59:10  lr_architecture: 0.010000  loss_cls: 7.4999 (7.3723)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 1.0176 (1.4736)  time: 0.6219  data: 0.0001  max mem: 14587
[2024-01-21 16:44:03 root] (utils.py 302): INFO Epoch: [0]  [  30/4926]  eta: 0:56:07  lr_architecture: 0.010000  loss_cls: 7.1651 (7.2824)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6878 (1.1953)  time: 0.6120  data: 0.0001  max mem: 14587
[2024-01-21 16:44:09 root] (utils.py 302): INFO Epoch: [0]  [  40/4926]  eta: 0:54:27  lr_architecture: 0.010000  loss_cls: 7.0732 (7.2292)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5932 (1.0519)  time: 0.6112  data: 0.0001  max mem: 14587
[2024-01-21 16:44:15 root] (utils.py 302): INFO Epoch: [0]  [  50/4926]  eta: 0:53:24  lr_architecture: 0.010000  loss_cls: 7.0614 (7.1933)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6034 (0.9680)  time: 0.6099  data: 0.0001  max mem: 14587
[2024-01-21 16:44:21 root] (utils.py 302): INFO Epoch: [0]  [  60/4926]  eta: 0:52:40  lr_architecture: 0.010000  loss_cls: 7.0049 (7.1605)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5947 (0.9048)  time: 0.6098  data: 0.0001  max mem: 14587
[2024-01-21 16:44:27 root] (utils.py 302): INFO Epoch: [0]  [  70/4926]  eta: 0:52:06  lr_architecture: 0.010000  loss_cls: 6.9982 (7.1397)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5919 (0.8626)  time: 0.6096  data: 0.0001  max mem: 14587
[2024-01-21 16:44:33 root] (utils.py 302): INFO Epoch: [0]  [  80/4926]  eta: 0:51:40  lr_architecture: 0.010000  loss_cls: 7.0127 (7.1229)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5755 (0.8258)  time: 0.6103  data: 0.0001  max mem: 14587
[2024-01-21 16:44:39 root] (utils.py 302): INFO Epoch: [0]  [  90/4926]  eta: 0:51:17  lr_architecture: 0.010000  loss_cls: 7.0230 (7.1124)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5978 (0.8059)  time: 0.6099  data: 0.0001  max mem: 14587
[2024-01-21 16:44:45 root] (utils.py 302): INFO Epoch: [0]  [ 100/4926]  eta: 0:50:59  lr_architecture: 0.010000  loss_cls: 7.0230 (7.1008)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6228 (0.7881)  time: 0.6103  data: 0.0001  max mem: 14587
[2024-01-21 16:44:51 root] (utils.py 302): INFO Epoch: [0]  [ 110/4926]  eta: 0:50:42  lr_architecture: 0.010000  loss_cls: 6.9987 (7.0923)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6215 (0.7723)  time: 0.6105  data: 0.0001  max mem: 14587
[2024-01-21 16:44:58 root] (utils.py 302): INFO Epoch: [0]  [ 120/4926]  eta: 0:50:27  lr_architecture: 0.010000  loss_cls: 7.0015 (7.0846)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5993 (0.7575)  time: 0.6099  data: 0.0001  max mem: 14587
[2024-01-21 16:45:04 root] (utils.py 302): INFO Epoch: [0]  [ 130/4926]  eta: 0:50:13  lr_architecture: 0.010000  loss_cls: 6.9975 (7.0769)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5901 (0.7444)  time: 0.6100  data: 0.0001  max mem: 14587
[2024-01-21 16:45:10 root] (utils.py 302): INFO Epoch: [0]  [ 140/4926]  eta: 0:50:00  lr_architecture: 0.010000  loss_cls: 6.9848 (7.0710)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6096 (0.7388)  time: 0.6093  data: 0.0001  max mem: 14587
[2024-01-21 16:45:16 root] (utils.py 302): INFO Epoch: [0]  [ 150/4926]  eta: 0:49:49  lr_architecture: 0.010000  loss_cls: 6.9848 (7.0659)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6405 (0.7313)  time: 0.6098  data: 0.0001  max mem: 14587
[2024-01-21 16:45:22 root] (utils.py 302): INFO Epoch: [0]  [ 160/4926]  eta: 0:49:38  lr_architecture: 0.010000  loss_cls: 7.0058 (7.0628)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6468 (0.7292)  time: 0.6110  data: 0.0001  max mem: 14587
[2024-01-21 16:45:28 root] (utils.py 302): INFO Epoch: [0]  [ 170/4926]  eta: 0:49:28  lr_architecture: 0.010000  loss_cls: 7.0058 (7.0586)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6568 (0.7253)  time: 0.6110  data: 0.0001  max mem: 14587
[2024-01-21 16:45:34 root] (utils.py 302): INFO Epoch: [0]  [ 180/4926]  eta: 0:49:18  lr_architecture: 0.010000  loss_cls: 6.9931 (7.0564)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6547 (0.7218)  time: 0.6102  data: 0.0001  max mem: 14587
[2024-01-21 16:45:40 root] (utils.py 302): INFO Epoch: [0]  [ 190/4926]  eta: 0:49:09  lr_architecture: 0.010000  loss_cls: 6.9998 (7.0535)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6482 (0.7182)  time: 0.6100  data: 0.0001  max mem: 14587
[2024-01-21 16:45:46 root] (utils.py 302): INFO Epoch: [0]  [ 200/4926]  eta: 0:48:59  lr_architecture: 0.010000  loss_cls: 7.0166 (7.0520)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6583 (0.7165)  time: 0.6103  data: 0.0001  max mem: 14587
[2024-01-21 16:45:53 root] (utils.py 302): INFO Epoch: [0]  [ 210/4926]  eta: 0:48:51  lr_architecture: 0.010000  loss_cls: 6.9922 (7.0479)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6292 (0.7114)  time: 0.6105  data: 0.0001  max mem: 14587
[2024-01-21 16:45:59 root] (utils.py 302): INFO Epoch: [0]  [ 220/4926]  eta: 0:48:42  lr_architecture: 0.010000  loss_cls: 6.9852 (7.0454)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6292 (0.7089)  time: 0.6104  data: 0.0001  max mem: 14587
[2024-01-21 16:46:05 root] (utils.py 302): INFO Epoch: [0]  [ 230/4926]  eta: 0:48:34  lr_architecture: 0.010000  loss_cls: 6.9855 (7.0432)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6738 (0.7082)  time: 0.6106  data: 0.0001  max mem: 14587
[2024-01-21 16:46:11 root] (utils.py 302): INFO Epoch: [0]  [ 240/4926]  eta: 0:48:26  lr_architecture: 0.010000  loss_cls: 6.9887 (7.0414)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6858 (0.7072)  time: 0.6112  data: 0.0001  max mem: 14587
[2024-01-21 16:46:50 root] (main_pitome.py 219): INFO Namespace(batch_size=128, epochs=5, ratio=0.9425, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:46:53 root] (main_pitome.py 264): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:46:54 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 16:47:03 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 16:47:10 root] (main_pitome.py 446): INFO Start training for 5 epochs
[2024-01-21 16:47:13 root] (utils.py 302): INFO Epoch: [0]  [   0/2463]  eta: 2:08:09  lr_architecture: 0.010000  loss_cls: 3.1756 (3.1756)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 5.5643 (5.5643)  time: 3.1219  data: 0.0010  max mem: 19312
[2024-01-21 16:47:41 root] (main_pitome.py 219): INFO Namespace(batch_size=80, epochs=5, ratio=0.9425, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:47:45 root] (main_pitome.py 264): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:47:46 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 16:47:53 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 16:47:59 root] (main_pitome.py 446): INFO Start training for 5 epochs
[2024-01-21 16:48:02 root] (utils.py 302): INFO Epoch: [0]  [   0/3940]  eta: 2:59:53  lr_architecture: 0.010000  loss_cls: 3.2138 (3.2138)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 7.8372 (7.8372)  time: 2.7395  data: 0.0007  max mem: 13169
[2024-01-21 16:48:09 root] (utils.py 302): INFO Epoch: [0]  [  10/3940]  eta: 0:57:23  lr_architecture: 0.010000  loss_cls: 7.5160 (7.2375)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 1.1815 (1.9207)  time: 0.8762  data: 0.0001  max mem: 16612
[2024-01-21 16:48:16 root] (utils.py 302): INFO Epoch: [0]  [  20/3940]  eta: 0:50:38  lr_architecture: 0.010000  loss_cls: 7.5028 (7.3325)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.9072 (1.3803)  time: 0.6768  data: 0.0001  max mem: 16612
[2024-01-21 16:48:22 root] (utils.py 302): INFO Epoch: [0]  [  30/3940]  eta: 0:48:11  lr_architecture: 0.010000  loss_cls: 7.1654 (7.2630)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6089 (1.1205)  time: 0.6642  data: 0.0001  max mem: 16612
[2024-01-21 16:48:29 root] (utils.py 302): INFO Epoch: [0]  [  40/3940]  eta: 0:46:54  lr_architecture: 0.010000  loss_cls: 7.0786 (7.2129)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5684 (0.9822)  time: 0.6654  data: 0.0001  max mem: 16612
[2024-01-21 16:48:35 root] (utils.py 302): INFO Epoch: [0]  [  50/3940]  eta: 0:46:03  lr_architecture: 0.010000  loss_cls: 7.0273 (7.1726)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5125 (0.8878)  time: 0.6656  data: 0.0001  max mem: 16612
[2024-01-21 16:48:42 root] (utils.py 302): INFO Epoch: [0]  [  60/3940]  eta: 0:45:27  lr_architecture: 0.010000  loss_cls: 7.0012 (7.1433)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5004 (0.8275)  time: 0.6646  data: 0.0001  max mem: 16612
[2024-01-21 16:48:49 root] (utils.py 302): INFO Epoch: [0]  [  70/3940]  eta: 0:44:59  lr_architecture: 0.010000  loss_cls: 6.9909 (7.1234)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5141 (0.7836)  time: 0.6649  data: 0.0001  max mem: 16612
[2024-01-21 16:48:55 root] (utils.py 302): INFO Epoch: [0]  [  80/3940]  eta: 0:44:37  lr_architecture: 0.010000  loss_cls: 6.9950 (7.1076)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5245 (0.7501)  time: 0.6652  data: 0.0001  max mem: 16612
[2024-01-21 16:49:02 root] (utils.py 302): INFO Epoch: [0]  [  90/3940]  eta: 0:44:18  lr_architecture: 0.010000  loss_cls: 6.9703 (7.0929)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5218 (0.7254)  time: 0.6657  data: 0.0001  max mem: 16612
[2024-01-21 16:49:09 root] (utils.py 302): INFO Epoch: [0]  [ 100/3940]  eta: 0:44:02  lr_architecture: 0.010000  loss_cls: 6.9812 (7.0823)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5230 (0.7064)  time: 0.6660  data: 0.0001  max mem: 16612
[2024-01-21 16:49:15 root] (utils.py 302): INFO Epoch: [0]  [ 110/3940]  eta: 0:43:47  lr_architecture: 0.010000  loss_cls: 6.9770 (7.0718)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5271 (0.6889)  time: 0.6659  data: 0.0001  max mem: 16612
[2024-01-21 16:49:22 root] (utils.py 302): INFO Epoch: [0]  [ 120/3940]  eta: 0:43:34  lr_architecture: 0.010000  loss_cls: 6.9770 (7.0668)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5311 (0.6777)  time: 0.6657  data: 0.0001  max mem: 16612
[2024-01-21 16:49:29 root] (utils.py 302): INFO Epoch: [0]  [ 130/3940]  eta: 0:43:22  lr_architecture: 0.010000  loss_cls: 6.9833 (7.0598)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5357 (0.6670)  time: 0.6652  data: 0.0001  max mem: 16612
[2024-01-21 16:49:35 root] (utils.py 302): INFO Epoch: [0]  [ 140/3940]  eta: 0:43:10  lr_architecture: 0.010000  loss_cls: 6.9848 (7.0564)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5181 (0.6600)  time: 0.6656  data: 0.0001  max mem: 16612
[2024-01-21 16:49:42 root] (utils.py 302): INFO Epoch: [0]  [ 150/3940]  eta: 0:43:00  lr_architecture: 0.010000  loss_cls: 7.0028 (7.0528)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5398 (0.6537)  time: 0.6663  data: 0.0001  max mem: 16612
[2024-01-21 16:49:49 root] (utils.py 302): INFO Epoch: [0]  [ 160/3940]  eta: 0:42:50  lr_architecture: 0.010000  loss_cls: 7.0004 (7.0488)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5398 (0.6481)  time: 0.6670  data: 0.0001  max mem: 16612
[2024-01-21 16:49:55 root] (utils.py 302): INFO Epoch: [0]  [ 170/3940]  eta: 0:42:40  lr_architecture: 0.010000  loss_cls: 6.9833 (7.0448)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5600 (0.6432)  time: 0.6674  data: 0.0001  max mem: 16612
[2024-01-21 16:50:02 root] (utils.py 302): INFO Epoch: [0]  [ 180/3940]  eta: 0:42:31  lr_architecture: 0.010000  loss_cls: 6.9909 (7.0423)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5694 (0.6411)  time: 0.6674  data: 0.0001  max mem: 16612
[2024-01-21 16:50:09 root] (utils.py 302): INFO Epoch: [0]  [ 190/3940]  eta: 0:42:21  lr_architecture: 0.010000  loss_cls: 6.9932 (7.0399)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5969 (0.6390)  time: 0.6665  data: 0.0001  max mem: 16612
[2024-01-21 16:55:52 root] (main_pitome.py 219): INFO Namespace(batch_size=64, epochs=5, ratio=0.9425, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:55:56 root] (main_pitome.py 264): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:55:57 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 16:56:04 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 16:56:11 root] (main_pitome.py 446): INFO Start training for 5 epochs
[2024-01-21 16:56:13 root] (utils.py 302): INFO Epoch: [0]  [   0/4926]  eta: 3:44:42  lr_architecture: 0.010000  loss_cls: 3.4098 (3.4098)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 8.7332 (8.7332)  time: 2.7369  data: 0.0007  max mem: 11144
[2024-01-21 16:56:20 root] (utils.py 302): INFO Epoch: [0]  [  10/4926]  eta: 1:08:41  lr_architecture: 0.010000  loss_cls: 7.6357 (7.2664)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 1.2290 (2.5742)  time: 0.8383  data: 0.0001  max mem: 14587
[2024-01-21 16:56:26 root] (utils.py 302): INFO Epoch: [0]  [  20/4926]  eta: 0:59:59  lr_architecture: 0.010000  loss_cls: 7.4318 (7.3757)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 1.0066 (1.7664)  time: 0.6335  data: 0.0001  max mem: 14587
[2024-01-21 16:56:32 root] (utils.py 302): INFO Epoch: [0]  [  30/4926]  eta: 0:56:46  lr_architecture: 0.010000  loss_cls: 7.2308 (7.3067)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.7483 (1.4092)  time: 0.6174  data: 0.0001  max mem: 14587
[2024-01-21 16:56:38 root] (utils.py 302): INFO Epoch: [0]  [  40/4926]  eta: 0:55:03  lr_architecture: 0.010000  loss_cls: 7.1219 (7.2494)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6479 (1.2223)  time: 0.6157  data: 0.0001  max mem: 14587
[2024-01-21 16:56:44 root] (utils.py 302): INFO Epoch: [0]  [  50/4926]  eta: 0:53:57  lr_architecture: 0.010000  loss_cls: 7.0414 (7.2065)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6165 (1.1017)  time: 0.6148  data: 0.0001  max mem: 14587
[2024-01-21 16:56:51 root] (utils.py 302): INFO Epoch: [0]  [  60/4926]  eta: 0:53:12  lr_architecture: 0.010000  loss_cls: 7.0061 (7.1716)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5763 (1.0137)  time: 0.6149  data: 0.0001  max mem: 14587
[2024-01-21 16:56:57 root] (utils.py 302): INFO Epoch: [0]  [  70/4926]  eta: 0:52:38  lr_architecture: 0.010000  loss_cls: 6.9899 (7.1484)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5724 (0.9545)  time: 0.6160  data: 0.0001  max mem: 14587
[2024-01-21 16:57:03 root] (utils.py 302): INFO Epoch: [0]  [  80/4926]  eta: 0:52:11  lr_architecture: 0.010000  loss_cls: 7.0041 (7.1315)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5724 (0.9083)  time: 0.6164  data: 0.0001  max mem: 14587
[2024-01-21 16:57:09 root] (utils.py 302): INFO Epoch: [0]  [  90/4926]  eta: 0:51:50  lr_architecture: 0.010000  loss_cls: 7.0105 (7.1195)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5978 (0.8753)  time: 0.6169  data: 0.0001  max mem: 14587
[2024-01-21 16:57:15 root] (utils.py 302): INFO Epoch: [0]  [ 100/4926]  eta: 0:51:31  lr_architecture: 0.010000  loss_cls: 7.0117 (7.1077)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6027 (0.8503)  time: 0.6182  data: 0.0001  max mem: 14587
[2024-01-21 16:57:22 root] (utils.py 302): INFO Epoch: [0]  [ 110/4926]  eta: 0:51:16  lr_architecture: 0.010000  loss_cls: 7.0117 (7.0976)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.5893 (0.8274)  time: 0.6189  data: 0.0001  max mem: 14587
[2024-01-21 16:57:28 root] (utils.py 302): INFO Epoch: [0]  [ 120/4926]  eta: 0:51:01  lr_architecture: 0.010000  loss_cls: 7.0033 (7.0896)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6008 (0.8094)  time: 0.6190  data: 0.0001  max mem: 14587
[2024-01-21 16:57:34 root] (utils.py 302): INFO Epoch: [0]  [ 130/4926]  eta: 0:50:48  lr_architecture: 0.010000  loss_cls: 7.0002 (7.0812)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6098 (0.7932)  time: 0.6179  data: 0.0001  max mem: 14587
[2024-01-21 16:57:40 root] (utils.py 302): INFO Epoch: [0]  [ 140/4926]  eta: 0:50:35  lr_architecture: 0.010000  loss_cls: 6.9935 (7.0745)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6150 (0.7830)  time: 0.6176  data: 0.0001  max mem: 14587
[2024-01-21 16:57:46 root] (utils.py 302): INFO Epoch: [0]  [ 150/4926]  eta: 0:50:24  lr_architecture: 0.010000  loss_cls: 6.9968 (7.0695)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6277 (0.7720)  time: 0.6184  data: 0.0001  max mem: 14587
[2024-01-21 16:57:52 root] (utils.py 302): INFO Epoch: [0]  [ 160/4926]  eta: 0:50:13  lr_architecture: 0.010000  loss_cls: 6.9898 (7.0651)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6486 (0.7663)  time: 0.6186  data: 0.0001  max mem: 14587
[2024-01-21 16:57:59 root] (utils.py 302): INFO Epoch: [0]  [ 170/4926]  eta: 0:50:03  lr_architecture: 0.010000  loss_cls: 6.9853 (7.0604)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6558 (0.7601)  time: 0.6183  data: 0.0001  max mem: 14587
[2024-01-21 16:58:05 root] (utils.py 302): INFO Epoch: [0]  [ 180/4926]  eta: 0:49:53  lr_architecture: 0.010000  loss_cls: 6.9916 (7.0579)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6606 (0.7542)  time: 0.6177  data: 0.0001  max mem: 14587
[2024-01-21 16:58:11 root] (utils.py 302): INFO Epoch: [0]  [ 190/4926]  eta: 0:49:44  lr_architecture: 0.010000  loss_cls: 6.9920 (7.0551)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6469 (0.7486)  time: 0.6183  data: 0.0001  max mem: 14587
[2024-01-21 16:58:17 root] (utils.py 302): INFO Epoch: [0]  [ 200/4926]  eta: 0:49:35  lr_architecture: 0.010000  loss_cls: 6.9961 (7.0528)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6659 (0.7464)  time: 0.6182  data: 0.0001  max mem: 14587
[2024-01-21 16:58:23 root] (utils.py 302): INFO Epoch: [0]  [ 210/4926]  eta: 0:49:25  lr_architecture: 0.010000  loss_cls: 6.9960 (7.0490)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6335 (0.7410)  time: 0.6171  data: 0.0001  max mem: 14587
[2024-01-21 16:58:30 root] (utils.py 302): INFO Epoch: [0]  [ 220/4926]  eta: 0:49:17  lr_architecture: 0.010000  loss_cls: 6.9871 (7.0463)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6337 (0.7367)  time: 0.6180  data: 0.0001  max mem: 14587
[2024-01-21 16:58:36 root] (utils.py 302): INFO Epoch: [0]  [ 230/4926]  eta: 0:49:09  lr_architecture: 0.010000  loss_cls: 6.9867 (7.0436)  loss_flops: 857.0523 (857.0523)  flops: 32.2755 (32.2755)  grad_norm: 0.6513 (0.7340)  time: 0.6188  data: 0.0001  max mem: 14587
[2024-01-21 16:59:18 root] (main_pitome.py 219): INFO Namespace(batch_size=64, epochs=5, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 16:59:21 root] (main_pitome.py 264): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 16:59:23 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 16:59:29 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 16:59:36 root] (main_pitome.py 446): INFO Start training for 5 epochs
[2024-01-21 16:59:39 root] (utils.py 302): INFO Epoch: [0]  [   0/4926]  eta: 3:46:41  lr_architecture: 0.010000  loss_cls: 3.4130 (3.4130)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 9.4229 (9.4229)  time: 2.7611  data: 0.0008  max mem: 10987
[2024-01-21 16:59:45 root] (utils.py 302): INFO Epoch: [0]  [  10/4926]  eta: 1:08:54  lr_architecture: 0.010000  loss_cls: 7.5376 (7.2831)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.1803 (2.0192)  time: 0.8410  data: 0.0002  max mem: 14432
[2024-01-21 16:59:51 root] (utils.py 302): INFO Epoch: [0]  [  20/4926]  eta: 0:59:56  lr_architecture: 0.010000  loss_cls: 7.4079 (7.3215)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.9764 (1.4387)  time: 0.6317  data: 0.0001  max mem: 14434
[2024-01-21 16:59:58 root] (utils.py 302): INFO Epoch: [0]  [  30/4926]  eta: 0:56:39  lr_architecture: 0.010000  loss_cls: 7.1456 (7.2458)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6895 (1.1816)  time: 0.6138  data: 0.0001  max mem: 14434
[2024-01-21 17:00:04 root] (utils.py 302): INFO Epoch: [0]  [  40/4926]  eta: 0:54:57  lr_architecture: 0.010000  loss_cls: 7.0570 (7.1968)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6252 (1.0374)  time: 0.6137  data: 0.0001  max mem: 14434
[2024-01-21 17:00:10 root] (utils.py 302): INFO Epoch: [0]  [  50/4926]  eta: 0:53:52  lr_architecture: 0.010000  loss_cls: 7.0456 (7.1647)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5731 (0.9519)  time: 0.6140  data: 0.0001  max mem: 14434
[2024-01-21 17:00:16 root] (utils.py 302): INFO Epoch: [0]  [  60/4926]  eta: 0:53:05  lr_architecture: 0.010000  loss_cls: 7.0228 (7.1386)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5753 (0.8909)  time: 0.6135  data: 0.0001  max mem: 14434
[2024-01-21 17:00:22 root] (utils.py 302): INFO Epoch: [0]  [  70/4926]  eta: 0:52:32  lr_architecture: 0.010000  loss_cls: 6.9922 (7.1180)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5796 (0.8483)  time: 0.6145  data: 0.0001  max mem: 14434
[2024-01-21 17:00:28 root] (utils.py 302): INFO Epoch: [0]  [  80/4926]  eta: 0:52:05  lr_architecture: 0.010000  loss_cls: 7.0025 (7.1058)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5887 (0.8158)  time: 0.6151  data: 0.0001  max mem: 14434
[2024-01-21 17:00:34 root] (utils.py 302): INFO Epoch: [0]  [  90/4926]  eta: 0:51:42  lr_architecture: 0.010000  loss_cls: 7.0199 (7.0959)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5943 (0.7935)  time: 0.6141  data: 0.0001  max mem: 14434
[2024-01-21 17:00:41 root] (utils.py 302): INFO Epoch: [0]  [ 100/4926]  eta: 0:51:23  lr_architecture: 0.010000  loss_cls: 7.0199 (7.0873)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6133 (0.7774)  time: 0.6146  data: 0.0001  max mem: 14434
[2024-01-21 17:00:47 root] (utils.py 302): INFO Epoch: [0]  [ 110/4926]  eta: 0:51:06  lr_architecture: 0.010000  loss_cls: 6.9987 (7.0787)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6184 (0.7631)  time: 0.6145  data: 0.0001  max mem: 14434
[2024-01-21 17:00:53 root] (utils.py 302): INFO Epoch: [0]  [ 120/4926]  eta: 0:50:50  lr_architecture: 0.010000  loss_cls: 7.0061 (7.0733)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6203 (0.7528)  time: 0.6131  data: 0.0001  max mem: 14434
[2024-01-21 17:00:59 root] (utils.py 302): INFO Epoch: [0]  [ 130/4926]  eta: 0:50:35  lr_architecture: 0.010000  loss_cls: 7.0193 (7.0658)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5944 (0.7393)  time: 0.6123  data: 0.0001  max mem: 14434
[2024-01-21 17:01:05 root] (utils.py 302): INFO Epoch: [0]  [ 140/4926]  eta: 0:50:22  lr_architecture: 0.010000  loss_cls: 6.9869 (7.0604)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5944 (0.7343)  time: 0.6123  data: 0.0001  max mem: 14434
[2024-01-21 17:01:11 root] (utils.py 302): INFO Epoch: [0]  [ 150/4926]  eta: 0:50:10  lr_architecture: 0.010000  loss_cls: 7.0125 (7.0570)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6336 (0.7273)  time: 0.6132  data: 0.0001  max mem: 14434
[2024-01-21 17:01:17 root] (utils.py 302): INFO Epoch: [0]  [ 160/4926]  eta: 0:49:59  lr_architecture: 0.010000  loss_cls: 7.0098 (7.0533)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6168 (0.7225)  time: 0.6144  data: 0.0001  max mem: 14434
[2024-01-21 17:01:23 root] (utils.py 302): INFO Epoch: [0]  [ 170/4926]  eta: 0:49:49  lr_architecture: 0.010000  loss_cls: 6.9900 (7.0498)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6369 (0.7186)  time: 0.6145  data: 0.0001  max mem: 14434
[2024-01-21 17:01:30 root] (utils.py 302): INFO Epoch: [0]  [ 180/4926]  eta: 0:49:39  lr_architecture: 0.010000  loss_cls: 6.9900 (7.0472)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6385 (0.7139)  time: 0.6145  data: 0.0001  max mem: 14434
[2024-01-21 17:01:36 root] (utils.py 302): INFO Epoch: [0]  [ 190/4926]  eta: 0:49:29  lr_architecture: 0.010000  loss_cls: 6.9940 (7.0454)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6392 (0.7104)  time: 0.6149  data: 0.0001  max mem: 14434
[2024-01-21 17:01:42 root] (utils.py 302): INFO Epoch: [0]  [ 200/4926]  eta: 0:49:20  lr_architecture: 0.010000  loss_cls: 6.9899 (7.0429)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6539 (0.7093)  time: 0.6145  data: 0.0001  max mem: 14434
[2024-01-21 17:01:48 root] (utils.py 302): INFO Epoch: [0]  [ 210/4926]  eta: 0:49:11  lr_architecture: 0.010000  loss_cls: 6.9949 (7.0398)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6626 (0.7069)  time: 0.6145  data: 0.0001  max mem: 14434
[2024-01-21 17:01:54 root] (utils.py 302): INFO Epoch: [0]  [ 220/4926]  eta: 0:49:02  lr_architecture: 0.010000  loss_cls: 6.9942 (7.0372)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6700 (0.7048)  time: 0.6145  data: 0.0001  max mem: 14434
[2024-01-21 17:07:01 root] (main_pitome.py 219): INFO Namespace(batch_size=64, epochs=5, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 17:07:05 root] (main_pitome.py 264): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 17:07:06 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 17:07:13 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 17:07:20 root] (main_pitome.py 446): INFO Start training for 5 epochs
[2024-01-21 17:08:29 root] (main_pitome.py 219): INFO Namespace(batch_size=64, epochs=5, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 17:08:32 root] (main_pitome.py 264): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 17:08:34 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 17:08:40 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 17:08:47 root] (main_pitome.py 446): INFO Start training for 5 epochs
[2024-01-21 17:08:50 root] (utils.py 302): INFO Epoch: [0]  [   0/4926]  eta: 3:43:28  lr_architecture: 0.010000  loss_cls: 3.4186 (3.4186)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 8.7347 (8.7347)  time: 2.7219  data: 0.0006  max mem: 10987
[2024-01-21 17:08:56 root] (utils.py 302): INFO Epoch: [0]  [  10/4926]  eta: 1:07:26  lr_architecture: 0.010000  loss_cls: 7.7732 (7.3828)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.2888 (2.1405)  time: 0.8231  data: 0.0001  max mem: 14432
[2024-01-21 17:09:02 root] (utils.py 302): INFO Epoch: [0]  [  20/4926]  eta: 0:59:06  lr_architecture: 0.010000  loss_cls: 7.6786 (7.4821)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.0581 (1.5520)  time: 0.6230  data: 0.0001  max mem: 14434
[2024-01-21 17:09:08 root] (utils.py 302): INFO Epoch: [0]  [  30/4926]  eta: 0:56:06  lr_architecture: 0.010000  loss_cls: 7.2521 (7.3837)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.7337 (1.2633)  time: 0.6130  data: 0.0001  max mem: 14434
[2024-01-21 17:09:15 root] (utils.py 302): INFO Epoch: [0]  [  40/4926]  eta: 0:54:31  lr_architecture: 0.010000  loss_cls: 7.0805 (7.3063)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.6310 (1.1065)  time: 0.6136  data: 0.0001  max mem: 14434
[2024-01-21 17:09:21 root] (utils.py 302): INFO Epoch: [0]  [  50/4926]  eta: 0:53:29  lr_architecture: 0.010000  loss_cls: 7.0357 (7.2499)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5784 (0.9989)  time: 0.6127  data: 0.0001  max mem: 14434
[2024-01-21 17:09:27 root] (utils.py 302): INFO Epoch: [0]  [  60/4926]  eta: 0:52:47  lr_architecture: 0.010000  loss_cls: 6.9920 (7.2065)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5475 (0.9240)  time: 0.6128  data: 0.0001  max mem: 14434
[2024-01-21 17:09:33 root] (utils.py 302): INFO Epoch: [0]  [  70/4926]  eta: 0:52:14  lr_architecture: 0.010000  loss_cls: 6.9847 (7.1772)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5477 (0.8724)  time: 0.6133  data: 0.0001  max mem: 14434
[2024-01-21 17:09:39 root] (utils.py 302): INFO Epoch: [0]  [  80/4926]  eta: 0:51:48  lr_architecture: 0.010000  loss_cls: 6.9921 (7.1545)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5538 (0.8330)  time: 0.6126  data: 0.0001  max mem: 14434
[2024-01-21 17:09:45 root] (utils.py 302): INFO Epoch: [0]  [  90/4926]  eta: 0:51:28  lr_architecture: 0.010000  loss_cls: 7.0102 (7.1395)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5538 (0.8083)  time: 0.6138  data: 0.0001  max mem: 14434
[2024-01-21 17:09:51 root] (utils.py 302): INFO Epoch: [0]  [ 100/4926]  eta: 0:51:08  lr_architecture: 0.010000  loss_cls: 7.0215 (7.1256)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 0.5798 (0.7882)  time: 0.6134  data: 0.0001  max mem: 14434
[2024-01-21 17:10:38 root] (main_pitome.py 219): INFO Namespace(batch_size=64, epochs=5, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 17:10:42 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 17:10:48 root] (main_pitome.py 391): INFO number of params: 304326632
[2024-01-21 17:10:55 root] (main_pitome.py 446): INFO Start training for 5 epochs
[2024-01-21 17:10:57 root] (utils.py 302): INFO Epoch: [0]  [    0/19704]  eta: 11:52:46  lr_architecture: 0.010000  loss_cls: 3.1518 (3.1518)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 18.6736 (18.6736)  time: 2.1704  data: 0.0012  max mem: 10983
[2024-01-21 17:11:01 root] (utils.py 302): INFO Epoch: [0]  [   10/19704]  eta: 3:06:48  lr_architecture: 0.010000  loss_cls: 8.1049 (7.7033)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.5934 (inf)  time: 0.5692  data: 0.0002  max mem: 14439
[2024-01-21 17:11:05 root] (utils.py 302): INFO Epoch: [0]  [   20/19704]  eta: 2:40:52  lr_architecture: 0.010000  loss_cls: 8.4660 (8.0426)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1148 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:11:09 root] (utils.py 302): INFO Epoch: [0]  [   30/19704]  eta: 2:31:39  lr_architecture: 0.010000  loss_cls: 7.9523 (7.9579)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8523 (inf)  time: 0.4039  data: 0.0001  max mem: 14439
[2024-01-21 17:11:13 root] (utils.py 302): INFO Epoch: [0]  [   40/19704]  eta: 2:26:52  lr_architecture: 0.010000  loss_cls: 7.5096 (7.8332)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.5098 (inf)  time: 0.4038  data: 0.0001  max mem: 14439
[2024-01-21 17:11:17 root] (utils.py 302): INFO Epoch: [0]  [   50/19704]  eta: 2:23:51  lr_architecture: 0.010000  loss_cls: 7.4130 (7.7404)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3434 (inf)  time: 0.4030  data: 0.0001  max mem: 14439
[2024-01-21 17:11:21 root] (utils.py 302): INFO Epoch: [0]  [   60/19704]  eta: 2:21:55  lr_architecture: 0.010000  loss_cls: 7.3359 (7.6678)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3524 (inf)  time: 0.4034  data: 0.0001  max mem: 14439
[2024-01-21 17:11:25 root] (utils.py 302): INFO Epoch: [0]  [   70/19704]  eta: 2:20:29  lr_architecture: 0.010000  loss_cls: 7.1903 (7.5934)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.2918 (inf)  time: 0.4042  data: 0.0001  max mem: 14439
[2024-01-21 17:11:29 root] (utils.py 302): INFO Epoch: [0]  [   80/19704]  eta: 2:19:24  lr_architecture: 0.010000  loss_cls: 7.1198 (7.5334)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.2103 (inf)  time: 0.4042  data: 0.0001  max mem: 14439
[2024-01-21 17:11:33 root] (utils.py 302): INFO Epoch: [0]  [   90/19704]  eta: 2:18:32  lr_architecture: 0.010000  loss_cls: 7.1300 (7.4950)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.2138 (inf)  time: 0.4043  data: 0.0001  max mem: 14439
[2024-01-21 17:11:37 root] (utils.py 302): INFO Epoch: [0]  [  100/19704]  eta: 2:17:50  lr_architecture: 0.010000  loss_cls: 7.1259 (7.4539)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.2712 (inf)  time: 0.4043  data: 0.0001  max mem: 14439
[2024-01-21 17:11:41 root] (utils.py 302): INFO Epoch: [0]  [  110/19704]  eta: 2:17:16  lr_architecture: 0.010000  loss_cls: 7.0840 (7.4248)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3081 (inf)  time: 0.4047  data: 0.0001  max mem: 14439
[2024-01-21 17:11:45 root] (utils.py 302): INFO Epoch: [0]  [  120/19704]  eta: 2:16:48  lr_architecture: 0.010000  loss_cls: 7.0867 (7.3950)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3096 (inf)  time: 0.4052  data: 0.0001  max mem: 14439
[2024-01-21 17:11:50 root] (utils.py 302): INFO Epoch: [0]  [  130/19704]  eta: 2:16:23  lr_architecture: 0.010000  loss_cls: 7.1148 (7.3773)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3384 (inf)  time: 0.4055  data: 0.0001  max mem: 14439
[2024-01-21 17:11:54 root] (utils.py 302): INFO Epoch: [0]  [  140/19704]  eta: 2:16:01  lr_architecture: 0.010000  loss_cls: 7.0975 (7.3551)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3381 (inf)  time: 0.4052  data: 0.0001  max mem: 14439
[2024-01-21 17:11:58 root] (utils.py 302): INFO Epoch: [0]  [  150/19704]  eta: 2:15:42  lr_architecture: 0.010000  loss_cls: 7.0867 (7.3393)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3381 (inf)  time: 0.4051  data: 0.0001  max mem: 14439
[2024-01-21 17:12:02 root] (utils.py 302): INFO Epoch: [0]  [  160/19704]  eta: 2:15:25  lr_architecture: 0.010000  loss_cls: 7.0963 (7.3210)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3366 (inf)  time: 0.4057  data: 0.0001  max mem: 14439
[2024-01-21 17:12:06 root] (utils.py 302): INFO Epoch: [0]  [  170/19704]  eta: 2:15:09  lr_architecture: 0.010000  loss_cls: 7.0793 (7.3073)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3609 (inf)  time: 0.4057  data: 0.0001  max mem: 14439
[2024-01-21 17:12:10 root] (utils.py 302): INFO Epoch: [0]  [  180/19704]  eta: 2:14:55  lr_architecture: 0.010000  loss_cls: 7.1002 (7.2963)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4003 (inf)  time: 0.4060  data: 0.0001  max mem: 14439
[2024-01-21 17:12:14 root] (utils.py 302): INFO Epoch: [0]  [  190/19704]  eta: 2:14:42  lr_architecture: 0.010000  loss_cls: 7.1070 (7.2853)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4337 (inf)  time: 0.4058  data: 0.0001  max mem: 14439
[2024-01-21 17:12:18 root] (utils.py 302): INFO Epoch: [0]  [  200/19704]  eta: 2:14:30  lr_architecture: 0.010000  loss_cls: 7.0655 (7.2736)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4111 (inf)  time: 0.4056  data: 0.0001  max mem: 14439
[2024-01-21 17:12:22 root] (utils.py 302): INFO Epoch: [0]  [  210/19704]  eta: 2:14:20  lr_architecture: 0.010000  loss_cls: 7.0821 (7.2646)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3431 (inf)  time: 0.4068  data: 0.0001  max mem: 14439
[2024-01-21 17:12:26 root] (utils.py 302): INFO Epoch: [0]  [  220/19704]  eta: 2:14:09  lr_architecture: 0.010000  loss_cls: 7.0965 (7.2568)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3397 (inf)  time: 0.4068  data: 0.0001  max mem: 14439
[2024-01-21 17:12:30 root] (utils.py 302): INFO Epoch: [0]  [  230/19704]  eta: 2:13:59  lr_architecture: 0.010000  loss_cls: 7.1303 (7.2502)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.5306 (inf)  time: 0.4062  data: 0.0001  max mem: 14439
[2024-01-21 17:12:34 root] (utils.py 302): INFO Epoch: [0]  [  240/19704]  eta: 2:13:50  lr_architecture: 0.010000  loss_cls: 7.1303 (7.2438)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.5127 (inf)  time: 0.4063  data: 0.0001  max mem: 14439
[2024-01-21 17:12:38 root] (utils.py 302): INFO Epoch: [0]  [  250/19704]  eta: 2:13:41  lr_architecture: 0.010000  loss_cls: 7.1550 (7.2399)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.5127 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:12:42 root] (utils.py 302): INFO Epoch: [0]  [  260/19704]  eta: 2:13:32  lr_architecture: 0.010000  loss_cls: 7.1550 (7.2338)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4607 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:12:46 root] (utils.py 302): INFO Epoch: [0]  [  270/19704]  eta: 2:13:25  lr_architecture: 0.010000  loss_cls: 7.0629 (7.2272)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4377 (inf)  time: 0.4066  data: 0.0001  max mem: 14439
[2024-01-21 17:12:50 root] (utils.py 302): INFO Epoch: [0]  [  280/19704]  eta: 2:13:17  lr_architecture: 0.010000  loss_cls: 7.0417 (7.2209)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4064 (inf)  time: 0.4068  data: 0.0001  max mem: 14439
[2024-01-21 17:12:55 root] (utils.py 302): INFO Epoch: [0]  [  290/19704]  eta: 2:13:09  lr_architecture: 0.010000  loss_cls: 7.0937 (7.2179)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3911 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:12:59 root] (utils.py 302): INFO Epoch: [0]  [  300/19704]  eta: 2:13:01  lr_architecture: 0.010000  loss_cls: 7.1033 (7.2138)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4797 (inf)  time: 0.4061  data: 0.0001  max mem: 14439
[2024-01-21 17:13:03 root] (utils.py 302): INFO Epoch: [0]  [  310/19704]  eta: 2:12:54  lr_architecture: 0.010000  loss_cls: 7.1255 (7.2110)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.5541 (inf)  time: 0.4057  data: 0.0001  max mem: 14439
[2024-01-21 17:13:07 root] (utils.py 302): INFO Epoch: [0]  [  320/19704]  eta: 2:12:46  lr_architecture: 0.010000  loss_cls: 7.1255 (7.2084)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.5280 (inf)  time: 0.4056  data: 0.0001  max mem: 14439
[2024-01-21 17:13:11 root] (utils.py 302): INFO Epoch: [0]  [  330/19704]  eta: 2:12:39  lr_architecture: 0.010000  loss_cls: 7.0880 (7.2063)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.5222 (inf)  time: 0.4060  data: 0.0001  max mem: 14439
[2024-01-21 17:13:15 root] (utils.py 302): INFO Epoch: [0]  [  340/19704]  eta: 2:12:33  lr_architecture: 0.010000  loss_cls: 7.0880 (7.2028)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.5179 (inf)  time: 0.4062  data: 0.0001  max mem: 14439
[2024-01-21 17:13:19 root] (utils.py 302): INFO Epoch: [0]  [  350/19704]  eta: 2:12:26  lr_architecture: 0.010000  loss_cls: 7.0978 (7.1997)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4992 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:13:23 root] (utils.py 302): INFO Epoch: [0]  [  360/19704]  eta: 2:12:20  lr_architecture: 0.010000  loss_cls: 7.1051 (7.1974)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.5790 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:13:27 root] (utils.py 302): INFO Epoch: [0]  [  370/19704]  eta: 2:12:14  lr_architecture: 0.010000  loss_cls: 7.1311 (7.1965)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6596 (inf)  time: 0.4062  data: 0.0001  max mem: 14439
[2024-01-21 17:13:31 root] (utils.py 302): INFO Epoch: [0]  [  380/19704]  eta: 2:12:07  lr_architecture: 0.010000  loss_cls: 7.1337 (7.1943)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6409 (inf)  time: 0.4060  data: 0.0001  max mem: 14439
[2024-01-21 17:13:35 root] (utils.py 302): INFO Epoch: [0]  [  390/19704]  eta: 2:12:01  lr_architecture: 0.010000  loss_cls: 7.1153 (7.1929)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6537 (inf)  time: 0.4057  data: 0.0001  max mem: 14439
[2024-01-21 17:13:39 root] (utils.py 302): INFO Epoch: [0]  [  400/19704]  eta: 2:11:55  lr_architecture: 0.010000  loss_cls: 7.1143 (7.1908)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6590 (inf)  time: 0.4062  data: 0.0001  max mem: 14439
[2024-01-21 17:13:43 root] (utils.py 302): INFO Epoch: [0]  [  410/19704]  eta: 2:11:49  lr_architecture: 0.010000  loss_cls: 7.0844 (7.1881)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.5480 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:13:47 root] (utils.py 302): INFO Epoch: [0]  [  420/19704]  eta: 2:11:43  lr_architecture: 0.010000  loss_cls: 7.0905 (7.1868)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.5480 (inf)  time: 0.4061  data: 0.0001  max mem: 14439
[2024-01-21 17:13:51 root] (utils.py 302): INFO Epoch: [0]  [  430/19704]  eta: 2:11:37  lr_architecture: 0.010000  loss_cls: 7.0649 (7.1841)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6252 (inf)  time: 0.4055  data: 0.0001  max mem: 14439
[2024-01-21 17:13:55 root] (utils.py 302): INFO Epoch: [0]  [  440/19704]  eta: 2:11:31  lr_architecture: 0.010000  loss_cls: 7.0666 (7.1819)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6274 (inf)  time: 0.4049  data: 0.0001  max mem: 14439
[2024-01-21 17:13:59 root] (utils.py 302): INFO Epoch: [0]  [  450/19704]  eta: 2:11:25  lr_architecture: 0.010000  loss_cls: 7.0770 (7.1798)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6403 (inf)  time: 0.4054  data: 0.0001  max mem: 14439
[2024-01-21 17:14:04 root] (utils.py 302): INFO Epoch: [0]  [  460/19704]  eta: 2:11:19  lr_architecture: 0.010000  loss_cls: 7.0705 (7.1775)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6295 (inf)  time: 0.4054  data: 0.0001  max mem: 14439
[2024-01-21 17:14:08 root] (utils.py 302): INFO Epoch: [0]  [  470/19704]  eta: 2:11:13  lr_architecture: 0.010000  loss_cls: 7.0909 (7.1762)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6191 (inf)  time: 0.4054  data: 0.0001  max mem: 14439
[2024-01-21 17:14:12 root] (utils.py 302): INFO Epoch: [0]  [  480/19704]  eta: 2:11:08  lr_architecture: 0.010000  loss_cls: 7.1035 (7.1739)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6230 (inf)  time: 0.4060  data: 0.0001  max mem: 14439
[2024-01-21 17:14:16 root] (utils.py 302): INFO Epoch: [0]  [  490/19704]  eta: 2:11:03  lr_architecture: 0.010000  loss_cls: 7.1035 (7.1728)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6312 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:14:20 root] (utils.py 302): INFO Epoch: [0]  [  500/19704]  eta: 2:10:57  lr_architecture: 0.010000  loss_cls: 7.1239 (7.1720)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6312 (inf)  time: 0.4059  data: 0.0001  max mem: 14439
[2024-01-21 17:14:24 root] (utils.py 302): INFO Epoch: [0]  [  510/19704]  eta: 2:10:52  lr_architecture: 0.010000  loss_cls: 7.1239 (7.1701)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7289 (inf)  time: 0.4058  data: 0.0001  max mem: 14439
[2024-01-21 17:14:28 root] (utils.py 302): INFO Epoch: [0]  [  520/19704]  eta: 2:10:47  lr_architecture: 0.010000  loss_cls: 7.0955 (7.1683)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8173 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:14:32 root] (utils.py 302): INFO Epoch: [0]  [  530/19704]  eta: 2:10:47  lr_architecture: 0.010000  loss_cls: 7.0894 (7.1667)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7901 (inf)  time: 0.4136  data: 0.0001  max mem: 14439
[2024-01-21 17:14:36 root] (utils.py 302): INFO Epoch: [0]  [  540/19704]  eta: 2:10:42  lr_architecture: 0.010000  loss_cls: 7.0894 (7.1649)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6946 (inf)  time: 0.4132  data: 0.0001  max mem: 14439
[2024-01-21 17:14:40 root] (utils.py 302): INFO Epoch: [0]  [  550/19704]  eta: 2:10:36  lr_architecture: 0.010000  loss_cls: 7.0397 (7.1619)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7424 (inf)  time: 0.4057  data: 0.0001  max mem: 14439
[2024-01-21 17:14:44 root] (utils.py 302): INFO Epoch: [0]  [  560/19704]  eta: 2:10:31  lr_architecture: 0.010000  loss_cls: 7.0428 (7.1599)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7552 (inf)  time: 0.4058  data: 0.0001  max mem: 14439
[2024-01-21 17:14:48 root] (utils.py 302): INFO Epoch: [0]  [  570/19704]  eta: 2:10:26  lr_architecture: 0.010000  loss_cls: 7.1056 (7.1600)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7552 (inf)  time: 0.4056  data: 0.0001  max mem: 14439
[2024-01-21 17:14:52 root] (utils.py 302): INFO Epoch: [0]  [  580/19704]  eta: 2:10:20  lr_architecture: 0.010000  loss_cls: 7.0741 (7.1576)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7123 (inf)  time: 0.4050  data: 0.0001  max mem: 14439
[2024-01-21 17:14:56 root] (utils.py 302): INFO Epoch: [0]  [  590/19704]  eta: 2:10:15  lr_architecture: 0.010000  loss_cls: 7.0706 (7.1568)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6151 (inf)  time: 0.4052  data: 0.0001  max mem: 14439
[2024-01-21 17:15:00 root] (utils.py 302): INFO Epoch: [0]  [  600/19704]  eta: 2:10:10  lr_architecture: 0.010000  loss_cls: 7.0362 (7.1548)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6894 (inf)  time: 0.4056  data: 0.0001  max mem: 14439
[2024-01-21 17:15:05 root] (utils.py 302): INFO Epoch: [0]  [  610/19704]  eta: 2:10:05  lr_architecture: 0.010000  loss_cls: 7.0701 (7.1545)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7145 (inf)  time: 0.4056  data: 0.0001  max mem: 14439
[2024-01-21 17:15:09 root] (utils.py 302): INFO Epoch: [0]  [  620/19704]  eta: 2:10:00  lr_architecture: 0.010000  loss_cls: 7.1357 (7.1543)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8094 (inf)  time: 0.4055  data: 0.0001  max mem: 14439
[2024-01-21 17:15:13 root] (utils.py 302): INFO Epoch: [0]  [  630/19704]  eta: 2:09:55  lr_architecture: 0.010000  loss_cls: 7.1462 (7.1546)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8365 (inf)  time: 0.4057  data: 0.0001  max mem: 14439
[2024-01-21 17:15:17 root] (utils.py 302): INFO Epoch: [0]  [  640/19704]  eta: 2:09:50  lr_architecture: 0.010000  loss_cls: 7.0939 (7.1528)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7908 (inf)  time: 0.4057  data: 0.0001  max mem: 14439
[2024-01-21 17:15:21 root] (utils.py 302): INFO Epoch: [0]  [  650/19704]  eta: 2:09:45  lr_architecture: 0.010000  loss_cls: 7.0610 (7.1526)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8134 (inf)  time: 0.4058  data: 0.0001  max mem: 14439
[2024-01-21 17:15:25 root] (utils.py 302): INFO Epoch: [0]  [  660/19704]  eta: 2:09:40  lr_architecture: 0.010000  loss_cls: 7.0752 (7.1509)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9258 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:15:29 root] (utils.py 302): INFO Epoch: [0]  [  670/19704]  eta: 2:09:36  lr_architecture: 0.010000  loss_cls: 7.0396 (7.1494)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7152 (inf)  time: 0.4067  data: 0.0001  max mem: 14439
[2024-01-21 17:15:33 root] (utils.py 302): INFO Epoch: [0]  [  680/19704]  eta: 2:09:31  lr_architecture: 0.010000  loss_cls: 7.0396 (7.1473)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7656 (inf)  time: 0.4067  data: 0.0001  max mem: 14439
[2024-01-21 17:15:37 root] (utils.py 302): INFO Epoch: [0]  [  690/19704]  eta: 2:09:27  lr_architecture: 0.010000  loss_cls: 7.0354 (7.1465)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7493 (inf)  time: 0.4068  data: 0.0001  max mem: 14439
[2024-01-21 17:15:41 root] (utils.py 302): INFO Epoch: [0]  [  700/19704]  eta: 2:09:22  lr_architecture: 0.010000  loss_cls: 7.1194 (7.1460)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7398 (inf)  time: 0.4066  data: 0.0001  max mem: 14439
[2024-01-21 17:15:45 root] (utils.py 302): INFO Epoch: [0]  [  710/19704]  eta: 2:09:17  lr_architecture: 0.010000  loss_cls: 7.0591 (7.1445)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7999 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:15:49 root] (utils.py 302): INFO Epoch: [0]  [  720/19704]  eta: 2:09:13  lr_architecture: 0.010000  loss_cls: 7.0585 (7.1437)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8111 (inf)  time: 0.4063  data: 0.0001  max mem: 14439
[2024-01-21 17:15:53 root] (utils.py 302): INFO Epoch: [0]  [  730/19704]  eta: 2:09:08  lr_architecture: 0.010000  loss_cls: 7.0683 (7.1429)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8543 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:15:57 root] (utils.py 302): INFO Epoch: [0]  [  740/19704]  eta: 2:09:04  lr_architecture: 0.010000  loss_cls: 7.1148 (7.1429)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8984 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:16:01 root] (utils.py 302): INFO Epoch: [0]  [  750/19704]  eta: 2:08:59  lr_architecture: 0.010000  loss_cls: 7.0835 (7.1418)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8984 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:16:06 root] (utils.py 302): INFO Epoch: [0]  [  760/19704]  eta: 2:08:55  lr_architecture: 0.010000  loss_cls: 7.0498 (7.1417)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.7644 (inf)  time: 0.4067  data: 0.0001  max mem: 14439
[2024-01-21 17:16:10 root] (utils.py 302): INFO Epoch: [0]  [  770/19704]  eta: 2:08:50  lr_architecture: 0.010000  loss_cls: 7.0717 (7.1409)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8413 (inf)  time: 0.4068  data: 0.0001  max mem: 14439
[2024-01-21 17:16:14 root] (utils.py 302): INFO Epoch: [0]  [  780/19704]  eta: 2:08:46  lr_architecture: 0.010000  loss_cls: 7.0851 (7.1408)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0606 (inf)  time: 0.4071  data: 0.0001  max mem: 14439
[2024-01-21 17:16:18 root] (utils.py 302): INFO Epoch: [0]  [  790/19704]  eta: 2:08:41  lr_architecture: 0.010000  loss_cls: 7.1307 (7.1407)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.2334 (inf)  time: 0.4069  data: 0.0001  max mem: 14439
[2024-01-21 17:16:22 root] (utils.py 302): INFO Epoch: [0]  [  800/19704]  eta: 2:08:37  lr_architecture: 0.010000  loss_cls: 7.1523 (7.1411)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0381 (inf)  time: 0.4061  data: 0.0001  max mem: 14439
[2024-01-21 17:16:26 root] (utils.py 302): INFO Epoch: [0]  [  810/19704]  eta: 2:08:32  lr_architecture: 0.010000  loss_cls: 7.1130 (7.1403)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9694 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:16:30 root] (utils.py 302): INFO Epoch: [0]  [  820/19704]  eta: 2:08:28  lr_architecture: 0.010000  loss_cls: 7.1073 (7.1403)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8907 (inf)  time: 0.4066  data: 0.0001  max mem: 14439
[2024-01-21 17:16:34 root] (utils.py 302): INFO Epoch: [0]  [  830/19704]  eta: 2:08:23  lr_architecture: 0.010000  loss_cls: 7.1157 (7.1405)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9063 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:16:38 root] (utils.py 302): INFO Epoch: [0]  [  840/19704]  eta: 2:08:19  lr_architecture: 0.010000  loss_cls: 7.1228 (7.1401)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0248 (inf)  time: 0.4066  data: 0.0001  max mem: 14439
[2024-01-21 17:16:42 root] (utils.py 302): INFO Epoch: [0]  [  850/19704]  eta: 2:08:15  lr_architecture: 0.010000  loss_cls: 7.0474 (7.1386)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9479 (inf)  time: 0.4070  data: 0.0001  max mem: 14439
[2024-01-21 17:16:46 root] (utils.py 302): INFO Epoch: [0]  [  860/19704]  eta: 2:08:10  lr_architecture: 0.010000  loss_cls: 7.0514 (7.1380)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9014 (inf)  time: 0.4071  data: 0.0001  max mem: 14439
[2024-01-21 17:16:50 root] (utils.py 302): INFO Epoch: [0]  [  870/19704]  eta: 2:08:06  lr_architecture: 0.010000  loss_cls: 7.0513 (7.1372)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9125 (inf)  time: 0.4067  data: 0.0001  max mem: 14439
[2024-01-21 17:16:54 root] (utils.py 302): INFO Epoch: [0]  [  880/19704]  eta: 2:08:02  lr_architecture: 0.010000  loss_cls: 7.0626 (7.1370)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8360 (inf)  time: 0.4071  data: 0.0001  max mem: 14439
[2024-01-21 17:16:58 root] (utils.py 302): INFO Epoch: [0]  [  890/19704]  eta: 2:07:57  lr_architecture: 0.010000  loss_cls: 7.1047 (7.1368)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9431 (inf)  time: 0.4070  data: 0.0001  max mem: 14439
[2024-01-21 17:17:02 root] (utils.py 302): INFO Epoch: [0]  [  900/19704]  eta: 2:07:53  lr_architecture: 0.010000  loss_cls: 7.1513 (7.1366)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0430 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:17:07 root] (utils.py 302): INFO Epoch: [0]  [  910/19704]  eta: 2:07:48  lr_architecture: 0.010000  loss_cls: 7.1513 (7.1365)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0683 (inf)  time: 0.4060  data: 0.0001  max mem: 14439
[2024-01-21 17:17:11 root] (utils.py 302): INFO Epoch: [0]  [  920/19704]  eta: 2:07:44  lr_architecture: 0.010000  loss_cls: 7.1617 (7.1366)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0645 (inf)  time: 0.4055  data: 0.0001  max mem: 14439
[2024-01-21 17:17:15 root] (utils.py 302): INFO Epoch: [0]  [  930/19704]  eta: 2:07:39  lr_architecture: 0.010000  loss_cls: 7.0647 (7.1356)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9789 (inf)  time: 0.4053  data: 0.0001  max mem: 14439
[2024-01-21 17:17:19 root] (utils.py 302): INFO Epoch: [0]  [  940/19704]  eta: 2:07:34  lr_architecture: 0.010000  loss_cls: 7.0297 (7.1347)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9422 (inf)  time: 0.4051  data: 0.0001  max mem: 14439
[2024-01-21 17:17:23 root] (utils.py 302): INFO Epoch: [0]  [  950/19704]  eta: 2:07:30  lr_architecture: 0.010000  loss_cls: 7.0356 (7.1339)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9360 (inf)  time: 0.4062  data: 0.0001  max mem: 14439
[2024-01-21 17:17:27 root] (utils.py 302): INFO Epoch: [0]  [  960/19704]  eta: 2:07:26  lr_architecture: 0.010000  loss_cls: 7.0807 (7.1336)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9360 (inf)  time: 0.4069  data: 0.0001  max mem: 14439
[2024-01-21 17:17:31 root] (utils.py 302): INFO Epoch: [0]  [  970/19704]  eta: 2:07:21  lr_architecture: 0.010000  loss_cls: 7.0999 (7.1332)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9783 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:17:35 root] (utils.py 302): INFO Epoch: [0]  [  980/19704]  eta: 2:07:17  lr_architecture: 0.010000  loss_cls: 7.0845 (7.1323)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0308 (inf)  time: 0.4063  data: 0.0001  max mem: 14439
[2024-01-21 17:17:39 root] (utils.py 302): INFO Epoch: [0]  [  990/19704]  eta: 2:07:13  lr_architecture: 0.010000  loss_cls: 7.0784 (7.1316)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1052 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:17:43 root] (utils.py 302): INFO Epoch: [0]  [ 1000/19704]  eta: 2:07:08  lr_architecture: 0.010000  loss_cls: 7.0702 (7.1312)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0830 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:17:47 root] (utils.py 302): INFO Epoch: [0]  [ 1010/19704]  eta: 2:07:04  lr_architecture: 0.010000  loss_cls: 7.1056 (7.1305)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9306 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:17:51 root] (utils.py 302): INFO Epoch: [0]  [ 1020/19704]  eta: 2:07:00  lr_architecture: 0.010000  loss_cls: 7.0817 (7.1294)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9887 (inf)  time: 0.4068  data: 0.0001  max mem: 14439
[2024-01-21 17:17:55 root] (utils.py 302): INFO Epoch: [0]  [ 1030/19704]  eta: 2:06:55  lr_architecture: 0.010000  loss_cls: 7.0577 (7.1294)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1070 (inf)  time: 0.4067  data: 0.0001  max mem: 14439
[2024-01-21 17:17:59 root] (utils.py 302): INFO Epoch: [0]  [ 1040/19704]  eta: 2:06:51  lr_architecture: 0.010000  loss_cls: 7.1264 (7.1296)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9652 (inf)  time: 0.4068  data: 0.0001  max mem: 14439
[2024-01-21 17:18:03 root] (utils.py 302): INFO Epoch: [0]  [ 1050/19704]  eta: 2:06:47  lr_architecture: 0.010000  loss_cls: 7.1091 (7.1294)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9451 (inf)  time: 0.4066  data: 0.0001  max mem: 14439
[2024-01-21 17:18:07 root] (utils.py 302): INFO Epoch: [0]  [ 1060/19704]  eta: 2:06:43  lr_architecture: 0.010000  loss_cls: 7.0800 (7.1286)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.9600 (inf)  time: 0.4066  data: 0.0001  max mem: 14439
[2024-01-21 17:18:12 root] (utils.py 302): INFO Epoch: [0]  [ 1070/19704]  eta: 2:06:38  lr_architecture: 0.010000  loss_cls: 7.1451 (7.1287)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0767 (inf)  time: 0.4069  data: 0.0001  max mem: 14439
[2024-01-21 17:18:16 root] (utils.py 302): INFO Epoch: [0]  [ 1080/19704]  eta: 2:06:34  lr_architecture: 0.010000  loss_cls: 7.1555 (7.1284)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0946 (inf)  time: 0.4075  data: 0.0001  max mem: 14439
[2024-01-21 17:18:20 root] (utils.py 302): INFO Epoch: [0]  [ 1090/19704]  eta: 2:06:30  lr_architecture: 0.010000  loss_cls: 7.0550 (7.1279)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0437 (inf)  time: 0.4076  data: 0.0001  max mem: 14439
[2024-01-21 17:18:24 root] (utils.py 302): INFO Epoch: [0]  [ 1100/19704]  eta: 2:06:26  lr_architecture: 0.010000  loss_cls: 7.0721 (7.1276)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0364 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:18:28 root] (utils.py 302): INFO Epoch: [0]  [ 1110/19704]  eta: 2:06:21  lr_architecture: 0.010000  loss_cls: 7.0888 (7.1274)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0200 (inf)  time: 0.4063  data: 0.0001  max mem: 14439
[2024-01-21 17:18:32 root] (utils.py 302): INFO Epoch: [0]  [ 1120/19704]  eta: 2:06:17  lr_architecture: 0.010000  loss_cls: 7.0614 (7.1272)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0788 (inf)  time: 0.4067  data: 0.0001  max mem: 14439
[2024-01-21 17:18:36 root] (utils.py 302): INFO Epoch: [0]  [ 1130/19704]  eta: 2:06:13  lr_architecture: 0.010000  loss_cls: 7.0935 (7.1272)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0788 (inf)  time: 0.4068  data: 0.0001  max mem: 14439
[2024-01-21 17:18:40 root] (utils.py 302): INFO Epoch: [0]  [ 1140/19704]  eta: 2:06:09  lr_architecture: 0.010000  loss_cls: 7.0791 (7.1263)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0785 (inf)  time: 0.4069  data: 0.0001  max mem: 14439
[2024-01-21 17:18:44 root] (utils.py 302): INFO Epoch: [0]  [ 1150/19704]  eta: 2:06:04  lr_architecture: 0.010000  loss_cls: 7.0694 (7.1262)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0239 (inf)  time: 0.4067  data: 0.0001  max mem: 14439
[2024-01-21 17:18:48 root] (utils.py 302): INFO Epoch: [0]  [ 1160/19704]  eta: 2:06:00  lr_architecture: 0.010000  loss_cls: 7.1224 (7.1260)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0070 (inf)  time: 0.4059  data: 0.0001  max mem: 14439
[2024-01-21 17:18:52 root] (utils.py 302): INFO Epoch: [0]  [ 1170/19704]  eta: 2:05:56  lr_architecture: 0.010000  loss_cls: 7.0341 (7.1253)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0370 (inf)  time: 0.4058  data: 0.0001  max mem: 14439
[2024-01-21 17:18:56 root] (utils.py 302): INFO Epoch: [0]  [ 1180/19704]  eta: 2:05:51  lr_architecture: 0.010000  loss_cls: 7.0362 (7.1253)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0423 (inf)  time: 0.4056  data: 0.0001  max mem: 14439
[2024-01-21 17:19:00 root] (utils.py 302): INFO Epoch: [0]  [ 1190/19704]  eta: 2:05:47  lr_architecture: 0.010000  loss_cls: 7.0988 (7.1248)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1448 (inf)  time: 0.4055  data: 0.0001  max mem: 14439
[2024-01-21 17:19:04 root] (utils.py 302): INFO Epoch: [0]  [ 1200/19704]  eta: 2:05:42  lr_architecture: 0.010000  loss_cls: 7.0402 (7.1240)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.2075 (inf)  time: 0.4059  data: 0.0001  max mem: 14439
[2024-01-21 17:19:08 root] (utils.py 302): INFO Epoch: [0]  [ 1210/19704]  eta: 2:05:38  lr_architecture: 0.010000  loss_cls: 7.0630 (7.1239)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1242 (inf)  time: 0.4063  data: 0.0001  max mem: 14439
[2024-01-21 17:19:13 root] (utils.py 302): INFO Epoch: [0]  [ 1220/19704]  eta: 2:05:34  lr_architecture: 0.010000  loss_cls: 7.0680 (7.1232)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1022 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:19:17 root] (utils.py 302): INFO Epoch: [0]  [ 1230/19704]  eta: 2:05:30  lr_architecture: 0.010000  loss_cls: 7.0693 (7.1229)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0608 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:19:21 root] (utils.py 302): INFO Epoch: [0]  [ 1240/19704]  eta: 2:05:26  lr_architecture: 0.010000  loss_cls: 7.0790 (7.1226)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.3743 (inf)  time: 0.4069  data: 0.0001  max mem: 14439
[2024-01-21 17:19:25 root] (utils.py 302): INFO Epoch: [0]  [ 1250/19704]  eta: 2:05:22  lr_architecture: 0.010000  loss_cls: 7.0478 (7.1220)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0922 (inf)  time: 0.4074  data: 0.0001  max mem: 14439
[2024-01-21 17:19:29 root] (utils.py 302): INFO Epoch: [0]  [ 1260/19704]  eta: 2:05:17  lr_architecture: 0.010000  loss_cls: 7.0535 (7.1222)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1551 (inf)  time: 0.4075  data: 0.0001  max mem: 14439
[2024-01-21 17:19:33 root] (utils.py 302): INFO Epoch: [0]  [ 1270/19704]  eta: 2:05:13  lr_architecture: 0.010000  loss_cls: 7.0914 (7.1221)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1810 (inf)  time: 0.4072  data: 0.0001  max mem: 14439
[2024-01-21 17:19:37 root] (utils.py 302): INFO Epoch: [0]  [ 1280/19704]  eta: 2:05:09  lr_architecture: 0.010000  loss_cls: 7.0294 (7.1215)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1289 (inf)  time: 0.4072  data: 0.0001  max mem: 14439
[2024-01-21 17:19:41 root] (utils.py 302): INFO Epoch: [0]  [ 1290/19704]  eta: 2:05:05  lr_architecture: 0.010000  loss_cls: 7.0410 (7.1211)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0712 (inf)  time: 0.4070  data: 0.0001  max mem: 14439
[2024-01-21 17:19:45 root] (utils.py 302): INFO Epoch: [0]  [ 1300/19704]  eta: 2:05:01  lr_architecture: 0.010000  loss_cls: 7.1003 (7.1209)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0812 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:19:49 root] (utils.py 302): INFO Epoch: [0]  [ 1310/19704]  eta: 2:04:57  lr_architecture: 0.010000  loss_cls: 7.0679 (7.1203)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0350 (inf)  time: 0.4068  data: 0.0001  max mem: 14439
[2024-01-21 17:19:53 root] (utils.py 302): INFO Epoch: [0]  [ 1320/19704]  eta: 2:04:52  lr_architecture: 0.010000  loss_cls: 7.0679 (7.1201)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0350 (inf)  time: 0.4068  data: 0.0001  max mem: 14439
[2024-01-21 17:19:57 root] (utils.py 302): INFO Epoch: [0]  [ 1330/19704]  eta: 2:04:48  lr_architecture: 0.010000  loss_cls: 7.0885 (7.1203)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0850 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:20:01 root] (utils.py 302): INFO Epoch: [0]  [ 1340/19704]  eta: 2:04:44  lr_architecture: 0.010000  loss_cls: 7.0796 (7.1199)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1022 (inf)  time: 0.4062  data: 0.0001  max mem: 14439
[2024-01-21 17:20:05 root] (utils.py 302): INFO Epoch: [0]  [ 1350/19704]  eta: 2:04:40  lr_architecture: 0.010000  loss_cls: 7.0224 (7.1195)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0935 (inf)  time: 0.4065  data: 0.0001  max mem: 14439
[2024-01-21 17:20:10 root] (utils.py 302): INFO Epoch: [0]  [ 1360/19704]  eta: 2:04:36  lr_architecture: 0.010000  loss_cls: 7.0692 (7.1195)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.0340 (inf)  time: 0.4071  data: 0.0001  max mem: 14439
[2024-01-21 17:20:14 root] (utils.py 302): INFO Epoch: [0]  [ 1370/19704]  eta: 2:04:31  lr_architecture: 0.010000  loss_cls: 7.0735 (7.1191)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1038 (inf)  time: 0.4064  data: 0.0001  max mem: 14439
[2024-01-21 17:20:18 root] (utils.py 302): INFO Epoch: [0]  [ 1380/19704]  eta: 2:04:27  lr_architecture: 0.010000  loss_cls: 7.0455 (7.1188)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8818 (inf)  time: 0.4059  data: 0.0001  max mem: 14439
[2024-01-21 17:20:22 root] (utils.py 302): INFO Epoch: [0]  [ 1390/19704]  eta: 2:04:23  lr_architecture: 0.010000  loss_cls: 7.0891 (7.1187)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.3452 (inf)  time: 0.4068  data: 0.0001  max mem: 14439
[2024-01-21 17:20:26 root] (utils.py 302): INFO Epoch: [0]  [ 1400/19704]  eta: 2:04:19  lr_architecture: 0.010000  loss_cls: 7.0891 (7.1183)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.4715 (inf)  time: 0.4072  data: 0.0001  max mem: 14439
[2024-01-21 17:20:30 root] (utils.py 302): INFO Epoch: [0]  [ 1410/19704]  eta: 2:04:15  lr_architecture: 0.010000  loss_cls: 7.0809 (7.1180)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1716 (inf)  time: 0.4070  data: 0.0001  max mem: 14439
[2024-01-21 17:20:34 root] (utils.py 302): INFO Epoch: [0]  [ 1420/19704]  eta: 2:04:10  lr_architecture: 0.010000  loss_cls: 7.0665 (7.1177)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1716 (inf)  time: 0.4059  data: 0.0001  max mem: 14439
[2024-01-21 17:20:38 root] (utils.py 302): INFO Epoch: [0]  [ 1430/19704]  eta: 2:04:06  lr_architecture: 0.010000  loss_cls: 7.0665 (7.1175)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1941 (inf)  time: 0.4060  data: 0.0001  max mem: 14439
[2024-01-21 17:20:42 root] (utils.py 302): INFO Epoch: [0]  [ 1440/19704]  eta: 2:04:02  lr_architecture: 0.010000  loss_cls: 7.0846 (7.1172)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.1326 (inf)  time: 0.4063  data: 0.0001  max mem: 14439
[2024-01-21 17:20:44 root] (engine.py 60): INFO Loss is nan, stopping training
[2024-01-21 17:25:48 root] (main_pitome.py 219): INFO Namespace(batch_size=64, epochs=5, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 17:35:19 root] (main_pitome.py 219): INFO Namespace(batch_size=100, epochs=300, ratio=0.95, model='deit_base_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='$', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=True, warmup_compression_rate=False, distributed=False)
[2024-01-21 17:35:23 root] (main_pitome.py 304): INFO Creating model: deit_base_patch16_224
[2024-01-21 17:35:25 timm.models.helpers] (helpers.py 183): INFO Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth)
[2024-01-21 17:36:18 root] (main_pitome.py 219): INFO Namespace(batch_size=64, epochs=5, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 17:36:23 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 17:36:28 root] (main_pitome.py 390): INFO number of params: 304326632
[2024-01-21 17:36:35 root] (main_pitome.py 445): INFO Start training for 5 epochs
[2024-01-21 17:37:17 root] (main_pitome.py 219): INFO Namespace(batch_size=64, epochs=5, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 17:37:22 root] (main_pitome.py 304): INFO Creating model: vit_large_patch16_mae
[2024-01-21 17:37:27 root] (main_pitome.py 390): INFO number of params: 304326632
[2024-01-21 17:37:34 root] (main_pitome.py 445): INFO Start training for 5 epochs
[2024-01-21 17:37:36 root] (utils.py 302): INFO Epoch: [0]  [    0/19704]  eta: 11:40:11  lr_architecture: 0.010000  loss_cls: 3.1604 (3.1604)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 20.9582 (20.9582)  time: 2.1321  data: 0.0007  max mem: 10983
[2024-01-21 17:37:40 root] (utils.py 302): INFO Epoch: [0]  [   10/19704]  eta: 3:04:51  lr_architecture: 0.010000  loss_cls: 8.2670 (8.1534)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.4447 (inf)  time: 0.5632  data: 0.0001  max mem: 14439
[2024-01-21 17:37:44 root] (utils.py 302): INFO Epoch: [0]  [   20/19704]  eta: 2:39:47  lr_architecture: 0.010000  loss_cls: 8.5741 (8.3856)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 2.2706 (inf)  time: 0.4048  data: 0.0001  max mem: 14439
[2024-01-21 17:37:48 root] (utils.py 302): INFO Epoch: [0]  [   30/19704]  eta: 2:30:59  lr_architecture: 0.010000  loss_cls: 8.2514 (8.2743)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.8811 (inf)  time: 0.4040  data: 0.0001  max mem: 14439
[2024-01-21 17:37:52 root] (utils.py 302): INFO Epoch: [0]  [   40/19704]  eta: 2:26:26  lr_architecture: 0.010000  loss_cls: 7.6610 (8.1176)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.6114 (inf)  time: 0.4046  data: 0.0001  max mem: 14439
[2024-01-21 17:37:56 root] (utils.py 302): INFO Epoch: [0]  [   50/19704]  eta: 2:23:34  lr_architecture: 0.010000  loss_cls: 7.6099 (8.0087)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4457 (inf)  time: 0.4040  data: 0.0001  max mem: 14439
[2024-01-21 17:38:00 root] (utils.py 302): INFO Epoch: [0]  [   60/19704]  eta: 2:21:37  lr_architecture: 0.010000  loss_cls: 7.4096 (7.9019)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4258 (inf)  time: 0.4034  data: 0.0001  max mem: 14439
[2024-01-21 17:38:04 root] (utils.py 302): INFO Epoch: [0]  [   70/19704]  eta: 2:20:10  lr_architecture: 0.010000  loss_cls: 7.2118 (7.7987)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.2971 (inf)  time: 0.4030  data: 0.0001  max mem: 14439
[2024-01-21 17:38:08 root] (utils.py 302): INFO Epoch: [0]  [   80/19704]  eta: 2:19:00  lr_architecture: 0.010000  loss_cls: 7.1319 (7.7132)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.2000 (inf)  time: 0.4020  data: 0.0001  max mem: 14439
[2024-01-21 17:38:12 root] (utils.py 302): INFO Epoch: [0]  [   90/19704]  eta: 2:18:09  lr_architecture: 0.010000  loss_cls: 7.1545 (7.6546)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.2363 (inf)  time: 0.4022  data: 0.0001  max mem: 14439
[2024-01-21 17:38:16 root] (utils.py 302): INFO Epoch: [0]  [  100/19704]  eta: 2:17:28  lr_architecture: 0.010000  loss_cls: 7.1085 (7.5954)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.2363 (inf)  time: 0.4035  data: 0.0001  max mem: 14439
[2024-01-21 17:38:20 root] (utils.py 302): INFO Epoch: [0]  [  110/19704]  eta: 2:16:55  lr_architecture: 0.010000  loss_cls: 7.0547 (7.5509)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.2786 (inf)  time: 0.4040  data: 0.0001  max mem: 14439
[2024-01-21 17:38:24 root] (utils.py 302): INFO Epoch: [0]  [  120/19704]  eta: 2:16:26  lr_architecture: 0.010000  loss_cls: 7.1076 (7.5123)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.2786 (inf)  time: 0.4042  data: 0.0001  max mem: 14439
[2024-01-21 17:38:29 root] (utils.py 302): INFO Epoch: [0]  [  130/19704]  eta: 2:15:59  lr_architecture: 0.010000  loss_cls: 7.1364 (7.4849)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3319 (inf)  time: 0.4035  data: 0.0001  max mem: 14439
[2024-01-21 17:38:33 root] (utils.py 302): INFO Epoch: [0]  [  140/19704]  eta: 2:15:37  lr_architecture: 0.010000  loss_cls: 7.1213 (7.4559)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3918 (inf)  time: 0.4034  data: 0.0001  max mem: 14439
[2024-01-21 17:38:37 root] (utils.py 302): INFO Epoch: [0]  [  150/19704]  eta: 2:15:19  lr_architecture: 0.010000  loss_cls: 7.0713 (7.4323)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4366 (inf)  time: 0.4047  data: 0.0001  max mem: 14439
[2024-01-21 17:38:41 root] (utils.py 302): INFO Epoch: [0]  [  160/19704]  eta: 2:15:03  lr_architecture: 0.010000  loss_cls: 7.0563 (7.4093)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4015 (inf)  time: 0.4054  data: 0.0001  max mem: 14439
[2024-01-21 17:38:45 root] (utils.py 302): INFO Epoch: [0]  [  170/19704]  eta: 2:14:47  lr_architecture: 0.010000  loss_cls: 7.0582 (7.3892)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3767 (inf)  time: 0.4046  data: 0.0001  max mem: 14439
[2024-01-21 17:38:49 root] (utils.py 302): INFO Epoch: [0]  [  180/19704]  eta: 2:14:32  lr_architecture: 0.010000  loss_cls: 7.0970 (7.3741)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4017 (inf)  time: 0.4042  data: 0.0001  max mem: 14439
[2024-01-21 17:38:53 root] (utils.py 302): INFO Epoch: [0]  [  190/19704]  eta: 2:14:19  lr_architecture: 0.010000  loss_cls: 7.0899 (7.3576)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4017 (inf)  time: 0.4045  data: 0.0001  max mem: 14439
[2024-01-21 17:38:57 root] (utils.py 302): INFO Epoch: [0]  [  200/19704]  eta: 2:14:10  lr_architecture: 0.010000  loss_cls: 7.0607 (7.3416)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3859 (inf)  time: 0.4060  data: 0.0001  max mem: 14439
[2024-01-21 17:39:01 root] (utils.py 302): INFO Epoch: [0]  [  210/19704]  eta: 2:13:59  lr_architecture: 0.010000  loss_cls: 7.0607 (7.3289)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3330 (inf)  time: 0.4067  data: 0.0001  max mem: 14439
[2024-01-21 17:39:05 root] (utils.py 302): INFO Epoch: [0]  [  220/19704]  eta: 2:13:49  lr_architecture: 0.010000  loss_cls: 7.0744 (7.3175)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.3829 (inf)  time: 0.4058  data: 0.0001  max mem: 14439
[2024-01-21 17:39:09 root] (utils.py 302): INFO Epoch: [0]  [  230/19704]  eta: 2:13:39  lr_architecture: 0.010000  loss_cls: 7.1259 (7.3077)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4816 (inf)  time: 0.4055  data: 0.0001  max mem: 14439
[2024-01-21 17:39:13 root] (utils.py 302): INFO Epoch: [0]  [  240/19704]  eta: 2:13:31  lr_architecture: 0.010000  loss_cls: 7.1266 (7.2997)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4816 (inf)  time: 0.4060  data: 0.0001  max mem: 14439
[2024-01-21 17:39:17 root] (utils.py 302): INFO Epoch: [0]  [  250/19704]  eta: 2:13:22  lr_architecture: 0.010000  loss_cls: 7.1588 (7.2929)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 1.4905 (inf)  time: 0.4061  data: 0.0001  max mem: 14439
[2024-01-21 17:39:49 root] (main_pitome.py 215): INFO Namespace(batch_size=64, epochs=5, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 17:39:54 root] (main_pitome.py 300): INFO Creating model: vit_large_patch16_mae
[2024-01-21 17:39:59 root] (main_pitome.py 386): INFO number of params: 304326632
[2024-01-21 17:40:06 root] (main_pitome.py 441): INFO Start training for 5 epochs
[2024-01-21 17:40:08 root] (utils.py 302): INFO Epoch: [0]  [    0/19704]  eta: 11:20:38  lr_architecture: 0.000063  loss_cls: 3.2101 (3.2101)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 17.5689 (17.5689)  time: 2.0726  data: 0.0006  max mem: 10983
[2024-01-21 17:40:12 root] (utils.py 302): INFO Epoch: [0]  [   10/19704]  eta: 3:04:34  lr_architecture: 0.000063  loss_cls: 3.5053 (3.2269)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 15.5412 (17.0628)  time: 0.5623  data: 0.0001  max mem: 14439
[2024-01-21 17:40:16 root] (utils.py 302): INFO Epoch: [0]  [   20/19704]  eta: 2:40:31  lr_architecture: 0.000063  loss_cls: 3.2291 (3.2544)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 12.9875 (14.7036)  time: 0.4102  data: 0.0001  max mem: 14439
[2024-01-21 17:40:20 root] (utils.py 302): INFO Epoch: [0]  [   30/19704]  eta: 2:31:59  lr_architecture: 0.000063  loss_cls: 3.1167 (3.2066)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 12.2330 (14.0469)  time: 0.4092  data: 0.0001  max mem: 14439
[2024-01-21 17:40:25 root] (utils.py 302): INFO Epoch: [0]  [   40/19704]  eta: 2:27:26  lr_architecture: 0.000063  loss_cls: 3.0799 (3.1859)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 12.6372 (13.7356)  time: 0.4084  data: 0.0001  max mem: 14439
[2024-01-21 17:40:29 root] (utils.py 302): INFO Epoch: [0]  [   50/19704]  eta: 2:24:38  lr_architecture: 0.000063  loss_cls: 3.0652 (3.1440)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 11.6673 (13.2255)  time: 0.4076  data: 0.0001  max mem: 14439
[2024-01-21 17:40:33 root] (utils.py 302): INFO Epoch: [0]  [   60/19704]  eta: 2:22:48  lr_architecture: 0.000063  loss_cls: 2.9067 (3.0971)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 10.9978 (12.9265)  time: 0.4082  data: 0.0001  max mem: 14439
[2024-01-21 17:40:37 root] (utils.py 302): INFO Epoch: [0]  [   70/19704]  eta: 2:21:28  lr_architecture: 0.000063  loss_cls: 2.8190 (3.0421)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 11.4997 (12.7777)  time: 0.4088  data: 0.0001  max mem: 14439
[2024-01-21 17:40:55 root] (main_pitome.py 215): INFO Namespace(batch_size=64, epochs=5, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 17:40:59 root] (main_pitome.py 260): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 17:41:00 root] (main_pitome.py 300): INFO Creating model: vit_large_patch16_mae
[2024-01-21 17:41:07 root] (main_pitome.py 386): INFO number of params: 304326632
[2024-01-21 17:41:14 root] (main_pitome.py 441): INFO Start training for 5 epochs
[2024-01-21 17:41:16 root] (utils.py 302): INFO Epoch: [0]  [   0/4926]  eta: 3:44:04  lr_architecture: 0.000250  loss_cls: 3.3717 (3.3717)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 9.1179 (9.1179)  time: 2.7292  data: 0.0005  max mem: 10987
[2024-01-21 17:41:23 root] (utils.py 302): INFO Epoch: [0]  [  10/4926]  eta: 1:08:11  lr_architecture: 0.000250  loss_cls: 3.8441 (3.7873)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.0908 (6.7913)  time: 0.8323  data: 0.0001  max mem: 14432
[2024-01-21 17:41:29 root] (utils.py 302): INFO Epoch: [0]  [  20/4926]  eta: 0:59:43  lr_architecture: 0.000250  loss_cls: 3.4926 (3.6004)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2937 (6.0860)  time: 0.6304  data: 0.0001  max mem: 14434
[2024-01-21 17:41:35 root] (utils.py 302): INFO Epoch: [0]  [  30/4926]  eta: 0:56:38  lr_architecture: 0.000250  loss_cls: 3.4926 (3.6183)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9420 (5.7617)  time: 0.6181  data: 0.0001  max mem: 14434
[2024-01-21 17:41:41 root] (utils.py 302): INFO Epoch: [0]  [  40/4926]  eta: 0:54:59  lr_architecture: 0.000250  loss_cls: 3.4302 (3.5396)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2213 (5.6275)  time: 0.6173  data: 0.0001  max mem: 14434
[2024-01-21 17:41:48 root] (utils.py 302): INFO Epoch: [0]  [  50/4926]  eta: 0:53:56  lr_architecture: 0.000250  loss_cls: 3.4296 (3.5436)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8586 (5.4696)  time: 0.6167  data: 0.0001  max mem: 14434
[2024-01-21 17:41:54 root] (utils.py 302): INFO Epoch: [0]  [  60/4926]  eta: 0:53:11  lr_architecture: 0.000250  loss_cls: 3.4490 (3.4918)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8267 (5.3690)  time: 0.6162  data: 0.0001  max mem: 14434
[2024-01-21 17:42:00 root] (utils.py 302): INFO Epoch: [0]  [  70/4926]  eta: 0:52:38  lr_architecture: 0.000250  loss_cls: 3.2519 (3.4470)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8266 (5.2887)  time: 0.6162  data: 0.0001  max mem: 14434
[2024-01-21 17:42:06 root] (utils.py 302): INFO Epoch: [0]  [  80/4926]  eta: 0:52:11  lr_architecture: 0.000250  loss_cls: 3.2519 (3.4182)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8266 (5.2455)  time: 0.6169  data: 0.0001  max mem: 14434
[2024-01-21 17:42:12 root] (utils.py 302): INFO Epoch: [0]  [  90/4926]  eta: 0:51:49  lr_architecture: 0.000250  loss_cls: 3.2850 (3.3996)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6682 (5.1779)  time: 0.6168  data: 0.0001  max mem: 14434
[2024-01-21 17:42:18 root] (utils.py 302): INFO Epoch: [0]  [ 100/4926]  eta: 0:51:31  lr_architecture: 0.000250  loss_cls: 3.4779 (3.4106)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6899 (5.1399)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 17:42:25 root] (utils.py 302): INFO Epoch: [0]  [ 110/4926]  eta: 0:51:15  lr_architecture: 0.000250  loss_cls: 3.6234 (3.4228)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7572 (5.0956)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 17:42:31 root] (utils.py 302): INFO Epoch: [0]  [ 120/4926]  eta: 0:51:00  lr_architecture: 0.000250  loss_cls: 3.6353 (3.4283)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7733 (5.0728)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 17:42:37 root] (utils.py 302): INFO Epoch: [0]  [ 130/4926]  eta: 0:50:47  lr_architecture: 0.000250  loss_cls: 3.6125 (3.4285)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7034 (5.0340)  time: 0.6188  data: 0.0001  max mem: 14434
[2024-01-21 17:42:43 root] (utils.py 302): INFO Epoch: [0]  [ 140/4926]  eta: 0:50:35  lr_architecture: 0.000250  loss_cls: 3.4450 (3.4208)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.4624 (4.9954)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 17:42:49 root] (utils.py 302): INFO Epoch: [0]  [ 150/4926]  eta: 0:50:23  lr_architecture: 0.000250  loss_cls: 3.1703 (3.4067)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.4797 (4.9662)  time: 0.6168  data: 0.0001  max mem: 14434
[2024-01-21 17:42:55 root] (utils.py 302): INFO Epoch: [0]  [ 160/4926]  eta: 0:50:12  lr_architecture: 0.000250  loss_cls: 3.4003 (3.4123)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.4463 (4.9276)  time: 0.6183  data: 0.0001  max mem: 14434
[2024-01-21 17:43:02 root] (utils.py 302): INFO Epoch: [0]  [ 170/4926]  eta: 0:50:02  lr_architecture: 0.000250  loss_cls: 3.3826 (3.4017)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.2543 (4.8925)  time: 0.6191  data: 0.0001  max mem: 14434
[2024-01-21 17:43:08 root] (utils.py 302): INFO Epoch: [0]  [ 180/4926]  eta: 0:49:53  lr_architecture: 0.000250  loss_cls: 3.0905 (3.3808)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.2543 (4.8659)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 17:43:14 root] (utils.py 302): INFO Epoch: [0]  [ 190/4926]  eta: 0:49:43  lr_architecture: 0.000250  loss_cls: 3.2984 (3.3857)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.3014 (4.8381)  time: 0.6185  data: 0.0001  max mem: 14434
[2024-01-21 17:43:20 root] (utils.py 302): INFO Epoch: [0]  [ 200/4926]  eta: 0:49:34  lr_architecture: 0.000250  loss_cls: 3.4357 (3.3814)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.3791 (4.8190)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 17:43:26 root] (utils.py 302): INFO Epoch: [0]  [ 210/4926]  eta: 0:49:26  lr_architecture: 0.000250  loss_cls: 3.4566 (3.3810)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.3336 (4.7891)  time: 0.6184  data: 0.0001  max mem: 14434
[2024-01-21 17:43:33 root] (utils.py 302): INFO Epoch: [0]  [ 220/4926]  eta: 0:49:17  lr_architecture: 0.000250  loss_cls: 3.4566 (3.3803)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.1175 (4.7570)  time: 0.6188  data: 0.0001  max mem: 14434
[2024-01-21 17:43:39 root] (utils.py 302): INFO Epoch: [0]  [ 230/4926]  eta: 0:49:09  lr_architecture: 0.000250  loss_cls: 3.2543 (3.3799)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.0804 (4.7331)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 17:43:45 root] (utils.py 302): INFO Epoch: [0]  [ 240/4926]  eta: 0:49:00  lr_architecture: 0.000250  loss_cls: 3.4269 (3.3812)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.2741 (4.7161)  time: 0.6178  data: 0.0001  max mem: 14434
[2024-01-21 17:43:51 root] (utils.py 302): INFO Epoch: [0]  [ 250/4926]  eta: 0:48:53  lr_architecture: 0.000250  loss_cls: 3.2327 (3.3727)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.3100 (4.7060)  time: 0.6185  data: 0.0001  max mem: 14434
[2024-01-21 17:43:57 root] (utils.py 302): INFO Epoch: [0]  [ 260/4926]  eta: 0:48:44  lr_architecture: 0.000250  loss_cls: 3.0048 (3.3646)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.2500 (4.6867)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 17:44:03 root] (utils.py 302): INFO Epoch: [0]  [ 270/4926]  eta: 0:48:37  lr_architecture: 0.000250  loss_cls: 3.3571 (3.3659)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.1848 (4.6718)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 17:44:10 root] (utils.py 302): INFO Epoch: [0]  [ 280/4926]  eta: 0:48:29  lr_architecture: 0.000250  loss_cls: 3.5469 (3.3687)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.1996 (4.6519)  time: 0.6192  data: 0.0001  max mem: 14434
[2024-01-21 17:44:16 root] (utils.py 302): INFO Epoch: [0]  [ 290/4926]  eta: 0:48:22  lr_architecture: 0.000250  loss_cls: 3.4064 (3.3655)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.1996 (4.6436)  time: 0.6183  data: 0.0001  max mem: 14434
[2024-01-21 17:44:22 root] (utils.py 302): INFO Epoch: [0]  [ 300/4926]  eta: 0:48:14  lr_architecture: 0.000250  loss_cls: 3.2146 (3.3546)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.1383 (4.6274)  time: 0.6183  data: 0.0001  max mem: 14434
[2024-01-21 17:44:28 root] (utils.py 302): INFO Epoch: [0]  [ 310/4926]  eta: 0:48:07  lr_architecture: 0.000250  loss_cls: 3.2292 (3.3542)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.1383 (4.6173)  time: 0.6188  data: 0.0001  max mem: 14434
[2024-01-21 17:44:34 root] (utils.py 302): INFO Epoch: [0]  [ 320/4926]  eta: 0:48:00  lr_architecture: 0.000250  loss_cls: 3.6944 (3.3683)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.3412 (4.6076)  time: 0.6189  data: 0.0001  max mem: 14434
[2024-01-21 17:44:41 root] (utils.py 302): INFO Epoch: [0]  [ 330/4926]  eta: 0:47:53  lr_architecture: 0.000250  loss_cls: 3.8435 (3.3667)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.3926 (4.5995)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 17:44:47 root] (utils.py 302): INFO Epoch: [0]  [ 340/4926]  eta: 0:47:45  lr_architecture: 0.000250  loss_cls: 3.4637 (3.3695)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.0816 (4.5827)  time: 0.6180  data: 0.0001  max mem: 14434
[2024-01-21 17:44:53 root] (utils.py 302): INFO Epoch: [0]  [ 350/4926]  eta: 0:47:38  lr_architecture: 0.000250  loss_cls: 3.3748 (3.3725)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.0780 (4.5714)  time: 0.6180  data: 0.0001  max mem: 14434
[2024-01-21 17:44:59 root] (utils.py 302): INFO Epoch: [0]  [ 360/4926]  eta: 0:47:31  lr_architecture: 0.000250  loss_cls: 3.5038 (3.3736)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.2127 (4.5629)  time: 0.6180  data: 0.0001  max mem: 14434
[2024-01-21 17:45:05 root] (utils.py 302): INFO Epoch: [0]  [ 370/4926]  eta: 0:47:24  lr_architecture: 0.000250  loss_cls: 3.2496 (3.3703)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.1301 (4.5478)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 17:45:12 root] (utils.py 302): INFO Epoch: [0]  [ 380/4926]  eta: 0:47:17  lr_architecture: 0.000250  loss_cls: 3.3858 (3.3717)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.0326 (4.5363)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 17:45:18 root] (utils.py 302): INFO Epoch: [0]  [ 390/4926]  eta: 0:47:10  lr_architecture: 0.000250  loss_cls: 3.3924 (3.3700)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.0326 (4.5250)  time: 0.6187  data: 0.0001  max mem: 14434
[2024-01-21 17:45:24 root] (utils.py 302): INFO Epoch: [0]  [ 400/4926]  eta: 0:47:03  lr_architecture: 0.000250  loss_cls: 3.6331 (3.3764)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.0574 (4.5138)  time: 0.6189  data: 0.0001  max mem: 14434
[2024-01-21 17:45:30 root] (utils.py 302): INFO Epoch: [0]  [ 410/4926]  eta: 0:46:57  lr_architecture: 0.000250  loss_cls: 3.6331 (3.3833)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.1395 (4.5044)  time: 0.6185  data: 0.0001  max mem: 14434
[2024-01-21 17:45:36 root] (utils.py 302): INFO Epoch: [0]  [ 420/4926]  eta: 0:46:50  lr_architecture: 0.000250  loss_cls: 3.5714 (3.3844)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.0826 (4.4948)  time: 0.6181  data: 0.0001  max mem: 14434
[2024-01-21 17:45:42 root] (utils.py 302): INFO Epoch: [0]  [ 430/4926]  eta: 0:46:43  lr_architecture: 0.000250  loss_cls: 3.8005 (3.3959)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.0192 (4.4848)  time: 0.6185  data: 0.0001  max mem: 14434
[2024-01-21 17:45:49 root] (utils.py 302): INFO Epoch: [0]  [ 440/4926]  eta: 0:46:36  lr_architecture: 0.000250  loss_cls: 3.8453 (3.4034)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.9928 (4.4721)  time: 0.6185  data: 0.0001  max mem: 14434
[2024-01-21 17:45:55 root] (utils.py 302): INFO Epoch: [0]  [ 450/4926]  eta: 0:46:30  lr_architecture: 0.000250  loss_cls: 3.6285 (3.4054)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.7533 (4.4552)  time: 0.6193  data: 0.0001  max mem: 14434
[2024-01-21 17:46:01 root] (utils.py 302): INFO Epoch: [0]  [ 460/4926]  eta: 0:46:23  lr_architecture: 0.000250  loss_cls: 3.4887 (3.4018)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.7370 (4.4458)  time: 0.6192  data: 0.0001  max mem: 14434
[2024-01-21 17:46:07 root] (utils.py 302): INFO Epoch: [0]  [ 470/4926]  eta: 0:46:16  lr_architecture: 0.000250  loss_cls: 3.1043 (3.3940)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.9635 (4.4350)  time: 0.6178  data: 0.0001  max mem: 14434
[2024-01-21 17:46:13 root] (utils.py 302): INFO Epoch: [0]  [ 480/4926]  eta: 0:46:10  lr_architecture: 0.000250  loss_cls: 3.1719 (3.3946)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.9889 (4.4305)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 17:46:20 root] (utils.py 302): INFO Epoch: [0]  [ 490/4926]  eta: 0:46:03  lr_architecture: 0.000250  loss_cls: 3.4706 (3.4024)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.1521 (4.4282)  time: 0.6194  data: 0.0001  max mem: 14434
[2024-01-21 17:46:26 root] (utils.py 302): INFO Epoch: [0]  [ 500/4926]  eta: 0:45:56  lr_architecture: 0.000250  loss_cls: 3.5067 (3.4025)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.0871 (4.4180)  time: 0.6189  data: 0.0001  max mem: 14434
[2024-01-21 17:46:32 root] (utils.py 302): INFO Epoch: [0]  [ 510/4926]  eta: 0:45:50  lr_architecture: 0.000250  loss_cls: 3.5067 (3.4100)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.7761 (4.4069)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 17:46:38 root] (utils.py 302): INFO Epoch: [0]  [ 520/4926]  eta: 0:45:43  lr_architecture: 0.000250  loss_cls: 3.6069 (3.4104)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.8723 (4.3979)  time: 0.6189  data: 0.0001  max mem: 14434
[2024-01-21 17:46:44 root] (utils.py 302): INFO Epoch: [0]  [ 530/4926]  eta: 0:45:38  lr_architecture: 0.000250  loss_cls: 3.4371 (3.4060)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.8621 (4.3888)  time: 0.6249  data: 0.0001  max mem: 14434
[2024-01-21 17:46:51 root] (utils.py 302): INFO Epoch: [0]  [ 540/4926]  eta: 0:45:31  lr_architecture: 0.000250  loss_cls: 3.4202 (3.4056)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.9374 (4.3807)  time: 0.6247  data: 0.0001  max mem: 14434
[2024-01-21 17:46:57 root] (utils.py 302): INFO Epoch: [0]  [ 550/4926]  eta: 0:45:25  lr_architecture: 0.000250  loss_cls: 3.5245 (3.4044)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.9464 (4.3732)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 17:47:03 root] (utils.py 302): INFO Epoch: [0]  [ 560/4926]  eta: 0:45:18  lr_architecture: 0.000250  loss_cls: 3.7421 (3.4106)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.9717 (4.3677)  time: 0.6189  data: 0.0001  max mem: 14434
[2024-01-21 17:47:09 root] (utils.py 302): INFO Epoch: [0]  [ 570/4926]  eta: 0:45:12  lr_architecture: 0.000250  loss_cls: 3.8735 (3.4167)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.7966 (4.3585)  time: 0.6194  data: 0.0001  max mem: 14434
[2024-01-21 17:47:15 root] (utils.py 302): INFO Epoch: [0]  [ 580/4926]  eta: 0:45:05  lr_architecture: 0.000250  loss_cls: 3.6615 (3.4183)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.7333 (4.3502)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 17:47:22 root] (utils.py 302): INFO Epoch: [0]  [ 590/4926]  eta: 0:44:59  lr_architecture: 0.000250  loss_cls: 3.6412 (3.4211)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.8094 (4.3409)  time: 0.6184  data: 0.0001  max mem: 14434
[2024-01-21 17:47:28 root] (utils.py 302): INFO Epoch: [0]  [ 600/4926]  eta: 0:44:53  lr_architecture: 0.000250  loss_cls: 3.6412 (3.4221)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.7948 (4.3303)  time: 0.6261  data: 0.0001  max mem: 14434
[2024-01-21 17:47:34 root] (utils.py 302): INFO Epoch: [0]  [ 610/4926]  eta: 0:44:46  lr_architecture: 0.000250  loss_cls: 3.3160 (3.4206)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.8225 (4.3231)  time: 0.6255  data: 0.0001  max mem: 14434
[2024-01-21 17:47:40 root] (utils.py 302): INFO Epoch: [0]  [ 620/4926]  eta: 0:44:40  lr_architecture: 0.000250  loss_cls: 3.5496 (3.4245)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.8725 (4.3156)  time: 0.6183  data: 0.0001  max mem: 14434
[2024-01-21 17:47:46 root] (utils.py 302): INFO Epoch: [0]  [ 630/4926]  eta: 0:44:34  lr_architecture: 0.000250  loss_cls: 3.5904 (3.4269)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.8833 (4.3100)  time: 0.6197  data: 0.0001  max mem: 14434
[2024-01-21 17:47:53 root] (utils.py 302): INFO Epoch: [0]  [ 640/4926]  eta: 0:44:27  lr_architecture: 0.000250  loss_cls: 3.4258 (3.4255)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.9091 (4.3019)  time: 0.6192  data: 0.0001  max mem: 14434
[2024-01-21 17:47:59 root] (utils.py 302): INFO Epoch: [0]  [ 650/4926]  eta: 0:44:21  lr_architecture: 0.000250  loss_cls: 3.4258 (3.4267)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.7774 (4.2962)  time: 0.6183  data: 0.0001  max mem: 14434
[2024-01-21 17:48:05 root] (utils.py 302): INFO Epoch: [0]  [ 660/4926]  eta: 0:44:14  lr_architecture: 0.000250  loss_cls: 3.2639 (3.4226)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.7880 (4.2907)  time: 0.6192  data: 0.0001  max mem: 14434
[2024-01-21 17:48:11 root] (utils.py 302): INFO Epoch: [0]  [ 670/4926]  eta: 0:44:08  lr_architecture: 0.000250  loss_cls: 3.7676 (3.4272)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.9316 (4.2878)  time: 0.6190  data: 0.0001  max mem: 14434
[2024-01-21 17:48:17 root] (utils.py 302): INFO Epoch: [0]  [ 680/4926]  eta: 0:44:01  lr_architecture: 0.000250  loss_cls: 3.7676 (3.4286)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.8267 (4.2795)  time: 0.6187  data: 0.0001  max mem: 14434
[2024-01-21 17:48:24 root] (utils.py 302): INFO Epoch: [0]  [ 690/4926]  eta: 0:43:55  lr_architecture: 0.000250  loss_cls: 3.2302 (3.4264)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.7496 (4.2732)  time: 0.6184  data: 0.0001  max mem: 14434
[2024-01-21 17:48:30 root] (utils.py 302): INFO Epoch: [0]  [ 700/4926]  eta: 0:43:48  lr_architecture: 0.000250  loss_cls: 3.2302 (3.4242)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.6901 (4.2645)  time: 0.6183  data: 0.0001  max mem: 14434
[2024-01-21 17:48:36 root] (utils.py 302): INFO Epoch: [0]  [ 710/4926]  eta: 0:43:42  lr_architecture: 0.000250  loss_cls: 3.4381 (3.4226)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.7017 (4.2592)  time: 0.6197  data: 0.0001  max mem: 14434
[2024-01-21 17:48:42 root] (utils.py 302): INFO Epoch: [0]  [ 720/4926]  eta: 0:43:36  lr_architecture: 0.000250  loss_cls: 3.4381 (3.4219)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.8216 (4.2531)  time: 0.6197  data: 0.0001  max mem: 14434
[2024-01-21 17:48:48 root] (utils.py 302): INFO Epoch: [0]  [ 730/4926]  eta: 0:43:29  lr_architecture: 0.000250  loss_cls: 3.6297 (3.4253)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 3.7615 (4.2469)  time: 0.6187  data: 0.0001  max mem: 14434
[2024-01-21 17:49:19 root] (main_pitome.py 215): INFO Namespace(batch_size=64, epochs=10, ratio=0.94, model='vit_large_patch16_mae', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='./log/temp', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=True, world_size=4, port='15662', dist_url='env://', target_flops=3.0, granularity=4, load_compression_rate=False, warmup_compression_rate=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
[2024-01-21 17:49:23 root] (main_pitome.py 260): INFO Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[2024-01-21 17:49:24 root] (main_pitome.py 300): INFO Creating model: vit_large_patch16_mae
[2024-01-21 17:49:31 root] (main_pitome.py 386): INFO number of params: 304326632
[2024-01-21 17:49:37 root] (main_pitome.py 441): INFO Start training for 10 epochs
[2024-01-21 17:49:40 root] (utils.py 302): INFO Epoch: [0]  [   0/4926]  eta: 3:43:07  lr_architecture: 0.000050  loss_cls: 3.4326 (3.4326)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 9.9756 (9.9756)  time: 2.7177  data: 0.0006  max mem: 10987
[2024-01-21 17:49:47 root] (utils.py 302): INFO Epoch: [0]  [  10/4926]  eta: 1:07:50  lr_architecture: 0.000050  loss_cls: 3.0872 (3.0699)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 9.9756 (10.1166)  time: 0.8281  data: 0.0002  max mem: 14432
[2024-01-21 17:49:53 root] (utils.py 302): INFO Epoch: [0]  [  20/4926]  eta: 0:59:26  lr_architecture: 0.000050  loss_cls: 3.0066 (2.9858)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 7.8741 (8.4506)  time: 0.6275  data: 0.0001  max mem: 14434
[2024-01-21 17:49:59 root] (utils.py 302): INFO Epoch: [0]  [  30/4926]  eta: 0:56:25  lr_architecture: 0.000050  loss_cls: 2.9456 (3.0060)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.3897 (7.8338)  time: 0.6162  data: 0.0001  max mem: 14434
[2024-01-21 17:50:05 root] (utils.py 302): INFO Epoch: [0]  [  40/4926]  eta: 0:54:42  lr_architecture: 0.000050  loss_cls: 2.9456 (2.9614)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.6886 (inf)  time: 0.6140  data: 0.0001  max mem: 14434
[2024-01-21 17:50:11 root] (utils.py 302): INFO Epoch: [0]  [  50/4926]  eta: 0:53:43  lr_architecture: 0.000050  loss_cls: 2.8068 (2.9583)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.6692 (inf)  time: 0.6141  data: 0.0001  max mem: 14434
[2024-01-21 17:50:17 root] (utils.py 302): INFO Epoch: [0]  [  60/4926]  eta: 0:53:00  lr_architecture: 0.000050  loss_cls: 2.7651 (2.9194)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.5364 (inf)  time: 0.6161  data: 0.0001  max mem: 14434
[2024-01-21 17:50:23 root] (utils.py 302): INFO Epoch: [0]  [  70/4926]  eta: 0:52:28  lr_architecture: 0.000050  loss_cls: 2.6946 (2.8876)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.3946 (inf)  time: 0.6157  data: 0.0001  max mem: 14434
[2024-01-21 17:50:30 root] (utils.py 302): INFO Epoch: [0]  [  80/4926]  eta: 0:52:02  lr_architecture: 0.000050  loss_cls: 2.7103 (2.8666)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.1701 (inf)  time: 0.6164  data: 0.0001  max mem: 14434
[2024-01-21 17:50:36 root] (utils.py 302): INFO Epoch: [0]  [  90/4926]  eta: 0:51:41  lr_architecture: 0.000050  loss_cls: 2.7103 (2.8556)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.2078 (inf)  time: 0.6167  data: 0.0001  max mem: 14434
[2024-01-21 17:50:42 root] (utils.py 302): INFO Epoch: [0]  [ 100/4926]  eta: 0:51:24  lr_architecture: 0.000050  loss_cls: 2.9046 (2.8666)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.4734 (inf)  time: 0.6173  data: 0.0001  max mem: 14434
[2024-01-21 17:50:48 root] (utils.py 302): INFO Epoch: [0]  [ 110/4926]  eta: 0:51:08  lr_architecture: 0.000050  loss_cls: 3.0351 (2.8732)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.4934 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 17:50:54 root] (utils.py 302): INFO Epoch: [0]  [ 120/4926]  eta: 0:50:53  lr_architecture: 0.000050  loss_cls: 2.8841 (2.8704)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.4413 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 17:51:00 root] (utils.py 302): INFO Epoch: [0]  [ 130/4926]  eta: 0:50:40  lr_architecture: 0.000050  loss_cls: 2.9230 (2.8699)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 6.2094 (inf)  time: 0.6167  data: 0.0001  max mem: 14434
[2024-01-21 17:51:07 root] (utils.py 302): INFO Epoch: [0]  [ 140/4926]  eta: 0:50:28  lr_architecture: 0.000050  loss_cls: 2.8987 (2.8618)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.7837 (inf)  time: 0.6163  data: 0.0001  max mem: 14434
[2024-01-21 17:51:13 root] (utils.py 302): INFO Epoch: [0]  [ 150/4926]  eta: 0:50:17  lr_architecture: 0.000050  loss_cls: 2.7129 (2.8512)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.8021 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 17:51:19 root] (utils.py 302): INFO Epoch: [0]  [ 160/4926]  eta: 0:50:06  lr_architecture: 0.000050  loss_cls: 2.7878 (2.8563)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.8019 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 17:51:25 root] (utils.py 302): INFO Epoch: [0]  [ 170/4926]  eta: 0:49:56  lr_architecture: 0.000050  loss_cls: 2.7878 (2.8471)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.6494 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 17:51:31 root] (utils.py 302): INFO Epoch: [0]  [ 180/4926]  eta: 0:49:46  lr_architecture: 0.000050  loss_cls: 2.5860 (2.8268)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.6344 (inf)  time: 0.6169  data: 0.0001  max mem: 14434
[2024-01-21 17:51:38 root] (utils.py 302): INFO Epoch: [0]  [ 190/4926]  eta: 0:49:37  lr_architecture: 0.000050  loss_cls: 2.7118 (2.8296)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.6800 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 17:51:44 root] (utils.py 302): INFO Epoch: [0]  [ 200/4926]  eta: 0:49:28  lr_architecture: 0.000050  loss_cls: 2.8565 (2.8202)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.6800 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 17:51:50 root] (utils.py 302): INFO Epoch: [0]  [ 210/4926]  eta: 0:49:19  lr_architecture: 0.000050  loss_cls: 2.8208 (2.8188)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.6706 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 17:51:56 root] (utils.py 302): INFO Epoch: [0]  [ 220/4926]  eta: 0:49:11  lr_architecture: 0.000050  loss_cls: 2.8208 (2.8165)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.7570 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 17:52:02 root] (utils.py 302): INFO Epoch: [0]  [ 230/4926]  eta: 0:49:03  lr_architecture: 0.000050  loss_cls: 2.7491 (2.8173)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.7570 (inf)  time: 0.6178  data: 0.0001  max mem: 14434
[2024-01-21 17:52:08 root] (utils.py 302): INFO Epoch: [0]  [ 240/4926]  eta: 0:48:55  lr_architecture: 0.000050  loss_cls: 2.7812 (2.8170)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.8120 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 17:52:15 root] (utils.py 302): INFO Epoch: [0]  [ 250/4926]  eta: 0:48:47  lr_architecture: 0.000050  loss_cls: 2.6528 (2.8087)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.8120 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 17:52:21 root] (utils.py 302): INFO Epoch: [0]  [ 260/4926]  eta: 0:48:39  lr_architecture: 0.000050  loss_cls: 2.5307 (2.8010)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1731 (inf)  time: 0.6184  data: 0.0001  max mem: 14434
[2024-01-21 17:52:27 root] (utils.py 302): INFO Epoch: [0]  [ 270/4926]  eta: 0:48:32  lr_architecture: 0.000050  loss_cls: 2.6472 (2.7999)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.3726 (inf)  time: 0.6178  data: 0.0001  max mem: 14434
[2024-01-21 17:52:33 root] (utils.py 302): INFO Epoch: [0]  [ 280/4926]  eta: 0:48:24  lr_architecture: 0.000050  loss_cls: 2.9929 (2.7993)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.6691 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 17:52:39 root] (utils.py 302): INFO Epoch: [0]  [ 290/4926]  eta: 0:48:17  lr_architecture: 0.000050  loss_cls: 2.8911 (2.7958)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.6690 (inf)  time: 0.6178  data: 0.0001  max mem: 14434
[2024-01-21 17:52:45 root] (utils.py 302): INFO Epoch: [0]  [ 300/4926]  eta: 0:48:09  lr_architecture: 0.000050  loss_cls: 2.6226 (2.7881)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.6340 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 17:52:52 root] (utils.py 302): INFO Epoch: [0]  [ 310/4926]  eta: 0:48:02  lr_architecture: 0.000050  loss_cls: 2.7208 (2.7867)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4217 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 17:52:58 root] (utils.py 302): INFO Epoch: [0]  [ 320/4926]  eta: 0:47:55  lr_architecture: 0.000050  loss_cls: 2.9346 (2.7976)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.3677 (inf)  time: 0.6185  data: 0.0001  max mem: 14434
[2024-01-21 17:53:04 root] (utils.py 302): INFO Epoch: [0]  [ 330/4926]  eta: 0:47:48  lr_architecture: 0.000050  loss_cls: 2.9346 (2.7938)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4007 (inf)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 17:53:10 root] (utils.py 302): INFO Epoch: [0]  [ 340/4926]  eta: 0:47:40  lr_architecture: 0.000050  loss_cls: 2.8833 (2.7953)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.7561 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 17:53:16 root] (utils.py 302): INFO Epoch: [0]  [ 350/4926]  eta: 0:47:34  lr_architecture: 0.000050  loss_cls: 2.7944 (2.7969)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.9009 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 17:53:23 root] (utils.py 302): INFO Epoch: [0]  [ 360/4926]  eta: 0:47:27  lr_architecture: 0.000050  loss_cls: 2.7944 (2.7952)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.9009 (inf)  time: 0.6187  data: 0.0001  max mem: 14434
[2024-01-21 17:53:29 root] (utils.py 302): INFO Epoch: [0]  [ 370/4926]  eta: 0:47:20  lr_architecture: 0.000050  loss_cls: 2.6903 (2.7911)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4450 (inf)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 17:53:35 root] (utils.py 302): INFO Epoch: [0]  [ 380/4926]  eta: 0:47:13  lr_architecture: 0.000050  loss_cls: 2.7895 (2.7908)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2555 (inf)  time: 0.6173  data: 0.0001  max mem: 14434
[2024-01-21 17:53:41 root] (utils.py 302): INFO Epoch: [0]  [ 390/4926]  eta: 0:47:06  lr_architecture: 0.000050  loss_cls: 2.8693 (2.7876)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2525 (inf)  time: 0.6189  data: 0.0001  max mem: 14434
[2024-01-21 17:53:47 root] (utils.py 302): INFO Epoch: [0]  [ 400/4926]  eta: 0:46:59  lr_architecture: 0.000050  loss_cls: 2.8570 (2.7902)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2586 (inf)  time: 0.6197  data: 0.0001  max mem: 14434
[2024-01-21 17:53:53 root] (utils.py 302): INFO Epoch: [0]  [ 410/4926]  eta: 0:46:53  lr_architecture: 0.000050  loss_cls: 2.9178 (2.7955)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.9010 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 17:54:00 root] (utils.py 302): INFO Epoch: [0]  [ 420/4926]  eta: 0:46:46  lr_architecture: 0.000050  loss_cls: 3.0271 (2.7956)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.7760 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 17:54:06 root] (utils.py 302): INFO Epoch: [0]  [ 430/4926]  eta: 0:46:39  lr_architecture: 0.000050  loss_cls: 3.1247 (2.8040)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4484 (inf)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 17:54:12 root] (utils.py 302): INFO Epoch: [0]  [ 440/4926]  eta: 0:46:32  lr_architecture: 0.000050  loss_cls: 3.1634 (2.8081)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4484 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 17:54:18 root] (utils.py 302): INFO Epoch: [0]  [ 450/4926]  eta: 0:46:26  lr_architecture: 0.000050  loss_cls: 2.9264 (2.8108)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4086 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 17:54:24 root] (utils.py 302): INFO Epoch: [0]  [ 460/4926]  eta: 0:46:19  lr_architecture: 0.000050  loss_cls: 2.7793 (2.8058)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4560 (inf)  time: 0.6184  data: 0.0001  max mem: 14434
[2024-01-21 17:54:31 root] (utils.py 302): INFO Epoch: [0]  [ 470/4926]  eta: 0:46:12  lr_architecture: 0.000050  loss_cls: 2.5307 (2.7974)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4456 (inf)  time: 0.6187  data: 0.0001  max mem: 14434
[2024-01-21 17:54:37 root] (utils.py 302): INFO Epoch: [0]  [ 480/4926]  eta: 0:46:06  lr_architecture: 0.000050  loss_cls: 2.5526 (2.7966)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2645 (inf)  time: 0.6191  data: 0.0001  max mem: 14434
[2024-01-21 17:54:43 root] (utils.py 302): INFO Epoch: [0]  [ 490/4926]  eta: 0:45:59  lr_architecture: 0.000050  loss_cls: 2.9380 (2.8020)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2740 (inf)  time: 0.6183  data: 0.0001  max mem: 14434
[2024-01-21 17:54:49 root] (utils.py 302): INFO Epoch: [0]  [ 500/4926]  eta: 0:45:53  lr_architecture: 0.000050  loss_cls: 3.0031 (2.8018)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2740 (inf)  time: 0.6167  data: 0.0001  max mem: 14434
[2024-01-21 17:54:55 root] (utils.py 302): INFO Epoch: [0]  [ 510/4926]  eta: 0:45:46  lr_architecture: 0.000050  loss_cls: 3.0031 (2.8068)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.3210 (inf)  time: 0.6171  data: 0.0001  max mem: 14434
[2024-01-21 17:55:01 root] (utils.py 302): INFO Epoch: [0]  [ 520/4926]  eta: 0:45:39  lr_architecture: 0.000050  loss_cls: 2.9498 (2.8063)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2423 (inf)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 17:55:08 root] (utils.py 302): INFO Epoch: [0]  [ 530/4926]  eta: 0:45:34  lr_architecture: 0.000050  loss_cls: 2.7633 (2.8013)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0388 (inf)  time: 0.6261  data: 0.0001  max mem: 14434
[2024-01-21 17:55:14 root] (utils.py 302): INFO Epoch: [0]  [ 540/4926]  eta: 0:45:28  lr_architecture: 0.000050  loss_cls: 2.7528 (2.8012)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.3543 (inf)  time: 0.6265  data: 0.0001  max mem: 14434
[2024-01-21 17:55:20 root] (utils.py 302): INFO Epoch: [0]  [ 550/4926]  eta: 0:45:21  lr_architecture: 0.000050  loss_cls: 2.9275 (2.8010)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4547 (inf)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 17:55:26 root] (utils.py 302): INFO Epoch: [0]  [ 560/4926]  eta: 0:45:15  lr_architecture: 0.000050  loss_cls: 3.0738 (2.8048)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4547 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 17:55:33 root] (utils.py 302): INFO Epoch: [0]  [ 570/4926]  eta: 0:45:08  lr_architecture: 0.000050  loss_cls: 3.0343 (2.8089)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2466 (inf)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 17:55:39 root] (utils.py 302): INFO Epoch: [0]  [ 580/4926]  eta: 0:45:02  lr_architecture: 0.000050  loss_cls: 2.9448 (2.8097)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2466 (inf)  time: 0.6188  data: 0.0001  max mem: 14434
[2024-01-21 17:55:45 root] (utils.py 302): INFO Epoch: [0]  [ 590/4926]  eta: 0:44:55  lr_architecture: 0.000050  loss_cls: 2.9111 (2.8106)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2825 (inf)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 17:55:51 root] (utils.py 302): INFO Epoch: [0]  [ 600/4926]  eta: 0:44:51  lr_architecture: 0.000050  loss_cls: 2.9994 (2.8093)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.3029 (inf)  time: 0.6311  data: 0.0001  max mem: 14434
[2024-01-21 17:55:58 root] (utils.py 302): INFO Epoch: [0]  [ 610/4926]  eta: 0:44:44  lr_architecture: 0.000050  loss_cls: 2.7886 (2.8078)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1365 (inf)  time: 0.6315  data: 0.0001  max mem: 14434
[2024-01-21 17:56:04 root] (utils.py 302): INFO Epoch: [0]  [ 620/4926]  eta: 0:44:37  lr_architecture: 0.000050  loss_cls: 2.8444 (2.8092)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1741 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 17:56:10 root] (utils.py 302): INFO Epoch: [0]  [ 630/4926]  eta: 0:44:31  lr_architecture: 0.000050  loss_cls: 2.9609 (2.8104)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.3385 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 17:56:16 root] (utils.py 302): INFO Epoch: [0]  [ 640/4926]  eta: 0:44:25  lr_architecture: 0.000050  loss_cls: 2.8238 (2.8088)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1989 (inf)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 17:56:22 root] (utils.py 302): INFO Epoch: [0]  [ 650/4926]  eta: 0:44:18  lr_architecture: 0.000050  loss_cls: 2.7866 (2.8094)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.3483 (inf)  time: 0.6185  data: 0.0001  max mem: 14434
[2024-01-21 17:56:28 root] (utils.py 302): INFO Epoch: [0]  [ 660/4926]  eta: 0:44:12  lr_architecture: 0.000050  loss_cls: 2.6359 (2.8047)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.3698 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 17:56:35 root] (utils.py 302): INFO Epoch: [0]  [ 670/4926]  eta: 0:44:05  lr_architecture: 0.000050  loss_cls: 2.8639 (2.8071)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.6347 (inf)  time: 0.6171  data: 0.0001  max mem: 14434
[2024-01-21 17:56:41 root] (utils.py 302): INFO Epoch: [0]  [ 680/4926]  eta: 0:43:59  lr_architecture: 0.000050  loss_cls: 2.9144 (2.8067)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.6008 (inf)  time: 0.6169  data: 0.0001  max mem: 14434
[2024-01-21 17:56:47 root] (utils.py 302): INFO Epoch: [0]  [ 690/4926]  eta: 0:43:52  lr_architecture: 0.000050  loss_cls: 2.7554 (2.8053)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4817 (inf)  time: 0.6167  data: 0.0001  max mem: 14434
[2024-01-21 17:56:53 root] (utils.py 302): INFO Epoch: [0]  [ 700/4926]  eta: 0:43:46  lr_architecture: 0.000050  loss_cls: 2.7533 (2.8041)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4146 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 17:56:59 root] (utils.py 302): INFO Epoch: [0]  [ 710/4926]  eta: 0:43:39  lr_architecture: 0.000050  loss_cls: 2.8335 (2.8019)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2502 (inf)  time: 0.6183  data: 0.0001  max mem: 14434
[2024-01-21 17:57:05 root] (utils.py 302): INFO Epoch: [0]  [ 720/4926]  eta: 0:43:33  lr_architecture: 0.000050  loss_cls: 2.8335 (2.7999)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.5115 (inf)  time: 0.6184  data: 0.0001  max mem: 14434
[2024-01-21 17:57:12 root] (utils.py 302): INFO Epoch: [0]  [ 730/4926]  eta: 0:43:26  lr_architecture: 0.000050  loss_cls: 2.9814 (2.8022)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.5500 (inf)  time: 0.6181  data: 0.0001  max mem: 14434
[2024-01-21 17:57:18 root] (utils.py 302): INFO Epoch: [0]  [ 740/4926]  eta: 0:43:20  lr_architecture: 0.000050  loss_cls: 3.0550 (2.8078)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1203 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 17:57:24 root] (utils.py 302): INFO Epoch: [0]  [ 750/4926]  eta: 0:43:14  lr_architecture: 0.000050  loss_cls: 3.0550 (2.8060)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0405 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 17:57:30 root] (utils.py 302): INFO Epoch: [0]  [ 760/4926]  eta: 0:43:07  lr_architecture: 0.000050  loss_cls: 3.0756 (2.8078)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.3628 (inf)  time: 0.6181  data: 0.0001  max mem: 14434
[2024-01-21 17:57:36 root] (utils.py 302): INFO Epoch: [0]  [ 770/4926]  eta: 0:43:01  lr_architecture: 0.000050  loss_cls: 3.0863 (2.8090)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.6187 (inf)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 17:57:43 root] (utils.py 302): INFO Epoch: [0]  [ 780/4926]  eta: 0:42:54  lr_architecture: 0.000050  loss_cls: 2.8358 (2.8106)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4230 (inf)  time: 0.6181  data: 0.0001  max mem: 14434
[2024-01-21 17:57:49 root] (utils.py 302): INFO Epoch: [0]  [ 790/4926]  eta: 0:42:48  lr_architecture: 0.000050  loss_cls: 2.8358 (2.8097)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1810 (inf)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 17:57:55 root] (utils.py 302): INFO Epoch: [0]  [ 800/4926]  eta: 0:42:42  lr_architecture: 0.000050  loss_cls: 2.8818 (2.8115)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1586 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 17:58:01 root] (utils.py 302): INFO Epoch: [0]  [ 810/4926]  eta: 0:42:35  lr_architecture: 0.000050  loss_cls: 2.6484 (2.8050)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1471 (inf)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 17:58:07 root] (utils.py 302): INFO Epoch: [0]  [ 820/4926]  eta: 0:42:29  lr_architecture: 0.000050  loss_cls: 2.6484 (2.8068)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9418 (inf)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 17:58:13 root] (utils.py 302): INFO Epoch: [0]  [ 830/4926]  eta: 0:42:23  lr_architecture: 0.000050  loss_cls: 2.8017 (2.8032)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0879 (inf)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 17:58:20 root] (utils.py 302): INFO Epoch: [0]  [ 840/4926]  eta: 0:42:16  lr_architecture: 0.000050  loss_cls: 2.4988 (2.8023)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2562 (inf)  time: 0.6180  data: 0.0001  max mem: 14434
[2024-01-21 17:58:26 root] (utils.py 302): INFO Epoch: [0]  [ 850/4926]  eta: 0:42:10  lr_architecture: 0.000050  loss_cls: 2.8081 (2.8027)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4314 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 17:58:32 root] (utils.py 302): INFO Epoch: [0]  [ 860/4926]  eta: 0:42:04  lr_architecture: 0.000050  loss_cls: 2.7530 (2.8023)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0060 (inf)  time: 0.6168  data: 0.0001  max mem: 14434
[2024-01-21 17:58:38 root] (utils.py 302): INFO Epoch: [0]  [ 870/4926]  eta: 0:41:57  lr_architecture: 0.000050  loss_cls: 2.8008 (2.8033)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9770 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 17:58:44 root] (utils.py 302): INFO Epoch: [0]  [ 880/4926]  eta: 0:41:51  lr_architecture: 0.000050  loss_cls: 2.8008 (2.8006)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2608 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 17:58:50 root] (utils.py 302): INFO Epoch: [0]  [ 890/4926]  eta: 0:41:44  lr_architecture: 0.000050  loss_cls: 2.8244 (2.7992)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1742 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 17:58:57 root] (utils.py 302): INFO Epoch: [0]  [ 900/4926]  eta: 0:41:38  lr_architecture: 0.000050  loss_cls: 2.8611 (2.7983)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1742 (inf)  time: 0.6187  data: 0.0001  max mem: 14434
[2024-01-21 17:59:03 root] (utils.py 302): INFO Epoch: [0]  [ 910/4926]  eta: 0:41:32  lr_architecture: 0.000050  loss_cls: 2.8692 (2.7983)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2509 (inf)  time: 0.6192  data: 0.0001  max mem: 14434
[2024-01-21 17:59:09 root] (utils.py 302): INFO Epoch: [0]  [ 920/4926]  eta: 0:41:26  lr_architecture: 0.000050  loss_cls: 3.0018 (2.7996)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4124 (inf)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 17:59:15 root] (utils.py 302): INFO Epoch: [0]  [ 930/4926]  eta: 0:41:19  lr_architecture: 0.000050  loss_cls: 3.0631 (2.8020)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4424 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 17:59:21 root] (utils.py 302): INFO Epoch: [0]  [ 940/4926]  eta: 0:41:13  lr_architecture: 0.000050  loss_cls: 2.8767 (2.7994)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.3109 (inf)  time: 0.6173  data: 0.0001  max mem: 14434
[2024-01-21 17:59:28 root] (utils.py 302): INFO Epoch: [0]  [ 950/4926]  eta: 0:41:07  lr_architecture: 0.000050  loss_cls: 2.5466 (2.7957)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2997 (inf)  time: 0.6178  data: 0.0001  max mem: 14434
[2024-01-21 17:59:34 root] (utils.py 302): INFO Epoch: [0]  [ 960/4926]  eta: 0:41:00  lr_architecture: 0.000050  loss_cls: 2.6342 (2.7962)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1092 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 17:59:40 root] (utils.py 302): INFO Epoch: [0]  [ 970/4926]  eta: 0:40:54  lr_architecture: 0.000050  loss_cls: 2.8527 (2.7970)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1582 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 17:59:46 root] (utils.py 302): INFO Epoch: [0]  [ 980/4926]  eta: 0:40:48  lr_architecture: 0.000050  loss_cls: 2.8620 (2.7983)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2626 (inf)  time: 0.6169  data: 0.0001  max mem: 14434
[2024-01-21 17:59:52 root] (utils.py 302): INFO Epoch: [0]  [ 990/4926]  eta: 0:40:41  lr_architecture: 0.000050  loss_cls: 2.9977 (2.7977)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4092 (inf)  time: 0.6164  data: 0.0001  max mem: 14434
[2024-01-21 17:59:58 root] (utils.py 302): INFO Epoch: [0]  [1000/4926]  eta: 0:40:35  lr_architecture: 0.000050  loss_cls: 2.9506 (2.7974)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1340 (inf)  time: 0.6173  data: 0.0001  max mem: 14434
[2024-01-21 18:00:05 root] (utils.py 302): INFO Epoch: [0]  [1010/4926]  eta: 0:40:29  lr_architecture: 0.000050  loss_cls: 2.9506 (2.7983)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0145 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 18:00:11 root] (utils.py 302): INFO Epoch: [0]  [1020/4926]  eta: 0:40:22  lr_architecture: 0.000050  loss_cls: 2.8083 (2.7982)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1103 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 18:00:17 root] (utils.py 302): INFO Epoch: [0]  [1030/4926]  eta: 0:40:16  lr_architecture: 0.000050  loss_cls: 2.5512 (2.7957)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2242 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 18:00:23 root] (utils.py 302): INFO Epoch: [0]  [1040/4926]  eta: 0:40:10  lr_architecture: 0.000050  loss_cls: 3.0120 (2.7987)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1670 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 18:00:29 root] (utils.py 302): INFO Epoch: [0]  [1050/4926]  eta: 0:40:03  lr_architecture: 0.000050  loss_cls: 3.0424 (2.7990)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1596 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 18:00:36 root] (utils.py 302): INFO Epoch: [0]  [1060/4926]  eta: 0:39:57  lr_architecture: 0.000050  loss_cls: 2.9408 (2.7997)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0127 (inf)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 18:00:42 root] (utils.py 302): INFO Epoch: [0]  [1070/4926]  eta: 0:39:51  lr_architecture: 0.000050  loss_cls: 2.9408 (2.7993)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9255 (inf)  time: 0.6188  data: 0.0001  max mem: 14434
[2024-01-21 18:00:48 root] (utils.py 302): INFO Epoch: [0]  [1080/4926]  eta: 0:39:45  lr_architecture: 0.000050  loss_cls: 2.8175 (2.7992)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0092 (inf)  time: 0.6189  data: 0.0001  max mem: 14434
[2024-01-21 18:00:54 root] (utils.py 302): INFO Epoch: [0]  [1090/4926]  eta: 0:39:38  lr_architecture: 0.000050  loss_cls: 2.8493 (2.7992)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0889 (inf)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 18:01:00 root] (utils.py 302): INFO Epoch: [0]  [1100/4926]  eta: 0:39:32  lr_architecture: 0.000050  loss_cls: 2.7056 (2.7983)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1153 (inf)  time: 0.6189  data: 0.0001  max mem: 14434
[2024-01-21 18:01:06 root] (utils.py 302): INFO Epoch: [0]  [1110/4926]  eta: 0:39:26  lr_architecture: 0.000050  loss_cls: 2.8166 (2.7996)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2399 (inf)  time: 0.6184  data: 0.0001  max mem: 14434
[2024-01-21 18:01:13 root] (utils.py 302): INFO Epoch: [0]  [1120/4926]  eta: 0:39:20  lr_architecture: 0.000050  loss_cls: 3.0494 (2.8009)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2399 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 18:01:19 root] (utils.py 302): INFO Epoch: [0]  [1130/4926]  eta: 0:39:13  lr_architecture: 0.000050  loss_cls: 3.0572 (2.8024)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0182 (inf)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 18:01:25 root] (utils.py 302): INFO Epoch: [0]  [1140/4926]  eta: 0:39:07  lr_architecture: 0.000050  loss_cls: 2.8511 (2.8007)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8994 (inf)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 18:01:31 root] (utils.py 302): INFO Epoch: [0]  [1150/4926]  eta: 0:39:01  lr_architecture: 0.000050  loss_cls: 2.7764 (2.8010)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8269 (inf)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 18:01:37 root] (utils.py 302): INFO Epoch: [0]  [1160/4926]  eta: 0:38:54  lr_architecture: 0.000050  loss_cls: 2.8263 (2.8000)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8349 (inf)  time: 0.6173  data: 0.0001  max mem: 14434
[2024-01-21 18:01:44 root] (utils.py 302): INFO Epoch: [0]  [1170/4926]  eta: 0:38:48  lr_architecture: 0.000050  loss_cls: 2.8263 (2.8004)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7490 (inf)  time: 0.6157  data: 0.0001  max mem: 14434
[2024-01-21 18:01:50 root] (utils.py 302): INFO Epoch: [0]  [1180/4926]  eta: 0:38:42  lr_architecture: 0.000050  loss_cls: 2.9948 (2.8035)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8116 (inf)  time: 0.6164  data: 0.0001  max mem: 14434
[2024-01-21 18:01:56 root] (utils.py 302): INFO Epoch: [0]  [1190/4926]  eta: 0:38:36  lr_architecture: 0.000050  loss_cls: 3.0012 (2.8048)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8462 (inf)  time: 0.6181  data: 0.0001  max mem: 14434
[2024-01-21 18:02:02 root] (utils.py 302): INFO Epoch: [0]  [1200/4926]  eta: 0:38:29  lr_architecture: 0.000050  loss_cls: 2.9277 (2.8058)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0580 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 18:02:08 root] (utils.py 302): INFO Epoch: [0]  [1210/4926]  eta: 0:38:23  lr_architecture: 0.000050  loss_cls: 2.8495 (2.8049)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2814 (inf)  time: 0.6166  data: 0.0001  max mem: 14434
[2024-01-21 18:02:14 root] (utils.py 302): INFO Epoch: [0]  [1220/4926]  eta: 0:38:17  lr_architecture: 0.000050  loss_cls: 2.8495 (2.8040)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2515 (inf)  time: 0.6168  data: 0.0001  max mem: 14434
[2024-01-21 18:02:21 root] (utils.py 302): INFO Epoch: [0]  [1230/4926]  eta: 0:38:10  lr_architecture: 0.000050  loss_cls: 2.9989 (2.8044)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2051 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 18:02:27 root] (utils.py 302): INFO Epoch: [0]  [1240/4926]  eta: 0:38:04  lr_architecture: 0.000050  loss_cls: 3.0189 (2.8049)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0342 (inf)  time: 0.6165  data: 0.0001  max mem: 14434
[2024-01-21 18:02:33 root] (utils.py 302): INFO Epoch: [0]  [1250/4926]  eta: 0:37:58  lr_architecture: 0.000050  loss_cls: 2.7626 (2.8038)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8747 (inf)  time: 0.6168  data: 0.0001  max mem: 14434
[2024-01-21 18:02:39 root] (utils.py 302): INFO Epoch: [0]  [1260/4926]  eta: 0:37:52  lr_architecture: 0.000050  loss_cls: 2.7612 (2.8045)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7353 (inf)  time: 0.6185  data: 0.0001  max mem: 14434
[2024-01-21 18:02:45 root] (utils.py 302): INFO Epoch: [0]  [1270/4926]  eta: 0:37:45  lr_architecture: 0.000050  loss_cls: 2.8915 (2.8062)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0784 (inf)  time: 0.6188  data: 0.0001  max mem: 14434
[2024-01-21 18:02:51 root] (utils.py 302): INFO Epoch: [0]  [1280/4926]  eta: 0:37:39  lr_architecture: 0.000050  loss_cls: 3.1704 (2.8087)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2665 (inf)  time: 0.6178  data: 0.0001  max mem: 14434
[2024-01-21 18:02:58 root] (utils.py 302): INFO Epoch: [0]  [1290/4926]  eta: 0:37:33  lr_architecture: 0.000050  loss_cls: 2.9670 (2.8090)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.4759 (inf)  time: 0.6173  data: 0.0001  max mem: 14434
[2024-01-21 18:03:04 root] (utils.py 302): INFO Epoch: [0]  [1300/4926]  eta: 0:37:27  lr_architecture: 0.000050  loss_cls: 2.8946 (2.8097)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.3382 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 18:03:10 root] (utils.py 302): INFO Epoch: [0]  [1310/4926]  eta: 0:37:20  lr_architecture: 0.000050  loss_cls: 2.8126 (2.8086)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1645 (inf)  time: 0.6171  data: 0.0001  max mem: 14434
[2024-01-21 18:03:16 root] (utils.py 302): INFO Epoch: [0]  [1320/4926]  eta: 0:37:14  lr_architecture: 0.000050  loss_cls: 2.5248 (2.8065)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0273 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 18:03:22 root] (utils.py 302): INFO Epoch: [0]  [1330/4926]  eta: 0:37:08  lr_architecture: 0.000050  loss_cls: 2.7528 (2.8075)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8058 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 18:03:28 root] (utils.py 302): INFO Epoch: [0]  [1340/4926]  eta: 0:37:02  lr_architecture: 0.000050  loss_cls: 2.9596 (2.8081)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8058 (inf)  time: 0.6165  data: 0.0001  max mem: 14434
[2024-01-21 18:03:35 root] (utils.py 302): INFO Epoch: [0]  [1350/4926]  eta: 0:36:55  lr_architecture: 0.000050  loss_cls: 2.9734 (2.8083)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8322 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 18:03:41 root] (utils.py 302): INFO Epoch: [0]  [1360/4926]  eta: 0:36:49  lr_architecture: 0.000050  loss_cls: 2.8074 (2.8092)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8372 (inf)  time: 0.6171  data: 0.0001  max mem: 14434
[2024-01-21 18:03:47 root] (utils.py 302): INFO Epoch: [0]  [1370/4926]  eta: 0:36:43  lr_architecture: 0.000050  loss_cls: 2.9177 (2.8104)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2666 (inf)  time: 0.6167  data: 0.0001  max mem: 14434
[2024-01-21 18:03:53 root] (utils.py 302): INFO Epoch: [0]  [1380/4926]  eta: 0:36:37  lr_architecture: 0.000050  loss_cls: 3.0035 (2.8109)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0463 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 18:03:59 root] (utils.py 302): INFO Epoch: [0]  [1390/4926]  eta: 0:36:30  lr_architecture: 0.000050  loss_cls: 2.9502 (2.8112)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0112 (inf)  time: 0.6198  data: 0.0001  max mem: 14434
[2024-01-21 18:04:06 root] (utils.py 302): INFO Epoch: [0]  [1400/4926]  eta: 0:36:24  lr_architecture: 0.000050  loss_cls: 2.9990 (2.8116)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0490 (inf)  time: 0.6197  data: 0.0001  max mem: 14434
[2024-01-21 18:04:12 root] (utils.py 302): INFO Epoch: [0]  [1410/4926]  eta: 0:36:18  lr_architecture: 0.000050  loss_cls: 3.0225 (2.8141)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9136 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 18:04:18 root] (utils.py 302): INFO Epoch: [0]  [1420/4926]  eta: 0:36:12  lr_architecture: 0.000050  loss_cls: 2.8621 (2.8136)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9136 (inf)  time: 0.6169  data: 0.0001  max mem: 14434
[2024-01-21 18:04:24 root] (utils.py 302): INFO Epoch: [0]  [1430/4926]  eta: 0:36:05  lr_architecture: 0.000050  loss_cls: 2.8537 (2.8142)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0128 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 18:04:30 root] (utils.py 302): INFO Epoch: [0]  [1440/4926]  eta: 0:35:59  lr_architecture: 0.000050  loss_cls: 2.7932 (2.8133)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0694 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 18:04:36 root] (utils.py 302): INFO Epoch: [0]  [1450/4926]  eta: 0:35:53  lr_architecture: 0.000050  loss_cls: 2.7784 (2.8130)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0275 (inf)  time: 0.6169  data: 0.0001  max mem: 14434
[2024-01-21 18:04:43 root] (utils.py 302): INFO Epoch: [0]  [1460/4926]  eta: 0:35:47  lr_architecture: 0.000050  loss_cls: 3.0316 (2.8149)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7960 (inf)  time: 0.6169  data: 0.0001  max mem: 14434
[2024-01-21 18:04:49 root] (utils.py 302): INFO Epoch: [0]  [1470/4926]  eta: 0:35:40  lr_architecture: 0.000050  loss_cls: 2.8188 (2.8143)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8363 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 18:04:55 root] (utils.py 302): INFO Epoch: [0]  [1480/4926]  eta: 0:35:34  lr_architecture: 0.000050  loss_cls: 2.6210 (2.8115)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8363 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 18:05:01 root] (utils.py 302): INFO Epoch: [0]  [1490/4926]  eta: 0:35:28  lr_architecture: 0.000050  loss_cls: 2.5433 (2.8089)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9056 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 18:05:07 root] (utils.py 302): INFO Epoch: [0]  [1500/4926]  eta: 0:35:22  lr_architecture: 0.000050  loss_cls: 2.5911 (2.8079)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0355 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 18:05:13 root] (utils.py 302): INFO Epoch: [0]  [1510/4926]  eta: 0:35:15  lr_architecture: 0.000050  loss_cls: 2.7640 (2.8084)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0300 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 18:05:20 root] (utils.py 302): INFO Epoch: [0]  [1520/4926]  eta: 0:35:09  lr_architecture: 0.000050  loss_cls: 3.0288 (2.8103)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8817 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 18:05:26 root] (utils.py 302): INFO Epoch: [0]  [1530/4926]  eta: 0:35:03  lr_architecture: 0.000050  loss_cls: 3.0288 (2.8098)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8144 (inf)  time: 0.6180  data: 0.0001  max mem: 14434
[2024-01-21 18:05:32 root] (utils.py 302): INFO Epoch: [0]  [1540/4926]  eta: 0:34:57  lr_architecture: 0.000050  loss_cls: 2.8057 (2.8095)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6871 (inf)  time: 0.6180  data: 0.0001  max mem: 14434
[2024-01-21 18:05:38 root] (utils.py 302): INFO Epoch: [0]  [1550/4926]  eta: 0:34:50  lr_architecture: 0.000050  loss_cls: 2.7224 (2.8080)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7930 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 18:05:44 root] (utils.py 302): INFO Epoch: [0]  [1560/4926]  eta: 0:34:44  lr_architecture: 0.000050  loss_cls: 2.7224 (2.8069)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1756 (inf)  time: 0.6168  data: 0.0001  max mem: 14434
[2024-01-21 18:05:51 root] (utils.py 302): INFO Epoch: [0]  [1570/4926]  eta: 0:34:38  lr_architecture: 0.000050  loss_cls: 2.5522 (2.8054)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0830 (inf)  time: 0.6168  data: 0.0001  max mem: 14434
[2024-01-21 18:05:57 root] (utils.py 302): INFO Epoch: [0]  [1580/4926]  eta: 0:34:32  lr_architecture: 0.000050  loss_cls: 2.7511 (2.8055)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8671 (inf)  time: 0.6169  data: 0.0001  max mem: 14434
[2024-01-21 18:06:03 root] (utils.py 302): INFO Epoch: [0]  [1590/4926]  eta: 0:34:25  lr_architecture: 0.000050  loss_cls: 3.0206 (2.8073)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2101 (inf)  time: 0.6167  data: 0.0001  max mem: 14434
[2024-01-21 18:06:09 root] (utils.py 302): INFO Epoch: [0]  [1600/4926]  eta: 0:34:19  lr_architecture: 0.000050  loss_cls: 2.9607 (2.8083)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.2909 (inf)  time: 0.6169  data: 0.0001  max mem: 14434
[2024-01-21 18:06:15 root] (utils.py 302): INFO Epoch: [0]  [1610/4926]  eta: 0:34:13  lr_architecture: 0.000050  loss_cls: 2.9242 (2.8090)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9003 (inf)  time: 0.6168  data: 0.0001  max mem: 14434
[2024-01-21 18:06:21 root] (utils.py 302): INFO Epoch: [0]  [1620/4926]  eta: 0:34:07  lr_architecture: 0.000050  loss_cls: 2.9242 (2.8090)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0110 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 18:06:28 root] (utils.py 302): INFO Epoch: [0]  [1630/4926]  eta: 0:34:01  lr_architecture: 0.000050  loss_cls: 2.9778 (2.8102)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7389 (inf)  time: 0.6178  data: 0.0001  max mem: 14434
[2024-01-21 18:06:34 root] (utils.py 302): INFO Epoch: [0]  [1640/4926]  eta: 0:33:54  lr_architecture: 0.000050  loss_cls: 3.0122 (2.8105)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7246 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 18:06:40 root] (utils.py 302): INFO Epoch: [0]  [1650/4926]  eta: 0:33:48  lr_architecture: 0.000050  loss_cls: 2.8167 (2.8085)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7044 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 18:06:46 root] (utils.py 302): INFO Epoch: [0]  [1660/4926]  eta: 0:33:42  lr_architecture: 0.000050  loss_cls: 2.4676 (2.8064)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6887 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 18:06:52 root] (utils.py 302): INFO Epoch: [0]  [1670/4926]  eta: 0:33:36  lr_architecture: 0.000050  loss_cls: 2.5760 (2.8067)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8399 (inf)  time: 0.6165  data: 0.0001  max mem: 14434
[2024-01-21 18:06:58 root] (utils.py 302): INFO Epoch: [0]  [1680/4926]  eta: 0:33:29  lr_architecture: 0.000050  loss_cls: 3.0154 (2.8065)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9823 (inf)  time: 0.6167  data: 0.0001  max mem: 14434
[2024-01-21 18:07:05 root] (utils.py 302): INFO Epoch: [0]  [1690/4926]  eta: 0:33:23  lr_architecture: 0.000050  loss_cls: 2.8443 (2.8067)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9823 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 18:07:11 root] (utils.py 302): INFO Epoch: [0]  [1700/4926]  eta: 0:33:17  lr_architecture: 0.000050  loss_cls: 3.0447 (2.8092)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9441 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 18:07:17 root] (utils.py 302): INFO Epoch: [0]  [1710/4926]  eta: 0:33:11  lr_architecture: 0.000050  loss_cls: 2.9899 (2.8092)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9527 (inf)  time: 0.6173  data: 0.0001  max mem: 14434
[2024-01-21 18:07:23 root] (utils.py 302): INFO Epoch: [0]  [1720/4926]  eta: 0:33:05  lr_architecture: 0.000050  loss_cls: 2.7881 (2.8085)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8780 (inf)  time: 0.6230  data: 0.0001  max mem: 14434
[2024-01-21 18:07:29 root] (utils.py 302): INFO Epoch: [0]  [1730/4926]  eta: 0:32:58  lr_architecture: 0.000050  loss_cls: 2.8925 (2.8092)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9376 (inf)  time: 0.6232  data: 0.0001  max mem: 14434
[2024-01-21 18:07:36 root] (utils.py 302): INFO Epoch: [0]  [1740/4926]  eta: 0:32:52  lr_architecture: 0.000050  loss_cls: 2.8572 (2.8092)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0414 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 18:07:42 root] (utils.py 302): INFO Epoch: [0]  [1750/4926]  eta: 0:32:46  lr_architecture: 0.000050  loss_cls: 2.6761 (2.8081)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9026 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 18:07:48 root] (utils.py 302): INFO Epoch: [0]  [1760/4926]  eta: 0:32:40  lr_architecture: 0.000050  loss_cls: 2.5958 (2.8081)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8929 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 18:07:54 root] (utils.py 302): INFO Epoch: [0]  [1770/4926]  eta: 0:32:34  lr_architecture: 0.000050  loss_cls: 2.8860 (2.8091)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9366 (inf)  time: 0.6231  data: 0.0001  max mem: 14434
[2024-01-21 18:08:01 root] (utils.py 302): INFO Epoch: [0]  [1780/4926]  eta: 0:32:28  lr_architecture: 0.000050  loss_cls: 3.0266 (2.8094)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9497 (inf)  time: 0.6294  data: 0.0001  max mem: 14434
[2024-01-21 18:08:07 root] (utils.py 302): INFO Epoch: [0]  [1790/4926]  eta: 0:32:22  lr_architecture: 0.000050  loss_cls: 2.8444 (2.8087)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6417 (inf)  time: 0.6239  data: 0.0001  max mem: 14434
[2024-01-21 18:08:13 root] (utils.py 302): INFO Epoch: [0]  [1800/4926]  eta: 0:32:15  lr_architecture: 0.000050  loss_cls: 2.9951 (2.8099)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6119 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 18:08:19 root] (utils.py 302): INFO Epoch: [0]  [1810/4926]  eta: 0:32:09  lr_architecture: 0.000050  loss_cls: 2.8577 (2.8089)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.5780 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 18:08:25 root] (utils.py 302): INFO Epoch: [0]  [1820/4926]  eta: 0:32:03  lr_architecture: 0.000050  loss_cls: 2.6277 (2.8092)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6436 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 18:08:31 root] (utils.py 302): INFO Epoch: [0]  [1830/4926]  eta: 0:31:57  lr_architecture: 0.000050  loss_cls: 3.0061 (2.8103)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7217 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 18:08:38 root] (utils.py 302): INFO Epoch: [0]  [1840/4926]  eta: 0:31:50  lr_architecture: 0.000050  loss_cls: 2.9333 (2.8100)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7587 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 18:08:44 root] (utils.py 302): INFO Epoch: [0]  [1850/4926]  eta: 0:31:44  lr_architecture: 0.000050  loss_cls: 2.7767 (2.8091)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8273 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 18:08:50 root] (utils.py 302): INFO Epoch: [0]  [1860/4926]  eta: 0:31:38  lr_architecture: 0.000050  loss_cls: 2.7767 (2.8093)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9505 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 18:08:56 root] (utils.py 302): INFO Epoch: [0]  [1870/4926]  eta: 0:31:32  lr_architecture: 0.000050  loss_cls: 2.8695 (2.8086)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9542 (inf)  time: 0.6180  data: 0.0001  max mem: 14434
[2024-01-21 18:09:02 root] (utils.py 302): INFO Epoch: [0]  [1880/4926]  eta: 0:31:26  lr_architecture: 0.000050  loss_cls: 2.9677 (2.8099)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8330 (inf)  time: 0.6172  data: 0.0001  max mem: 14434
[2024-01-21 18:09:08 root] (utils.py 302): INFO Epoch: [0]  [1890/4926]  eta: 0:31:19  lr_architecture: 0.000050  loss_cls: 2.9769 (2.8097)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0078 (inf)  time: 0.6168  data: 0.0001  max mem: 14434
[2024-01-21 18:09:15 root] (utils.py 302): INFO Epoch: [0]  [1900/4926]  eta: 0:31:13  lr_architecture: 0.000050  loss_cls: 2.7527 (2.8094)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8176 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 18:09:21 root] (utils.py 302): INFO Epoch: [0]  [1910/4926]  eta: 0:31:07  lr_architecture: 0.000050  loss_cls: 2.9356 (2.8100)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7115 (inf)  time: 0.6180  data: 0.0001  max mem: 14434
[2024-01-21 18:09:27 root] (utils.py 302): INFO Epoch: [0]  [1920/4926]  eta: 0:31:01  lr_architecture: 0.000050  loss_cls: 2.6465 (2.8076)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6049 (inf)  time: 0.6181  data: 0.0001  max mem: 14434
[2024-01-21 18:09:33 root] (utils.py 302): INFO Epoch: [0]  [1930/4926]  eta: 0:30:54  lr_architecture: 0.000050  loss_cls: 2.5200 (2.8072)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6834 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 18:09:39 root] (utils.py 302): INFO Epoch: [0]  [1940/4926]  eta: 0:30:48  lr_architecture: 0.000050  loss_cls: 2.7904 (2.8067)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7753 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 18:09:45 root] (utils.py 302): INFO Epoch: [0]  [1950/4926]  eta: 0:30:42  lr_architecture: 0.000050  loss_cls: 2.8173 (2.8057)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6946 (inf)  time: 0.6177  data: 0.0001  max mem: 14434
[2024-01-21 18:09:52 root] (utils.py 302): INFO Epoch: [0]  [1960/4926]  eta: 0:30:36  lr_architecture: 0.000050  loss_cls: 2.8305 (2.8057)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8224 (inf)  time: 0.6181  data: 0.0001  max mem: 14434
[2024-01-21 18:09:58 root] (utils.py 302): INFO Epoch: [0]  [1970/4926]  eta: 0:30:30  lr_architecture: 0.000050  loss_cls: 2.8015 (2.8047)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9604 (inf)  time: 0.6191  data: 0.0001  max mem: 14434
[2024-01-21 18:10:04 root] (utils.py 302): INFO Epoch: [0]  [1980/4926]  eta: 0:30:23  lr_architecture: 0.000050  loss_cls: 2.7445 (2.8039)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.0287 (inf)  time: 0.6188  data: 0.0001  max mem: 14434
[2024-01-21 18:10:10 root] (utils.py 302): INFO Epoch: [0]  [1990/4926]  eta: 0:30:17  lr_architecture: 0.000050  loss_cls: 2.7445 (2.8033)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9067 (inf)  time: 0.6180  data: 0.0001  max mem: 14434
[2024-01-21 18:10:16 root] (utils.py 302): INFO Epoch: [0]  [2000/4926]  eta: 0:30:11  lr_architecture: 0.000050  loss_cls: 2.7086 (2.8028)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6025 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 18:10:23 root] (utils.py 302): INFO Epoch: [0]  [2010/4926]  eta: 0:30:05  lr_architecture: 0.000050  loss_cls: 2.9155 (2.8041)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8850 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 18:10:29 root] (utils.py 302): INFO Epoch: [0]  [2020/4926]  eta: 0:29:59  lr_architecture: 0.000050  loss_cls: 2.9155 (2.8038)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7547 (inf)  time: 0.6167  data: 0.0001  max mem: 14434
[2024-01-21 18:10:35 root] (utils.py 302): INFO Epoch: [0]  [2030/4926]  eta: 0:29:52  lr_architecture: 0.000050  loss_cls: 2.9563 (2.8047)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6635 (inf)  time: 0.6164  data: 0.0001  max mem: 14434
[2024-01-21 18:10:41 root] (utils.py 302): INFO Epoch: [0]  [2040/4926]  eta: 0:29:46  lr_architecture: 0.000050  loss_cls: 3.0384 (2.8052)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7570 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 18:10:47 root] (utils.py 302): INFO Epoch: [0]  [2050/4926]  eta: 0:29:40  lr_architecture: 0.000050  loss_cls: 2.8580 (2.8051)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7615 (inf)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 18:10:53 root] (utils.py 302): INFO Epoch: [0]  [2060/4926]  eta: 0:29:34  lr_architecture: 0.000050  loss_cls: 2.7213 (2.8049)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1213 (inf)  time: 0.6183  data: 0.0001  max mem: 14434
[2024-01-21 18:11:00 root] (utils.py 302): INFO Epoch: [0]  [2070/4926]  eta: 0:29:27  lr_architecture: 0.000050  loss_cls: 2.9978 (2.8054)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 5.1233 (inf)  time: 0.6182  data: 0.0001  max mem: 14434
[2024-01-21 18:11:06 root] (utils.py 302): INFO Epoch: [0]  [2080/4926]  eta: 0:29:21  lr_architecture: 0.000050  loss_cls: 2.8579 (2.8047)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9250 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 18:11:12 root] (utils.py 302): INFO Epoch: [0]  [2090/4926]  eta: 0:29:15  lr_architecture: 0.000050  loss_cls: 2.8698 (2.8056)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9216 (inf)  time: 0.6174  data: 0.0001  max mem: 14434
[2024-01-21 18:11:18 root] (utils.py 302): INFO Epoch: [0]  [2100/4926]  eta: 0:29:09  lr_architecture: 0.000050  loss_cls: 2.9242 (2.8052)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9333 (inf)  time: 0.6178  data: 0.0001  max mem: 14434
[2024-01-21 18:11:24 root] (utils.py 302): INFO Epoch: [0]  [2110/4926]  eta: 0:29:03  lr_architecture: 0.000050  loss_cls: 2.8135 (2.8057)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8400 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 18:11:31 root] (utils.py 302): INFO Epoch: [0]  [2120/4926]  eta: 0:28:56  lr_architecture: 0.000050  loss_cls: 2.8094 (2.8051)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.3897 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 18:11:37 root] (utils.py 302): INFO Epoch: [0]  [2130/4926]  eta: 0:28:50  lr_architecture: 0.000050  loss_cls: 2.9562 (2.8057)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6892 (inf)  time: 0.6170  data: 0.0001  max mem: 14434
[2024-01-21 18:11:43 root] (utils.py 302): INFO Epoch: [0]  [2140/4926]  eta: 0:28:44  lr_architecture: 0.000050  loss_cls: 3.0087 (2.8066)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7667 (inf)  time: 0.6168  data: 0.0001  max mem: 14434
[2024-01-21 18:11:49 root] (utils.py 302): INFO Epoch: [0]  [2150/4926]  eta: 0:28:38  lr_architecture: 0.000050  loss_cls: 3.0087 (2.8066)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9896 (inf)  time: 0.6173  data: 0.0001  max mem: 14434
[2024-01-21 18:11:55 root] (utils.py 302): INFO Epoch: [0]  [2160/4926]  eta: 0:28:32  lr_architecture: 0.000050  loss_cls: 3.0227 (2.8067)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8249 (inf)  time: 0.6183  data: 0.0001  max mem: 14434
[2024-01-21 18:12:01 root] (utils.py 302): INFO Epoch: [0]  [2170/4926]  eta: 0:28:25  lr_architecture: 0.000050  loss_cls: 3.0520 (2.8076)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8249 (inf)  time: 0.6181  data: 0.0001  max mem: 14434
[2024-01-21 18:12:08 root] (utils.py 302): INFO Epoch: [0]  [2180/4926]  eta: 0:28:19  lr_architecture: 0.000050  loss_cls: 2.8550 (2.8070)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9852 (inf)  time: 0.6175  data: 0.0001  max mem: 14434
[2024-01-21 18:12:14 root] (utils.py 302): INFO Epoch: [0]  [2190/4926]  eta: 0:28:13  lr_architecture: 0.000050  loss_cls: 2.8751 (2.8082)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9460 (inf)  time: 0.6179  data: 0.0001  max mem: 14434
[2024-01-21 18:12:20 root] (utils.py 302): INFO Epoch: [0]  [2200/4926]  eta: 0:28:07  lr_architecture: 0.000050  loss_cls: 2.7430 (2.8066)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8984 (inf)  time: 0.6193  data: 0.0001  max mem: 14434
[2024-01-21 18:12:26 root] (utils.py 302): INFO Epoch: [0]  [2210/4926]  eta: 0:28:01  lr_architecture: 0.000050  loss_cls: 2.4954 (2.8068)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8984 (inf)  time: 0.6184  data: 0.0001  max mem: 14434
[2024-01-21 18:12:32 root] (utils.py 302): INFO Epoch: [0]  [2220/4926]  eta: 0:27:54  lr_architecture: 0.000050  loss_cls: 2.8108 (2.8059)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6894 (inf)  time: 0.6173  data: 0.0001  max mem: 14434
[2024-01-21 18:12:38 root] (utils.py 302): INFO Epoch: [0]  [2230/4926]  eta: 0:27:48  lr_architecture: 0.000050  loss_cls: 2.7828 (2.8057)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.6500 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 18:12:45 root] (utils.py 302): INFO Epoch: [0]  [2240/4926]  eta: 0:27:42  lr_architecture: 0.000050  loss_cls: 2.7947 (2.8051)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7908 (inf)  time: 0.6176  data: 0.0001  max mem: 14434
[2024-01-21 18:12:51 root] (utils.py 302): INFO Epoch: [0]  [2250/4926]  eta: 0:27:36  lr_architecture: 0.000050  loss_cls: 2.7947 (2.8048)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9979 (inf)  time: 0.6185  data: 0.0001  max mem: 14434
[2024-01-21 18:12:57 root] (utils.py 302): INFO Epoch: [0]  [2260/4926]  eta: 0:27:30  lr_architecture: 0.000050  loss_cls: 2.8055 (2.8053)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.9130 (inf)  time: 0.6189  data: 0.0001  max mem: 14434
[2024-01-21 18:13:03 root] (utils.py 302): INFO Epoch: [0]  [2270/4926]  eta: 0:27:23  lr_architecture: 0.000050  loss_cls: 2.8178 (2.8054)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7291 (inf)  time: 0.6184  data: 0.0001  max mem: 14434
[2024-01-21 18:13:09 root] (utils.py 302): INFO Epoch: [0]  [2280/4926]  eta: 0:27:17  lr_architecture: 0.000050  loss_cls: 2.8853 (2.8060)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.7291 (inf)  time: 0.6186  data: 0.0001  max mem: 14434
[2024-01-21 18:13:16 root] (utils.py 302): INFO Epoch: [0]  [2290/4926]  eta: 0:27:11  lr_architecture: 0.000050  loss_cls: 2.9504 (2.8060)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8465 (inf)  time: 0.6188  data: 0.0001  max mem: 14434
[2024-01-21 18:13:22 root] (utils.py 302): INFO Epoch: [0]  [2300/4926]  eta: 0:27:05  lr_architecture: 0.000050  loss_cls: 2.7987 (2.8052)  loss_flops: 811.2119 (811.2119)  flops: 31.4818 (31.4818)  grad_norm: 4.8706 (inf)  time: 0.6187  data: 0.0001  max mem: 14434
